# Orchestrator Configuration File
# ================================
# Custom configuration for the preemptible experiment orchestrator
#
# Usage:
#   python telepathy/run_preemptible_experiments.py --config telepathy/configs/orchestrator_config.yaml

# Experiment selection
experiment: all  # Options: all, sst2, agnews, trec, scaling, ablation

# Output configuration
output_dir: runs/orchestrated

# Test mode (use small datasets for quick validation)
test: false

# Resume from previous run
resume: false

# Checkpoint settings
checkpoint_interval: 300  # seconds (5 minutes)
max_checkpoints: 3

# GPU configuration
gpu_memory_threshold: 70.0  # GB, warn if exceeded
enable_mixed_precision: true
mixed_precision_dtype: bf16  # bf16 or fp16

# Batch size optimization
auto_optimize_batch_size: true
target_batch_size: 64
gradient_accumulation_steps: 2
min_batch_size: 4
max_batch_size: 128

# Model configurations
models:
  llama_small: meta-llama/Llama-3.2-1B-Instruct
  llama_medium: meta-llama/Llama-3.2-3B-Instruct
  llama_large: meta-llama/Meta-Llama-3.1-8B-Instruct
  qwen_small: Qwen/Qwen2.5-1.5B-Instruct
  qwen_medium: Qwen/Qwen2.5-3B-Instruct
  qwen_large: Qwen/Qwen2.5-7B-Instruct

# Default telepathy architecture
telepathy:
  latent_len: 32
  d_z: 256
  encoder_type: byte
  use_adapter: true
  adapter_layers: 2
  adapter_hidden_dim: 512

# Training defaults
training:
  epochs: 10
  learning_rate: 1.0e-4
  warmup_ratio: 0.1
  weight_decay: 0.01
  max_grad_norm: 1.0
  seed: 42

# Evaluation defaults
evaluation:
  eval_batch_size: 64
  metrics:
    - accuracy
    - f1
    - first_token_accuracy
    - latency_ms
    - memory_mb

# Dataset configurations
datasets:
  sst2:
    train_samples: 67349
    eval_samples: 872
    max_length: 128
    num_classes: 2

  agnews:
    train_samples: 120000
    eval_samples: 7600
    max_length: 256
    num_classes: 4

  trec:
    train_samples: 5452
    eval_samples: 500
    max_length: 128
    num_classes: 6

  xsum:
    train_samples: 204045
    eval_samples: 11332
    max_length: 512
    max_target_length: 128

# Experiment priorities (lower is higher priority)
priorities:
  baseline: 1
  telepathy: 0
  ablation: 2
  scaling: 3
  transfer: 4

# Failure handling
failure_handling:
  max_retries: 3
  retry_delay: 60  # seconds
  oom_batch_reduction: 0.5
  gradient_explosion_threshold: 10.0

# Monitoring and logging
monitoring:
  log_interval: 100  # steps
  eval_interval: 1000  # steps
  save_interval: 1000  # steps
  gpu_monitor_interval: 30  # seconds
  detailed_gpu_logging: true

# Distributed training
distributed:
  backend: nccl
  init_method: env://
  find_unused_parameters: false

# Preemption handling
preemption:
  grace_period: 120  # seconds
  checkpoint_on_preemption: true
  push_to_git_on_preemption: true

# Git integration
git:
  auto_commit: true
  commit_message_prefix: "exp:"
  push_results: true
  branch: main

# Custom experiment definitions
custom_experiments:
  - name: custom_high_compression
    phase: telepathy
    dataset: sst2
    model_config:
      source_model: ${models.llama_large}
      target_model: ${models.qwen_large}
      latent_len: 16  # High compression
      d_z: 128
    training_config:
      epochs: 15
      learning_rate: 5.0e-5
      batch_size: 16
    priority: 1

  - name: custom_large_latent
    phase: telepathy
    dataset: agnews
    model_config:
      source_model: ${models.llama_large}
      target_model: ${models.qwen_large}
      latent_len: 128  # Large latent space
      d_z: 512
    training_config:
      epochs: 5
      learning_rate: 2.0e-4
      batch_size: 8
    priority: 2