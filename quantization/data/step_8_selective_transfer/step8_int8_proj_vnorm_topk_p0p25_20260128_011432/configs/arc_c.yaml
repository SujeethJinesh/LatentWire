model:
  model_name: Rosetta
  rosetta_config:
    base_model: Qwen/Qwen3-0.6B
    teacher_model: Qwen/Qwen2.5-0.5B-Instruct
    is_do_alignment: false
    alignment_strategy: longest
    checkpoints_dir: /workspace/c2c_checkpoints/C2C_Fuser/qwen3_0.6b+qwen2.5_0.5b_Fuser/final
    kv_quant_config:
      enabled: true
      scheme: int8
      axis: head
      eps: 1.0e-06
      collect_stats: false
    kv_transfer_config:
      enabled: true
      token_select_mode: proj_vnorm_topk
      token_select_proportion: 0.25
      token_select_scope: prompt
      token_select_min_tokens: 64
      sparse_fuse: true
      scatter_fill: receiver_only
      index_dtype_bytes: 2
      include_scale_overhead: false
  generation_config:
    do_sample: false
    max_new_tokens: 64
output:
  output_dir: /workspace/LatentWire/quantization/data/step_8_selective_transfer/step8_int8_proj_vnorm_topk_p0p25_20260128_011432/results/arc_c
eval:
  dataset: ai2-arc
  gpu_ids:
  - 0
  answer_method: generate
  use_cot: false
  use_template: true
  sample_interval: 1
  math_grading_method: comprehensive
  kv_cache_proportion: 1.0
  kv_cache_order_mode: front
