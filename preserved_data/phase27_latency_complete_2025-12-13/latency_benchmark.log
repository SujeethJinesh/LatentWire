[Sat Dec 13 17:59:37 PST 2025] Starting latency benchmark...

Found existing SST-2 checkpoint: ./bridge_sst2.pt

==============================================
PHASE 2: Running Latency Benchmark
==============================================

/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Using device: cuda:0
Loading Mistral...
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 4118.79it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:03,  1.65s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:01,  1.24s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.24s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.28s/it]
Loading Llama...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 4055.41it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.07s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.29s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.17s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.23it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.05it/s]

Loading SST-2 dataset...

============================================================
DIRECT TEXT LATENCY MEASUREMENT
============================================================
Warming up (5 iterations)...
Running 50 timed trials...
Direct Text:   0%|          | 0/50 [00:00<?, ?it/s]Direct Text:   4%|▍         | 2/50 [00:00<00:03, 12.04it/s]Direct Text:   8%|▊         | 4/50 [00:00<00:06,  7.59it/s]Direct Text:  10%|█         | 5/50 [00:00<00:07,  5.83it/s]Direct Text:  12%|█▏        | 6/50 [00:00<00:08,  5.26it/s]Direct Text:  14%|█▍        | 7/50 [00:01<00:07,  5.62it/s]Direct Text:  18%|█▊        | 9/50 [00:01<00:05,  7.38it/s]Direct Text:  22%|██▏       | 11/50 [00:01<00:04,  8.82it/s]Direct Text:  26%|██▌       | 13/50 [00:01<00:03,  9.91it/s]Direct Text:  30%|███       | 15/50 [00:01<00:03, 10.71it/s]Direct Text:  34%|███▍      | 17/50 [00:01<00:02, 11.27it/s]Direct Text:  38%|███▊      | 19/50 [00:02<00:02, 11.68it/s]Direct Text:  42%|████▏     | 21/50 [00:02<00:02, 11.88it/s]Direct Text:  46%|████▌     | 23/50 [00:02<00:02, 12.11it/s]Direct Text:  50%|█████     | 25/50 [00:02<00:02, 12.28it/s]Direct Text:  54%|█████▍    | 27/50 [00:02<00:01, 12.38it/s]Direct Text:  58%|█████▊    | 29/50 [00:02<00:01, 12.46it/s]Direct Text:  62%|██████▏   | 31/50 [00:03<00:01, 12.50it/s]Direct Text:  66%|██████▌   | 33/50 [00:03<00:01, 12.40it/s]Direct Text:  70%|███████   | 35/50 [00:03<00:01,  9.49it/s]Direct Text:  74%|███████▍  | 37/50 [00:03<00:01,  8.43it/s]Direct Text:  76%|███████▌  | 38/50 [00:04<00:01,  8.05it/s]Direct Text:  80%|████████  | 40/50 [00:04<00:01,  8.96it/s]Direct Text:  84%|████████▍ | 42/50 [00:04<00:00,  9.91it/s]Direct Text:  88%|████████▊ | 44/50 [00:04<00:00, 10.65it/s]Direct Text:  92%|█████████▏| 46/50 [00:04<00:00, 11.21it/s]Direct Text:  96%|█████████▌| 48/50 [00:04<00:00, 11.62it/s]Direct Text: 100%|██████████| 50/50 [00:04<00:00, 11.90it/s]Direct Text: 100%|██████████| 50/50 [00:04<00:00, 10.07it/s]
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(

Direct Text: 98.8ms avg

============================================================
TEXT-RELAY LATENCY MEASUREMENT
============================================================
Warming up (5 iterations)...
Running 50 timed trials...
Text-Relay:   0%|          | 0/50 [00:00<?, ?it/s]Text-Relay:   2%|▏         | 1/50 [00:01<00:51,  1.04s/it]Text-Relay:   4%|▍         | 2/50 [00:01<00:40,  1.18it/s]Text-Relay:   6%|▌         | 3/50 [00:02<00:37,  1.27it/s]Text-Relay:   8%|▊         | 4/50 [00:03<00:41,  1.10it/s]Text-Relay:  10%|█         | 5/50 [00:04<00:37,  1.19it/s]Text-Relay:  12%|█▏        | 6/50 [00:05<00:36,  1.22it/s]Text-Relay:  14%|█▍        | 7/50 [00:06<00:37,  1.16it/s]Text-Relay:  16%|█▌        | 8/50 [00:06<00:36,  1.16it/s]Text-Relay:  18%|█▊        | 9/50 [00:07<00:33,  1.22it/s]Text-Relay:  20%|██        | 10/50 [00:08<00:31,  1.27it/s]Text-Relay:  22%|██▏       | 11/50 [00:09<00:34,  1.13it/s]Text-Relay:  24%|██▍       | 12/50 [00:10<00:31,  1.20it/s]Text-Relay:  26%|██▌       | 13/50 [00:10<00:29,  1.25it/s]Text-Relay:  28%|██▊       | 14/50 [00:11<00:31,  1.13it/s]Text-Relay:  30%|███       | 15/50 [00:12<00:29,  1.19it/s]Text-Relay:  32%|███▏      | 16/50 [00:13<00:27,  1.25it/s]Text-Relay:  34%|███▍      | 17/50 [00:14<00:25,  1.28it/s]Text-Relay:  36%|███▌      | 18/50 [00:15<00:27,  1.15it/s]Text-Relay:  38%|███▊      | 19/50 [00:15<00:25,  1.21it/s]Text-Relay:  40%|████      | 20/50 [00:16<00:23,  1.26it/s]Text-Relay:  42%|████▏     | 21/50 [00:17<00:25,  1.13it/s]Text-Relay:  44%|████▍     | 22/50 [00:18<00:23,  1.20it/s]Text-Relay:  46%|████▌     | 23/50 [00:19<00:21,  1.25it/s]Text-Relay:  48%|████▊     | 24/50 [00:20<00:21,  1.19it/s]Text-Relay:  50%|█████     | 25/50 [00:20<00:21,  1.18it/s]Text-Relay:  52%|█████▏    | 26/50 [00:21<00:20,  1.15it/s]Text-Relay:  54%|█████▍    | 27/50 [00:22<00:20,  1.15it/s]Text-Relay:  56%|█████▌    | 28/50 [00:23<00:19,  1.12it/s]Text-Relay:  58%|█████▊    | 29/50 [00:24<00:17,  1.19it/s]Text-Relay:  60%|██████    | 30/50 [00:25<00:16,  1.25it/s]Text-Relay:  62%|██████▏   | 31/50 [00:26<00:16,  1.12it/s]Text-Relay:  64%|██████▍   | 32/50 [00:26<00:15,  1.19it/s]Text-Relay:  66%|██████▌   | 33/50 [00:27<00:13,  1.25it/s]Text-Relay:  68%|██████▊   | 34/50 [00:28<00:14,  1.13it/s]Text-Relay:  70%|███████   | 35/50 [00:29<00:12,  1.19it/s]Text-Relay:  72%|███████▏  | 36/50 [00:30<00:11,  1.24it/s]Text-Relay:  74%|███████▍  | 37/50 [00:31<00:10,  1.24it/s]Text-Relay:  76%|███████▌  | 38/50 [00:32<00:10,  1.16it/s]Text-Relay:  78%|███████▊  | 39/50 [00:32<00:09,  1.22it/s]Text-Relay:  80%|████████  | 40/50 [00:33<00:07,  1.27it/s]Text-Relay:  82%|████████▏ | 41/50 [00:34<00:07,  1.13it/s]Text-Relay:  84%|████████▍ | 42/50 [00:35<00:06,  1.17it/s]Text-Relay:  86%|████████▌ | 43/50 [00:36<00:05,  1.23it/s]Text-Relay:  88%|████████▊ | 44/50 [00:37<00:05,  1.11it/s]Text-Relay:  90%|█████████ | 45/50 [00:37<00:04,  1.18it/s]Text-Relay:  92%|█████████▏| 46/50 [00:38<00:03,  1.23it/s]Text-Relay:  94%|█████████▍| 47/50 [00:39<00:02,  1.25it/s]Text-Relay:  96%|█████████▌| 48/50 [00:40<00:01,  1.14it/s]Text-Relay:  98%|█████████▊| 49/50 [00:41<00:00,  1.21it/s]Text-Relay: 100%|██████████| 50/50 [00:41<00:00,  1.26it/s]Text-Relay: 100%|██████████| 50/50 [00:41<00:00,  1.19it/s]
Text-Relay: 834.5ms avg (51 summary tokens)
[PerceiverResampler] 8 latents, 2 layers, 8 heads
[LatentBridgeV15] Telepathy Bridge - CONTINUOUS (no quantization)
  - src_dim: 4096
  - tgt_dim: 4096
  - num_latents: 8
  - mode: CONTINUOUS (Perceiver output directly)
  - target_rms: 0.0300

============================================================
BRIDGE LATENCY MEASUREMENT
============================================================
Warming up (5 iterations)...
Running 50 timed trials...
Bridge:   0%|          | 0/50 [00:00<?, ?it/s]Bridge:   8%|▊         | 4/50 [00:00<00:01, 33.73it/s]Bridge:  16%|█▌        | 8/50 [00:00<00:01, 31.74it/s]Bridge:  24%|██▍       | 12/50 [00:00<00:01, 32.40it/s]Bridge:  32%|███▏      | 16/50 [00:00<00:01, 32.89it/s]Bridge:  40%|████      | 20/50 [00:00<00:00, 33.15it/s]Bridge:  48%|████▊     | 24/50 [00:00<00:00, 33.32it/s]Bridge:  56%|█████▌    | 28/50 [00:00<00:00, 30.94it/s]Bridge:  64%|██████▍   | 32/50 [00:01<00:00, 23.75it/s]Bridge:  70%|███████   | 35/50 [00:01<00:00, 19.67it/s]Bridge:  76%|███████▌  | 38/50 [00:01<00:00, 19.44it/s]Bridge:  84%|████████▍ | 42/50 [00:01<00:00, 22.24it/s]Bridge:  92%|█████████▏| 46/50 [00:01<00:00, 25.02it/s]Bridge: 100%|██████████| 50/50 [00:01<00:00, 27.26it/s]Bridge: 100%|██████████| 50/50 [00:01<00:00, 26.57it/s]
Bridge: 37.3ms avg (8 soft tokens)

============================================================
QUALITATIVE EXAMPLES: Text-Relay Summaries
============================================================

[1] Label: positive
    Original (12 tokens): "it 's a charming and often affecting journey . ..."
    Summary (51 tokens): " 
The film is a charming and often affecting journey. 

Note: The sentence is a ..."

[2] Label: negative
    Original (9 tokens): "unflinchingly bleak and desperate ..."
    Summary (51 tokens): " 

The novel is a bleak and desperate portrayal of a world in chaos, where the c..."

[3] Label: positive
    Original (23 tokens): "allows us to hope that nolan is poised to embark a major career as a commercial ..."
    Summary (51 tokens): " 
The article discusses the film "Insomnia" and how it showcases director Christ..."

[4] Label: positive
    Original (25 tokens): "the acting , costumes , music , cinematography and sound are all astounding give..."
    Summary (50 tokens): " 
The film's technical aspects are impressive considering the limited resources ..."

[5] Label: negative
    Original (12 tokens): "it 's slow -- very , very slow . ..."
    Summary (51 tokens): " The speaker is describing something as moving very slowly. 

## Step 1: Identif..."

============================================================
LATENCY BENCHMARK SUMMARY
============================================================
Direct Text (Mistral): 98.8ms
Text-Relay (Llama→text→Mistral): 834.5ms
Bridge (Llama→soft tokens→Mistral): 37.3ms

Bridge is 22.4x faster than Text-Relay

Results saved to: runs/latency_benchmark_20251213_175937/latency_benchmark.json

==============================================
COMPLETE
==============================================

Results saved to: runs/latency_benchmark_20251213_175937/latency_benchmark.json

SUMMARY:
Direct Text: 98.8ms
Text-Relay: 834.5ms
Bridge: 37.3ms

Bridge is 22.4x faster than Text-Relay

[Sat Dec 13 18:00:59 PST 2025] Done!
