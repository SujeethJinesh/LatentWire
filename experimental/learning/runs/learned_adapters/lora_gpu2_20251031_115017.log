================================================================================
LEARNED ADAPTER EXPERIMENT - LORA
================================================================================
Platform: hpc
Log file: /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/learned_adapters/lora_gpu2_20251031_115017.log
GPU assigned: 2

Loading models on hpc...
Using bfloat16 for H100
Using Flash Attention 2
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|##########| 4/4 [00:00<00:00, 3656.76it/s]Downloading shards: 100%|##########| 4/4 [00:00<00:00, 3656.76it/s]

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  50%|#####     | 2/4 [00:00<00:00, 14.93it/s]Loading checkpoint shards:  50%|#####     | 2/4 [00:00<00:00, 14.93it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:00<00:00, 15.62it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:00<00:00, 15.62it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:00<00:00, 15.49it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:00<00:00, 15.49it/s]

Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|##########| 3/3 [00:00<00:00, 3630.38it/s]Downloading shards: 100%|##########| 3/3 [00:00<00:00, 3630.38it/s]

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  67%|######6   | 2/3 [00:00<00:00, 12.49it/s]Loading checkpoint shards:  67%|######6   | 2/3 [00:00<00:00, 12.49it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:00<00:00, 13.37it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:00<00:00, 13.37it/s]


Training LoRAAdapter...
Loading dataset (10000 samples)...

Epoch 1/10
  Step 10/1250: Loss = 11.7239
  Step 20/1250: Loss = 11.6829
  Step 30/1250: Loss = 11.6142
  Step 40/1250: Loss = 11.6038
  Step 50/1250: Loss = 11.5754
  Step 60/1250: Loss = 11.5337
  Step 70/1250: Loss = 11.4913
  Step 80/1250: Loss = 11.4643
  Step 90/1250: Loss = 11.4070
  Step 100/1250: Loss = 11.3650
  Step 110/1250: Loss = 11.3252
  Step 120/1250: Loss = 11.2687
  Step 130/1250: Loss = 11.2162
  Step 140/1250: Loss = 11.1703
  Step 150/1250: Loss = 11.1353
  Step 160/1250: Loss = 11.0998
  Step 170/1250: Loss = 11.0619
  Step 180/1250: Loss = 11.0218
  Step 190/1250: Loss = 10.9840
  Step 200/1250: Loss = 10.9446
  Step 210/1250: Loss = 10.9077
  Step 220/1250: Loss = 10.8699
  Step 230/1250: Loss = 10.8320
  Step 240/1250: Loss = 10.8017
  Step 250/1250: Loss = 10.7687
  Step 260/1250: Loss = 10.7311
  Step 270/1250: Loss = 10.6991
  Step 280/1250: Loss = 10.6704
  Step 290/1250: Loss = 10.6433
  Step 300/1250: Loss = 10.6170
  Step 310/1250: Loss = 10.5939
  Step 320/1250: Loss = 10.5698
  Step 330/1250: Loss = 10.5445
  Step 340/1250: Loss = 10.5177
  Step 350/1250: Loss = 10.4954
  Step 360/1250: Loss = 10.4743
  Step 370/1250: Loss = 10.4520
  Step 380/1250: Loss = 10.4336
  Step 390/1250: Loss = 10.4078
  Step 400/1250: Loss = 10.3859
  Step 410/1250: Loss = 10.3638
  Step 420/1250: Loss = 10.3391
  Step 430/1250: Loss = 10.3206
  Step 440/1250: Loss = 10.3003
  Step 450/1250: Loss = 10.2810
  Step 460/1250: Loss = 10.2628
  Step 470/1250: Loss = 10.2446
  Step 480/1250: Loss = 10.2257
  Step 490/1250: Loss = 10.2047
  Step 500/1250: Loss = 10.1845
  Step 510/1250: Loss = 10.1663
  Step 520/1250: Loss = 10.1499
  Step 530/1250: Loss = 10.1323
  Step 540/1250: Loss = 10.1153
  Step 550/1250: Loss = 10.0974
  Step 560/1250: Loss = 10.0788
  Step 570/1250: Loss = 10.0636
  Step 580/1250: Loss = 10.0458
  Step 590/1250: Loss = 10.0265
  Step 600/1250: Loss = 10.0100
  Step 610/1250: Loss = 9.9948
  Step 620/1250: Loss = 9.9769
  Step 630/1250: Loss = 9.9607
  Step 640/1250: Loss = 9.9468
  Step 650/1250: Loss = 9.9309
  Step 660/1250: Loss = 9.9154
  Step 670/1250: Loss = 9.9012
  Step 680/1250: Loss = 9.8840
  Step 690/1250: Loss = 9.8686
  Step 700/1250: Loss = 9.8534
  Step 710/1250: Loss = 9.8394
  Step 720/1250: Loss = 9.8241
  Step 730/1250: Loss = 9.8092
  Step 740/1250: Loss = 9.7952
  Step 750/1250: Loss = 9.7807
  Step 760/1250: Loss = 9.7656
  Step 770/1250: Loss = 9.7518
  Step 780/1250: Loss = 9.7379
  Step 790/1250: Loss = 9.7251
  Step 800/1250: Loss = 9.7120
  Step 810/1250: Loss = 9.6995
  Step 820/1250: Loss = 9.6874
  Step 830/1250: Loss = 9.6744
  Step 840/1250: Loss = 9.6615
  Step 850/1250: Loss = 9.6481
  Step 860/1250: Loss = 9.6356
  Step 870/1250: Loss = 9.6236
  Step 880/1250: Loss = 9.6122
  Step 890/1250: Loss = 9.5997
  Step 900/1250: Loss = 9.5871
  Step 910/1250: Loss = 9.5754
  Step 920/1250: Loss = 9.5626
  Step 930/1250: Loss = 9.5503
  Step 940/1250: Loss = 9.5374
  Step 950/1250: Loss = 9.5265
  Step 960/1250: Loss = 9.5157
  Step 970/1250: Loss = 9.5046
  Step 980/1250: Loss = 9.4940
  Step 990/1250: Loss = 9.4835
  Step 1000/1250: Loss = 9.4723
  Step 1010/1250: Loss = 9.4614
  Step 1020/1250: Loss = 9.4507
  Step 1030/1250: Loss = 9.4396
  Step 1040/1250: Loss = 9.4301
  Step 1050/1250: Loss = 9.4197
  Step 1060/1250: Loss = 9.4102
  Step 1070/1250: Loss = 9.3994
  Step 1080/1250: Loss = 9.3891
  Step 1090/1250: Loss = 9.3799
  Step 1100/1250: Loss = 9.3705
  Step 1110/1250: Loss = 9.3607
  Step 1120/1250: Loss = 9.3513
  Step 1130/1250: Loss = 9.3416
  Step 1140/1250: Loss = 9.3321
  Step 1150/1250: Loss = 9.3225
  Step 1160/1250: Loss = 9.3131
  Step 1170/1250: Loss = 9.3041
  Step 1180/1250: Loss = 9.2952
  Step 1190/1250: Loss = 9.2862
  Step 1200/1250: Loss = 9.2777
  Step 1210/1250: Loss = 9.2684
  Step 1220/1250: Loss = 9.2603
  Step 1230/1250: Loss = 9.2519
  Step 1240/1250: Loss = 9.2439
  Step 1250/1250: Loss = 9.2355

================================================================================
LORA ADAPTER EXPERIMENT FAILED
================================================================================
Error: list index out of range
Traceback (most recent call last):
Traceback (most recent call last):
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 1076, in run_adapter_experiment
    adapter, metrics = train_adapter(
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 1076, in run_adapter_experiment
    adapter, metrics = train_adapter(
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 944, in train_adapter
    source_repr = outputs_a.hidden_states[ALIGNMENT_LAYERS[1]][:, 0, :]
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 944, in train_adapter
    source_repr = outputs_a.hidden_states[ALIGNMENT_LAYERS[1]][:, 0, :]
IndexError: list index out of range
IndexError: list index out of range
