================================================================================
LEARNED ADAPTER EXPERIMENT - LINEAR
================================================================================
Platform: hpc
Log file: /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/learned_adapters/linear_allgpus_20251031_184340.log

================================================================================
GPU CONFIGURATION
================================================================================
Mode: DataParallel (multi-GPU)
Number of GPUs: 4
GPU IDs: [0, 1, 2, 3]
Primary device: cuda:0
Batch size per GPU: 5
Total batch size: 20
Effective batch (with grad accum): 320
================================================================================


Loading models on hpc...
Using bfloat16 for H100
Using Flash Attention 2
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|##########| 4/4 [00:00<00:00, 3697.87it/s]Downloading shards: 100%|##########| 4/4 [00:00<00:00, 3697.87it/s]

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|##5       | 1/4 [00:00<00:00,  8.81it/s]Loading checkpoint shards:  25%|##5       | 1/4 [00:00<00:00,  8.81it/s]Loading checkpoint shards:  75%|#######5  | 3/4 [00:00<00:00, 13.45it/s]Loading checkpoint shards:  75%|#######5  | 3/4 [00:00<00:00, 13.45it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:00<00:00, 13.77it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:00<00:00, 13.77it/s]

Wrapped Llama model with DataParallel
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|##########| 3/3 [00:00<00:00, 3370.72it/s]Downloading shards: 100%|##########| 3/3 [00:00<00:00, 3370.72it/s]

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  67%|######6   | 2/3 [00:00<00:00, 13.43it/s]Loading checkpoint shards:  67%|######6   | 2/3 [00:00<00:00, 13.43it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:00<00:00, 14.34it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:00<00:00, 14.34it/s]

Wrapped Mistral model with DataParallel

Training LinearAdapter...
Loading dataset (10000 samples)...

================================================================================
TRAINING CONFIGURATION
================================================================================
Total epochs: 10
Steps per epoch: 500
Total training steps: 5000
Batch size: 20
Gradient accumulation: 16 (effective batch: 320)
Learning rate: 5e-05
Alignment layers: [16]
================================================================================


================================================================================
Epoch 1/10
================================================================================

================================================================================
Epoch 1/10
================================================================================
/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn(
  Step 10/500: Loss = 11.3334 (Gen: 11.0325, Contr: 2.9957, Align: 64.5149, Uniform: -1.0543)
  Step 20/500: Loss = 11.0064 (Gen: 10.7040, Contr: 2.9949, Align: 66.4310, Uniform: -1.0668)
  Step 30/500: Loss = 10.5897 (Gen: 10.2859, Contr: 2.9952, Align: 66.5624, Uniform: -1.0638)
  Step 40/500: Loss = 10.3098 (Gen: 10.0045, Contr: 2.9950, Align: 65.4607, Uniform: -1.0672)
  Step 50/500: Loss = 10.1256 (Gen: 9.8187, Contr: 2.9951, Align: 64.5967, Uniform: -1.0634)
  Step 60/500: Loss = 9.9310 (Gen: 9.6226, Contr: 2.9951, Align: 64.3357, Uniform: -1.0629)
  Step 70/500: Loss = 9.7699 (Gen: 9.4601, Contr: 2.9946, Align: 63.8825, Uniform: -1.0567)
  Step 80/500: Loss = 9.6364 (Gen: 9.3251, Contr: 2.9945, Align: 63.6230, Uniform: -1.0580)
  Step 90/500: Loss = 9.5178 (Gen: 9.2050, Contr: 2.9943, Align: 64.4823, Uniform: -1.0535)
  [ 20.0%] Step  100/500 | Loss: 9.4189 (Gen: 9.1047, Contr: 2.9941, Align: 65.0437, Uniform: -1.0505) | ContrW: 0.110 | LR: 5.00e-05 | GradNorm: 0.000 | 0.34 steps/s | ETA: 19.5m
  [ 20.0%] Step  100/500 | Loss: 9.4189 (Gen: 9.1047, Contr: 2.9941, Align: 65.0437, Uniform: -1.0505) | ContrW: 0.110 | LR: 5.00e-05 | GradNorm: 0.000 | 0.34 steps/s | ETA: 19.5m
  Step 110/500: Loss = 9.3271 (Gen: 9.0114, Contr: 2.9942, Align: 65.6347, Uniform: -1.0482)
  Step 120/500: Loss = 9.2434 (Gen: 8.9262, Contr: 2.9941, Align: 64.9888, Uniform: -1.0480)
  Step 130/500: Loss = 9.1733 (Gen: 8.8546, Contr: 2.9941, Align: 65.3735, Uniform: -1.0475)
  Step 140/500: Loss = 9.1026 (Gen: 8.7824, Contr: 2.9939, Align: 65.4785, Uniform: -1.0455)
  Step 150/500: Loss = 9.0426 (Gen: 8.7210, Contr: 2.9937, Align: 65.0737, Uniform: -1.0431)
  Step 160/500: Loss = 8.9875 (Gen: 8.6643, Contr: 2.9936, Align: 64.8722, Uniform: -1.0409)
  Step 170/500: Loss = 8.9310 (Gen: 8.6063, Contr: 2.9938, Align: 64.4965, Uniform: -1.0401)
  Step 180/500: Loss = 8.8807 (Gen: 8.5546, Contr: 2.9936, Align: 65.3368, Uniform: -1.0389)
  Step 190/500: Loss = 8.8339 (Gen: 8.5062, Contr: 2.9935, Align: 65.1590, Uniform: -1.0353)
  [ 40.0%] Step  200/500 | Loss: 8.7881 (Gen: 8.4590, Contr: 2.9934, Align: 65.4385, Uniform: -1.0322) | ContrW: 0.120 | LR: 4.98e-05 | GradNorm: 0.000 | 0.35 steps/s | ETA: 14.3m
  [ 40.0%] Step  200/500 | Loss: 8.7881 (Gen: 8.4590, Contr: 2.9934, Align: 65.4385, Uniform: -1.0322) | ContrW: 0.120 | LR: 4.98e-05 | GradNorm: 0.000 | 0.35 steps/s | ETA: 14.3m
  Step 210/500: Loss = 8.7483 (Gen: 8.4177, Contr: 2.9933, Align: 65.5081, Uniform: -1.0285)
  Step 220/500: Loss = 8.7102 (Gen: 8.3781, Contr: 2.9932, Align: 65.7738, Uniform: -1.0251)
  Step 230/500: Loss = 8.6747 (Gen: 8.3411, Contr: 2.9929, Align: 66.0530, Uniform: -1.0212)
  Step 240/500: Loss = 8.6394 (Gen: 8.3044, Contr: 2.9927, Align: 66.0621, Uniform: -1.0176)
  Step 250/500: Loss = 8.6095 (Gen: 8.2730, Contr: 2.9924, Align: 66.1553, Uniform: -1.0138)
  Step 260/500: Loss = 8.5794 (Gen: 8.2415, Contr: 2.9923, Align: 65.9074, Uniform: -1.0105)
  Step 270/500: Loss = 8.5522 (Gen: 8.2128, Contr: 2.9920, Align: 65.7612, Uniform: -1.0068)
  Step 280/500: Loss = 8.5250 (Gen: 8.1841, Contr: 2.9917, Align: 65.5500, Uniform: -1.0022)
  Step 290/500: Loss = 8.4994 (Gen: 8.1570, Contr: 2.9914, Align: 65.7189, Uniform: -0.9987)
  [ 60.0%] Step  300/500 | Loss: 8.4757 (Gen: 8.1319, Contr: 2.9911, Align: 65.7897, Uniform: -0.9949) | ContrW: 0.130 | LR: 4.96e-05 | GradNorm: 0.000 | 0.35 steps/s | ETA: 9.5m
  [ 60.0%] Step  300/500 | Loss: 8.4757 (Gen: 8.1319, Contr: 2.9911, Align: 65.7897, Uniform: -0.9949) | ContrW: 0.130 | LR: 4.96e-05 | GradNorm: 0.000 | 0.35 steps/s | ETA: 9.5m
  Step 310/500: Loss = 8.4518 (Gen: 8.1065, Contr: 2.9907, Align: 65.7376, Uniform: -0.9910)
  Step 320/500: Loss = 8.4309 (Gen: 8.0842, Contr: 2.9905, Align: 65.8878, Uniform: -0.9872)
  Step 330/500: Loss = 8.4094 (Gen: 8.0612, Contr: 2.9901, Align: 66.0710, Uniform: -0.9838)
  Step 340/500: Loss = 8.3884 (Gen: 8.0388, Contr: 2.9898, Align: 66.0594, Uniform: -0.9800)
  Step 350/500: Loss = 8.3693 (Gen: 8.0182, Contr: 2.9894, Align: 66.1184, Uniform: -0.9767)
  Step 360/500: Loss = 8.3498 (Gen: 7.9973, Contr: 2.9891, Align: 66.3582, Uniform: -0.9729)
  Step 370/500: Loss = 8.3323 (Gen: 7.9783, Contr: 2.9888, Align: 66.2428, Uniform: -0.9685)
  Step 380/500: Loss = 8.3146 (Gen: 7.9592, Contr: 2.9884, Align: 66.3877, Uniform: -0.9650)
  Step 390/500: Loss = 8.2971 (Gen: 7.9402, Contr: 2.9880, Align: 66.4487, Uniform: -0.9617)
  [ 80.0%] Step  400/500 | Loss: 8.2814 (Gen: 7.9231, Contr: 2.9877, Align: 66.4520, Uniform: -0.9578) | ContrW: 0.140 | LR: 4.92e-05 | GradNorm: 0.719 | 0.35 steps/s | ETA: 4.7m
  [ 80.0%] Step  400/500 | Loss: 8.2814 (Gen: 7.9231, Contr: 2.9877, Align: 66.4520, Uniform: -0.9578) | ContrW: 0.140 | LR: 4.92e-05 | GradNorm: 0.719 | 0.35 steps/s | ETA: 4.7m
  Step 410/500: Loss = 8.2672 (Gen: 7.9075, Contr: 2.9873, Align: 66.5923, Uniform: -0.9545)
  Step 420/500: Loss = 8.2525 (Gen: 7.8913, Contr: 2.9869, Align: 66.6691, Uniform: -0.9511)
  Step 430/500: Loss = 8.2386 (Gen: 7.8760, Contr: 2.9865, Align: 66.9443, Uniform: -0.9478)
  Step 440/500: Loss = 8.2255 (Gen: 7.8615, Contr: 2.9860, Align: 66.9345, Uniform: -0.9440)
  Step 450/500: Loss = 8.2121 (Gen: 7.8466, Contr: 2.9856, Align: 66.9216, Uniform: -0.9410)
  Step 460/500: Loss = 8.1998 (Gen: 7.8329, Contr: 2.9852, Align: 67.1314, Uniform: -0.9380)
  Step 470/500: Loss = 8.1882 (Gen: 7.8198, Contr: 2.9848, Align: 67.0693, Uniform: -0.9341)
  Step 480/500: Loss = 8.1750 (Gen: 7.8052, Contr: 2.9843, Align: 67.0558, Uniform: -0.9305)
  Step 490/500: Loss = 8.1649 (Gen: 7.7937, Contr: 2.9838, Align: 67.2229, Uniform: -0.9275)
  [100.0%] Step  500/500 | Loss: 8.1539 (Gen: 7.7813, Contr: 2.9834, Align: 67.1832, Uniform: -0.9244) | ContrW: 0.150 | LR: 4.88e-05 | GradNorm: 0.000 | 0.35 steps/s | ETA: 0.0m
  [100.0%] Step  500/500 | Loss: 8.1539 (Gen: 7.7813, Contr: 2.9834, Align: 67.1832, Uniform: -0.9244) | ContrW: 0.150 | LR: 4.88e-05 | GradNorm: 0.000 | 0.35 steps/s | ETA: 0.0m

================================================================================
Epoch 1/10 Complete | Time: 23.7m | Total: 23.7m
  Total Loss: 8.1539 (Gen: 7.7813, Contr: 2.9834)
  CKA Score: 0.2113 | LR: 0.000049
  ETA for remaining 9 epochs: 213.4m
================================================================================

================================================================================
Epoch 1/10 Complete | Time: 23.7m | Total: 23.7m
  Total Loss: 8.1539 (Gen: 7.7813, Contr: 2.9834)
  CKA Score: 0.2113 | LR: 0.000049
  ETA for remaining 9 epochs: 213.4m
================================================================================
  Checkpoint saved to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/learned_adapters/linear_checkpoint/checkpoint.pt

================================================================================
Epoch 2/10
================================================================================

================================================================================
Epoch 2/10
================================================================================
  Step 10/500: Loss = 7.6199 (Gen: 7.1745, Contr: 2.9604, Align: 67.7982, Uniform: -0.7581)
  Step 20/500: Loss = 7.6124 (Gen: 7.1656, Contr: 2.9599, Align: 73.6344, Uniform: -0.7644)
  Step 30/500: Loss = 7.6252 (Gen: 7.1769, Contr: 2.9599, Align: 73.2219, Uniform: -0.7656)
  Step 40/500: Loss = 7.6295 (Gen: 7.1798, Contr: 2.9596, Align: 74.0460, Uniform: -0.7674)
  Step 50/500: Loss = 7.6276 (Gen: 7.1764, Contr: 2.9602, Align: 73.5645, Uniform: -0.7656)
  Step 60/500: Loss = 7.6188 (Gen: 7.1661, Contr: 2.9594, Align: 73.1834, Uniform: -0.7667)
  Step 70/500: Loss = 7.6121 (Gen: 7.1580, Contr: 2.9592, Align: 73.9412, Uniform: -0.7662)
  Step 80/500: Loss = 7.6089 (Gen: 7.1534, Contr: 2.9592, Align: 73.4327, Uniform: -0.7649)
  Step 90/500: Loss = 7.6046 (Gen: 7.1478, Contr: 2.9580, Align: 72.5961, Uniform: -0.7640)
  [ 20.0%] Step  100/500 | Loss: 7.5959 (Gen: 7.1376, Contr: 2.9576, Align: 72.5441, Uniform: -0.7639) | ContrW: 0.160 | LR: 4.83e-05 | GradNorm: 0.000 | 0.36 steps/s | ETA: 18.7m
  [ 20.0%] Step  100/500 | Loss: 7.5959 (Gen: 7.1376, Contr: 2.9576, Align: 72.5441, Uniform: -0.7639) | ContrW: 0.160 | LR: 4.83e-05 | GradNorm: 0.000 | 0.36 steps/s | ETA: 18.7m
  Step 110/500: Loss = 7.5965 (Gen: 7.1368, Contr: 2.9572, Align: 71.9994, Uniform: -0.7602)
  Step 120/500: Loss = 7.5946 (Gen: 7.1336, Contr: 2.9566, Align: 71.8272, Uniform: -0.7599)
  Step 130/500: Loss = 7.5934 (Gen: 7.1309, Contr: 2.9560, Align: 72.4454, Uniform: -0.7604)
  Step 140/500: Loss = 7.5902 (Gen: 7.1264, Contr: 2.9553, Align: 72.6600, Uniform: -0.7611)
  Step 150/500: Loss = 7.5892 (Gen: 7.1240, Contr: 2.9549, Align: 73.3262, Uniform: -0.7606)
  Step 160/500: Loss = 7.5894 (Gen: 7.1228, Contr: 2.9544, Align: 72.3210, Uniform: -0.7594)
  Step 170/500: Loss = 7.5834 (Gen: 7.1154, Contr: 2.9536, Align: 71.7551, Uniform: -0.7583)
  Step 180/500: Loss = 7.5786 (Gen: 7.1092, Contr: 2.9530, Align: 71.4235, Uniform: -0.7576)
  Step 190/500: Loss = 7.5776 (Gen: 7.1069, Contr: 2.9524, Align: 71.5502, Uniform: -0.7577)
  [ 40.0%] Step  200/500 | Loss: 7.5774 (Gen: 7.1052, Contr: 2.9521, Align: 72.0367, Uniform: -0.7576) | ContrW: 0.170 | LR: 4.77e-05 | GradNorm: 0.000 | 0.36 steps/s | ETA: 14.1m
  [ 40.0%] Step  200/500 | Loss: 7.5774 (Gen: 7.1052, Contr: 2.9521, Align: 72.0367, Uniform: -0.7576) | ContrW: 0.170 | LR: 4.77e-05 | GradNorm: 0.000 | 0.36 steps/s | ETA: 14.1m
  Step 210/500: Loss = 7.5760 (Gen: 7.1024, Contr: 2.9517, Align: 72.5887, Uniform: -0.7568)
  Step 220/500: Loss = 7.5745 (Gen: 7.0995, Contr: 2.9513, Align: 72.4963, Uniform: -0.7561)
  Step 230/500: Loss = 7.5738 (Gen: 7.0974, Contr: 2.9508, Align: 72.5656, Uniform: -0.7565)
  Step 240/500: Loss = 7.5723 (Gen: 7.0946, Contr: 2.9505, Align: 73.0293, Uniform: -0.7564)
  Step 250/500: Loss = 7.5706 (Gen: 7.0915, Contr: 2.9498, Align: 73.0252, Uniform: -0.7563)
  Step 260/500: Loss = 7.5706 (Gen: 7.0901, Contr: 2.9493, Align: 73.0850, Uniform: -0.7562)
  Step 270/500: Loss = 7.5711 (Gen: 7.0892, Contr: 2.9488, Align: 73.1446, Uniform: -0.7556)
  Step 280/500: Loss = 7.5696 (Gen: 7.0863, Contr: 2.9483, Align: 73.0926, Uniform: -0.7552)
  Step 290/500: Loss = 7.5696 (Gen: 7.0848, Contr: 2.9479, Align: 72.9517, Uniform: -0.7544)
  [ 60.0%] Step  300/500 | Loss: 7.5700 (Gen: 7.0839, Contr: 2.9476, Align: 72.7495, Uniform: -0.7534) | ContrW: 0.180 | LR: 4.70e-05 | GradNorm: 0.000 | 0.36 steps/s | ETA: 9.4m
  [ 60.0%] Step  300/500 | Loss: 7.5700 (Gen: 7.0839, Contr: 2.9476, Align: 72.7495, Uniform: -0.7534) | ContrW: 0.180 | LR: 4.70e-05 | GradNorm: 0.000 | 0.36 steps/s | ETA: 9.4m
  Step 310/500: Loss = 7.5696 (Gen: 7.0821, Contr: 2.9471, Align: 72.8261, Uniform: -0.7532)
  Step 320/500: Loss = 7.5683 (Gen: 7.0794, Contr: 2.9468, Align: 72.6719, Uniform: -0.7521)
  Step 330/500: Loss = 7.5678 (Gen: 7.0775, Contr: 2.9460, Align: 72.6200, Uniform: -0.7518)
  Step 340/500: Loss = 7.5664 (Gen: 7.0748, Contr: 2.9457, Align: 72.5598, Uniform: -0.7512)
  Step 350/500: Loss = 7.5658 (Gen: 7.0728, Contr: 2.9451, Align: 72.5084, Uniform: -0.7510)
  Step 360/500: Loss = 7.5632 (Gen: 7.0688, Contr: 2.9445, Align: 72.7788, Uniform: -0.7516)
  Step 370/500: Loss = 7.5623 (Gen: 7.0665, Contr: 2.9440, Align: 72.9934, Uniform: -0.7520)
  Step 380/500: Loss = 7.5617 (Gen: 7.0645, Contr: 2.9437, Align: 72.7604, Uniform: -0.7503)
  Step 390/500: Loss = 7.5609 (Gen: 7.0622, Contr: 2.9432, Align: 72.7938, Uniform: -0.7495)
  [ 80.0%] Step  400/500 | Loss: 7.5600 (Gen: 7.0600, Contr: 2.9427, Align: 72.9366, Uniform: -0.7493) | ContrW: 0.190 | LR: 4.61e-05 | GradNorm: 0.498 | 0.36 steps/s | ETA: 4.7m
  [ 80.0%] Step  400/500 | Loss: 7.5600 (Gen: 7.0600, Contr: 2.9427, Align: 72.9366, Uniform: -0.7493) | ContrW: 0.190 | LR: 4.61e-05 | GradNorm: 0.498 | 0.36 steps/s | ETA: 4.7m
