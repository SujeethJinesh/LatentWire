================================================================================
LEARNED ADAPTER EXPERIMENT - LORA
================================================================================
Platform: hpc
Log file: /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/learned_adapters/lora_allgpus_20251031_225245.log

Loading models on hpc...
Using bfloat16 for H100
Using Flash Attention 2
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|##########| 4/4 [00:00<00:00, 8648.05it/s]Downloading shards: 100%|##########| 4/4 [00:00<00:00, 8648.05it/s]

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|##5       | 1/4 [00:00<00:01,  2.05it/s]Loading checkpoint shards:  25%|##5       | 1/4 [00:00<00:01,  2.05it/s]Loading checkpoint shards:  50%|#####     | 2/4 [00:00<00:00,  2.88it/s]Loading checkpoint shards:  50%|#####     | 2/4 [00:00<00:00,  2.88it/s]Loading checkpoint shards:  75%|#######5  | 3/4 [00:00<00:00,  3.30it/s]Loading checkpoint shards:  75%|#######5  | 3/4 [00:00<00:00,  3.30it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:01<00:00,  3.55it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:01<00:00,  3.55it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:01<00:00,  3.19it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:01<00:00,  3.19it/s]

Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|##########| 3/3 [00:00<00:00, 8636.18it/s]Downloading shards: 100%|##########| 3/3 [00:00<00:00, 8636.18it/s]

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|###3      | 1/3 [00:00<00:00,  2.42it/s]Loading checkpoint shards:  33%|###3      | 1/3 [00:00<00:00,  2.42it/s]Loading checkpoint shards:  67%|######6   | 2/3 [00:00<00:00,  2.83it/s]Loading checkpoint shards:  67%|######6   | 2/3 [00:00<00:00,  2.83it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:00<00:00,  3.31it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:00<00:00,  3.31it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:00<00:00,  3.10it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:00<00:00,  3.10it/s]


Training LoRAAdapter...

================================================================================
TRAINING CONFIGURATION
================================================================================
Total epochs: 5
Steps per epoch: 250
Total training steps: 1250
Batch size: 10
Gradient accumulation: 8 (effective batch: 80)
Learning rate: 5e-05
Alignment layers: [8, 16, 24]
================================================================================

  Step 10/250: Loss = 11.2312 (Gen: 10.9988, Contr: 2.3028, Align: 92.8275, Uniform: -0.9316)
  Step 20/250: Loss = 11.2639 (Gen: 11.0294, Contr: 2.3019, Align: 94.3915, Uniform: -0.9259)
  Step 30/250: Loss = 11.3613 (Gen: 11.1243, Contr: 2.3032, Align: 92.7300, Uniform: -0.9294)
  Step 40/250: Loss = 11.3434 (Gen: 11.1041, Contr: 2.3034, Align: 94.8085, Uniform: -0.9415)
  Step 50/250: Loss = 11.2845 (Gen: 11.0430, Contr: 2.3025, Align: 95.0238, Uniform: -0.9510)
  Step 60/250: Loss = 11.2731 (Gen: 11.0292, Contr: 2.3029, Align: 97.6864, Uniform: -0.9498)
  Step 70/250: Loss = 11.2653 (Gen: 11.0191, Contr: 2.3034, Align: 98.5525, Uniform: -0.9511)
  Step 80/250: Loss = 11.2513 (Gen: 11.0029, Contr: 2.3026, Align: 99.3549, Uniform: -0.9501)
  Step 90/250: Loss = 11.2540 (Gen: 11.0033, Contr: 2.3023, Align: 99.8183, Uniform: -0.9496)
  [ 40.0%] Step  100/250 | Loss: 11.2284 (Gen: 10.9755, Contr: 2.3020, Align: 102.1217, Uniform: -0.9502) | ContrW: 0.120 | LR: 4.93e-05 | GradNorm: 0.000 | 0.38 steps/s | ETA: 6.5m
  [ 40.0%] Step  100/250 | Loss: 11.2284 (Gen: 10.9755, Contr: 2.3020, Align: 102.1217, Uniform: -0.9502) | ContrW: 0.120 | LR: 4.93e-05 | GradNorm: 0.000 | 0.38 steps/s | ETA: 6.5m
  Step 110/250: Loss = 11.2094 (Gen: 10.9541, Contr: 2.3018, Align: 102.2248, Uniform: -0.9479)
  Step 120/250: Loss = 11.1921 (Gen: 10.9346, Contr: 2.3016, Align: 102.5938, Uniform: -0.9488)
  Step 130/250: Loss = 11.1712 (Gen: 10.9114, Contr: 2.3019, Align: 102.0238, Uniform: -0.9495)
  Step 140/250: Loss = 11.1563 (Gen: 10.8941, Contr: 2.3021, Align: 101.6395, Uniform: -0.9474)
  Step 150/250: Loss = 11.1438 (Gen: 10.8793, Contr: 2.3021, Align: 101.3858, Uniform: -0.9464)
  Step 160/250: Loss = 11.1217 (Gen: 10.8549, Contr: 2.3024, Align: 101.5214, Uniform: -0.9465)
  Step 170/250: Loss = 11.0916 (Gen: 10.8224, Contr: 2.3027, Align: 103.3147, Uniform: -0.9478)
  Step 180/250: Loss = 11.0696 (Gen: 10.7981, Contr: 2.3027, Align: 103.1692, Uniform: -0.9460)
  Step 190/250: Loss = 11.0396 (Gen: 10.7658, Contr: 2.3027, Align: 103.3443, Uniform: -0.9456)
  [ 80.0%] Step  200/250 | Loss: 11.0090 (Gen: 10.7329, Contr: 2.3026, Align: 103.6886, Uniform: -0.9460) | ContrW: 0.140 | LR: 4.69e-05 | GradNorm: 4.906 | 0.39 steps/s | ETA: 2.2m
  [ 80.0%] Step  200/250 | Loss: 11.0090 (Gen: 10.7329, Contr: 2.3026, Align: 103.6886, Uniform: -0.9460) | ContrW: 0.140 | LR: 4.69e-05 | GradNorm: 4.906 | 0.39 steps/s | ETA: 2.2m
  Step 210/250: Loss = 10.9796 (Gen: 10.7012, Contr: 2.3026, Align: 103.3068, Uniform: -0.9442)
  Step 220/250: Loss = 10.9551 (Gen: 10.6744, Contr: 2.3026, Align: 104.0148, Uniform: -0.9466)
  Step 230/250: Loss = 10.9320 (Gen: 10.6490, Contr: 2.3027, Align: 104.4124, Uniform: -0.9460)
  Step 240/250: Loss = 10.9067 (Gen: 10.6214, Contr: 2.3027, Align: 103.8364, Uniform: -0.9467)
  Step 250/250: Loss = 10.8866 (Gen: 10.5990, Contr: 2.3027, Align: 102.9650, Uniform: -0.9464)
  Step 10/250: Loss = 10.2956 (Gen: 9.9482, Contr: 2.3020, Align: 103.1093, Uniform: -0.9848)
  Step 20/250: Loss = 10.2735 (Gen: 9.9238, Contr: 2.3025, Align: 98.2152, Uniform: -0.9749)
  Step 30/250: Loss = 10.2575 (Gen: 9.9053, Contr: 2.3034, Align: 106.7291, Uniform: -0.9683)
  Step 40/250: Loss = 10.2316 (Gen: 9.8771, Contr: 2.3033, Align: 105.8303, Uniform: -0.9719)
  Step 50/250: Loss = 10.2167 (Gen: 9.8599, Contr: 2.3030, Align: 107.2803, Uniform: -0.9648)
  Step 60/250: Loss = 10.2065 (Gen: 9.8475, Contr: 2.3031, Align: 105.7649, Uniform: -0.9583)
  Step 70/250: Loss = 10.1859 (Gen: 9.8246, Contr: 2.3026, Align: 106.2472, Uniform: -0.9543)
  Step 80/250: Loss = 10.1672 (Gen: 9.8035, Contr: 2.3029, Align: 105.3428, Uniform: -0.9553)
  Step 90/250: Loss = 10.1610 (Gen: 9.7950, Contr: 2.3035, Align: 102.9586, Uniform: -0.9550)
  [ 40.0%] Step  100/250 | Loss: 10.1535 (Gen: 9.7852, Contr: 2.3032, Align: 101.6404, Uniform: -0.9544) | ContrW: 0.170 | LR: 4.12e-05 | GradNorm: 0.000 | 0.39 steps/s | ETA: 6.4m
  [ 40.0%] Step  100/250 | Loss: 10.1535 (Gen: 9.7852, Contr: 2.3032, Align: 101.6404, Uniform: -0.9544) | ContrW: 0.170 | LR: 4.12e-05 | GradNorm: 0.000 | 0.39 steps/s | ETA: 6.4m
  Step 110/250: Loss = 10.1361 (Gen: 9.7656, Contr: 2.3030, Align: 101.1023, Uniform: -0.9581)
  Step 120/250: Loss = 10.1174 (Gen: 9.7445, Contr: 2.3033, Align: 101.9438, Uniform: -0.9573)
  Step 130/250: Loss = 10.0942 (Gen: 9.7190, Contr: 2.3031, Align: 100.9776, Uniform: -0.9556)
  Step 140/250: Loss = 10.0793 (Gen: 9.7018, Contr: 2.3033, Align: 100.4929, Uniform: -0.9548)
  Step 150/250: Loss = 10.0657 (Gen: 9.6859, Contr: 2.3035, Align: 100.8324, Uniform: -0.9510)
  Step 160/250: Loss = 10.0493 (Gen: 9.6672, Contr: 2.3034, Align: 101.4419, Uniform: -0.9497)
  Step 170/250: Loss = 10.0334 (Gen: 9.6489, Contr: 2.3034, Align: 101.2287, Uniform: -0.9495)
  Step 180/250: Loss = 10.0208 (Gen: 9.6340, Contr: 2.3033, Align: 101.3218, Uniform: -0.9512)
  Step 190/250: Loss = 10.0063 (Gen: 9.6173, Contr: 2.3033, Align: 101.7756, Uniform: -0.9518)
  [ 80.0%] Step  200/250 | Loss: 9.9911 (Gen: 9.5998, Contr: 2.3032, Align: 102.2577, Uniform: -0.9507) | ContrW: 0.190 | LR: 3.57e-05 | GradNorm: 3.891 | 0.39 steps/s | ETA: 2.1m
  [ 80.0%] Step  200/250 | Loss: 9.9911 (Gen: 9.5998, Contr: 2.3032, Align: 102.2577, Uniform: -0.9507) | ContrW: 0.190 | LR: 3.57e-05 | GradNorm: 3.891 | 0.39 steps/s | ETA: 2.1m
