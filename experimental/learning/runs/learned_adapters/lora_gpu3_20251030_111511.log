================================================================================
LEARNED ADAPTER EXPERIMENT: LORA
================================================================================
GPU: 3 (cuda:0)
Layer: 16 (middle layer)
Timestamp: 20251030_111511
Log file: runs/learned_adapters/lora_gpu3_20251030_111511.log
Results file: runs/learned_adapters/lora_results_20251030_111511.json
================================================================================

Loading models on GPU 3...
  ✓ Llama 3.1 8B loaded
  ✓ Mistral 7B loaded

Loading datasets...
  Checking cache at: /projects/m000066/sujinesh/.cache/huggingface/datasets/rajpurkar___squad
  Cache exists: False
  Cache directory does not exist - proceeding with fresh download
  Training: 1000 texts (indices 2000-3000)
  Evaluation: 500 texts

================================================================================
Training LORA Adapter on GPU cuda:0
================================================================================
Adapter parameters: 65,536

Epoch 1/3
----------------------------------------
