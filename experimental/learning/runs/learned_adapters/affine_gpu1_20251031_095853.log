================================================================================
LEARNED ADAPTER EXPERIMENT - AFFINE
================================================================================
Platform: hpc
Log file: /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/learned_adapters/affine_gpu1_20251031_095853.log
GPU assigned: 1

Loading models on hpc...
Using bfloat16 for H100
Using Flash Attention 2
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|##########| 4/4 [00:00<00:00, 5102.56it/s]Downloading shards: 100%|##########| 4/4 [00:00<00:00, 5102.56it/s]

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|##5       | 1/4 [00:00<00:00,  5.49it/s]Loading checkpoint shards:  25%|##5       | 1/4 [00:00<00:00,  5.49it/s]Loading checkpoint shards:  50%|#####     | 2/4 [00:00<00:00,  6.25it/s]Loading checkpoint shards:  50%|#####     | 2/4 [00:00<00:00,  6.25it/s]Loading checkpoint shards:  75%|#######5  | 3/4 [00:00<00:00,  6.60it/s]Loading checkpoint shards:  75%|#######5  | 3/4 [00:00<00:00,  6.60it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:00<00:00,  6.78it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:00<00:00,  6.78it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:00<00:00,  6.56it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:00<00:00,  6.56it/s]

Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|##########| 3/3 [00:00<00:00, 41.99it/s]Downloading shards: 100%|##########| 3/3 [00:00<00:00, 41.99it/s]

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|###3      | 1/3 [00:00<00:00,  4.46it/s]Loading checkpoint shards:  33%|###3      | 1/3 [00:00<00:00,  4.46it/s]Loading checkpoint shards:  67%|######6   | 2/3 [00:00<00:00,  5.69it/s]Loading checkpoint shards:  67%|######6   | 2/3 [00:00<00:00,  5.69it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:00<00:00,  6.01it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:00<00:00,  6.01it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:00<00:00,  5.72it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:00<00:00,  5.72it/s]


Training AffineAdapter...
Loading dataset (10000 samples)...

Epoch 1/10

================================================================================
AFFINE ADAPTER EXPERIMENT FAILED
================================================================================
Error: mat1 and mat2 must have the same dtype, but got BFloat16 and Float
Traceback (most recent call last):
Traceback (most recent call last):
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 1073, in run_adapter_experiment
    adapter, metrics = train_adapter(
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 1073, in run_adapter_experiment
    adapter, metrics = train_adapter(
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 834, in train_adapter
    aligned_repr = adapter(source_repr)
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 834, in train_adapter
    aligned_repr = adapter(source_repr)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 342, in forward
    return self.proj(x)
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 342, in forward
    return self.proj(x)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 must have the same dtype, but got BFloat16 and Float
RuntimeError: mat1 and mat2 must have the same dtype, but got BFloat16 and Float
