/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
==> Using CUDA on HPC (2 GPUs available)
  - Batch size: 16
  - Samples: 10000
  - Epochs: 10
  - BF16: True
  - Flash Attention: True
Python: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]
PyTorch: 2.5.1+cu121
CUDA available: True
CUDA devices: 2
================================================================================
UNIFIED CROSS-MODEL ALIGNMENT EXPERIMENTS
Timestamp: 2025-10-31T09:56:41.613060
Platform: hpc
Device: cuda
Available CUDA GPUs: 2
================================================================================

1. Starting Procrustes experiment on cuda...

================================================================================
PROCRUSTES ALIGNMENT EXPERIMENT (GPU-ACCELERATED)
================================================================================
Device: cuda (Procrustes on hpc)

Loading models on hpc...
Using bfloat16 for H100
Loading models on separate GPUs to avoid OOM...
Using Flash Attention 2
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 1948.80it/s]
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  7.89it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  5.34it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  5.07it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.41it/s]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2084.64it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  6.11it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  6.12it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  3.00it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  3.48it/s]
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Llama model moved to cuda:0
Mistral model moved to cuda:1

Loading calibration dataset (50 samples)...

============================================================
Testing Layer 0
============================================================
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
  WARNING: Orthogonality error = 0.091226
  WARNING: Orthogonality error = 0.089725

Testing generation...

============================================================
Testing Layer 8
============================================================
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
  WARNING: Orthogonality error = 0.033226
  WARNING: Orthogonality error = 0.033129

Testing generation...

============================================================
Testing Layer 16
============================================================
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
  WARNING: Orthogonality error = 0.033363
  WARNING: Orthogonality error = 0.033375

Testing generation...

============================================================
Testing Layer 24
============================================================
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
  WARNING: Orthogonality error = 0.034813
  WARNING: Orthogonality error = 0.035054

Testing generation...

============================================================
Testing Layer 32
============================================================
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
  WARNING: Orthogonality error = 0.102234
  WARNING: Orthogonality error = 0.102734

Testing generation...
Procrustes results saved to: /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/unified_experiments/procrustes_results_20251031_095641.json

2. Starting learned adapter experiments...
Running Linear and Affine adapters in parallel on 2 GPUs...
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
==> Using CUDA on HPC (2 GPUs available)
  - Batch size: 16
  - Samples: 10000
  - Epochs: 10
  - BF16: True
  - Flash Attention: True
================================================================================
LEARNED ADAPTER EXPERIMENT - LINEAR
================================================================================
Platform: hpc
Log file: /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/learned_adapters/linear_gpu0_20251031_095853.log
GPU assigned: 0

Loading models on hpc...
Using bfloat16 for H100
Using Flash Attention 2
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]==> Using CUDA on HPC (2 GPUs available)
  - Batch size: 16
  - Samples: 10000
  - Epochs: 10
  - BF16: True
  - Flash Attention: True
================================================================================
LEARNED ADAPTER EXPERIMENT - AFFINE
================================================================================
Platform: hpc
Log file: /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/learned_adapters/affine_gpu1_20251031_095853.log
GPU assigned: 1

Loading models on hpc...
Using bfloat16 for H100
Using Flash Attention 2
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|##########| 4/4 [00:00<00:00, 1403.60it/s]Downloading shards: 100%|##########| 4/4 [00:00<00:00, 5102.56it/s]You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|##5       | 1/4 [00:00<00:00,  5.59it/s]Loading checkpoint shards:  25%|##5       | 1/4 [00:00<00:00,  5.49it/s]Loading checkpoint shards:  50%|#####     | 2/4 [00:00<00:00,  6.32it/s]Loading checkpoint shards:  50%|#####     | 2/4 [00:00<00:00,  6.25it/s]Loading checkpoint shards:  75%|#######5  | 3/4 [00:00<00:00,  6.60it/s]Loading checkpoint shards:  75%|#######5  | 3/4 [00:00<00:00,  6.48it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:00<00:00,  6.84it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:00<00:00,  6.78it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:00<00:00,  6.56it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:00<00:00,  6.56it/s]

Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|##########| 3/3 [00:00<00:00, 42.14it/s]Downloading shards: 100%|##########| 3/3 [00:00<00:00, 41.99it/s]

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|###3      | 1/3 [00:00<00:00,  4.45it/s]Loading checkpoint shards:  33%|###3      | 1/3 [00:00<00:00,  4.46it/s]Loading checkpoint shards:  67%|######6   | 2/3 [00:00<00:00,  5.69it/s]Loading checkpoint shards:  67%|######6   | 2/3 [00:00<00:00,  5.57it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:00<00:00,  6.20it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:00<00:00,  5.75it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:00<00:00,  6.01it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:00<00:00,  5.72it/s]

================================================================================
AFFINE ADAPTER EXPERIMENT FAILED
================================================================================
Error: mat1 and mat2 must have the same dtype, but got BFloat16 and Float
Traceback (most recent call last):
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 1073, in run_adapter_experiment
    adapter, metrics = train_adapter(
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 834, in train_adapter
    aligned_repr = adapter(source_repr)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 342, in forward
    return self.proj(x)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 must have the same dtype, but got BFloat16 and Float


================================================================================
LINEAR ADAPTER EXPERIMENT FAILED
================================================================================
Error: expected mat1 and mat2 to have the same dtype, but got: c10::BFloat16 != float
Traceback (most recent call last):
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 1073, in run_adapter_experiment
    adapter, metrics = train_adapter(
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 834, in train_adapter
    aligned_repr = adapter(source_repr)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 329, in forward
    return self.proj(x)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: expected mat1 and mat2 to have the same dtype, but got: c10::BFloat16 != float

3. Starting LoRA experiment (sequential on GPU 0)...
================================================================================
LEARNED ADAPTER EXPERIMENT - LORA
================================================================================
Platform: hpc
Log file: /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/learned_adapters/lora_gpu0_20251031_095956.log
GPU assigned: 0

Loading models on hpc...
Using bfloat16 for H100
Using Flash Attention 2
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|##########| 4/4 [00:00<00:00, 3585.64it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|##5       | 1/4 [00:00<00:00,  8.88it/s]Loading checkpoint shards:  75%|#######5  | 3/4 [00:00<00:00, 13.48it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:00<00:00, 13.76it/s]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|##########| 3/3 [00:00<00:00, 3177.50it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|###3      | 1/3 [00:00<00:00,  9.92it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:00<00:00, 10.39it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:00<00:00,  9.58it/s]

================================================================================
LORA ADAPTER EXPERIMENT FAILED
================================================================================
Error: expected mat1 and mat2 to have the same dtype, but got: c10::BFloat16 != float
Traceback (most recent call last):
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 1073, in run_adapter_experiment
    adapter, metrics = train_adapter(
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 834, in train_adapter
    aligned_repr = adapter(source_repr)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 361, in forward
    return x + self.scaling * self.lora_B(self.lora_A(x))
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: expected mat1 and mat2 to have the same dtype, but got: c10::BFloat16 != float

3. Starting token-initialized compression experiment...

================================================================================
TOKEN-INITIALIZED COMPRESSION EXPERIMENT
================================================================================
Loading meta-llama/Llama-3.1-8B...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 3808.68it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  9.58it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00, 13.93it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 14.18it/s]
/users/sujinesh/.local/lib/python3.10/site-packages/torch/_compile.py:32: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information
  return disable_fn(*args, **kwargs)
Applying LoRA to all transformer layers...
Warning: Could not apply LoRA: No module named 'peft'
Creating token-initialized compressor (compressed_length=64, d_z=256)...
Loading SQuAD dataset (1000 samples)...

Training for 10 epochs...
Batch size: 16, Learning rate: 5e-05
Traceback (most recent call last):
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 1465, in <module>
    main()
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 1429, in main
    token_results = run_token_compression_experiment(
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 1241, in run_token_compression_experiment
    compressed = compressor(inputs.input_ids)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 444, in forward
    z = self.to_latent(init_embeds)  # [B, compressed_length, d_z]
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 must have the same dtype, but got BFloat16 and Float
