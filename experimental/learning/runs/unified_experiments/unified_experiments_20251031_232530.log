Using DDP (DistributedDataParallel) with torchrun for 4 GPUs

W1031 23:25:32.264000 1495247 torch/distributed/run.py:793] 
W1031 23:25:32.264000 1495247 torch/distributed/run.py:793] *****************************************
W1031 23:25:32.264000 1495247 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1031 23:25:32.264000 1495247 torch/distributed/run.py:793] *****************************************
==> Using CUDA on HPC (4 GPUs available)==> Using CUDA on HPC (4 GPUs available)

==> Using CUDA on HPC (4 GPUs available)
  - Batch size per GPU: 10
  - Global batch size: 40
  - Effective batch (with grad accum): 320
  - Samples: 10000
  - Epochs: 5
  - BF16: True
  - Flash Attention: True
Python: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]
PyTorch: 2.5.1+cu121
CUDA available: True
CUDA devices: 4
================================================================================
UNIFIED CROSS-MODEL ALIGNMENT EXPERIMENTS
Timestamp: 2025-10-31T23:25:42.363931
Platform: hpc
Device: cuda
Available CUDA GPUs: 4
================================================================================
  - Batch size per GPU: 10
1. Starting Procrustes experiment on cuda...

================================================================================
PROCRUSTES ALIGNMENT EXPERIMENT (GPU-ACCELERATED)
================================================================================
Device: cuda (Procrustes on hpc)

Loading models on hpc...
Using bfloat16 for H100
Loading models on separate GPUs to avoid OOM...
Using Flash Attention 2

  - Global batch size: 40
  - Effective batch (with grad accum): 320
  - Samples: 10000
  - Epochs: 5
  - BF16: True
  - Flash Attention: True
Python: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]
PyTorch: 2.5.1+cu121
CUDA available: True
CUDA devices: 4
================================================================================
UNIFIED CROSS-MODEL ALIGNMENT EXPERIMENTS
Timestamp: 2025-10-31T23:25:42.368712
Platform: hpc
Device: cuda
Available CUDA GPUs: 4
================================================================================
  - Batch size per GPU: 10
1. Starting Procrustes experiment on cuda...

================================================================================
PROCRUSTES ALIGNMENT EXPERIMENT (GPU-ACCELERATED)
================================================================================
Device: cuda (Procrustes on hpc)

Loading models on hpc...
Using bfloat16 for H100
Loading models on separate GPUs to avoid OOM...
Using Flash Attention 2

  - Global batch size: 40
  - Effective batch (with grad accum): 320
  - Samples: 10000
  - Epochs: 5
  - BF16: True
  - Flash Attention: True
Python: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]==> Using CUDA on HPC (4 GPUs available)

PyTorch: 2.5.1+cu121
CUDA available: True
CUDA devices: 4
================================================================================
UNIFIED CROSS-MODEL ALIGNMENT EXPERIMENTS
Timestamp: 2025-10-31T23:25:42.374301
Platform: hpc
Device: cuda
Available CUDA GPUs: 4
================================================================================

1. Starting Procrustes experiment on cuda...

================================================================================
PROCRUSTES ALIGNMENT EXPERIMENT (GPU-ACCELERATED)
================================================================================
Device: cuda (Procrustes on hpc)

Loading models on hpc...
Using bfloat16 for H100
Loading models on separate GPUs to avoid OOM...
Using Flash Attention 2
  - Batch size per GPU: 10
  - Global batch size: 40
  - Effective batch (with grad accum): 320
  - Samples: 10000
  - Epochs: 5
  - BF16: True
  - Flash Attention: True
Python: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]
PyTorch: 2.5.1+cu121
CUDA available: True
CUDA devices: 4
================================================================================
UNIFIED CROSS-MODEL ALIGNMENT EXPERIMENTS
Timestamp: 2025-10-31T23:25:42.385082
Platform: hpc
Device: cuda
Available CUDA GPUs: 4
================================================================================

1. Starting Procrustes experiment on cuda...

================================================================================
PROCRUSTES ALIGNMENT EXPERIMENT (GPU-ACCELERATED)
================================================================================
Device: cuda (Procrustes on hpc)

Loading models on hpc...
Using bfloat16 for H100
Loading models on separate GPUs to avoid OOM...
Using Flash Attention 2
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2971.52it/s]
Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 3396.89it/s]
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 9269.18it/s]
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 9203.08it/s]
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  1.82it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  2.03it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  2.09it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  1.62it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.12it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.16it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.88it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.78it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  2.16it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  2.08it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  2.15it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  1.91it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.34it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.38it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.24it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.29it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.26it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.11it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.23it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.09it/s]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 1054.99it/s]
Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 4059.00it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 353.95it/s]

Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 1726.52it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  2.25it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  2.24it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  2.54it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  2.19it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  2.37it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  2.19it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  2.13it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  2.09it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.37it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.33it/s]
Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.21it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]
Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.17it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.17it/s]
Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.17it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.16it/s]
Llama model moved to cuda:0Llama model moved to cuda:0Llama model moved to cuda:0
Mistral model moved to cuda:1

Mistral model moved to cuda:1

Mistral model moved to cuda:1
Llama model moved to cuda:0
Mistral model moved to cuda:1

Loading calibration dataset (50 samples)...
Loading calibration dataset (50 samples)...
Loading calibration dataset (50 samples)...



Loading calibration dataset (50 samples)...

============================================================
Testing Layer 0
============================================================

============================================================
Testing Layer 0
============================================================

============================================================
Testing Layer 0
============================================================

============================================================
Testing Layer 0
============================================================
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
  WARNING: Orthogonality error = 0.091226
  WARNING: Orthogonality error = 0.091226
  WARNING: Orthogonality error = 0.091226
  WARNING: Orthogonality error = 0.091226
  WARNING: Orthogonality error = 0.089725
  Computing CKA similarity scores...
  CKA Mistral→Llama:
    Before alignment: 0.4029
    After alignment:  0.4029
    Improvement:      -0.0001
  CKA Llama→Mistral after alignment: 0.4028
  WARNING: Orthogonality error = 0.089725
  Computing CKA similarity scores...
  CKA Mistral→Llama:
    Before alignment: 0.4029
    After alignment:  0.4029
    Improvement:      -0.0001
  CKA Llama→Mistral after alignment: 0.4028
  WARNING: Orthogonality error = 0.089725
  Computing CKA similarity scores...
  CKA Mistral→Llama:
    Before alignment: 0.4029
    After alignment:  0.4029
    Improvement:      -0.0001
  CKA Llama→Mistral after alignment: 0.4028
  Saved Procrustes alignment to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/procrustes_alignments/layer_0.pt

Testing generation...
  Prompt 1/5: The capital of France is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  Saved Procrustes alignment to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/procrustes_alignments/layer_0.pt

Testing generation...
  Prompt 1/5: The capital of France is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  Saved Procrustes alignment to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/procrustes_alignments/layer_0.pt

Testing generation...
  Prompt 1/5: The capital of France is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  WARNING: Orthogonality error = 0.089725
  Computing CKA similarity scores...
  CKA Mistral→Llama:
    Before alignment: 0.4029
    After alignment:  0.4029
    Improvement:      -0.0001
  CKA Llama→Mistral after alignment: 0.4028
  Saved Procrustes alignment to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/procrustes_alignments/layer_0.pt

Testing generation...
  Prompt 1/5: The capital of France is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city that is full of history and culture. It is a cit
    Testing Llama→Llama (baseline)...
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city that is full of history and culture. It is a cit      Generated: The capital of France is a city that is full of history and culture. It is a cit
    Testing Llama→Llama (baseline)...

    Testing Llama→Llama (baseline)...
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city that is full of history and culture. It is a cit
    Testing Llama→Llama (baseline)...
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city of many faces. It is a city of history, a city o
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1.2734
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
      Generated: The capital of France is a city of many faces. It is a city of history, a city o      Generated: The capital of France is a city of many faces. It is a city of history, a city o
    Testing Llama→Mistral (cross-model via Procrustes)...

    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1.2734      Transformation norm: 1.2734

The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
      Generated: The capital of France is a city of many faces. It is a city of history, a city o
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1.2734
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
      Generated: esign

# Re-designing the world’s most popular online dating app


    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1.4062
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: esign

# Re-designing the world’s most popular online dating app

      Generated: esign

# Re-designing the world’s most popular online dating app


    Testing Mistral→Llama (cross-model via Procrustes)...

    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1.4062      Transformation norm: 1.4062
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.

The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: esign

# Re-designing the world’s most popular online dating app


    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1.4062
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The 2019-2020 school year is off to a great start! We are excited
  Prompt 2/5: To solve this problem, we need to...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The 2019-2020 school year is off to a great start! We are excited      Generated: 
The 2019-2020 school year is off to a great start! We are excited
  Prompt 2/5: To solve this problem, we need to...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

  Prompt 2/5: To solve this problem, we need to...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The 2019-2020 school year is off to a great start! We are excited
  Prompt 2/5: To solve this problem, we need to...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to understand the difference between the two type
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to understand the difference between the two type      Generated: To solve this problem, we need to understand the difference between the two type
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to understand the difference between the two type
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to find the value of the expression. We can do th
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1.5781
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to find the value of the expression. We can do th
    Testing Llama→Mistral (cross-model via Procrustes)...
      Generated: To solve this problem, we need to find the value of the expression. We can do th
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1.5781
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Transformation norm: 1.5781
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to find the value of the expression. We can do th
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1.5781
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 

The first thing you need to do is to make sure that you have a good understand
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1.7188
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 

The first thing you need to do is to make sure that you have a good understand
    Testing Mistral→Llama (cross-model via Procrustes)...
      Generated: 

The first thing you need to do is to make sure that you have a good understand
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1.7188
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Transformation norm: 1.7188
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 

The first thing you need to do is to make sure that you have a good understand
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1.7188
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The word “basil” is derived from the Greek word “basileus” which means
  Prompt 3/5: The future of artificial intelligence is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The word “basil” is derived from the Greek word “basileus” which means
  Prompt 3/5: The future of artificial intelligence is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The word “basil” is derived from the Greek word “basileus” which means
  Prompt 3/5: The future of artificial intelligence is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The word “basil” is derived from the Greek word “basileus” which means
  Prompt 3/5: The future of artificial intelligence is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here.

The future of artificial intelli
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here.

The future of artificial intelli
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here.

The future of artificial intelli
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here.

The future of artificial intelli
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here, and it’s already changing the way
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1.4609
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here, and it’s already changing the way
    Testing Llama→Mistral (cross-model via Procrustes)...
      Generated: The future of artificial intelligence is here, and it’s already changing the way      Transformation norm: 1.4609
    Testing Llama→Mistral (cross-model via Procrustes)...

The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Transformation norm: 1.4609
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here, and it’s already changing the way
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1.4609
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 

**A**

**S**

**S**

**S**
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1.6094
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 

**A**

**S**

**S**

**S**
    Testing Mistral→Llama (cross-model via Procrustes)...
      Generated: 

**A**

**S**

**S**

**S**
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1.6094
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Transformation norm: 1.6094
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 

**A**

**S**

**S**

**S**
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1.6094
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
A. The first letter of the Greek alphabet, α, used as a mathematical symbol to 
  Prompt 4/5: In the year 2050,...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
A. The first letter of the Greek alphabet, α, used as a mathematical symbol to 
  Prompt 4/5: In the year 2050,...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
A. The first letter of the Greek alphabet, α, used as a mathematical symbol to 
  Prompt 4/5: In the year 2050,...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
A. The first letter of the Greek alphabet, α, used as a mathematical symbol to 
  Prompt 4/5: In the year 2050,...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The United States has bee
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The United States has bee
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The United States has bee
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The United States has bee
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The population has grown 
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1.4219
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The population has grown 
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1.4219
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The population has grown 
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1.4219
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The population has grown 
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1.4219
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 

The

Michael J. B. Allen

and

James R
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1.5234
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 

The

Michael J. B. Allen

and

James R
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1.5234
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 

The

Michael J. B. Allen

and

James R
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1.5234
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 

The

Michael J. B. Allen

and

James R
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1.5234
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The 2018-2019 school year is off to a great start! We are excited
  Prompt 5/5: The main difference between cats and dogs is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The 2018-2019 school year is off to a great start! We are excited
  Prompt 5/5: The main difference between cats and dogs is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The 2018-2019 school year is off to a great start! We are excited
  Prompt 5/5: The main difference between cats and dogs is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The 2018-2019 school year is off to a great start! We are excited
  Prompt 5/5: The main difference between cats and dogs is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are carnivores and dogs a
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are carnivores and dogs a
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are carnivores and dogs a
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are carnivores and dogs a
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are solitary animals, whi
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1.7031
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are solitary animals, whi
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1.7031
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are solitary animals, whi
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1.7031
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are solitary animals, whi
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1.7031
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 

The

The

The

The

The

The


    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1.8516
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 

The

The

The

The

The

The


    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1.8516
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 

The

The

The

The

The

The


    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1.8516
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 

The

The

The

The

The

The


    Testing Mistral→Llama (cross-model via Procrustes)...
      Generated: 
The 2018-2019 school year is off to a great start! We are excited      Transformation norm: 1.8516
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


============================================================
Testing Layer 8
============================================================
      Generated: 
The 2018-2019 school year is off to a great start! We are excited

============================================================
Testing Layer 8
============================================================
      Generated: 
The 2018-2019 school year is off to a great start! We are excited

============================================================
Testing Layer 8
============================================================
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
      Generated: 
The 2018-2019 school year is off to a great start! We are excited

============================================================
Testing Layer 8
============================================================
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
  WARNING: Orthogonality error = 0.033226
  WARNING: Orthogonality error = 0.033226
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
  WARNING: Orthogonality error = 0.033226
  WARNING: Orthogonality error = 0.033129
  Computing CKA similarity scores...
  CKA Mistral→Llama:
    Before alignment: 0.9999
    After alignment:  0.9999
    Improvement:      -0.0000
  CKA Llama→Mistral after alignment: 0.9999
  Saved Procrustes alignment to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/procrustes_alignments/layer_8.pt

Testing generation...
  Prompt 1/5: The capital of France is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  WARNING: Orthogonality error = 0.033129
  Computing CKA similarity scores...
  CKA Mistral→Llama:
    Before alignment: 0.9999
    After alignment:  0.9999
    Improvement:      -0.0000
  CKA Llama→Mistral after alignment: 0.9999
  WARNING: Orthogonality error = 0.033226
  Saved Procrustes alignment to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/procrustes_alignments/layer_8.pt

Testing generation...
  Prompt 1/5: The capital of France is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  WARNING: Orthogonality error = 0.033129
  Computing CKA similarity scores...
  CKA Mistral→Llama:
    Before alignment: 0.9999
    After alignment:  0.9999
    Improvement:      -0.0000
  CKA Llama→Mistral after alignment: 0.9999
  Saved Procrustes alignment to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/procrustes_alignments/layer_8.pt

Testing generation...
  Prompt 1/5: The capital of France is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city that is full of history and culture. It is a cit
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  WARNING: Orthogonality error = 0.033129
  Computing CKA similarity scores...
  CKA Mistral→Llama:
    Before alignment: 0.9999
    After alignment:  0.9999
    Improvement:      -0.0000
  CKA Llama→Mistral after alignment: 0.9999
  Saved Procrustes alignment to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/procrustes_alignments/layer_8.pt

Testing generation...
  Prompt 1/5: The capital of France is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city that is full of history and culture. It is a cit
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city of many faces. It is a city of history, a city o
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 552.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city that is full of history and culture. It is a cit
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city of many faces. It is a city of history, a city o
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 552.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city that is full of history and culture. It is a cit
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city of many faces. It is a city of history, a city o
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 552.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: als, the first thing that comes to mind is the word “architecture”. The word “
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city of many faces. It is a city of history, a city o
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 552.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: als, the first thing that comes to mind is the word “architecture”. The word “
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  the Clergy the Clergy the Clergy the Cler the Clergy the Cler the Cler the Cler
  Prompt 2/5: To solve this problem, we need to...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: als, the first thing that comes to mind is the word “architecture”. The word “
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  the Clergy the Clergy the Clergy the Cler the Clergy the Cler the Cler the Cler      Generated: als, the first thing that comes to mind is the word “architecture”. The word “
  Prompt 2/5: To solve this problem, we need to...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  the Clergy the Clergy the Clergy the Cler the Clergy the Cler the Cler the Cler
  Prompt 2/5: To solve this problem, we need to...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to understand the difference between the two type
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  the Clergy the Clergy the Clergy the Cler the Clergy the Cler the Cler the Cler
  Prompt 2/5: To solve this problem, we need to...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to understand the difference between the two type
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to find the value of the expression. We can do th
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 552.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to understand the difference between the two type
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to find the value of the expression. We can do th
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 552.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to understand the difference between the two type
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to find the value of the expression. We can do th
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 552.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the the the the architectural style of the building.

The architectural style of
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to find the value of the expression. We can do th
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 552.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the the the the architectural style of the building.

The architectural style of
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The
The
The
The
The
The




The
The
  Prompt 3/5: The future of artificial intelligence is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the the the the architectural style of the building.

The architectural style of
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The
The
The
The
The
The




The
The
  Prompt 3/5: The future of artificial intelligence is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the the the the architectural style of the building.

The architectural style of
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The
The
The
The
The
The




The
The
  Prompt 3/5: The future of artificial intelligence is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here.

The future of artificial intelli
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The
The
The
The
The
The




The
The
  Prompt 3/5: The future of artificial intelligence is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here.

The future of artificial intelli
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here, and it’s already changing the way
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 552.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here.

The future of artificial intelli
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here, and it’s already changing the way
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 552.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here.

The future of artificial intelli
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here, and it’s already changing the way
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 552.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: , the 2014 winner of the Pritzker Prize, the architecture world’s
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here, and it’s already changing the way
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 552.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: , the 2014 winner of the Pritzker Prize, the architecture world’s
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: ly
Arch
Arch
Arch
Arch
Arch
Arch
Arch



Arch
  Prompt 4/5: In the year 2050,...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: , the 2014 winner of the Pritzker Prize, the architecture world’s
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: ly
Arch
Arch
Arch
Arch
Arch
Arch
Arch



Arch
  Prompt 4/5: In the year 2050,...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: , the 2014 winner of the Pritzker Prize, the architecture world’s
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: ly
Arch
Arch
Arch
Arch
Arch
Arch
Arch



Arch
  Prompt 4/5: In the year 2050,...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The United States has bee
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: ly
Arch
Arch
Arch
Arch
Arch
Arch
Arch



Arch
  Prompt 4/5: In the year 2050,...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The United States has bee
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The population has grown 
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 552.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The United States has bee
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The population has grown 
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 552.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The United States has bee
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The population has grown 
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 552.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: , 1969, 1969, 1969, 
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The population has grown 
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 552.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: , 1969, 1969, 1969, 
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The Architectural
TheArchitectural'
TheArchitectural'
TheArchitectural
  Prompt 5/5: The main difference between cats and dogs is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: , 1969, 1969, 1969, 
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The Architectural
TheArchitectural'
TheArchitectural'
TheArchitectural
  Prompt 5/5: The main difference between cats and dogs is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: , 1969, 1969, 1969, 
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The Architectural
TheArchitectural'
TheArchitectural'
TheArchitectural
  Prompt 5/5: The main difference between cats and dogs is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are carnivores and dogs a
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The Architectural
TheArchitectural'
TheArchitectural'
TheArchitectural
  Prompt 5/5: The main difference between cats and dogs is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are carnivores and dogs a
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are solitary animals, whi
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 552.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are carnivores and dogs a
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are solitary animals, whi
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 552.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are carnivores and dogs a
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are solitary animals, whi
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 552.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 

The architectural style of the school is a modern interpretation of the tradit
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are solitary animals, whi
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 552.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 

The architectural style of the school is a modern interpretation of the tradit
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The Church of the Church of the Church of the Churchof the Churchof the Churcho

============================================================
Testing Layer 16
============================================================
      Generated: 

The architectural style of the school is a modern interpretation of the tradit
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The Church of the Church of the Church of the Churchof the Churchof the Churcho

============================================================
Testing Layer 16
============================================================
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
      Generated: 

The architectural style of the school is a modern interpretation of the tradit
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
The Church of the Church of the Church of the Churchof the Churchof the Churcho

============================================================
Testing Layer 16
============================================================
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
  WARNING: Orthogonality error = 0.033363
      Generated: 
The Church of the Church of the Church of the Churchof the Churchof the Churcho

============================================================
Testing Layer 16
============================================================
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
  WARNING: Orthogonality error = 0.033363
  WARNING: Orthogonality error = 0.033375
  Computing CKA similarity scores...
  CKA Mistral→Llama:
    Before alignment: 0.9997
    After alignment:  0.9997
    Improvement:      -0.0000
  CKA Llama→Mistral after alignment: 0.9997
  Saved Procrustes alignment to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/procrustes_alignments/layer_16.pt

Testing generation...
  Prompt 1/5: The capital of France is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  WARNING: Orthogonality error = 0.033363
      Generated: The capital of France is a city that is full of history and culture. It is a cit
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  WARNING: Orthogonality error = 0.033375
  Computing CKA similarity scores...
  CKA Mistral→Llama:
    Before alignment: 0.9997
    After alignment:  0.9997
    Improvement:      -0.0000
  CKA Llama→Mistral after alignment: 0.9997
  WARNING: Orthogonality error = 0.033363
  Saved Procrustes alignment to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/procrustes_alignments/layer_16.pt

Testing generation...
  Prompt 1/5: The capital of France is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city of many faces. It is a city of history, a city o
    Testing Llama→Mistral (cross-model via Procrustes)...
  WARNING: Orthogonality error = 0.033375
  Computing CKA similarity scores...
  CKA Mistral→Llama:
    Before alignment: 0.9997
    After alignment:  0.9997
    Improvement:      -0.0000
  CKA Llama→Mistral after alignment: 0.9997
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  Saved Procrustes alignment to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/procrustes_alignments/layer_16.pt

Testing generation...
  Prompt 1/5: The capital of France is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city that is full of history and culture. It is a cit
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  WARNING: Orthogonality error = 0.033375
  Computing CKA similarity scores...
  CKA Mistral→Llama:
    Before alignment: 0.9997
    After alignment:  0.9997
    Improvement:      -0.0000
  CKA Llama→Mistral after alignment: 0.9997
  Saved Procrustes alignment to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/procrustes_alignments/layer_16.pt

Testing generation...
  Prompt 1/5: The capital of France is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: s of the Church of the Holy Sepulchre, Jerusalem, 1850.
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city of many faces. It is a city of history, a city o
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city that is full of history and culture. It is a cit
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city that is full of history and culture. It is a cit
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  Church
The Arch
The Architectural
The Architect
The Architect






  Prompt 2/5: To solve this problem, we need to...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city of many faces. It is a city of history, a city o
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: s of the Church of the Holy Sepulchre, Jerusalem, 1850.
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city of many faces. It is a city of history, a city o
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to understand the difference between the two type
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  Church
The Arch
The Architectural
The Architect
The Architect






  Prompt 2/5: To solve this problem, we need to...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: s of the Church of the Holy Sepulchre, Jerusalem, 1850.
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: s of the Church of the Holy Sepulchre, Jerusalem, 1850.
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to find the value of the expression. We can do th
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  Church
The Arch
The Architectural
The Architect
The Architect






  Prompt 2/5: To solve this problem, we need to...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to understand the difference between the two type
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  Church
The Arch
The Architectural
The Architect
The Architect






  Prompt 2/5: To solve this problem, we need to...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the the the is the most important.

The most important thing is to have a good t
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to find the value of the expression. We can do th
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to understand the difference between the two type
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to understand the difference between the two type
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  of the Church of the Church of the Church of the Church of the Church of the Ch
  Prompt 3/5: The future of artificial intelligence is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to find the value of the expression. We can do th
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the the the is the most important.

The most important thing is to have a good t
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to find the value of the expression. We can do th
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here.

The future of artificial intelli
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  of the Church of the Church of the Church of the Church of the Church of the Ch
  Prompt 3/5: The future of artificial intelligence is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the the the is the most important.

The most important thing is to have a good t
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the the the is the most important.

The most important thing is to have a good t
    Testing Mistral→Llama (cross-model via Procrustes)...
      Generated: The future of artificial intelligence is here, and it’s already changing the way      Transformation norm: 556.0000
    Testing Llama→Mistral (cross-model via Procrustes)...

The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  of the Church of the Church of the Church of the Church of the Church of the Ch
  Prompt 3/5: The future of artificial intelligence is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here.

The future of artificial intelli
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  of the Church of the Church of the Church of the Church of the Church of the Ch
  Prompt 3/5: The future of artificial intelligence is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: , the building is a 19th century former church, which has been converted into a 
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here, and it’s already changing the way
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here.

The future of artificial intelli
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here.

The future of artificial intelli
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
Architectural
Architect
Architect
Architect





Arch
  Prompt 4/5: In the year 2050,...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here, and it’s already changing the way
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: , the building is a 19th century former church, which has been converted into a 
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here, and it’s already changing the way
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The United States has bee
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
Architectural
Architect
Architect
Architect





Arch
  Prompt 4/5: In the year 2050,...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: , the building is a 19th century former church, which has been converted into a 
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: , the building is a 19th century former church, which has been converted into a 
    Testing Mistral→Llama (cross-model via Procrustes)...
      Generated: In the year 2050, the world is a very different place. The population has grown 
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 556.0000      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
Architectural
Architect
Architect
Architect





Arch
  Prompt 4/5: In the year 2050,...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The United States has bee
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
Architectural
Architect
Architect
Architect





Arch
  Prompt 4/5: In the year 2050,...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the
 Question:

What is the difference between a "sandwich" and a "
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The population has grown 
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The United States has bee
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The United States has bee
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
Architectural
Architectural
Architect
Architect
Architect
Architect
  Prompt 5/5: The main difference between cats and dogs is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The population has grown 
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the
 Question:

What is the difference between a "sandwich" and a "
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The population has grown 
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are carnivores and dogs a
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
Architectural
Architectural
Architect
Architect
Architect
Architect
  Prompt 5/5: The main difference between cats and dogs is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the
 Question:

What is the difference between a "sandwich" and a "
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are solitary animals, whi
    Testing Llama→Mistral (cross-model via Procrustes)...
      Generated: the
 Question:

What is the difference between a "sandwich" and a "
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
Architectural
Architectural
Architect
Architect
Architect
Architect
  Prompt 5/5: The main difference between cats and dogs is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are carnivores and dogs a
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 
Architectural
Architectural
Architect
Architect
Architect
Architect
  Prompt 5/5: The main difference between cats and dogs is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 

The architectural style of the building is a combination of the traditional an
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are solitary animals, whi
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are carnivores and dogs a
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are carnivores and dogs a
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: a
Architectural
Architectural
Architect




Architect


============================================================
Testing Layer 24
============================================================
      Generated: The main difference between cats and dogs is that cats are solitary animals, whi
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 

The architectural style of the building is a combination of the traditional an
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
      Generated: The main difference between cats and dogs is that cats are solitary animals, whi
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: 

The architectural style of the building is a combination of the traditional an
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
      Generated: a
Architectural
Architectural
Architect




Architect
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


============================================================
Testing Layer 24
============================================================
      Generated: 

The architectural style of the building is a combination of the traditional an
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 556.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  WARNING: Orthogonality error = 0.034813
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
      Generated: a
Architectural
Architectural
Architect




Architect


============================================================
Testing Layer 24
============================================================
      Generated: a
Architectural
Architectural
Architect




Architect


============================================================
Testing Layer 24
============================================================
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
  WARNING: Orthogonality error = 0.034813
  WARNING: Orthogonality error = 0.035054
  Computing CKA similarity scores...
  CKA Mistral→Llama:
    Before alignment: 0.9948
    After alignment:  0.9948
    Improvement:      -0.0000
  CKA Llama→Mistral after alignment: 0.9948
  Saved Procrustes alignment to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/procrustes_alignments/layer_24.pt

Testing generation...
  Prompt 1/5: The capital of France is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city that is full of history and culture. It is a cit
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  WARNING: Orthogonality error = 0.034813
      Generated: The capital of France is a city of many faces. It is a city of history, a city o
    Testing Llama→Mistral (cross-model via Procrustes)...
  WARNING: Orthogonality error = 0.034813
      Transformation norm: 572.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the building is a 19th century church, which was converted into a house in the 
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 528.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  WARNING: Orthogonality error = 0.035054
  Computing CKA similarity scores...
  CKA Mistral→Llama:
    Before alignment: 0.9948
    After alignment:  0.9948
    Improvement:      -0.0000
  CKA Llama→Mistral after alignment: 0.9948
  Saved Procrustes alignment to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/procrustes_alignments/layer_24.pt

Testing generation...
  Prompt 1/5: The capital of France is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: , the house was built in the 1970s, the house was built in the 197
  Prompt 2/5: To solve this problem, we need to...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city that is full of history and culture. It is a cit
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  WARNING: Orthogonality error = 0.035054
  Computing CKA similarity scores...
  CKA Mistral→Llama:
    Before alignment: 0.9948
    After alignment:  0.9948
    Improvement:      -0.0000
  CKA Llama→Mistral after alignment: 0.9948
  Saved Procrustes alignment to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/procrustes_alignments/layer_24.pt

Testing generation...
  Prompt 1/5: The capital of France is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  WARNING: Orthogonality error = 0.035054
  Computing CKA similarity scores...
  CKA Mistral→Llama:
    Before alignment: 0.9948
    After alignment:  0.9948
    Improvement:      -0.0000
  CKA Llama→Mistral after alignment: 0.9948
  Saved Procrustes alignment to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/procrustes_alignments/layer_24.pt

Testing generation...
  Prompt 1/5: The capital of France is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to understand the difference between the two type
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city of many faces. It is a city of history, a city o
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 572.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to find the value of the expression. We can do th      Generated: The capital of France is a city that is full of history and culture. It is a cit
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 572.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city that is full of history and culture. It is a cit
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the building is a 19th century church, which was converted into a house in the 
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 528.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city of many faces. It is a city of history, a city o
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 572.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city of many faces. It is a city of history, a city o
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 572.0000      Generated: building is a 19th century brick building that was once the home of the local po
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 532.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: , the house was built in the 1970s, the house was built in the 197
  Prompt 2/5: To solve this problem, we need to...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the building is a 19th century church, which was converted into a house in the 
    Testing Mistral→Llama (cross-model via Procrustes)...
      Generated:  building is a structure that hasastructurethat hasapstructurethatwasathatwas現ha
  Prompt 3/5: The future of artificial intelligence is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Transformation norm: 528.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the building is a 19th century church, which was converted into a house in the 
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 528.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to understand the difference between the two type
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: , the house was built in the 1970s, the house was built in the 197
  Prompt 2/5: To solve this problem, we need to...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here.

The future of artificial intelli
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: , the house was built in the 1970s, the house was built in the 197
  Prompt 2/5: To solve this problem, we need to...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to find the value of the expression. We can do th
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 572.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here, and it’s already changing the way
    Testing Llama→Mistral (cross-model via Procrustes)...
      Generated: To solve this problem, we need to understand the difference between the two type
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Transformation norm: 572.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to understand the difference between the two type
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: building is a 19th century brick building that was once the home of the local po
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 532.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to find the value of the expression. We can do th
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 572.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to find the value of the expression. We can do th      Generated: , the, Question 1���� Questionnaire

The questionnaire is a tool
    Testing Llama→Mistral (cross-model via Procrustes)...

    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 572.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Transformation norm: 532.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  building is a structure that hasastructurethat hasapstructurethatwasathatwas現ha
  Prompt 3/5: The future of artificial intelligence is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: building is a 19th century brick building that was once the home of the local po      Generated:  for the 19th century, and the 19th century, and the  19th
    Testing Mistral→Llama (cross-model via Procrustes)...

  Prompt 4/5: In the year 2050,...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Transformation norm: 532.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: building is a 19th century brick building that was once the home of the local po
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 532.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here.

The future of artificial intelli
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  building is a structure that hasastructurethat hasapstructurethatwasathatwas現ha
  Prompt 3/5: The future of artificial intelligence is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The United States has bee
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  building is a structure that hasastructurethat hasapstructurethatwasathatwas現ha
  Prompt 3/5: The future of artificial intelligence is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here, and it’s already changing the way
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 572.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The population has grown 
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 572.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here.

The future of artificial intelli
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here.

The future of artificial intelli
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: , the, Question 1���� Questionnaire

The questionnaire is a tool
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 532.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here, and it’s already changing the way
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 572.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the Question is, and Question 2.2.

## What is the best way to
    Testing Mistral→Llama (cross-model via Procrustes)...
      Generated: The future of artificial intelligence is here, and it’s already changing the way
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 532.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Transformation norm: 572.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  for the 19th century, and the 19th century, and the  19th
  Prompt 4/5: In the year 2050,...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  the 19th-century, the 19th century, the  19th century, the
  Prompt 5/5: The main difference between cats and dogs is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: , the, Question 1���� Questionnaire

The questionnaire is a tool
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 532.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: , the, Question 1���� Questionnaire

The questionnaire is a tool
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 532.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The United States has bee
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  for the 19th century, and the 19th century, and the  19th
  Prompt 4/5: In the year 2050,...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are carnivores and dogs a
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  for the 19th century, and the 19th century, and the  19th
  Prompt 4/5: In the year 2050,...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The population has grown 
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 572.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are solitary animals, whi
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 572.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The United States has bee
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The United States has bee
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the Question is, and Question 2.2.

## What is the best way to
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 532.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The population has grown 
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 572.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the church of St. St. John the Baptist, the church of St. John the Bapt
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 532.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The population has grown 
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 572.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  the 19th-century, the 19th century, the  19th century, the
  Prompt 5/5: The main difference between cats and dogs is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  to the point of view, the point of view, the point of view, the point of view

============================================================
Testing Layer 32
============================================================
      Generated: the Question is, and Question 2.2.

## What is the best way to
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 532.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the Question is, and Question 2.2.

## What is the best way to
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 532.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
      Generated: The main difference between cats and dogs is that cats are carnivores and dogs a
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  the 19th-century, the 19th century, the  19th century, the
  Prompt 5/5: The main difference between cats and dogs is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  the 19th-century, the 19th century, the  19th century, the
  Prompt 5/5: The main difference between cats and dogs is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are solitary animals, whi
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 572.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are carnivores and dogs a
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are carnivores and dogs a
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the church of St. St. John the Baptist, the church of St. John the Bapt
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 532.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are solitary animals, whi
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 572.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are solitary animals, whi
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 572.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  WARNING: Orthogonality error = 0.102234
      Generated:  to the point of view, the point of view, the point of view, the point of view

============================================================
Testing Layer 32
============================================================
      Generated: the church of St. St. John the Baptist, the church of St. John the Bapt
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 532.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the church of St. St. John the Baptist, the church of St. John the Bapt
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 532.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
      Generated:  to the point of view, the point of view, the point of view, the point of view

============================================================
Testing Layer 32
============================================================
      Generated:  to the point of view, the point of view, the point of view, the point of view

============================================================
Testing Layer 32
============================================================
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
  Moving 570 samples to GPU 0 for fast SVD

Fitting Procrustes alignments on cuda...
  WARNING: Orthogonality error = 0.102734
  Computing CKA similarity scores...
  CKA Mistral→Llama:
    Before alignment: 0.4596
    After alignment:  0.4596
    Improvement:      -0.0000
  CKA Llama→Mistral after alignment: 0.4596
  Saved Procrustes alignment to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/procrustes_alignments/layer_32.pt

Testing generation...
  Prompt 1/5: The capital of France is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city that is full of history and culture. It is a cit
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city of many faces. It is a city of history, a city o
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 948.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  WARNING: Orthogonality error = 0.102234
      Generated: the bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan beka
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1032.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  sculpt,
  Prompt 2/5: To solve this problem, we need to...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to understand the difference between the two type
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  WARNING: Orthogonality error = 0.102234
      Generated: To solve this problem, we need to find the value of the expression. We can do th
    Testing Llama→Mistral (cross-model via Procrustes)...
  WARNING: Orthogonality error = 0.102234
      Transformation norm: 1192.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan beka
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1272.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  Bau,AAAAAAAA, said, said, said, said, said, said, said, said,
  Prompt 3/5: The future of artificial intelligence is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here.

The future of artificial intelli
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  WARNING: Orthogonality error = 0.102734
  Computing CKA similarity scores...
  CKA Mistral→Llama:
    Before alignment: 0.4596
    After alignment:  0.4596
    Improvement:      -0.0000
  CKA Llama→Mistral after alignment: 0.4596
  Saved Procrustes alignment to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/procrustes_alignments/layer_32.pt

Testing generation...
  Prompt 1/5: The capital of France is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here, and it’s already changing the way
    Testing Llama→Mistral (cross-model via Procrustes)...
      Generated: The capital of France is a city that is full of history and culture. It is a cit
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Transformation norm: 1040.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  WARNING: Orthogonality error = 0.102734
  Computing CKA similarity scores...
  CKA Mistral→Llama:
    Before alignment: 0.4596
    After alignment:  0.4596
    Improvement:      -0.0000
  CKA Llama→Mistral after alignment: 0.4596
  Saved Procrustes alignment to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/procrustes_alignments/layer_32.pt

Testing generation...
  Prompt 1/5: The capital of France is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  WARNING: Orthogonality error = 0.102734
  Computing CKA similarity scores...
  CKA Mistral→Llama:
    Before alignment: 0.4596
    After alignment:  0.4596
    Improvement:      -0.0000
  CKA Llama→Mistral after alignment: 0.4596
  Saved Procrustes alignment to /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/procrustes_alignments/layer_32.pt

Testing generation...
  Prompt 1/5: The capital of France is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city of many faces. It is a city of history, a city o
    Testing Llama→Mistral (cross-model via Procrustes)...
      Generated: the bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan beka
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 948.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Transformation norm: 1152.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city that is full of history and culture. It is a cit
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  often the the theoo, the first, the second, the third, the fourth, the fifth
  Prompt 4/5: In the year 2050,...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city that is full of history and culture. It is a cit
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan beka
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1032.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  sculpt,
  Prompt 2/5: To solve this problem, we need to...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city of many faces. It is a city of history, a city o
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 948.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The capital of France is a city of many faces. It is a city of history, a city o
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 948.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The United States has bee
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to understand the difference between the two type
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The population has grown 
    Testing Llama→Mistral (cross-model via Procrustes)...
      Generated: the bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan beka
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1072.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Transformation norm: 1032.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  sculpt,
  Prompt 2/5: To solve this problem, we need to...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan beka
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1032.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to find the value of the expression. We can do th      Generated:  sculpt,
    Testing Llama→Mistral (cross-model via Procrustes)...

  Prompt 2/5: To solve this problem, we need to...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Transformation norm: 1192.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan beka
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1216.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to understand the difference between the two type
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to understand the difference between the two type
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan beka
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1272.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  monuments,://AAAAAAAAA, 2, 2, 2, 2, 2
  Prompt 5/5: The main difference between cats and dogs is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to find the value of the expression. We can do th
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1192.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: To solve this problem, we need to find the value of the expression. We can do th
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1192.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  Bau,AAAAAAAA, said, said, said, said, said, said, said, said,
  Prompt 3/5: The future of artificial intelligence is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are carnivores and dogs a
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan beka
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1272.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan beka
    Testing Mistral→Llama (cross-model via Procrustes)...
      Generated: The future of artificial intelligence is here.

The future of artificial intelli
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Transformation norm: 1272.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are solitary animals, whi
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1168.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  Bau,AAAAAAAA, said, said, said, said, said, said, said, said,
  Prompt 3/5: The future of artificial intelligence is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here, and it’s already changing the way
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1040.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  Bau,AAAAAAAA, said, said, said, said, said, said, said, said,
  Prompt 3/5: The future of artificial intelligence is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: and bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan beka
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1280.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: racl,      Generated: The future of artificial intelligence is here.

The future of artificial intelli
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.


================================================================================
PROCRUSTES EXPERIMENT SUMMARY
================================================================================

Layer 0:
  Baselines:
    Mistral→Mistral: 5/5 succeeded
    Llama→Llama: 5/5 succeeded
  Cross-model:
    Llama→Mistral: 5/5 succeeded, 0/5 failed
    Mistral→Llama: 5/5 succeeded, 0/5 failed

Layer 8:
  Baselines:
    Mistral→Mistral: 5/5 succeeded
    Llama→Llama: 5/5 succeeded
  Cross-model:
    Llama→Mistral: 5/5 succeeded, 0/5 failed
    Mistral→Llama: 5/5 succeeded, 0/5 failed

Layer 16:
  Baselines:
    Mistral→Mistral: 5/5 succeeded
    Llama→Llama: 5/5 succeeded
  Cross-model:
    Llama→Mistral: 5/5 succeeded, 0/5 failed
    Mistral→Llama: 5/5 succeeded, 0/5 failed

Layer 24:
  Baselines:
    Mistral→Mistral: 5/5 succeeded
    Llama→Llama: 5/5 succeeded
  Cross-model:
    Llama→Mistral: 5/5 succeeded, 0/5 failed
    Mistral→Llama: 5/5 succeeded, 0/5 failed

Layer 32:
  Baselines:
    Mistral→Mistral: 5/5 succeeded
    Llama→Llama: 5/5 succeeded
  Cross-model:
    Llama→Mistral: 5/5 succeeded, 0/5 failed
    Mistral→Llama: 5/5 succeeded, 0/5 failed
================================================================================

Cleaning up Procrustes experiment...
      Generated: the bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan beka
    Testing Mistral→Llama (cross-model via Procrustes)...
      Generated: The future of artificial intelligence is here.

The future of artificial intelli
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Transformation norm: 1152.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  Models deleted and GPU memory cleared
Procrustes results saved to: /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/unified_experiments/procrustes_results_20251031_232542.json

Cleaning up GPU memory...
  GPU cache cleared

2. Starting all experiments sequentially (PRIORITY ORDER)...
Strategy: Each experiment uses all 4 GPUs for faster completion
Priority: LoRA → Activation → Token Compression → Linear → Affine
Benefits: Critical experiments first + full GPU utilization


================================================================================
EXPERIMENT 2/6: LORA ADAPTER (PRIORITY 1)
================================================================================
Why First: 260K params vs 16M (98% reduction), transferable across models

================================================================================
LEARNED ADAPTER EXPERIMENT - LORA
================================================================================
Platform: hpc
Log file: /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/learned_adapters/lora_allgpus_20251031_233036.log
[W1031 23:30:36.021805023 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())

================================================================================
GPU CONFIGURATION
================================================================================
Mode: DistributedDataParallel (DDP)
Number of GPUs: 4
GPU IDs: [0, 1, 2, 3]
Rank: 0, Device: cuda:0
Batch size per GPU: 10
Global batch size: 40
Effective batch (with grad accum): 320
================================================================================


Loading models on hpc...
Using bfloat16 for H100
Using Flash Attention 2
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|##########| 4/4 [00:00<00:00, 4069.18it/s]
      Generated: The future of artificial intelligence is here, and it’s already changing the way
    Testing Llama→Mistral (cross-model via Procrustes)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]      Transformation norm: 1040.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The future of artificial intelligence is here, and it’s already changing the way
    Testing Llama→Mistral (cross-model via Procrustes)...
      Generated:  often the the theoo, the first, the second, the third, the fourth, the fifth
  Prompt 4/5: In the year 2050,...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Transformation norm: 1040.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Loading checkpoint shards:  25%|##5       | 1/4 [00:00<00:01,  2.11it/s]Loading checkpoint shards:  50%|#####     | 2/4 [00:00<00:00,  2.95it/s]Loading checkpoint shards:  75%|#######5  | 3/4 [00:00<00:00,  3.38it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:01<00:00,  3.38it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:01<00:00,  3.16it/s]
      Generated: the bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan beka
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1152.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The United States has bee
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan beka
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1152.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  often the the theoo, the first, the second, the third, the fourth, the fifth
  Prompt 4/5: In the year 2050,...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The population has grown 
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1072.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  often the the theoo, the first, the second, the third, the fourth, the fifth
  Prompt 4/5: In the year 2050,...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The United States has bee
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan beka
    Testing Mistral→Llama (cross-model via Procrustes)...
      Generated: In the year 2050, the world is a very different place. The United States has bee      Transformation norm: 1216.0000
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: In the year 2050, the world is a very different place. The population has grown 
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1072.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  monuments,://AAAAAAAAA, 2, 2, 2, 2, 2      Generated: In the year 2050, the world is a very different place. The population has grown 
  Prompt 5/5: The main difference between cats and dogs is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1072.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan beka
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1216.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are carnivores and dogs a
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: the bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan beka
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1216.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  monuments,://AAAAAAAAA, 2, 2, 2, 2, 2
  Prompt 5/5: The main difference between cats and dogs is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are solitary animals, whi
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1168.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated:  monuments,://AAAAAAAAA, 2, 2, 2, 2, 2
  Prompt 5/5: The main difference between cats and dogs is...
    Testing Mistral→Mistral (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are carnivores and dogs a
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: and bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan beka
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1280.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: The main difference between cats and dogs is that cats are carnivores and dogs a
    Testing Llama→Llama (baseline)...
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
      Generated: racl,

================================================================================
PROCRUSTES EXPERIMENT SUMMARY
================================================================================

Layer 0:
  Baselines:
    Mistral→Mistral: 5/5 succeeded
    Llama→Llama: 5/5 succeeded
  Cross-model:
    Llama→Mistral: 5/5 succeeded, 0/5 failed
    Mistral→Llama: 5/5 succeeded, 0/5 failed

Layer 8:
  Baselines:
    Mistral→Mistral: 5/5 succeeded
    Llama→Llama: 5/5 succeeded
  Cross-model:
    Llama→Mistral: 5/5 succeeded, 0/5 failed
    Mistral→Llama: 5/5 succeeded, 0/5 failed

Layer 16:
  Baselines:
    Mistral→Mistral: 5/5 succeeded
    Llama→Llama: 5/5 succeeded
  Cross-model:
    Llama→Mistral: 5/5 succeeded, 0/5 failed
    Mistral→Llama: 5/5 succeeded, 0/5 failed

Layer 24:
  Baselines:
    Mistral→Mistral: 5/5 succeeded
    Llama→Llama: 5/5 succeeded
  Cross-model:
    Llama→Mistral: 5/5 succeeded, 0/5 failed
    Mistral→Llama: 5/5 succeeded, 0/5 failed

Layer 32:
  Baselines:
    Mistral→Mistral: 5/5 succeeded
    Llama→Llama: 5/5 succeeded
  Cross-model:
    Llama→Mistral: 5/5 succeeded, 0/5 failed
    Mistral→Llama: 5/5 succeeded, 0/5 failed
================================================================================

Cleaning up Procrustes experiment...
      Generated: The main difference between cats and dogs is that cats are solitary animals, whi
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1168.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  Models deleted and GPU memory cleared
Procrustes results saved to: /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/unified_experiments/procrustes_results_20251031_232542.json

Cleaning up GPU memory...
  GPU cache cleared

2. Starting all experiments sequentially (PRIORITY ORDER)...
Strategy: Each experiment uses all 4 GPUs for faster completion
Priority: LoRA → Activation → Token Compression → Linear → Affine
Benefits: Critical experiments first + full GPU utilization


================================================================================
EXPERIMENT 2/6: LORA ADAPTER (PRIORITY 1)
================================================================================
Why First: 260K params vs 16M (98% reduction), transferable across models

================================================================================
LEARNED ADAPTER EXPERIMENT - LORA
================================================================================
Platform: hpc
Log file: /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/learned_adapters/lora_allgpus_20251031_233049.log
[W1031 23:30:49.002599924 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
      Generated: The main difference between cats and dogs is that cats are solitary animals, whi
    Testing Llama→Mistral (cross-model via Procrustes)...
      Transformation norm: 1168.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.

Loading models on hpc...
Using bfloat16 for H100
Using Flash Attention 2
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|##########| 4/4 [00:00<00:00, 9172.89it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]      Generated: and bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan beka
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1280.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Loading checkpoint shards:  25%|##5       | 1/4 [00:00<00:01,  1.83it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Loading checkpoint shards:  50%|#####     | 2/4 [00:00<00:00,  2.65it/s]      Generated: racl,

================================================================================
PROCRUSTES EXPERIMENT SUMMARY
================================================================================

Layer 0:
  Baselines:
    Mistral→Mistral: 5/5 succeeded
    Llama→Llama: 5/5 succeeded
  Cross-model:
    Llama→Mistral: 5/5 succeeded, 0/5 failed
    Mistral→Llama: 5/5 succeeded, 0/5 failed

Layer 8:
  Baselines:
    Mistral→Mistral: 5/5 succeeded
    Llama→Llama: 5/5 succeeded
  Cross-model:
    Llama→Mistral: 5/5 succeeded, 0/5 failed
    Mistral→Llama: 5/5 succeeded, 0/5 failed

Layer 16:
  Baselines:
    Mistral→Mistral: 5/5 succeeded
    Llama→Llama: 5/5 succeeded
  Cross-model:
    Llama→Mistral: 5/5 succeeded, 0/5 failed
    Mistral→Llama: 5/5 succeeded, 0/5 failed

Layer 24:
  Baselines:
    Mistral→Mistral: 5/5 succeeded
    Llama→Llama: 5/5 succeeded
  Cross-model:
    Llama→Mistral: 5/5 succeeded, 0/5 failed
    Mistral→Llama: 5/5 succeeded, 0/5 failed

Layer 32:
  Baselines:
    Mistral→Mistral: 5/5 succeeded
    Llama→Llama: 5/5 succeeded
  Cross-model:
    Llama→Mistral: 5/5 succeeded, 0/5 failed
    Mistral→Llama: 5/5 succeeded, 0/5 failed
================================================================================

Cleaning up Procrustes experiment...
      Generated: and bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan bekan beka
    Testing Mistral→Llama (cross-model via Procrustes)...
      Transformation norm: 1280.0000
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
Loading checkpoint shards:  75%|#######5  | 3/4 [00:01<00:00,  3.12it/s]      Generated: racl,

================================================================================
PROCRUSTES EXPERIMENT SUMMARY
================================================================================

Layer 0:
  Baselines:
    Mistral→Mistral: 5/5 succeeded
    Llama→Llama: 5/5 succeeded
  Cross-model:
    Llama→Mistral: 5/5 succeeded, 0/5 failed
    Mistral→Llama: 5/5 succeeded, 0/5 failed

Layer 8:
  Baselines:
    Mistral→Mistral: 5/5 succeeded
    Llama→Llama: 5/5 succeeded
  Cross-model:
    Llama→Mistral: 5/5 succeeded, 0/5 failed
    Mistral→Llama: 5/5 succeeded, 0/5 failed

Layer 16:
  Baselines:
    Mistral→Mistral: 5/5 succeeded
    Llama→Llama: 5/5 succeeded
  Cross-model:
    Llama→Mistral: 5/5 succeeded, 0/5 failed
    Mistral→Llama: 5/5 succeeded, 0/5 failed

Layer 24:
  Baselines:
    Mistral→Mistral: 5/5 succeeded
    Llama→Llama: 5/5 succeeded
  Cross-model:
    Llama→Mistral: 5/5 succeeded, 0/5 failed
    Mistral→Llama: 5/5 succeeded, 0/5 failed

Layer 32:
  Baselines:
    Mistral→Mistral: 5/5 succeeded
    Llama→Llama: 5/5 succeeded
  Cross-model:
    Llama→Mistral: 5/5 succeeded, 0/5 failed
    Mistral→Llama: 5/5 succeeded, 0/5 failed
================================================================================

Cleaning up Procrustes experiment...
Loading checkpoint shards: 100%|##########| 4/4 [00:01<00:00,  3.49it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:01<00:00,  3.03it/s]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|##########| 3/3 [00:00<00:00, 3833.92it/s]
  Models deleted and GPU memory cleared
Procrustes results saved to: /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/unified_experiments/procrustes_results_20251031_232542.json

Cleaning up GPU memory...
  GPU cache cleared

2. Starting all experiments sequentially (PRIORITY ORDER)...
Strategy: Each experiment uses all 4 GPUs for faster completion
Priority: LoRA → Activation → Token Compression → Linear → Affine
Benefits: Critical experiments first + full GPU utilization


================================================================================
EXPERIMENT 2/6: LORA ADAPTER (PRIORITY 1)
================================================================================
Why First: 260K params vs 16M (98% reduction), transferable across models

================================================================================
LEARNED ADAPTER EXPERIMENT - LORA
================================================================================
Platform: hpc
Log file: /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/learned_adapters/lora_allgpus_20251031_233053.log
[W1031 23:30:53.075415668 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|###3      | 1/3 [00:00<00:00,  2.57it/s]  Models deleted and GPU memory cleared
Procrustes results saved to: /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/unified_experiments/procrustes_results_20251031_232542.json

Cleaning up GPU memory...
  GPU cache cleared

2. Starting all experiments sequentially (PRIORITY ORDER)...
Strategy: Each experiment uses all 4 GPUs for faster completion
Priority: LoRA → Activation → Token Compression → Linear → Affine
Benefits: Critical experiments first + full GPU utilization


================================================================================
EXPERIMENT 2/6: LORA ADAPTER (PRIORITY 1)
================================================================================
Why First: 260K params vs 16M (98% reduction), transferable across models

================================================================================
LEARNED ADAPTER EXPERIMENT - LORA
================================================================================
Platform: hpc
Log file: /projects/m000066/sujinesh/LatentWire/experimental/learning/runs/learned_adapters/lora_allgpus_20251031_233053.log
[W1031 23:30:53.756487112 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())

Loading models on hpc...
Using bfloat16 for H100
Using Flash Attention 2
Loading checkpoint shards:  67%|######6   | 2/3 [00:00<00:00,  2.70it/s]
Loading models on hpc...
Using bfloat16 for H100
Using Flash Attention 2
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|##########| 4/4 [00:00<00:00, 8834.76it/s]
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|##########| 4/4 [00:00<00:00, 8839.42it/s]
Loading checkpoint shards: 100%|##########| 3/3 [00:01<00:00,  3.14it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:01<00:00,  2.95it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|##5       | 1/4 [00:00<00:01,  1.94it/s]Loading checkpoint shards:  25%|##5       | 1/4 [00:00<00:01,  1.90it/s]Loading checkpoint shards:  50%|#####     | 2/4 [00:00<00:00,  2.27it/s]Loading checkpoint shards:  50%|#####     | 2/4 [00:00<00:00,  2.33it/s]Loading checkpoint shards:  75%|#######5  | 3/4 [00:01<00:00,  2.58it/s]Loading checkpoint shards:  75%|#######5  | 3/4 [00:01<00:00,  2.55it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:01<00:00,  2.86it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:01<00:00,  2.62it/s]
Loading checkpoint shards: 100%|##########| 4/4 [00:01<00:00,  2.85it/s]Loading checkpoint shards: 100%|##########| 4/4 [00:01<00:00,  2.62it/s]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|##########| 3/3 [00:00<00:00, 6096.37it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|###3      | 1/3 [00:00<00:00,  2.26it/s]Loading checkpoint shards:  67%|######6   | 2/3 [00:00<00:00,  2.77it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:01<00:00,  3.03it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:01<00:00,  2.86it/s]
[rank0]:[W1031 23:31:08.700535213 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|##########| 3/3 [00:00<00:00, 8630.26it/s]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|##########| 3/3 [00:00<00:00, 9539.74it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|###3      | 1/3 [00:00<00:00,  2.01it/s]Loading checkpoint shards:  33%|###3      | 1/3 [00:00<00:01,  1.89it/s]Loading checkpoint shards:  67%|######6   | 2/3 [00:00<00:00,  2.10it/s]Loading checkpoint shards:  67%|######6   | 2/3 [00:00<00:00,  2.04it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:01<00:00,  2.17it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:01<00:00,  2.14it/s]
Loading checkpoint shards: 100%|##########| 3/3 [00:01<00:00,  2.19it/s]Loading checkpoint shards: 100%|##########| 3/3 [00:01<00:00,  2.13it/s]
[rank2]:[W1031 23:31:26.555625231 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank3]:[W1031 23:31:29.335522327 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank1]:[W1031 23:31:29.335389306 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.

================================================================================
Epoch 1/5
================================================================================
  [ 40.0%] Step  100/250 | Loss: 11.2219 (Gen: 10.9688, Contr: 2.3037, Align: 105.2686, Uniform: -0.9367) | ContrW: 0.120 | LR: 4.93e-05 | GradNorm: 0.000 | 0.38 steps/s | ETA: 6.5m
  [ 40.0%] Step  100/250 | Loss: 11.2239 (Gen: 10.9707, Contr: 2.3043, Align: 103.4951, Uniform: -0.9477) | ContrW: 0.120 | LR: 4.93e-05 | GradNorm: 0.000 | 0.38 steps/s | ETA: 6.5m
  [ 40.0%] Step  100/250 | Loss: 11.1569 (Gen: 10.9037, Contr: 2.3038, Align: 106.6591, Uniform: -0.9640) | ContrW: 0.120 | LR: 4.93e-05 | GradNorm: 0.000 | 0.38 steps/s | ETA: 6.5m
  [ 40.0%] Step  100/250 | Loss: 11.2036 (Gen: 10.9506, Contr: 2.3020, Align: 102.1190, Uniform: -0.9502) | ContrW: 0.120 | LR: 4.93e-05 | GradNorm: 0.000 | 0.38 steps/s | ETA: 6.5m
  [ 80.0%] Step  200/250 | Loss: 10.9563 (Gen: 10.6802, Contr: 2.3026, Align: 103.6846, Uniform: -0.9459) | ContrW: 0.140 | LR: 4.69e-05 | GradNorm: 4.875 | 0.39 steps/s | ETA: 2.2m
  [ 80.0%] Step  200/250 | Loss: 10.9730 (Gen: 10.6968, Contr: 2.3038, Align: 105.1294, Uniform: -0.9485) | ContrW: 0.140 | LR: 4.69e-05 | GradNorm: 4.875 | 0.39 steps/s | ETA: 2.2m
  [ 80.0%] Step  200/250 | Loss: 10.9657 (Gen: 10.6895, Contr: 2.3031, Align: 103.9945, Uniform: -0.9383) | ContrW: 0.140 | LR: 4.69e-05 | GradNorm: 4.875 | 0.39 steps/s | ETA: 2.2m
  [ 80.0%] Step  200/250 | Loss: 10.9189 (Gen: 10.6426, Contr: 2.3042, Align: 107.2572, Uniform: -0.9575) | ContrW: 0.140 | LR: 4.69e-05 | GradNorm: 4.875 | 0.39 steps/s | ETA: 2.2m

  Computing multi-layer CKA similarity...

================================================================================
LORA ADAPTER EXPERIMENT FAILED
================================================================================
Error: The size of tensor a (10) must match the size of tensor b (12) at non-singleton dimension 1
Traceback (most recent call last):
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 2291, in run_adapter_experiment
    adapter, metrics = train_adapter(
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 2023, in train_adapter
    eval_results = evaluate_adapter_epoch(
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 1518, in evaluate_adapter_epoch
    cka_score = CKA.cka_similarity(adapted_flat, target_flat, debiased=False)
  File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 380, in cka_similarity
    hsic = torch.sum(K_c * L_c)
RuntimeError: The size of tensor a (10) must match the size of tensor b (12) at non-singleton dimension 1
[rank0]: Traceback (most recent call last):
[rank0]:   File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 3390, in <module>
[rank0]:     main()
[rank0]:   File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 3265, in main
[rank0]:     run_adapter_experiment("lora", gpu_id=None)  # None = use all GPUs with DDP
[rank0]:   File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 2291, in run_adapter_experiment
[rank0]:     adapter, metrics = train_adapter(
[rank0]:   File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 2023, in train_adapter
[rank0]:     eval_results = evaluate_adapter_epoch(
[rank0]:   File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 1518, in evaluate_adapter_epoch
[rank0]:     cka_score = CKA.cka_similarity(adapted_flat, target_flat, debiased=False)
[rank0]:   File "/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py", line 380, in cka_similarity
[rank0]:     hsic = torch.sum(K_c * L_c)
[rank0]: RuntimeError: The size of tensor a (10) must match the size of tensor b (12) at non-singleton dimension 1
W1031 23:43:23.538000 1495247 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1495308 closing signal SIGTERM
W1031 23:43:23.539000 1495247 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1495310 closing signal SIGTERM
W1031 23:43:23.539000 1495247 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1495319 closing signal SIGTERM
/marlowe/apps/Mambaforge/24.3.0-0/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/marlowe/apps/Mambaforge/24.3.0-0/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/marlowe/apps/Mambaforge/24.3.0-0/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
E1031 23:43:26.583000 1495247 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 1495307) of binary: /marlowe/apps/Mambaforge/24.3.0-0/bin/python
Traceback (most recent call last):
  File "/users/sujinesh/.local/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/projects/m000066/sujinesh/LatentWire/experimental/learning/unified_cross_model_experiments.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-10-31_23:43:23
  host      : n12.cm.cluster
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1495307)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
