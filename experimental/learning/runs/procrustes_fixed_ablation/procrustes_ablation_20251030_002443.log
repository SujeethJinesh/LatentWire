/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
================================================================================
PROCRUSTES FIXED ABLATION - STARTING
================================================================================
Python version: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]
PyTorch version: 2.5.1+cu121
CUDA available: True
CUDA device count: 1
CUDA current device: 0
Script: /projects/m000066/sujinesh/LatentWire/experimental/learning/procrustes_fixed_ablation.py
================================================================================

================================================================================
PROCRUSTES FIXED ABLATION - Layer Selection Study
================================================================================
Layers to test: [0, 8, 16, 24, 32]
Test prompts: 5
Device: cuda:0

Loading models...
  Llama: meta-llama/Llama-3.1-8B
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 1283.35it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:18<00:56, 18.77s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:36<00:36, 18.23s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:54<00:18, 18.24s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:59<00:00, 12.82s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:59<00:00, 14.85s/it]
  ✓ Llama loaded
  Mistral: mistralai/Mistral-7B-v0.3
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 3569.62it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:18<00:36, 18.12s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:35<00:17, 17.89s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:52<00:00, 17.29s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:52<00:00, 17.47s/it]
  ✓ Mistral loaded

Loading 100 calibration texts from SQuAD...
  Checking cache at: /projects/m000066/sujinesh/.cache/huggingface/datasets/rajpurkar___squad
  Cache exists: False
  Cache directory does not exist - proceeding with fresh download
Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]Generating train split:  35%|███▌      | 31000/87599 [00:00<00:00, 269402.11 examples/s]Generating train split: 100%|██████████| 87599/87599 [00:00<00:00, 362093.70 examples/s]
Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]Generating validation split: 100%|██████████| 10570/10570 [00:00<00:00, 410642.57 examples/s]
We detected that you are passing `past_key_values` as a tuple of tuples. This is deprecated and will be removed in v4.47. Please convert your cache or use an appropriate `Cache` class (https://huggingface.co/docs/transformers/kv_cache#legacy-cache-format)
We detected that you are passing `past_key_values` as a tuple of tuples. This is deprecated and will be removed in v4.47. Please convert your cache or use an appropriate `Cache` class (https://huggingface.co/docs/transformers/kv_cache#legacy-cache-format)
  ✓ Loaded 100 texts

================================================================================
LAYER 0: Embedding Space
================================================================================

[1/3] Mistral → Mistral (sanity check)
----------------------------------------
  Calibrating Procrustes for layer 0...
  Extracting representations from 100 texts...
  Representation shape: torch.Size([7053, 4096])
  Source mean norm: 0.0284
  Target mean norm: 0.0284
  Source Frobenius norm: 10.7734
  Target Frobenius norm: 10.7734
  ✓ Rotation matrix W: torch.Size([4096, 4096])
  Singular values (top 5): [0.03350268304347992, 0.030519554391503334, 0.024173850193619728, 0.023767126724123955, 0.023054342716932297]
  ✓ Calibration complete
  [1/5] Generating: The capital of France is...
       → The capital of France isa city of many faces. It is a city of history, culture, art, fashion, and gastronomy. It is a city of romance, of love, of passion. It is a city of light, of life, of joy.
  [2/5] Generating: To solve this problem, we need to...
       → To solve this problem, we need tounderstand the problem.

The problem is that the `<input>` element is not a `<button>` element.

The `<input>` element is a `<button>` element.

The `<
  [3/5] Generating: The future of artificial intelligence is...
       → The future of artificial intelligence ishere.

The future of artificial intelligence is here.

The future of artificial intelligence is here.

The future of artificial intelligence is here.

The future of artificial intelligence is here.

The future of artificial intelligence is
  [4/5] Generating: In the year 2050,...
       → In the year 2050,the world is in a state of chaos. The United States has been divided into three separate countries, and the rest of the world is in a state of war. The only hope for humanity is a group of young people who have been chosen to save
  [5/5] Generating: The main difference between cats and dogs is...
       → The main difference between cats and dogs isthat cats are carnivores and dogs are omnivores. Cats are obligate carnivores, which means that they need meat to survive. Dogs are omnivores, which means that they can survive on a

[2/3] Llama → Mistral (cross-model)
----------------------------------------
  Calibrating Procrustes for layer 0...
  Extracting representations from 100 texts...
  Representation shape: torch.Size([6057, 4096])
  Source mean norm: 0.1456
  Target mean norm: 0.0284
  Source Frobenius norm: 40.9375
  Target Frobenius norm: 9.9688
  ✓ Rotation matrix W: torch.Size([4096, 4096])
  Singular values (top 5): [0.003383505856618285, 0.003035870613530278, 0.002639685058966279, 0.002317155245691538, 0.0022113732993602753]
  ✓ Calibration complete
  [1/5] Generating: The capital of France is...
       → The capital of France is.

The first thing you need to do is to find a good online casino that offers the game you want to play. There are many different online casinos out there, so it can be difficult to find the right one. However, there
  [2/5] Generating: To solve this problem, we need to...
       → To solve this problem, we need to.

## 10.1.1.

The _Fractional State_ of the art is a very important concept in the field of mathematics. The _Fractional State_ of the art is a very important
  [3/5] Generating: The future of artificial intelligence is...
       → The future of artificial intelligence is

The 2018-19 season was a season of firsts for the UConn women’s basketball team.

The Huskies won their first national championship since 2016, their first under head
  [4/5] Generating: In the year 2050,...
       → In the year 2050,.

The first thing you notice about the house is the beautiful garden. It is a large garden with a variety of plants and flowers. The house itself is also very beautiful. It is a large house with a lot of rooms. The house
  [5/5] Generating: The main difference between cats and dogs is...
       → The main difference between cats and dogs is.

The first step in the process is to identify the type of education you want to pursue. There are many different types of education available, so it is important to choose one that is right for you. Once you have identified the type of

[3/3] Mistral → Llama (cross-model)
----------------------------------------
  Calibrating Procrustes for layer 0...
  Extracting representations from 100 texts...
  Representation shape: torch.Size([6057, 4096])
  Source mean norm: 0.0284
  Target mean norm: 0.1456
  Source Frobenius norm: 9.9688
  Target Frobenius norm: 40.9375
  ✓ Rotation matrix W: torch.Size([4096, 4096])
  Singular values (top 5): [0.00338398152962327, 0.0030352771282196045, 0.0026398119516670704, 0.0023171966895461082, 0.002211085520684719]
  ✓ Calibration complete
  [1/5] Generating: The capital of France is...
       → The capital of France is the. The of the and the. The of the and the. The of the and the. The of the and the. The of the and the. The of the and the. The of the and the. The of the and the.
  [2/5] Generating: To solve this problem, we need to...
       → To solve this problem, we need to inquisit inquisitio inquisitio inquisitio inquisitio inquisitio inquisitio inquisitio inquisitio inquisitio inquisitio inquisitio inquisit
  [3/5] Generating: The future of artificial intelligence is...
       → The future of artificial intelligence is the. The 2019-2020 school year, the school is a public school located in the 2019-2020 school year, the school is a public school located in the 2019-2020 school year, the school
  [4/5] Generating: In the year 2050,...
       → In the year 2050,
The 2018-19 season is the 50th season of the National Hockey League. The regular season began on October 3, 2018, and ended on April 6, 2019. The 2019 Stanley Cup
  [5/5] Generating: The main difference between cats and dogs is...
       → The main difference between cats and dogs is. The 2018-2019 school year is the 2nd year of the 5-year plan. The 2018-2019 school year is the 2nd year of the 5-year plan. The 2018-

================================================================================
LAYER 8: Hidden States Layer 8
================================================================================

[1/3] Mistral → Mistral (sanity check)
----------------------------------------
  Calibrating Procrustes for layer 8...
  Extracting representations from 100 texts...
  Representation shape: torch.Size([7053, 4096])
  Source mean norm: 3.7910
  Target mean norm: 3.7910
  Source Frobenius norm: inf
  Target Frobenius norm: inf
  ✓ Rotation matrix W: torch.Size([4096, 4096])
  Singular values (top 5): [9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07]
  ✓ Calibration complete
  [1/5] Generating: The capital of France is...
       → The capital of France is
  [2/5] Generating: To solve this problem, we need to...
       → To solve this problem, we need to
  [3/5] Generating: The future of artificial intelligence is...
       → The future of artificial intelligence is
  [4/5] Generating: In the year 2050,...
       → In the year 2050,
  [5/5] Generating: The main difference between cats and dogs is...
       → The main difference between cats and dogs is

[2/3] Llama → Mistral (cross-model)
----------------------------------------
  Calibrating Procrustes for layer 8...
  Extracting representations from 100 texts...
  Representation shape: torch.Size([6057, 4096])
  Source mean norm: 8.4531
  Target mean norm: 3.7930
  Source Frobenius norm: inf
  Target Frobenius norm: inf
  ✓ Rotation matrix W: torch.Size([4096, 4096])
  Singular values (top 5): [9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07]
  ✓ Calibration complete
  [1/5] Generating: The capital of France is...
       → The capital of France is
  [2/5] Generating: To solve this problem, we need to...
       → To solve this problem, we need to
  [3/5] Generating: The future of artificial intelligence is...
       → The future of artificial intelligence is
  [4/5] Generating: In the year 2050,...
       → In the year 2050,
  [5/5] Generating: The main difference between cats and dogs is...
       → The main difference between cats and dogs is

[3/3] Mistral → Llama (cross-model)
----------------------------------------
  Calibrating Procrustes for layer 8...
  Extracting representations from 100 texts...
  Representation shape: torch.Size([6057, 4096])
  Source mean norm: 3.7930
  Target mean norm: 8.4531
  Source Frobenius norm: inf
  Target Frobenius norm: inf
  ✓ Rotation matrix W: torch.Size([4096, 4096])
  Singular values (top 5): [9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07]
  ✓ Calibration complete
  [1/5] Generating: The capital of France is...
       → The capital of France is!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  [2/5] Generating: To solve this problem, we need to...
       → To solve this problem, we need to!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  [3/5] Generating: The future of artificial intelligence is...
       → The future of artificial intelligence is!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  [4/5] Generating: In the year 2050,...
       → In the year 2050,!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  [5/5] Generating: The main difference between cats and dogs is...
       → The main difference between cats and dogs is!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

================================================================================
LAYER 16: Hidden States Layer 16
================================================================================

[1/3] Mistral → Mistral (sanity check)
----------------------------------------
  Calibrating Procrustes for layer 16...
  Extracting representations from 100 texts...
  Representation shape: torch.Size([7053, 4096])
  Source mean norm: 4.8984
  Target mean norm: 4.8984
  Source Frobenius norm: inf
  Target Frobenius norm: inf
  ✓ Rotation matrix W: torch.Size([4096, 4096])
  Singular values (top 5): [9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07]
  ✓ Calibration complete
  [1/5] Generating: The capital of France is...
       → The capital of France is
  [2/5] Generating: To solve this problem, we need to...
       → To solve this problem, we need to
  [3/5] Generating: The future of artificial intelligence is...
       → The future of artificial intelligence is
  [4/5] Generating: In the year 2050,...
       → In the year 2050,
  [5/5] Generating: The main difference between cats and dogs is...
       → The main difference between cats and dogs is

[2/3] Llama → Mistral (cross-model)
----------------------------------------
  Calibrating Procrustes for layer 16...
  Extracting representations from 100 texts...
  Representation shape: torch.Size([6057, 4096])
  Source mean norm: 9.5938
  Target mean norm: 4.8789
  Source Frobenius norm: inf
  Target Frobenius norm: inf
  ✓ Rotation matrix W: torch.Size([4096, 4096])
  Singular values (top 5): [9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07]
  ✓ Calibration complete
  [1/5] Generating: The capital of France is...
       → The capital of France is
  [2/5] Generating: To solve this problem, we need to...
       → To solve this problem, we need to
  [3/5] Generating: The future of artificial intelligence is...
       → The future of artificial intelligence is
  [4/5] Generating: In the year 2050,...
       → In the year 2050,
  [5/5] Generating: The main difference between cats and dogs is...
       → The main difference between cats and dogs is

[3/3] Mistral → Llama (cross-model)
----------------------------------------
  Calibrating Procrustes for layer 16...
  Extracting representations from 100 texts...
  Representation shape: torch.Size([6057, 4096])
  Source mean norm: 4.8789
  Target mean norm: 9.5938
  Source Frobenius norm: inf
  Target Frobenius norm: inf
  ✓ Rotation matrix W: torch.Size([4096, 4096])
  Singular values (top 5): [9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07]
  ✓ Calibration complete
  [1/5] Generating: The capital of France is...
       → The capital of France is!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  [2/5] Generating: To solve this problem, we need to...
       → To solve this problem, we need to!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  [3/5] Generating: The future of artificial intelligence is...
       → The future of artificial intelligence is!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  [4/5] Generating: In the year 2050,...
       → In the year 2050,!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  [5/5] Generating: The main difference between cats and dogs is...
       → The main difference between cats and dogs is!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

================================================================================
LAYER 24: Hidden States Layer 24
================================================================================

[1/3] Mistral → Mistral (sanity check)
----------------------------------------
  Calibrating Procrustes for layer 24...
  Extracting representations from 100 texts...
  Representation shape: torch.Size([7053, 4096])
  Source mean norm: 9.2188
  Target mean norm: 9.2188
  Source Frobenius norm: inf
  Target Frobenius norm: inf
  ✓ Rotation matrix W: torch.Size([4096, 4096])
  Singular values (top 5): [9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07]
  ✓ Calibration complete
  [1/5] Generating: The capital of France is...
       → The capital of France is
  [2/5] Generating: To solve this problem, we need to...
       → To solve this problem, we need to
  [3/5] Generating: The future of artificial intelligence is...
       → The future of artificial intelligence is
  [4/5] Generating: In the year 2050,...
       → In the year 2050,
  [5/5] Generating: The main difference between cats and dogs is...
       → The main difference between cats and dogs is

[2/3] Llama → Mistral (cross-model)
----------------------------------------
  Calibrating Procrustes for layer 24...
  Extracting representations from 100 texts...
  Representation shape: torch.Size([6057, 4096])
  Source mean norm: 15.5625
  Target mean norm: 9.1406
  Source Frobenius norm: inf
  Target Frobenius norm: inf
  ✓ Rotation matrix W: torch.Size([4096, 4096])
  Singular values (top 5): [9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07]
  ✓ Calibration complete
  [1/5] Generating: The capital of France is...
       → The capital of France is
  [2/5] Generating: To solve this problem, we need to...
       → To solve this problem, we need to
  [3/5] Generating: The future of artificial intelligence is...
       → The future of artificial intelligence is
  [4/5] Generating: In the year 2050,...
       → In the year 2050,
  [5/5] Generating: The main difference between cats and dogs is...
       → The main difference between cats and dogs is

[3/3] Mistral → Llama (cross-model)
----------------------------------------
  Calibrating Procrustes for layer 24...
  Extracting representations from 100 texts...
  Representation shape: torch.Size([6057, 4096])
  Source mean norm: 9.1406
  Target mean norm: 15.5625
  Source Frobenius norm: inf
  Target Frobenius norm: inf
  ✓ Rotation matrix W: torch.Size([4096, 4096])
  Singular values (top 5): [9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07]
  ✓ Calibration complete
  [1/5] Generating: The capital of France is...
       → The capital of France is!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  [2/5] Generating: To solve this problem, we need to...
       → To solve this problem, we need to!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  [3/5] Generating: The future of artificial intelligence is...
       → The future of artificial intelligence is!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  [4/5] Generating: In the year 2050,...
       → In the year 2050,!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  [5/5] Generating: The main difference between cats and dogs is...
       → The main difference between cats and dogs is!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

================================================================================
LAYER 32: Hidden States Layer 32
================================================================================

[1/3] Mistral → Mistral (sanity check)
----------------------------------------
  Calibrating Procrustes for layer 32...
  Extracting representations from 100 texts...
  Representation shape: torch.Size([7053, 4096])
  Source mean norm: 151.5000
  Target mean norm: 151.5000
  Source Frobenius norm: inf
  Target Frobenius norm: inf
  ✓ Rotation matrix W: torch.Size([4096, 4096])
  Singular values (top 5): [9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07]
  ✓ Calibration complete
  [1/5] Generating: The capital of France is...
       → The capital of France is
  [2/5] Generating: To solve this problem, we need to...
       → To solve this problem, we need to
  [3/5] Generating: The future of artificial intelligence is...
       → The future of artificial intelligence is
  [4/5] Generating: In the year 2050,...
       → In the year 2050,
  [5/5] Generating: The main difference between cats and dogs is...
       → The main difference between cats and dogs is

[2/3] Llama → Mistral (cross-model)
----------------------------------------
  Calibrating Procrustes for layer 32...
  Extracting representations from 100 texts...
  Representation shape: torch.Size([6057, 4096])
  Source mean norm: 60.2812
  Target mean norm: 149.8750
  Source Frobenius norm: inf
  Target Frobenius norm: inf
  ✓ Rotation matrix W: torch.Size([4096, 4096])
  Singular values (top 5): [9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07]
  ✓ Calibration complete
  [1/5] Generating: The capital of France is...
       → The capital of France is
  [2/5] Generating: To solve this problem, we need to...
       → To solve this problem, we need to
  [3/5] Generating: The future of artificial intelligence is...
       → The future of artificial intelligence is
  [4/5] Generating: In the year 2050,...
       → In the year 2050,
  [5/5] Generating: The main difference between cats and dogs is...
       → The main difference between cats and dogs is

[3/3] Mistral → Llama (cross-model)
----------------------------------------
  Calibrating Procrustes for layer 32...
  Extracting representations from 100 texts...
  Representation shape: torch.Size([6057, 4096])
  Source mean norm: 149.8750
  Target mean norm: 60.2812
  Source Frobenius norm: inf
  Target Frobenius norm: inf
  ✓ Rotation matrix W: torch.Size([4096, 4096])
  Singular values (top 5): [9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07, 9.999999974752427e-07]
  ✓ Calibration complete
  [1/5] Generating: The capital of France is...
       → The capital of France is!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  [2/5] Generating: To solve this problem, we need to...
       → To solve this problem, we need to!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  [3/5] Generating: The future of artificial intelligence is...
       → The future of artificial intelligence is!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  [4/5] Generating: In the year 2050,...
       → In the year 2050,!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  [5/5] Generating: The main difference between cats and dogs is...
       → The main difference between cats and dogs is!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

================================================================================
EXPERIMENT COMPLETE
================================================================================
Results saved to: runs/procrustes_fixed_ablation/procrustes_layer_ablation_20251030_002448.json

SUMMARY:
--------------------------------------------------------------------------------
Embedding:
  mistral_to_mistral: All prompts generated successfully
  llama_to_mistral: All prompts generated successfully
  mistral_to_llama: All prompts generated successfully

Layer 8:
  mistral_to_mistral: 5/5 failures (immediate_EOS)
  llama_to_mistral: 5/5 failures (immediate_EOS)
  mistral_to_llama: All prompts generated successfully

Layer 16:
  mistral_to_mistral: 5/5 failures (immediate_EOS)
  llama_to_mistral: 5/5 failures (immediate_EOS)
  mistral_to_llama: All prompts generated successfully

Layer 24:
  mistral_to_mistral: 5/5 failures (immediate_EOS)
  llama_to_mistral: 5/5 failures (immediate_EOS)
  mistral_to_llama: All prompts generated successfully

Layer 32:
  mistral_to_mistral: 5/5 failures (immediate_EOS)
  llama_to_mistral: 5/5 failures (immediate_EOS)
  mistral_to_llama: All prompts generated successfully


================================================================================
EXPERIMENT COMPLETED SUCCESSFULLY
================================================================================
