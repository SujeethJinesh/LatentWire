Loading models...
Using device: mps
Loading meta-llama/Llama-3.1-8B...
Traceback (most recent call last):
  File "/Users/sujeethjinesh/Desktop/LatentWire/experimental/learning/cross_model_ablation.py", line 648, in <module>
    cross_model_experiment()
  File "/Users/sujeethjinesh/Desktop/LatentWire/experimental/learning/cross_model_ablation.py", line 517, in cross_model_experiment
    llama_model = AutoModelForCausalLM.from_pretrained(llama_model_id, **load_kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sujeethjinesh/Desktop/LatentWire/venv_arm64/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sujeethjinesh/Desktop/LatentWire/venv_arm64/lib/python3.11/site-packages/transformers/modeling_utils.py", line 3577, in from_pretrained
    raise ImportError(
ImportError: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install 'accelerate>=0.26.0'`
