/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
GPUs available: 4

Loading meta-llama/Meta-Llama-3.1-8B-Instruct...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 3954.09it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.40s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.27s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.00it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.11s/it]
Model loaded!

Loading 10000 training examples from squad...
Loading 100 eval examples...
Loaded 10000 train, 100 eval

Traceback (most recent call last):
  File "/projects/m000066/sujinesh/LatentWire/train_adapter_only_phase1.py", line 833, in <module>
    main()
  File "/projects/m000066/sujinesh/LatentWire/train_adapter_only_phase1.py", line 603, in main
    tokens_per_example if tokens_per_example is not None else "all"
UnboundLocalError: local variable 'tokens_per_example' referenced before assignment
