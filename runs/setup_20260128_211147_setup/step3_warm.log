warm: Qwen/Qwen3-0.6B
Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]Fetching 10 files:  10%|█         | 1/10 [00:00<00:03,  2.73it/s]Fetching 10 files:  40%|████      | 4/10 [00:04<00:06,  1.12s/it]Fetching 10 files:  70%|███████   | 7/10 [00:27<00:14,  4.72s/it]Fetching 10 files: 100%|██████████| 10/10 [00:27<00:00,  2.78s/it]
warm: Qwen/Qwen2.5-0.5B-Instruct
Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]Fetching 10 files:  10%|█         | 1/10 [00:00<00:01,  7.26it/s]Fetching 10 files:  40%|████      | 4/10 [00:07<00:12,  2.14s/it]Fetching 10 files:  70%|███████   | 7/10 [00:15<00:06,  2.30s/it]Fetching 10 files: 100%|██████████| 10/10 [00:15<00:00,  1.53s/it]
warm: meta-llama/Llama-3.2-1B-Instruct
Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]Fetching 13 files:   8%|▊         | 1/13 [00:00<00:03,  3.09it/s]Fetching 13 files:  54%|█████▍    | 7/13 [00:39<00:35,  5.92s/it]Fetching 13 files: 100%|██████████| 13/13 [00:39<00:00,  3.06s/it]
warm: google/gemma-3-1b-it
Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]Fetching 10 files:  10%|█         | 1/10 [00:00<00:02,  4.29it/s]Fetching 10 files:  60%|██████    | 6/10 [00:26<00:18,  4.69s/it]Fetching 10 files: 100%|██████████| 10/10 [00:26<00:00,  2.68s/it]
model warm ok
