[2026-01-19 12:25:01] Initializing experiment registry at runs/experiment_registry.json
==============================================================
REASONING-FOCUSED FINAL EXPERIMENTS (Publication Ready)
==============================================================
Job ID: 151015
Node: n05
GPUs: 0,1
Start time: Mon Jan 19 12:25:01 PM PST 2026

REASONING BENCHMARKS:
  - ARC-Easy (science)
  - WinoGrande (commonsense)
  - HellaSwag (situational)
  - BoolQ (reading comprehension)

GPU ALLOCATION:
  - GPU 0: Standard bridge (hail mary) + baselines (zero-shot, few-shot, DoRA, prompt tuning, linear probe)
  - GPU 1: Novel bridges + token capacity + latency/memory/throughput/batched benchmarks
==============================================================
Already up to date.

index, name, memory.free [MiB]
0, NVIDIA H100 80GB HBM3, 81106 MiB
1, NVIDIA H100 80GB HBM3, 81106 MiB


[2026-01-19 12:25:03] Starting parallel execution on 2 GPUs...

[2026-01-19 12:25:03] GPU 0 PID: 2583302 (Standard Bridge + Baselines)
[2026-01-19 12:25:03] GPU 1 PID: 2583303 (Novel Bridges + Benchmarks)

[2026-01-19 12:25:03] [GPU 1] Starting: Novel Bridges + Token Capacity + All Benchmarks

[2026-01-19 12:25:03] [GPU 0] Starting: Standard Bridge + Baselines
[2026-01-19 12:25:03] [GPU 1] Testing flow_matching on ARC-Easy (seed=42)
[2026-01-19 12:25:03] [GPU 0] Running Hail Mary Reasoning Evaluation
[2026-01-19 12:25:03] SKIP: hail_mary_reasoning (currently running (started 0.7h ago))
[2026-01-19 12:25:03] [GPU 0] Hail mary evaluation completed

[2026-01-19 12:25:03] [GPU 0] Running Zero-Shot Baseline on all reasoning datasets
[2026-01-19 12:25:03] [GPU 0] Zero-shot on arc_easy
Started: flow_matching_arc_easy_seed42
[2026-01-19 12:25:03] START: flow_matching_arc_easy_seed42
Started: zeroshot_arc_easy
[2026-01-19 12:25:03] START: zeroshot_arc_easy
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
============================================================
TELEPATHY TRAINING: ARC_EASY
============================================================

Dataset: arc_easy (4 classes)
Random baseline: 25.0%
Source layer: 31
Soft tokens: 8
Steps: 1500
Diversity weight: 0.1
============================================================
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2125.85it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Device: cuda:0

======================================================================
ZERO-SHOT BASELINE: ARC_EASY
======================================================================

Evaluating Llama...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2297.30it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.30s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:13,  4.39s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.88s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:04,  4.07s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.40s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.90s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.25s/it]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2233.79it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.22s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.99s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.48s/it]
Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.80s/it]Zero-shot Llama:   0%|          | 0/200 [00:00<?, ?it/s]Zero-shot Llama:   0%|          | 1/200 [00:00<02:00,  1.65it/s]Zero-shot Llama:   2%|▏         | 4/200 [00:00<00:29,  6.75it/s]Zero-shot Llama:   4%|▎         | 7/200 [00:00<00:17, 10.99it/s]Zero-shot Llama:   5%|▌         | 10/200 [00:00<00:13, 14.28it/s]Zero-shot Llama:   6%|▋         | 13/200 [00:01<00:10, 17.49it/s]Zero-shot Llama:   8%|▊         | 16/200 [00:01<00:09, 19.51it/s]Zero-shot Llama:  10%|▉         | 19/200 [00:01<00:08, 20.55it/s]Zero-shot Llama:  12%|█▏        | 23/200 [00:01<00:07, 24.21it/s]Zero-shot Llama:  13%|█▎        | 26/200 [00:01<00:07, 23.08it/s]Zero-shot Llama:  14%|█▍        | 29/200 [00:01<00:07, 22.07it/s]Zero-shot Llama:  16%|█▌        | 32/200 [00:01<00:07, 22.67it/s]Zero-shot Llama:  18%|█▊        | 35/200 [00:02<00:07, 21.11it/s]Zero-shot Llama:  19%|█▉        | 38/200 [00:02<00:07, 21.87it/s]Zero-shot Llama:  20%|██        | 41/200 [00:02<00:07, 21.35it/s]Zero-shot Llama:  22%|██▏       | 44/200 [00:02<00:07, 21.42it/s]Zero-shot Llama:  24%|██▎       | 47/200 [00:02<00:07, 20.95it/s]Zero-shot Llama:  25%|██▌       | 50/200 [00:02<00:07, 21.40it/s]Zero-shot Llama:  26%|██▋       | 53/200 [00:02<00:06, 21.73it/s]Zero-shot Llama:  28%|██▊       | 56/200 [00:03<00:06, 22.23it/s]Zero-shot Llama:  30%|██▉       | 59/200 [00:03<00:06, 22.92it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.96s/it]Zero-shot Llama:  31%|███       | 62/200 [00:03<00:05, 23.79it/s]Zero-shot Llama:  32%|███▎      | 65/200 [00:03<00:06, 21.83it/s]Zero-shot Llama:  34%|███▍      | 68/200 [00:03<00:06, 21.29it/s]Zero-shot Llama:  36%|███▌      | 71/200 [00:03<00:06, 21.49it/s]Zero-shot Llama:  37%|███▋      | 74/200 [00:03<00:05, 21.94it/s]Zero-shot Llama:  38%|███▊      | 77/200 [00:03<00:05, 20.97it/s]Zero-shot Llama:  40%|████      | 80/200 [00:04<00:05, 21.15it/s]Zero-shot Llama:  42%|████▏     | 83/200 [00:04<00:05, 20.76it/s]Zero-shot Llama:  43%|████▎     | 86/200 [00:04<00:05, 21.19it/s]Zero-shot Llama:  44%|████▍     | 89/200 [00:04<00:05, 20.92it/s]Zero-shot Llama:  46%|████▌     | 92/200 [00:04<00:05, 21.08it/s]Zero-shot Llama:  48%|████▊     | 95/200 [00:04<00:05, 20.96it/s]Zero-shot Llama:  49%|████▉     | 98/200 [00:04<00:04, 21.70it/s]Zero-shot Llama:  50%|█████     | 101/200 [00:05<00:04, 21.04it/s]Zero-shot Llama:  52%|█████▏    | 104/200 [00:05<00:04, 21.23it/s]Zero-shot Llama:  54%|█████▎    | 107/200 [00:05<00:04, 21.34it/s]Zero-shot Llama:  55%|█████▌    | 110/200 [00:05<00:04, 21.14it/s]Zero-shot Llama:  56%|█████▋    | 113/200 [00:05<00:04, 21.32it/s]Zero-shot Llama:  58%|█████▊    | 116/200 [00:05<00:03, 21.14it/s]Zero-shot Llama:  60%|█████▉    | 119/200 [00:05<00:03, 21.02it/s]Zero-shot Llama:  61%|██████    | 122/200 [00:06<00:03, 22.45it/s]Zero-shot Llama:  62%|██████▎   | 125/200 [00:06<00:03, 21.97it/s]Zero-shot Llama:  64%|██████▍   | 128/200 [00:06<00:03, 21.56it/s]Zero-shot Llama:  66%|██████▌   | 131/200 [00:06<00:03, 22.37it/s]Zero-shot Llama:  67%|██████▋   | 134/200 [00:06<00:02, 22.83it/s]Zero-shot Llama:  68%|██████▊   | 137/200 [00:06<00:02, 24.10it/s]Zero-shot Llama:  70%|███████   | 140/200 [00:06<00:02, 23.96it/s]Zero-shot Llama:  72%|███████▏  | 143/200 [00:07<00:02, 22.24it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.94s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.93s/it]
Zero-shot Llama:  74%|███████▎  | 147/200 [00:07<00:02, 25.30it/s]Zero-shot Llama:  76%|███████▌  | 151/200 [00:07<00:01, 28.73it/s]Zero-shot Llama:  78%|███████▊  | 156/200 [00:07<00:01, 32.91it/s]Zero-shot Llama:  80%|████████  | 160/200 [00:07<00:01, 30.02it/s]Zero-shot Llama:  82%|████████▏ | 164/200 [00:07<00:01, 25.80it/s]Zero-shot Llama:  84%|████████▎ | 167/200 [00:07<00:01, 25.08it/s]Zero-shot Llama:  85%|████████▌ | 170/200 [00:07<00:01, 24.28it/s]Zero-shot Llama:  87%|████████▋ | 174/200 [00:08<00:00, 27.28it/s]Zero-shot Llama:  88%|████████▊ | 177/200 [00:08<00:00, 26.40it/s]Zero-shot Llama:  90%|█████████ | 180/200 [00:08<00:00, 25.60it/s]Zero-shot Llama:  92%|█████████▏| 183/200 [00:08<00:00, 23.44it/s]Zero-shot Llama:  93%|█████████▎| 186/200 [00:08<00:00, 23.26it/s]Zero-shot Llama:  94%|█████████▍| 189/200 [00:08<00:00, 24.72it/s]Zero-shot Llama:  98%|█████████▊| 195/200 [00:08<00:00, 32.73it/s]Zero-shot Llama: 100%|█████████▉| 199/200 [00:08<00:00, 33.65it/s]Zero-shot Llama: 100%|██████████| 200/200 [00:08<00:00, 22.24it/s]
Llama: 21.0% (42/200)

Evaluating Mistral...
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2543.54it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]2026-01-19 12:25:39,908 - INFO - FlowMatchingBridge: 8 tokens, 4 flow steps
Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:06,  3.37s/it]Target embedding RMS: 0.0027
Using Flow Matching Bridge (MATH) - steps=4

Training on 2251 samples
Validation: 2376 samples
Starting training...

ARC_EASY:   0%|                                                            | 0/1500 [00:00<?, ?it/s]ARC_EASY:   0%|                                                            | 0/1500 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1285, in main
    loss, loss_dict = train_step(
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 714, in train_step
    soft_tokens, aux_loss, diversity, z_variance = bridge_module(src_h, src_mask)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 1196, in forward
    soft_tokens = self.integrate_flow(x0)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 1170, in integrate_flow
    v = self.compute_velocity(x, t)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 1150, in compute_velocity
    v = self.velocity_net(xt)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 must have the same dtype, but got Float and BFloat16
Loading checkpoint shards:  67%|██████▋   | 2/3 [00:06<00:03,  3.26s/it]
[ERROR] Training interrupted by exception at step 1
[ERROR] RuntimeError: mat1 and mat2 must have the same dtype, but got Float and BFloat16

[EMERGENCY] Checkpoint saved to runs/reasoning_final_20260119_122501/novel_bridges/flow_matching_arc_easy_seed42/emergency_checkpoint_step0.pt
[EMERGENCY] Error: RuntimeError: mat1 and mat2 must have the same dtype, but got Float and BFloat16
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1530, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1285, in main
    loss, loss_dict = train_step(
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 714, in train_step
    soft_tokens, aux_loss, diversity, z_variance = bridge_module(src_h, src_mask)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 1196, in forward
    soft_tokens = self.integrate_flow(x0)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 1170, in integrate_flow
    v = self.compute_velocity(x, t)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 1150, in compute_velocity
    v = self.velocity_net(xt)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 must have the same dtype, but got Float and BFloat16
[2026-01-19 12:25:46] FAILED: flow_matching_arc_easy_seed42 (exit code: 1)
Failed: flow_matching_arc_easy_seed42

[2026-01-19 12:25:46] [GPU 1] Testing optimal_transport on ARC-Easy (seed=42)
Started: optimal_transport_arc_easy_seed42
[2026-01-19 12:25:46] START: optimal_transport_arc_easy_seed42
Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  3.35s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  3.34s/it]
Zero-shot Mistral:   0%|          | 0/200 [00:00<?, ?it/s]/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Zero-shot Mistral:   1%|          | 2/200 [00:00<00:11, 17.26it/s]Zero-shot Mistral:   2%|▎         | 5/200 [00:00<00:09, 20.45it/s]Zero-shot Mistral:   4%|▍         | 8/200 [00:00<00:09, 19.20it/s]Zero-shot Mistral:   6%|▌         | 11/200 [00:00<00:09, 19.46it/s]Zero-shot Mistral:   7%|▋         | 14/200 [00:00<00:09, 19.81it/s]Zero-shot Mistral:   8%|▊         | 16/200 [00:00<00:09, 19.44it/s]Zero-shot Mistral:  10%|▉         | 19/200 [00:00<00:08, 20.58it/s]Zero-shot Mistral:  11%|█         | 22/200 [00:01<00:08, 20.74it/s]Zero-shot Mistral:  12%|█▎        | 25/200 [00:01<00:08, 20.48it/s]Zero-shot Mistral:  14%|█▍        | 28/200 [00:01<00:07, 21.59it/s]Zero-shot Mistral:  16%|█▋        | 33/200 [00:01<00:06, 27.23it/s]Zero-shot Mistral:  18%|█▊        | 36/200 [00:01<00:06, 23.90it/s]Zero-shot Mistral:  20%|█▉        | 39/200 [00:01<00:07, 22.55it/s]Zero-shot Mistral:  21%|██        | 42/200 [00:01<00:07, 22.49it/s]Zero-shot Mistral:  22%|██▎       | 45/200 [00:02<00:07, 20.88it/s]Zero-shot Mistral:  24%|██▍       | 48/200 [00:02<00:07, 20.86it/s]Zero-shot Mistral:  26%|██▌       | 51/200 [00:02<00:07, 19.91it/s]Zero-shot Mistral:  27%|██▋       | 54/200 [00:02<00:07, 19.32it/s]Zero-shot Mistral:  28%|██▊       | 56/200 [00:02<00:07, 19.30it/s]Zero-shot Mistral:  30%|██▉       | 59/200 [00:02<00:07, 19.91it/s]Zero-shot Mistral:  31%|███       | 62/200 [00:02<00:06, 19.92it/s]Zero-shot Mistral:  32%|███▎      | 65/200 [00:03<00:06, 20.09it/s]Zero-shot Mistral:  34%|███▍      | 68/200 [00:03<00:06, 20.87it/s]Zero-shot Mistral:  36%|███▌      | 71/200 [00:03<00:06, 20.81it/s]Zero-shot Mistral:  37%|███▋      | 74/200 [00:03<00:06, 20.72it/s]Zero-shot Mistral:  38%|███▊      | 77/200 [00:03<00:06, 19.70it/s]============================================================
TELEPATHY TRAINING: ARC_EASY
============================================================

Dataset: arc_easy (4 classes)
Random baseline: 25.0%
Source layer: 31
Soft tokens: 8
Steps: 1500
Diversity weight: 0.1
============================================================
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 1952.20it/s]
Zero-shot Mistral:  40%|███▉      | 79/200 [00:03<00:06, 18.65it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Zero-shot Mistral:  41%|████      | 82/200 [00:03<00:05, 20.47it/s]Zero-shot Mistral:  42%|████▎     | 85/200 [00:04<00:05, 20.08it/s]Zero-shot Mistral:  44%|████▍     | 88/200 [00:04<00:05, 18.78it/s]Zero-shot Mistral:  46%|████▌     | 91/200 [00:04<00:05, 19.70it/s]Zero-shot Mistral:  47%|████▋     | 94/200 [00:04<00:05, 20.79it/s]Zero-shot Mistral:  48%|████▊     | 97/200 [00:04<00:04, 21.39it/s]Zero-shot Mistral:  50%|█████     | 100/200 [00:04<00:04, 20.88it/s]Zero-shot Mistral:  52%|█████▏    | 103/200 [00:05<00:04, 20.11it/s]Zero-shot Mistral:  53%|█████▎    | 106/200 [00:05<00:04, 19.47it/s]Zero-shot Mistral:  54%|█████▍    | 108/200 [00:05<00:04, 18.86it/s]Zero-shot Mistral:  55%|█████▌    | 110/200 [00:05<00:04, 18.98it/s]Zero-shot Mistral:  56%|█████▌    | 112/200 [00:05<00:04, 19.08it/s]Zero-shot Mistral:  57%|█████▋    | 114/200 [00:05<00:04, 19.14it/s]Zero-shot Mistral:  58%|█████▊    | 116/200 [00:05<00:04, 19.15it/s]Zero-shot Mistral:  59%|█████▉    | 118/200 [00:05<00:04, 18.42it/s]Zero-shot Mistral:  60%|██████    | 121/200 [00:05<00:04, 18.28it/s]Zero-shot Mistral:  62%|██████▏   | 123/200 [00:06<00:04, 18.56it/s]Zero-shot Mistral:  62%|██████▎   | 125/200 [00:06<00:03, 18.84it/s]Zero-shot Mistral:  64%|██████▎   | 127/200 [00:06<00:03, 18.86it/s]Zero-shot Mistral:  64%|██████▍   | 129/200 [00:06<00:03, 19.13it/s]Zero-shot Mistral:  66%|██████▌   | 132/200 [00:06<00:03, 20.03it/s]Zero-shot Mistral:  68%|██████▊   | 135/200 [00:06<00:02, 21.90it/s]Zero-shot Mistral:  69%|██████▉   | 138/200 [00:06<00:02, 21.66it/s]Zero-shot Mistral:  70%|███████   | 141/200 [00:06<00:02, 22.32it/s]Zero-shot Mistral:  72%|███████▏  | 144/200 [00:07<00:02, 22.41it/s]Zero-shot Mistral:  74%|███████▎  | 147/200 [00:07<00:02, 22.16it/s]Zero-shot Mistral:  75%|███████▌  | 150/200 [00:07<00:02, 21.22it/s]Zero-shot Mistral:  76%|███████▋  | 153/200 [00:07<00:02, 21.08it/s]Zero-shot Mistral:  78%|███████▊  | 156/200 [00:07<00:02, 20.09it/s]Zero-shot Mistral:  80%|███████▉  | 159/200 [00:07<00:01, 20.69it/s]Zero-shot Mistral:  81%|████████  | 162/200 [00:07<00:01, 20.40it/s]Zero-shot Mistral:  82%|████████▎ | 165/200 [00:08<00:01, 20.42it/s]Zero-shot Mistral:  84%|████████▍ | 168/200 [00:08<00:01, 20.16it/s]Zero-shot Mistral:  86%|████████▌ | 171/200 [00:08<00:01, 20.49it/s]Zero-shot Mistral:  87%|████████▋ | 174/200 [00:08<00:01, 20.88it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:14,  4.68s/it]Zero-shot Mistral:  88%|████████▊ | 177/200 [00:08<00:01, 20.31it/s]Zero-shot Mistral:  90%|█████████ | 180/200 [00:08<00:00, 21.35it/s]Zero-shot Mistral:  92%|█████████▏| 183/200 [00:08<00:00, 21.28it/s]Zero-shot Mistral:  93%|█████████▎| 186/200 [00:09<00:00, 22.53it/s]Zero-shot Mistral:  94%|█████████▍| 189/200 [00:09<00:00, 22.58it/s]Zero-shot Mistral:  96%|█████████▌| 192/200 [00:09<00:00, 23.50it/s]Zero-shot Mistral:  98%|█████████▊| 195/200 [00:09<00:00, 22.62it/s]Zero-shot Mistral:  99%|█████████▉| 198/200 [00:09<00:00, 23.27it/s]Zero-shot Mistral: 100%|██████████| 200/200 [00:09<00:00, 20.65it/s]
Mistral: 24.0% (48/200)

Results saved to: runs/reasoning_final_20260119_122501/baselines/zeroshot/zeroshot_arc_easy_20260119_122510.json
[2026-01-19 12:26:00] SUCCESS: zeroshot_arc_easy
Completed: zeroshot_arc_easy
[2026-01-19 12:26:00] [GPU 0] Zero-shot on winogrande
Started: zeroshot_winogrande
[2026-01-19 12:26:00] START: zeroshot_winogrande
Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.38s/it]/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.23s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.96s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.48s/it]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2410.06it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Device: cuda:0

======================================================================
ZERO-SHOT BASELINE: WINOGRANDE
======================================================================
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 1648, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 1590, in main
    results = run_zeroshot_baseline(args, config, device)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 177, in run_zeroshot_baseline
    eval_ds = load_dataset(config["load_args"][0], config["load_args"][1],
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 2132, in load_dataset
    builder_instance = load_dataset_builder(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1853, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1729, in dataset_module_factory
    raise e1 from None
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1599, in dataset_module_factory
    dataset_readme_path = api.hf_hub_download(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 5467, in hf_hub_download
    return hf_hub_download(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1124, in _hf_hub_download_to_cache_dir
    os.makedirs(os.path.dirname(blob_path), exist_ok=True)
  File "/marlowe/apps/Mambaforge/24.3.0-0/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/marlowe/apps/Mambaforge/24.3.0-0/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
OSError: [Errno 122] Disk quota exceeded: '/projects/m000066/sujinesh/.cache/huggingface/hub/datasets--allenai--winogrande'
[2026-01-19 12:26:08] FAILED: zeroshot_winogrande (exit code: 1)
Failed: zeroshot_winogrande
[2026-01-19 12:26:09] [GPU 0] Zero-shot on hellaswag
Started: zeroshot_hellaswag
[2026-01-19 12:26:09] START: zeroshot_hellaswag
Loading checkpoint shards:  33%|███▎      | 1/3 [00:02<00:05,  2.88s/it]/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading checkpoint shards:  67%|██████▋   | 2/3 [00:06<00:03,  3.33s/it]Device: cuda:0

======================================================================
ZERO-SHOT BASELINE: HELLASWAG
======================================================================
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 1648, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 1590, in main
    results = run_zeroshot_baseline(args, config, device)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 180, in run_zeroshot_baseline
    eval_ds = load_dataset(config["load_args"][0],
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 2132, in load_dataset
    builder_instance = load_dataset_builder(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1853, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1729, in dataset_module_factory
    raise e1 from None
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1599, in dataset_module_factory
    dataset_readme_path = api.hf_hub_download(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 5467, in hf_hub_download
    return hf_hub_download(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1124, in _hf_hub_download_to_cache_dir
    os.makedirs(os.path.dirname(blob_path), exist_ok=True)
  File "/marlowe/apps/Mambaforge/24.3.0-0/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/marlowe/apps/Mambaforge/24.3.0-0/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
OSError: [Errno 122] Disk quota exceeded: '/projects/m000066/sujinesh/.cache/huggingface/hub/datasets--Rowan--hellaswag'
Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  3.41s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  3.35s/it]
[2026-01-19 12:26:17] FAILED: zeroshot_hellaswag (exit code: 1)
Failed: zeroshot_hellaswag
[2026-01-19 12:26:17] [GPU 0] Zero-shot on boolq
Started: zeroshot_boolq
[2026-01-19 12:26:18] START: zeroshot_boolq
2026-01-19 12:26:18,841 - INFO - OptimalTransportBridge: 8 anchors, eps=0.1
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Target embedding RMS: 0.0027
Using Optimal Transport Bridge (NOVEL) - epsilon=0.1

Training on 2251 samples
Validation: 2376 samples
Starting training...

ARC_EASY:   0%|                                                            | 0/1500 [00:00<?, ?it/s]ARC_EASY:   0%|                                                            | 0/1500 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1285, in main
    loss, loss_dict = train_step(
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 714, in train_step
    soft_tokens, aux_loss, diversity, z_variance = bridge_module(src_h, src_mask)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 259, in forward
    P = self.sinkhorn(C, a, b)  # [B, S, K]
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 215, in sinkhorn
    v = b / (torch.bmm(K.transpose(1, 2), u.unsqueeze(-1)).squeeze(-1) + 1e-8)
RuntimeError: expected scalar type Float but found BFloat16

[ERROR] Training interrupted by exception at step 1
[ERROR] RuntimeError: expected scalar type Float but found BFloat16

[EMERGENCY] Checkpoint saved to runs/reasoning_final_20260119_122501/novel_bridges/optimal_transport_arc_easy_seed42/emergency_checkpoint_step0.pt
[EMERGENCY] Error: RuntimeError: expected scalar type Float but found BFloat16
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1530, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1285, in main
    loss, loss_dict = train_step(
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 714, in train_step
    soft_tokens, aux_loss, diversity, z_variance = bridge_module(src_h, src_mask)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 259, in forward
    P = self.sinkhorn(C, a, b)  # [B, S, K]
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 215, in sinkhorn
    v = b / (torch.bmm(K.transpose(1, 2), u.unsqueeze(-1)).squeeze(-1) + 1e-8)
RuntimeError: expected scalar type Float but found BFloat16
[2026-01-19 12:26:23] FAILED: optimal_transport_arc_easy_seed42 (exit code: 1)
Failed: optimal_transport_arc_easy_seed42

[2026-01-19 12:26:24] [GPU 1] Testing moe on ARC-Easy (seed=42)
[2026-01-19 12:26:24] SKIP: moe_arc_easy_seed42 (currently running (started 0.7h ago))

[2026-01-19 12:26:24] [GPU 1] Starting HAIL MARY Bridge Experiments (6 literature-informed bridges)

[2026-01-19 12:26:24] [GPU 1] Testing HAIL MARY cross_modal_distillation on ARC-Easy (seed=42)
Started: hailmary_cross_modal_distillation_arc_easy_seed42
[2026-01-19 12:26:24] START: hailmary_cross_modal_distillation_arc_easy_seed42
Device: cuda:0

======================================================================
ZERO-SHOT BASELINE: BOOLQ
======================================================================
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 1648, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 1590, in main
    results = run_zeroshot_baseline(args, config, device)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 180, in run_zeroshot_baseline
    eval_ds = load_dataset(config["load_args"][0],
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 2132, in load_dataset
    builder_instance = load_dataset_builder(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1853, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1729, in dataset_module_factory
    raise e1 from None
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1599, in dataset_module_factory
    dataset_readme_path = api.hf_hub_download(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 5467, in hf_hub_download
    return hf_hub_download(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1124, in _hf_hub_download_to_cache_dir
    os.makedirs(os.path.dirname(blob_path), exist_ok=True)
  File "/marlowe/apps/Mambaforge/24.3.0-0/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/marlowe/apps/Mambaforge/24.3.0-0/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
OSError: [Errno 122] Disk quota exceeded: '/projects/m000066/sujinesh/.cache/huggingface/hub/datasets--google--boolq'
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[2026-01-19 12:26:27] FAILED: zeroshot_boolq (exit code: 1)
Failed: zeroshot_boolq

[2026-01-19 12:26:28] [GPU 0] Running Few-Shot Baseline (4-shot) on reasoning datasets
[2026-01-19 12:26:28] [GPU 0] Few-shot (4-shot) on arc_easy
Started: fewshot_arc_easy
[2026-01-19 12:26:28] START: fewshot_arc_easy
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
============================================================
TELEPATHY TRAINING: ARC_EASY
============================================================

Dataset: arc_easy (4 classes)
Random baseline: 25.0%
Source layer: 31
Soft tokens: 8
Steps: 1500
Diversity weight: 0.1
============================================================
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2269.65it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.32s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.26s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:08<00:02,  2.78s/it]Device: cuda:0

======================================================================
FEW-SHOT BASELINE (4-shot): ARC_EASY
======================================================================

Evaluating Llama (4-shot)...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2338.94it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.39s/it]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 812.69it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:04<00:08,  4.32s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:12,  4.33s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:08<00:04,  4.17s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.27s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:12<00:00,  3.98s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:12<00:00,  4.05s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.10s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.89s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.38s/it]
Seed 42:   0%|          | 0/200 [00:00<?, ?it/s]/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Seed 42:   0%|          | 1/200 [00:01<03:33,  1.07s/it]Seed 42:   1%|          | 2/200 [00:01<02:11,  1.50it/s]Seed 42:   2%|▏         | 3/200 [00:01<01:43,  1.90it/s]Seed 42:   2%|▏         | 4/200 [00:02<01:32,  2.11it/s]2026-01-19 12:27:01,159 - INFO - CrossModalDistillationBridge: 8 tokens, T=2.0, kd_weight=0.5
Seed 42:   2%|▎         | 5/200 [00:02<01:25,  2.28it/s]Seed 42:   3%|▎         | 6/200 [00:02<01:21,  2.38it/s]Seed 42:   4%|▎         | 7/200 [00:03<01:22,  2.33it/s]Seed 42:   4%|▍         | 8/200 [00:03<01:20,  2.38it/s]Seed 42:   4%|▍         | 9/200 [00:04<01:17,  2.45it/s]Seed 42:   5%|▌         | 10/200 [00:04<01:04,  2.94it/s]Seed 42:   6%|▌         | 11/200 [00:04<00:55,  3.40it/s]Seed 42:   6%|▌         | 12/200 [00:04<00:49,  3.77it/s]Seed 42:   6%|▋         | 13/200 [00:04<00:45,  4.15it/s]Seed 42:   7%|▋         | 14/200 [00:05<00:41,  4.47it/s]Seed 42:   8%|▊         | 15/200 [00:05<00:40,  4.58it/s]Seed 42:   8%|▊         | 16/200 [00:05<00:38,  4.80it/s]Seed 42:   8%|▊         | 17/200 [00:05<00:39,  4.64it/s]Seed 42:   9%|▉         | 18/200 [00:05<00:38,  4.79it/s]Seed 42:  10%|▉         | 19/200 [00:06<00:36,  4.94it/s]Target embedding RMS: 0.0027
Using Cross-Modal Distillation Bridge - KL divergence to sender logits

Training on 2251 samples
Validation: 2376 samples
Starting training...

ARC_EASY:   0%|                                                            | 0/1500 [00:00<?, ?it/s]Seed 42:  10%|█         | 20/200 [00:06<00:42,  4.20it/s]Seed 42:  10%|█         | 21/200 [00:06<00:52,  3.40it/s]Seed 42:  11%|█         | 22/200 [00:07<01:00,  2.95it/s]ARC_EASY:   0%|                             | 0/1500 [00:01<?, ?it/s, lm=8.74, aux=0.000, gn=760.00]ARC_EASY:   0%|                     | 1/1500 [00:01<32:35,  1.30s/it, lm=8.74, aux=0.000, gn=760.00]Seed 42:  12%|█▏        | 23/200 [00:07<01:08,  2.60it/s]ARC_EASY:   0%|                     | 1/1500 [00:01<32:35,  1.30s/it, lm=8.70, aux=0.000, gn=860.00]ARC_EASY:   0%|                     | 2/1500 [00:01<18:56,  1.32it/s, lm=8.70, aux=0.000, gn=860.00]ARC_EASY:   0%|                    | 2/1500 [00:02<18:56,  1.32it/s, lm=7.71, aux=0.000, gn=1008.00]ARC_EASY:   0%|                    | 3/1500 [00:02<14:16,  1.75it/s, lm=7.71, aux=0.000, gn=1008.00]Seed 42:  12%|█▏        | 24/200 [00:08<01:17,  2.27it/s]ARC_EASY:   0%|                     | 3/1500 [00:02<14:16,  1.75it/s, lm=7.73, aux=0.000, gn=470.00]ARC_EASY:   0%|                     | 4/1500 [00:02<11:59,  2.08it/s, lm=7.73, aux=0.000, gn=470.00]Seed 42:  12%|█▎        | 25/200 [00:08<01:23,  2.08it/s]ARC_EASY:   0%|                     | 4/1500 [00:02<11:59,  2.08it/s, lm=6.92, aux=0.000, gn=576.00]ARC_EASY:   0%|                     | 5/1500 [00:02<11:03,  2.25it/s, lm=6.92, aux=0.000, gn=576.00]ARC_EASY:   0%|                     | 5/1500 [00:03<11:03,  2.25it/s, lm=5.85, aux=0.000, gn=492.00]ARC_EASY:   0%|                     | 6/1500 [00:03<10:24,  2.39it/s, lm=5.85, aux=0.000, gn=492.00]Seed 42:  13%|█▎        | 26/200 [00:09<01:28,  1.96it/s]ARC_EASY:   0%|                     | 6/1500 [00:03<10:24,  2.39it/s, lm=4.42, aux=0.000, gn=556.00]ARC_EASY:   0%|                     | 7/1500 [00:03<09:52,  2.52it/s, lm=4.42, aux=0.000, gn=556.00]ARC_EASY:   0%|                     | 7/1500 [00:03<09:52,  2.52it/s, lm=2.84, aux=0.000, gn=696.00]ARC_EASY:   1%|                     | 8/1500 [00:03<09:35,  2.59it/s, lm=2.84, aux=0.000, gn=696.00]Seed 42:  14%|█▎        | 27/200 [00:10<01:35,  1.81it/s]ARC_EASY:   1%|                     | 8/1500 [00:04<09:35,  2.59it/s, lm=2.78, aux=0.000, gn=536.00]ARC_EASY:   1%|▏                    | 9/1500 [00:04<09:29,  2.62it/s, lm=2.78, aux=0.000, gn=536.00]ARC_EASY:   1%|▏                    | 9/1500 [00:04<09:29,  2.62it/s, lm=1.46, aux=0.000, gn=212.00]ARC_EASY:   1%|▏                   | 10/1500 [00:04<09:10,  2.71it/s, lm=1.46, aux=0.000, gn=212.00]Seed 42:  14%|█▍        | 28/200 [00:10<01:39,  1.72it/s]ARC_EASY:   1%|▏                  | 10/1500 [00:04<09:10,  2.71it/s, lm=3.85, aux=0.000, gn=2304.00]ARC_EASY:   1%|▏                  | 11/1500 [00:04<09:06,  2.72it/s, lm=3.85, aux=0.000, gn=2304.00]Seed 42:  14%|█▍        | 29/200 [00:11<01:41,  1.69it/s]ARC_EASY:   1%|▏                   | 11/1500 [00:05<09:06,  2.72it/s, lm=1.85, aux=0.000, gn=776.00]ARC_EASY:   1%|▏                   | 12/1500 [00:05<09:18,  2.66it/s, lm=1.85, aux=0.000, gn=776.00]ARC_EASY:   1%|▏                   | 12/1500 [00:05<09:18,  2.66it/s, lm=1.24, aux=0.000, gn=137.00]ARC_EASY:   1%|▏                   | 13/1500 [00:05<09:17,  2.67it/s, lm=1.24, aux=0.000, gn=137.00]Seed 42:  15%|█▌        | 30/200 [00:12<01:39,  1.71it/s]ARC_EASY:   1%|▏                   | 13/1500 [00:06<09:17,  2.67it/s, lm=0.95, aux=0.000, gn=148.00]ARC_EASY:   1%|▏                   | 14/1500 [00:06<09:07,  2.71it/s, lm=0.95, aux=0.000, gn=148.00]ARC_EASY:   1%|▏                    | 14/1500 [00:06<09:07,  2.71it/s, lm=0.76, aux=0.000, gn=78.50]ARC_EASY:   1%|▏                    | 15/1500 [00:06<09:10,  2.70it/s, lm=0.76, aux=0.000, gn=78.50]Seed 42:  16%|█▌        | 31/200 [00:12<01:45,  1.61it/s]ARC_EASY:   1%|▏                   | 15/1500 [00:06<09:10,  2.70it/s, lm=1.60, aux=0.000, gn=264.00]ARC_EASY:   1%|▏                   | 16/1500 [00:06<09:11,  2.69it/s, lm=1.60, aux=0.000, gn=264.00]Seed 42:  16%|█▌        | 32/200 [00:13<01:40,  1.67it/s]ARC_EASY:   1%|▏                    | 16/1500 [00:07<09:11,  2.69it/s, lm=0.71, aux=0.000, gn=50.00]ARC_EASY:   1%|▏                    | 17/1500 [00:07<09:27,  2.61it/s, lm=0.71, aux=0.000, gn=50.00]ARC_EASY:   1%|▏                   | 17/1500 [00:07<09:27,  2.61it/s, lm=3.42, aux=0.000, gn=352.00]ARC_EASY:   1%|▏                   | 18/1500 [00:07<09:26,  2.61it/s, lm=3.42, aux=0.000, gn=352.00]Seed 42:  16%|█▋        | 33/200 [00:13<01:42,  1.64it/s]ARC_EASY:   1%|▏                   | 18/1500 [00:07<10:39,  2.32it/s, lm=3.42, aux=0.000, gn=352.00]
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1280, in main
    batch = next(iter_dl)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 398, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 207, in collate
    raise RuntimeError("each element in list of batch should be of equal size")
RuntimeError: each element in list of batch should be of equal size
Seed 42:  17%|█▋        | 34/200 [00:14<01:33,  1.77it/s]Seed 42:  18%|█▊        | 35/200 [00:14<01:25,  1.94it/s]Seed 42:  18%|█▊        | 36/200 [00:15<01:18,  2.09it/s]Seed 42:  18%|█▊        | 37/200 [00:15<01:16,  2.13it/s]Seed 42:  19%|█▉        | 38/200 [00:16<01:13,  2.21it/s]Seed 42:  20%|█▉        | 39/200 [00:16<01:10,  2.28it/s]Seed 42:  20%|██        | 40/200 [00:16<01:08,  2.32it/s]Seed 42:  20%|██        | 41/200 [00:17<01:06,  2.38it/s]Seed 42:  21%|██        | 42/200 [00:17<01:04,  2.44it/s]Seed 42:  22%|██▏       | 43/200 [00:17<01:02,  2.53it/s]Seed 42:  22%|██▏       | 44/200 [00:18<01:00,  2.56it/s]Seed 42:  22%|██▎       | 45/200 [00:18<01:02,  2.50it/s]Seed 42:  23%|██▎       | 46/200 [00:19<01:02,  2.48it/s]Seed 42:  24%|██▎       | 47/200 [00:19<01:02,  2.43it/s]Seed 42:  24%|██▍       | 48/200 [00:20<01:00,  2.51it/s]Seed 42:  24%|██▍       | 49/200 [00:20<00:58,  2.57it/s]Seed 42:  25%|██▌       | 50/200 [00:20<00:57,  2.60it/s]Seed 42:  26%|██▌       | 51/200 [00:21<00:56,  2.62it/s]Seed 42:  26%|██▌       | 52/200 [00:21<00:55,  2.68it/s]Seed 42:  26%|██▋       | 53/200 [00:21<00:55,  2.66it/s]Seed 42:  27%|██▋       | 54/200 [00:22<00:53,  2.70it/s]Seed 42:  28%|██▊       | 55/200 [00:22<00:53,  2.71it/s]Seed 42:  28%|██▊       | 56/200 [00:22<00:53,  2.69it/s]Seed 42:  28%|██▊       | 57/200 [00:23<00:53,  2.68it/s]
[ERROR] Training interrupted by exception at step 19
[ERROR] RuntimeError: each element in list of batch should be of equal size

[EMERGENCY] Checkpoint saved to runs/reasoning_final_20260119_122501/novel_bridges/hailmary_cross_modal_distillation_arc_easy_seed42/emergency_checkpoint_step18.pt
[EMERGENCY] Error: RuntimeError: each element in list of batch should be of equal size
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1530, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1280, in main
    batch = next(iter_dl)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 398, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 207, in collate
    raise RuntimeError("each element in list of batch should be of equal size")
RuntimeError: each element in list of batch should be of equal size
Seed 42:  29%|██▉       | 58/200 [00:23<00:52,  2.71it/s]Seed 42:  30%|██▉       | 59/200 [00:24<00:53,  2.66it/s]Seed 42:  30%|███       | 60/200 [00:24<00:53,  2.60it/s]Seed 42:  30%|███       | 61/200 [00:24<00:53,  2.59it/s][2026-01-19 12:27:23] FAILED: hailmary_cross_modal_distillation_arc_easy_seed42 (exit code: 1)
Failed: hailmary_cross_modal_distillation_arc_easy_seed42

Seed 42:  31%|███       | 62/200 [00:25<00:50,  2.75it/s][2026-01-19 12:27:23] [GPU 1] Testing HAIL MARY mine on ARC-Easy (seed=42)
Started: hailmary_mine_arc_easy_seed42
[2026-01-19 12:27:24] START: hailmary_mine_arc_easy_seed42
Seed 42:  32%|███▏      | 63/200 [00:25<00:47,  2.91it/s]Seed 42:  32%|███▏      | 64/200 [00:25<00:50,  2.68it/s]Seed 42:  32%|███▎      | 65/200 [00:26<00:50,  2.70it/s]Seed 42:  33%|███▎      | 66/200 [00:26<00:51,  2.61it/s]Seed 42:  34%|███▎      | 67/200 [00:27<00:52,  2.54it/s]Seed 42:  34%|███▍      | 68/200 [00:27<00:51,  2.57it/s]Seed 42:  34%|███▍      | 69/200 [00:27<00:51,  2.55it/s]/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Seed 42:  35%|███▌      | 70/200 [00:28<00:53,  2.43it/s]Seed 42:  36%|███▌      | 71/200 [00:28<00:53,  2.42it/s]Seed 42:  36%|███▌      | 72/200 [00:29<00:51,  2.47it/s]Seed 42:  36%|███▋      | 73/200 [00:29<00:44,  2.83it/s]Seed 42:  37%|███▋      | 74/200 [00:29<00:48,  2.62it/s]Seed 42:  38%|███▊      | 75/200 [00:30<00:48,  2.58it/s]Seed 42:  38%|███▊      | 76/200 [00:30<00:50,  2.43it/s]Seed 42:  38%|███▊      | 77/200 [00:31<00:50,  2.45it/s]Seed 42:  39%|███▉      | 78/200 [00:31<00:52,  2.34it/s]============================================================
TELEPATHY TRAINING: ARC_EASY
============================================================

Dataset: arc_easy (4 classes)
Random baseline: 25.0%
Source layer: 31
Soft tokens: 8
Steps: 1500
Diversity weight: 0.1
============================================================
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 1952.43it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Seed 42:  40%|███▉      | 79/200 [00:32<00:52,  2.30it/s]Seed 42:  40%|████      | 80/200 [00:32<00:50,  2.37it/s]Seed 42:  40%|████      | 81/200 [00:32<00:50,  2.36it/s]Seed 42:  41%|████      | 82/200 [00:33<00:51,  2.30it/s]Seed 42:  42%|████▏     | 83/200 [00:33<00:49,  2.36it/s]Seed 42:  42%|████▏     | 84/200 [00:34<00:47,  2.47it/s]Seed 42:  42%|████▎     | 85/200 [00:34<00:43,  2.63it/s]Seed 42:  43%|████▎     | 86/200 [00:34<00:45,  2.53it/s]Seed 42:  44%|████▎     | 87/200 [00:35<00:44,  2.53it/s]Seed 42:  44%|████▍     | 88/200 [00:35<00:43,  2.58it/s]Seed 42:  44%|████▍     | 89/200 [00:35<00:42,  2.64it/s]Seed 42:  45%|████▌     | 90/200 [00:36<00:43,  2.55it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:14,  4.81s/it]Seed 42:  46%|████▌     | 91/200 [00:36<00:42,  2.54it/s]Seed 42:  46%|████▌     | 92/200 [00:37<00:42,  2.52it/s]Seed 42:  46%|████▋     | 93/200 [00:37<00:42,  2.53it/s]Seed 42:  47%|████▋     | 94/200 [00:37<00:42,  2.50it/s]Seed 42:  48%|████▊     | 95/200 [00:38<00:41,  2.55it/s]Seed 42:  48%|████▊     | 96/200 [00:38<00:41,  2.48it/s]Seed 42:  48%|████▊     | 97/200 [00:39<00:42,  2.41it/s]Seed 42:  49%|████▉     | 98/200 [00:39<00:42,  2.39it/s]Seed 42:  50%|████▉     | 99/200 [00:40<00:42,  2.37it/s]Seed 42:  50%|█████     | 100/200 [00:40<00:41,  2.43it/s]Seed 42:  50%|█████     | 101/200 [00:40<00:39,  2.48it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:09<00:08,  4.46s/it]Seed 42:  51%|█████     | 102/200 [00:41<00:38,  2.51it/s]Seed 42:  52%|█████▏    | 103/200 [00:41<00:36,  2.67it/s]Seed 42:  52%|█████▏    | 104/200 [00:41<00:36,  2.66it/s]Seed 42:  52%|█████▎    | 105/200 [00:42<00:36,  2.62it/s]Seed 42:  53%|█████▎    | 106/200 [00:42<00:35,  2.67it/s]Seed 42:  54%|█████▎    | 107/200 [00:43<00:34,  2.66it/s]Seed 42:  54%|█████▍    | 108/200 [00:43<00:34,  2.68it/s]Seed 42:  55%|█████▍    | 109/200 [00:43<00:33,  2.70it/s]Seed 42:  55%|█████▌    | 110/200 [00:44<00:33,  2.66it/s]Seed 42:  56%|█████▌    | 111/200 [00:44<00:32,  2.74it/s]Seed 42:  56%|█████▌    | 112/200 [00:44<00:32,  2.68it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:13<00:04,  4.25s/it]Seed 42:  56%|█████▋    | 113/200 [00:45<00:32,  2.69it/s]Seed 42:  57%|█████▋    | 114/200 [00:45<00:31,  2.71it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  2.98s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  3.51s/it]
Seed 42:  57%|█████▊    | 115/200 [00:45<00:30,  2.78it/s]Seed 42:  58%|█████▊    | 116/200 [00:46<00:26,  3.23it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2466.27it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Seed 42:  58%|█████▊    | 117/200 [00:46<00:26,  3.12it/s]Seed 42:  59%|█████▉    | 118/200 [00:46<00:27,  2.99it/s]Seed 42:  60%|█████▉    | 119/200 [00:47<00:27,  2.91it/s]Seed 42:  60%|██████    | 120/200 [00:47<00:28,  2.83it/s]Seed 42:  60%|██████    | 121/200 [00:48<00:28,  2.74it/s]Seed 42:  61%|██████    | 122/200 [00:48<00:28,  2.75it/s]Seed 42:  62%|██████▏   | 123/200 [00:48<00:29,  2.65it/s]Seed 42:  62%|██████▏   | 124/200 [00:49<00:28,  2.70it/s]Seed 42:  62%|██████▎   | 125/200 [00:49<00:28,  2.67it/s]Seed 42:  63%|██████▎   | 126/200 [00:49<00:27,  2.66it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.87s/it]Seed 42:  64%|██████▎   | 127/200 [00:50<00:27,  2.66it/s]Seed 42:  64%|██████▍   | 128/200 [00:50<00:26,  2.71it/s]Seed 42:  64%|██████▍   | 129/200 [00:51<00:26,  2.71it/s]Seed 42:  65%|██████▌   | 130/200 [00:51<00:25,  2.71it/s]Seed 42:  66%|██████▌   | 131/200 [00:51<00:25,  2.69it/s]Seed 42:  66%|██████▌   | 132/200 [00:52<00:25,  2.69it/s]Seed 42:  66%|██████▋   | 133/200 [00:52<00:24,  2.73it/s]Seed 42:  67%|██████▋   | 134/200 [00:52<00:24,  2.73it/s]Seed 42:  68%|██████▊   | 135/200 [00:53<00:23,  2.72it/s]Seed 42:  68%|██████▊   | 136/200 [00:53<00:23,  2.72it/s]Seed 42:  68%|██████▊   | 137/200 [00:53<00:23,  2.72it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.88s/it]Seed 42:  69%|██████▉   | 138/200 [00:54<00:22,  2.73it/s]Seed 42:  70%|██████▉   | 139/200 [00:54<00:22,  2.71it/s]Seed 42:  70%|███████   | 140/200 [00:55<00:22,  2.73it/s]Seed 42:  70%|███████   | 141/200 [00:55<00:21,  2.75it/s]Seed 42:  71%|███████   | 142/200 [00:55<00:21,  2.72it/s]Seed 42:  72%|███████▏  | 143/200 [00:56<00:20,  2.77it/s]Seed 42:  72%|███████▏  | 144/200 [00:56<00:20,  2.76it/s]Seed 42:  72%|███████▎  | 145/200 [00:56<00:20,  2.70it/s]Seed 42:  73%|███████▎  | 146/200 [00:57<00:19,  2.71it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.74s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.78s/it]
Seed 42:  74%|███████▎  | 147/200 [00:57<00:19,  2.73it/s]Seed 42:  74%|███████▍  | 148/200 [00:57<00:16,  3.19it/s]Seed 42:  74%|███████▍  | 149/200 [00:58<00:15,  3.23it/s]Seed 42:  75%|███████▌  | 150/200 [00:58<00:16,  3.09it/s]Seed 42:  76%|███████▌  | 151/200 [00:58<00:15,  3.22it/s]Seed 42:  76%|███████▌  | 152/200 [00:59<00:15,  3.03it/s]Seed 42:  76%|███████▋  | 153/200 [00:59<00:16,  2.92it/s]Seed 42:  77%|███████▋  | 154/200 [00:59<00:16,  2.85it/s]Seed 42:  78%|███████▊  | 155/200 [01:00<00:16,  2.79it/s]Seed 42:  78%|███████▊  | 156/200 [01:00<00:15,  2.81it/s]Seed 42:  78%|███████▊  | 157/200 [01:00<00:15,  2.75it/s]Seed 42:  79%|███████▉  | 158/200 [01:01<00:15,  2.78it/s]Seed 42:  80%|███████▉  | 159/200 [01:01<00:14,  2.78it/s]Seed 42:  80%|████████  | 160/200 [01:02<00:14,  2.74it/s]Seed 42:  80%|████████  | 161/200 [01:02<00:14,  2.77it/s]Seed 42:  81%|████████  | 162/200 [01:02<00:13,  2.77it/s]Seed 42:  82%|████████▏ | 163/200 [01:03<00:13,  2.65it/s]Seed 42:  82%|████████▏ | 164/200 [01:03<00:13,  2.68it/s]2026-01-19 12:28:02,567 - INFO - MINEBridge: 8 tokens, mine_weight=0.1
Seed 42:  82%|████████▎ | 165/200 [01:03<00:12,  2.70it/s]Seed 42:  83%|████████▎ | 166/200 [01:04<00:12,  2.69it/s]Seed 42:  84%|████████▎ | 167/200 [01:04<00:12,  2.69it/s]Seed 42:  84%|████████▍ | 168/200 [01:05<00:11,  2.73it/s]Seed 42:  84%|████████▍ | 169/200 [01:05<00:11,  2.70it/s]Seed 42:  85%|████████▌ | 170/200 [01:05<00:10,  2.84it/s]Seed 42:  86%|████████▌ | 171/200 [01:05<00:08,  3.29it/s]Seed 42:  86%|████████▌ | 172/200 [01:06<00:07,  3.69it/s]Seed 42:  86%|████████▋ | 173/200 [01:06<00:06,  4.04it/s]Seed 42:  87%|████████▋ | 174/200 [01:06<00:05,  4.38it/s]Seed 42:  88%|████████▊ | 175/200 [01:06<00:05,  4.60it/s]Seed 42:  88%|████████▊ | 176/200 [01:06<00:05,  4.75it/s]Seed 42:  88%|████████▊ | 177/200 [01:07<00:04,  4.69it/s]Seed 42:  89%|████████▉ | 178/200 [01:07<00:04,  4.88it/s]Seed 42:  90%|████████▉ | 179/200 [01:07<00:04,  4.82it/s]Target embedding RMS: 0.0027
Using MINE Bridge - Mutual Information Neural Estimation

Training on 2251 samples
Validation: 2376 samples
Starting training...

ARC_EASY:   0%|                                                            | 0/1500 [00:00<?, ?it/s]Seed 42:  90%|█████████ | 180/200 [01:07<00:04,  4.45it/s]ARC_EASY:   0%|                                                            | 0/1500 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1285, in main
    loss, loss_dict = train_step(
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 714, in train_step
    soft_tokens, aux_loss, diversity, z_variance = bridge_module(src_h, src_mask)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 1434, in forward
    mine_loss = self.compute_mine_loss(src_hidden, soft_tokens, src_mask)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 1385, in compute_mine_loss
    soft_flat = soft_tokens.view(B, -1)  # [B, K*D]
RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
Seed 42:  90%|█████████ | 181/200 [01:08<00:05,  3.56it/s]Seed 42:  91%|█████████ | 182/200 [01:08<00:05,  3.25it/s]Seed 42:  92%|█████████▏| 183/200 [01:08<00:05,  3.10it/s]Seed 42:  92%|█████████▏| 184/200 [01:09<00:05,  2.96it/s]Seed 42:  92%|█████████▎| 185/200 [01:09<00:05,  2.88it/s]Seed 42:  93%|█████████▎| 186/200 [01:09<00:04,  2.82it/s]Seed 42:  94%|█████████▎| 187/200 [01:10<00:04,  2.80it/s]Seed 42:  94%|█████████▍| 188/200 [01:10<00:04,  2.77it/s]Seed 42:  94%|█████████▍| 189/200 [01:11<00:03,  2.76it/s]
[ERROR] Training interrupted by exception at step 1
[ERROR] RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.

[EMERGENCY] Checkpoint saved to runs/reasoning_final_20260119_122501/novel_bridges/hailmary_mine_arc_easy_seed42/emergency_checkpoint_step0.pt
[EMERGENCY] Error: RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1530, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1285, in main
    loss, loss_dict = train_step(
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 714, in train_step
    soft_tokens, aux_loss, diversity, z_variance = bridge_module(src_h, src_mask)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 1434, in forward
    mine_loss = self.compute_mine_loss(src_hidden, soft_tokens, src_mask)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 1385, in compute_mine_loss
    soft_flat = soft_tokens.view(B, -1)  # [B, K*D]
RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
Seed 42:  95%|█████████▌| 190/200 [01:11<00:03,  2.74it/s]Seed 42:  96%|█████████▌| 191/200 [01:11<00:03,  2.70it/s]Seed 42:  96%|█████████▌| 192/200 [01:12<00:02,  2.74it/s]Seed 42:  96%|█████████▋| 193/200 [01:12<00:02,  2.66it/s][2026-01-19 12:28:11] FAILED: hailmary_mine_arc_easy_seed42 (exit code: 1)
Failed: hailmary_mine_arc_easy_seed42

[2026-01-19 12:28:11] [GPU 1] Testing HAIL MARY mixture_of_depths on ARC-Easy (seed=42)
Seed 42:  97%|█████████▋| 194/200 [01:12<00:02,  2.94it/s]Started: hailmary_mixture_of_depths_arc_easy_seed42
[2026-01-19 12:28:11] START: hailmary_mixture_of_depths_arc_easy_seed42
Seed 42:  98%|█████████▊| 195/200 [01:13<00:01,  2.98it/s]Seed 42:  98%|█████████▊| 196/200 [01:13<00:01,  2.86it/s]Seed 42:  98%|█████████▊| 197/200 [01:13<00:01,  2.81it/s]Seed 42:  99%|█████████▉| 198/200 [01:14<00:00,  2.70it/s]Seed 42: 100%|█████████▉| 199/200 [01:14<00:00,  2.61it/s]Seed 42: 100%|██████████| 200/200 [01:15<00:00,  2.67it/s]                                                          /users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
  Seed 42: 24.5%
Seed 123:   0%|          | 0/200 [00:00<?, ?it/s]Seed 123:   0%|          | 1/200 [00:00<01:19,  2.51it/s]Seed 123:   1%|          | 2/200 [00:00<01:12,  2.72it/s]Seed 123:   2%|▏         | 3/200 [00:00<01:01,  3.18it/s]Seed 123:   2%|▏         | 4/200 [00:01<01:07,  2.89it/s]Seed 123:   2%|▎         | 5/200 [00:01<01:10,  2.76it/s]Seed 123:   3%|▎         | 6/200 [00:02<01:12,  2.67it/s]Seed 123:   4%|▎         | 7/200 [00:02<01:14,  2.58it/s]Seed 123:   4%|▍         | 8/200 [00:02<01:13,  2.60it/s]============================================================
TELEPATHY TRAINING: ARC_EASY
============================================================

Dataset: arc_easy (4 classes)
Random baseline: 25.0%
Source layer: 31
Soft tokens: 8
Steps: 1500
Diversity weight: 0.1
============================================================
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 1519.81it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Seed 123:   4%|▍         | 9/200 [00:03<01:12,  2.62it/s]Seed 123:   5%|▌         | 10/200 [00:03<01:11,  2.65it/s]Seed 123:   6%|▌         | 11/200 [00:04<01:11,  2.64it/s]Seed 123:   6%|▌         | 12/200 [00:04<01:09,  2.71it/s]Seed 123:   6%|▋         | 13/200 [00:04<01:10,  2.66it/s]Seed 123:   7%|▋         | 14/200 [00:05<01:09,  2.66it/s]Seed 123:   8%|▊         | 15/200 [00:05<01:08,  2.69it/s]Seed 123:   8%|▊         | 16/200 [00:05<01:08,  2.70it/s]Seed 123:   8%|▊         | 17/200 [00:06<01:07,  2.71it/s]Seed 123:   9%|▉         | 18/200 [00:06<01:07,  2.71it/s]Seed 123:  10%|▉         | 19/200 [00:07<01:06,  2.71it/s]Seed 123:  10%|█         | 20/200 [00:07<01:06,  2.72it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:13,  4.37s/it]Seed 123:  10%|█         | 21/200 [00:07<01:05,  2.72it/s]Seed 123:  11%|█         | 22/200 [00:08<01:04,  2.74it/s]Seed 123:  12%|█▏        | 23/200 [00:08<01:02,  2.83it/s]Seed 123:  12%|█▏        | 24/200 [00:08<01:02,  2.79it/s]Seed 123:  12%|█▎        | 25/200 [00:09<01:03,  2.76it/s]Seed 123:  13%|█▎        | 26/200 [00:09<01:03,  2.75it/s]Seed 123:  14%|█▎        | 27/200 [00:09<01:03,  2.71it/s]Seed 123:  14%|█▍        | 28/200 [00:10<01:03,  2.71it/s]Seed 123:  14%|█▍        | 29/200 [00:10<01:03,  2.71it/s]Seed 123:  15%|█▌        | 30/200 [00:11<01:02,  2.71it/s]Seed 123:  16%|█▌        | 31/200 [00:11<01:02,  2.71it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.16s/it]Seed 123:  16%|█▌        | 32/200 [00:11<01:01,  2.72it/s]Seed 123:  16%|█▋        | 33/200 [00:12<01:02,  2.68it/s]Seed 123:  17%|█▋        | 34/200 [00:12<01:01,  2.70it/s]Seed 123:  18%|█▊        | 35/200 [00:12<01:01,  2.69it/s]Seed 123:  18%|█▊        | 36/200 [00:13<01:00,  2.72it/s]Seed 123:  18%|█▊        | 37/200 [00:13<00:59,  2.72it/s]Seed 123:  19%|█▉        | 38/200 [00:14<01:00,  2.69it/s]Seed 123:  20%|█▉        | 39/200 [00:14<00:59,  2.69it/s]Seed 123:  20%|██        | 40/200 [00:14<00:59,  2.70it/s]Seed 123:  20%|██        | 41/200 [00:15<00:58,  2.71it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.05s/it]Seed 123:  21%|██        | 42/200 [00:15<00:58,  2.72it/s]Seed 123:  22%|██▏       | 43/200 [00:15<00:58,  2.68it/s]Seed 123:  22%|██▏       | 44/200 [00:16<00:57,  2.72it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.85s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.33s/it]
Seed 123:  22%|██▎       | 45/200 [00:16<00:54,  2.86it/s]Seed 123:  23%|██▎       | 46/200 [00:16<00:46,  3.31it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2284.06it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Seed 123:  24%|██▎       | 47/200 [00:17<00:50,  3.02it/s]Seed 123:  24%|██▍       | 48/200 [00:17<00:53,  2.83it/s]Seed 123:  24%|██▍       | 49/200 [00:17<00:54,  2.77it/s]Seed 123:  25%|██▌       | 50/200 [00:18<00:54,  2.77it/s]Seed 123:  26%|██▌       | 51/200 [00:18<00:53,  2.79it/s]Seed 123:  26%|██▌       | 52/200 [00:19<00:53,  2.75it/s]Seed 123:  26%|██▋       | 53/200 [00:19<00:53,  2.74it/s]Seed 123:  27%|██▋       | 54/200 [00:19<00:53,  2.74it/s]Seed 123:  28%|██▊       | 55/200 [00:20<00:52,  2.74it/s]Seed 123:  28%|██▊       | 56/200 [00:20<00:52,  2.73it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.87s/it]Seed 123:  28%|██▊       | 57/200 [00:20<00:52,  2.71it/s]Seed 123:  29%|██▉       | 58/200 [00:21<00:52,  2.71it/s]Seed 123:  30%|██▉       | 59/200 [00:21<00:51,  2.72it/s]Seed 123:  30%|███       | 60/200 [00:21<00:51,  2.73it/s]Seed 123:  30%|███       | 61/200 [00:22<00:51,  2.72it/s]Seed 123:  31%|███       | 62/200 [00:22<00:51,  2.67it/s]Seed 123:  32%|███▏      | 63/200 [00:23<00:50,  2.69it/s]Seed 123:  32%|███▏      | 64/200 [00:23<00:50,  2.70it/s]Seed 123:  32%|███▎      | 65/200 [00:23<00:49,  2.71it/s]Seed 123:  33%|███▎      | 66/200 [00:24<00:49,  2.69it/s]Seed 123:  34%|███▎      | 67/200 [00:24<00:49,  2.69it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.90s/it]Seed 123:  34%|███▍      | 68/200 [00:24<00:48,  2.70it/s]Seed 123:  34%|███▍      | 69/200 [00:25<00:48,  2.70it/s]Seed 123:  35%|███▌      | 70/200 [00:25<00:48,  2.69it/s]Seed 123:  36%|███▌      | 71/200 [00:26<00:47,  2.70it/s]Seed 123:  36%|███▌      | 72/200 [00:26<00:47,  2.72it/s]Seed 123:  36%|███▋      | 73/200 [00:26<00:47,  2.70it/s]Seed 123:  37%|███▋      | 74/200 [00:27<00:46,  2.71it/s]Seed 123:  38%|███▊      | 75/200 [00:27<00:46,  2.70it/s]Seed 123:  38%|███▊      | 76/200 [00:27<00:45,  2.71it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.71s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.77s/it]
Seed 123:  38%|███▊      | 77/200 [00:28<00:42,  2.87it/s]Seed 123:  39%|███▉      | 78/200 [00:28<00:36,  3.31it/s]Seed 123:  40%|███▉      | 79/200 [00:28<00:38,  3.14it/s]Seed 123:  40%|████      | 80/200 [00:29<00:38,  3.14it/s]Seed 123:  40%|████      | 81/200 [00:29<00:39,  2.99it/s]Seed 123:  41%|████      | 82/200 [00:29<00:40,  2.90it/s]Seed 123:  42%|████▏     | 83/200 [00:30<00:41,  2.85it/s]Seed 123:  42%|████▏     | 84/200 [00:30<00:41,  2.81it/s]Seed 123:  42%|████▎     | 85/200 [00:30<00:41,  2.78it/s]Seed 123:  43%|████▎     | 86/200 [00:31<00:41,  2.74it/s]Seed 123:  44%|████▎     | 87/200 [00:31<00:40,  2.76it/s]Seed 123:  44%|████▍     | 88/200 [00:31<00:40,  2.74it/s]Seed 123:  44%|████▍     | 89/200 [00:32<00:40,  2.73it/s]Seed 123:  45%|████▌     | 90/200 [00:32<00:40,  2.73it/s]Seed 123:  46%|████▌     | 91/200 [00:33<00:40,  2.72it/s]Seed 123:  46%|████▌     | 92/200 [00:33<00:40,  2.68it/s]Seed 123:  46%|████▋     | 93/200 [00:33<00:39,  2.71it/s]Seed 123:  47%|████▋     | 94/200 [00:34<00:38,  2.73it/s]2026-01-19 12:28:48,807 - INFO - MixtureOfDepthsBridge: 8 tokens, 2 layers, capacity=0.5
Seed 123:  48%|████▊     | 95/200 [00:34<00:38,  2.71it/s]Seed 123:  48%|████▊     | 96/200 [00:34<00:37,  2.74it/s]Seed 123:  48%|████▊     | 97/200 [00:35<00:38,  2.68it/s]Seed 123:  49%|████▉     | 98/200 [00:35<00:37,  2.74it/s]Seed 123:  50%|████▉     | 99/200 [00:35<00:35,  2.84it/s]Seed 123:  50%|█████     | 100/200 [00:36<00:30,  3.30it/s]Seed 123:  50%|█████     | 101/200 [00:36<00:26,  3.71it/s]Seed 123:  51%|█████     | 102/200 [00:36<00:24,  4.08it/s]Seed 123:  52%|█████▏    | 103/200 [00:36<00:22,  4.36it/s]Seed 123:  52%|█████▏    | 104/200 [00:36<00:20,  4.64it/s]Seed 123:  52%|█████▎    | 105/200 [00:37<00:19,  4.81it/s]Seed 123:  53%|█████▎    | 106/200 [00:37<00:19,  4.91it/s]Seed 123:  54%|█████▎    | 107/200 [00:37<00:19,  4.82it/s]Seed 123:  54%|█████▍    | 108/200 [00:37<00:18,  4.97it/s]Seed 123:  55%|█████▍    | 109/200 [00:37<00:17,  5.06it/s]Target embedding RMS: 0.0027
Using Mixture-of-Depths Bridge - Adaptive compute via early exit

Training on 2251 samples
Validation: 2376 samples
Starting training...

ARC_EASY:   0%|                                                            | 0/1500 [00:00<?, ?it/s]Seed 123:  55%|█████▌    | 110/200 [00:38<00:17,  5.04it/s]Seed 123:  56%|█████▌    | 111/200 [00:38<00:21,  4.20it/s]Seed 123:  56%|█████▌    | 112/200 [00:38<00:24,  3.54it/s]Seed 123:  56%|█████▋    | 113/200 [00:39<00:28,  3.10it/s]ARC_EASY:   0%|                             | 0/1500 [00:01<?, ?it/s, lm=9.24, aux=0.000, gn=302.00]ARC_EASY:   0%|                     | 1/1500 [00:01<33:32,  1.34s/it, lm=9.24, aux=0.000, gn=302.00]Seed 123:  57%|█████▋    | 114/200 [00:39<00:32,  2.65it/s]ARC_EASY:   0%|                     | 1/1500 [00:01<33:32,  1.34s/it, lm=9.34, aux=0.000, gn=186.00]ARC_EASY:   0%|                     | 2/1500 [00:01<19:37,  1.27it/s, lm=9.34, aux=0.000, gn=186.00]ARC_EASY:   0%|                     | 2/1500 [00:02<19:37,  1.27it/s, lm=8.94, aux=0.000, gn=282.00]ARC_EASY:   0%|                     | 3/1500 [00:02<14:51,  1.68it/s, lm=8.94, aux=0.000, gn=282.00]Seed 123:  57%|█████▊    | 115/200 [00:40<00:38,  2.18it/s]ARC_EASY:   0%|                     | 3/1500 [00:02<14:51,  1.68it/s, lm=8.46, aux=0.000, gn=174.00]ARC_EASY:   0%|                     | 4/1500 [00:02<12:40,  1.97it/s, lm=8.46, aux=0.000, gn=174.00]ARC_EASY:   0%|                     | 4/1500 [00:02<12:40,  1.97it/s, lm=7.86, aux=0.000, gn=316.00]ARC_EASY:   0%|                     | 5/1500 [00:02<11:25,  2.18it/s, lm=7.86, aux=0.000, gn=316.00]Seed 123:  58%|█████▊    | 116/200 [00:40<00:41,  2.03it/s]ARC_EASY:   0%|                     | 5/1500 [00:03<11:25,  2.18it/s, lm=7.07, aux=0.000, gn=284.00]ARC_EASY:   0%|                     | 6/1500 [00:03<10:29,  2.37it/s, lm=7.07, aux=0.000, gn=284.00]Seed 123:  58%|█████▊    | 117/200 [00:41<00:44,  1.86it/s]ARC_EASY:   0%|                     | 6/1500 [00:03<10:29,  2.37it/s, lm=6.53, aux=0.000, gn=191.00]ARC_EASY:   0%|                     | 7/1500 [00:03<10:03,  2.47it/s, lm=6.53, aux=0.000, gn=191.00]ARC_EASY:   0%|                     | 7/1500 [00:03<10:03,  2.47it/s, lm=6.12, aux=0.000, gn=288.00]ARC_EASY:   1%|                     | 8/1500 [00:03<09:39,  2.58it/s, lm=6.12, aux=0.000, gn=288.00]Seed 123:  59%|█████▉    | 118/200 [00:42<00:46,  1.78it/s]ARC_EASY:   1%|                     | 8/1500 [00:04<09:39,  2.58it/s, lm=5.20, aux=0.000, gn=142.00]ARC_EASY:   1%|▏                    | 9/1500 [00:04<09:35,  2.59it/s, lm=5.20, aux=0.000, gn=142.00]ARC_EASY:   1%|▏                    | 9/1500 [00:04<09:35,  2.59it/s, lm=3.88, aux=0.000, gn=244.00]ARC_EASY:   1%|▏                   | 10/1500 [00:04<09:26,  2.63it/s, lm=3.88, aux=0.000, gn=244.00]Seed 123:  60%|█████▉    | 119/200 [00:42<00:45,  1.77it/s]ARC_EASY:   1%|▏                   | 10/1500 [00:05<09:26,  2.63it/s, lm=3.21, aux=0.000, gn=772.00]ARC_EASY:   1%|▏                   | 11/1500 [00:05<09:24,  2.64it/s, lm=3.21, aux=0.000, gn=772.00]Seed 123:  60%|██████    | 120/200 [00:43<00:46,  1.72it/s]ARC_EASY:   1%|▏                  | 11/1500 [00:05<09:24,  2.64it/s, lm=2.79, aux=0.000, gn=1168.00]ARC_EASY:   1%|▏                  | 12/1500 [00:05<09:25,  2.63it/s, lm=2.79, aux=0.000, gn=1168.00]ARC_EASY:   1%|▏                  | 12/1500 [00:05<09:25,  2.63it/s, lm=1.74, aux=0.000, gn=1144.00]ARC_EASY:   1%|▏                  | 13/1500 [00:05<09:26,  2.63it/s, lm=1.74, aux=0.000, gn=1144.00]Seed 123:  60%|██████    | 121/200 [00:43<00:45,  1.73it/s]ARC_EASY:   1%|▏                  | 13/1500 [00:06<09:26,  2.63it/s, lm=2.09, aux=0.000, gn=1304.00]ARC_EASY:   1%|▏                  | 14/1500 [00:06<09:23,  2.64it/s, lm=2.09, aux=0.000, gn=1304.00]Seed 123:  61%|██████    | 122/200 [00:44<00:45,  1.72it/s]ARC_EASY:   1%|▏                  | 14/1500 [00:06<09:23,  2.64it/s, lm=2.01, aux=0.000, gn=2080.00]ARC_EASY:   1%|▏                  | 15/1500 [00:06<09:06,  2.72it/s, lm=2.01, aux=0.000, gn=2080.00]ARC_EASY:   1%|▏                   | 15/1500 [00:06<09:06,  2.72it/s, lm=2.31, aux=0.000, gn=596.00]ARC_EASY:   1%|▏                   | 16/1500 [00:06<09:12,  2.69it/s, lm=2.31, aux=0.000, gn=596.00]Seed 123:  62%|██████▏   | 123/200 [00:45<00:44,  1.74it/s]ARC_EASY:   1%|▏                   | 16/1500 [00:07<09:12,  2.69it/s, lm=1.11, aux=0.000, gn=108.50]ARC_EASY:   1%|▏                   | 17/1500 [00:07<09:11,  2.69it/s, lm=1.11, aux=0.000, gn=108.50]Seed 123:  62%|██████▏   | 124/200 [00:45<00:44,  1.71it/s]ARC_EASY:   1%|▏                   | 17/1500 [00:07<09:11,  2.69it/s, lm=1.83, aux=0.000, gn=688.00]ARC_EASY:   1%|▏                   | 18/1500 [00:07<09:07,  2.70it/s, lm=1.83, aux=0.000, gn=688.00]ARC_EASY:   1%|▏                   | 18/1500 [00:07<10:45,  2.30it/s, lm=1.83, aux=0.000, gn=688.00]
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1280, in main
    batch = next(iter_dl)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 398, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 207, in collate
    raise RuntimeError("each element in list of batch should be of equal size")
RuntimeError: each element in list of batch should be of equal size
Seed 123:  62%|██████▎   | 125/200 [00:46<00:41,  1.83it/s]Seed 123:  63%|██████▎   | 126/200 [00:46<00:36,  2.01it/s]Seed 123:  64%|██████▎   | 127/200 [00:46<00:33,  2.17it/s]Seed 123:  64%|██████▍   | 128/200 [00:47<00:32,  2.23it/s]Seed 123:  64%|██████▍   | 129/200 [00:47<00:29,  2.37it/s]Seed 123:  65%|██████▌   | 130/200 [00:48<00:28,  2.46it/s]Seed 123:  66%|██████▌   | 131/200 [00:48<00:27,  2.52it/s]Seed 123:  66%|██████▌   | 132/200 [00:48<00:26,  2.59it/s]Seed 123:  66%|██████▋   | 133/200 [00:49<00:25,  2.60it/s]Seed 123:  67%|██████▋   | 134/200 [00:49<00:25,  2.63it/s]Seed 123:  68%|██████▊   | 135/200 [00:49<00:24,  2.65it/s]Seed 123:  68%|██████▊   | 136/200 [00:50<00:24,  2.66it/s]Seed 123:  68%|██████▊   | 137/200 [00:50<00:23,  2.69it/s]Seed 123:  69%|██████▉   | 138/200 [00:51<00:22,  2.70it/s]Seed 123:  70%|██████▉   | 139/200 [00:51<00:22,  2.67it/s]Seed 123:  70%|███████   | 140/200 [00:51<00:22,  2.71it/s]Seed 123:  70%|███████   | 141/200 [00:52<00:21,  2.70it/s]Seed 123:  71%|███████   | 142/200 [00:52<00:21,  2.69it/s]Seed 123:  72%|███████▏  | 143/200 [00:52<00:20,  2.73it/s]Seed 123:  72%|███████▏  | 144/200 [00:53<00:20,  2.69it/s]Seed 123:  72%|███████▎  | 145/200 [00:53<00:20,  2.72it/s]Seed 123:  73%|███████▎  | 146/200 [00:54<00:19,  2.71it/s]Seed 123:  74%|███████▎  | 147/200 [00:54<00:19,  2.68it/s]Seed 123:  74%|███████▍  | 148/200 [00:54<00:19,  2.68it/s]
[ERROR] Training interrupted by exception at step 19
[ERROR] RuntimeError: each element in list of batch should be of equal size

[EMERGENCY] Checkpoint saved to runs/reasoning_final_20260119_122501/novel_bridges/hailmary_mixture_of_depths_arc_easy_seed42/emergency_checkpoint_step18.pt
[EMERGENCY] Error: RuntimeError: each element in list of batch should be of equal size
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1530, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1280, in main
    batch = next(iter_dl)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 398, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 207, in collate
    raise RuntimeError("each element in list of batch should be of equal size")
RuntimeError: each element in list of batch should be of equal size
Seed 123:  74%|███████▍  | 149/200 [00:55<00:18,  2.71it/s]Seed 123:  75%|███████▌  | 150/200 [00:55<00:18,  2.70it/s]Seed 123:  76%|███████▌  | 151/200 [00:55<00:18,  2.69it/s]Seed 123:  76%|███████▌  | 152/200 [00:56<00:17,  2.72it/s]Seed 123:  76%|███████▋  | 153/200 [00:56<00:17,  2.72it/s][2026-01-19 12:29:11] FAILED: hailmary_mixture_of_depths_arc_easy_seed42 (exit code: 1)
Failed: hailmary_mixture_of_depths_arc_easy_seed42

[2026-01-19 12:29:11] [GPU 1] Testing HAIL MARY thalamic_relay on ARC-Easy (seed=42)
Seed 123:  77%|███████▋  | 154/200 [00:56<00:15,  2.98it/s]Started: hailmary_thalamic_relay_arc_easy_seed42
[2026-01-19 12:29:11] START: hailmary_thalamic_relay_arc_easy_seed42
Seed 123:  78%|███████▊  | 155/200 [00:57<00:14,  3.08it/s]Seed 123:  78%|███████▊  | 156/200 [00:57<00:15,  2.90it/s]Seed 123:  78%|███████▊  | 157/200 [00:57<00:14,  2.88it/s]Seed 123:  79%|███████▉  | 158/200 [00:58<00:15,  2.71it/s]Seed 123:  80%|███████▉  | 159/200 [00:58<00:15,  2.57it/s]Seed 123:  80%|████████  | 160/200 [00:59<00:15,  2.63it/s]Seed 123:  80%|████████  | 161/200 [00:59<00:14,  2.61it/s]/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Seed 123:  81%|████████  | 162/200 [00:59<00:15,  2.50it/s]Seed 123:  82%|████████▏ | 163/200 [01:00<00:14,  2.49it/s]Seed 123:  82%|████████▏ | 164/200 [01:00<00:14,  2.54it/s]Seed 123:  82%|████████▎ | 165/200 [01:00<00:12,  2.90it/s]Seed 123:  83%|████████▎ | 166/200 [01:01<00:12,  2.80it/s]Seed 123:  84%|████████▎ | 167/200 [01:01<00:12,  2.74it/s]Seed 123:  84%|████████▍ | 168/200 [01:02<00:12,  2.64it/s]Seed 123:  84%|████████▍ | 169/200 [01:02<00:12,  2.57it/s]Seed 123:  85%|████████▌ | 170/200 [01:02<00:11,  2.56it/s]============================================================
TELEPATHY TRAINING: ARC_EASY
============================================================

Dataset: arc_easy (4 classes)
Random baseline: 25.0%
Source layer: 31
Soft tokens: 8
Steps: 1500
Diversity weight: 0.1
============================================================
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 1500.38it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Seed 123:  86%|████████▌ | 171/200 [01:03<00:11,  2.53it/s]Seed 123:  86%|████████▌ | 172/200 [01:03<00:10,  2.59it/s]Seed 123:  86%|████████▋ | 173/200 [01:04<00:10,  2.62it/s]Seed 123:  87%|████████▋ | 174/200 [01:04<00:09,  2.64it/s]Seed 123:  88%|████████▊ | 175/200 [01:04<00:09,  2.66it/s]Seed 123:  88%|████████▊ | 176/200 [01:05<00:09,  2.65it/s]Seed 123:  88%|████████▊ | 177/200 [01:05<00:08,  2.68it/s]Seed 123:  89%|████████▉ | 178/200 [01:05<00:08,  2.71it/s]Seed 123:  90%|████████▉ | 179/200 [01:06<00:07,  2.69it/s]Seed 123:  90%|█████████ | 180/200 [01:06<00:07,  2.69it/s]Seed 123:  90%|█████████ | 181/200 [01:07<00:07,  2.69it/s]Seed 123:  91%|█████████ | 182/200 [01:07<00:06,  2.71it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:13,  4.39s/it]Seed 123:  92%|█████████▏| 183/200 [01:07<00:06,  2.67it/s]Seed 123:  92%|█████████▏| 184/200 [01:08<00:05,  2.68it/s]Seed 123:  92%|█████████▎| 185/200 [01:08<00:05,  2.70it/s]Seed 123:  93%|█████████▎| 186/200 [01:08<00:05,  2.67it/s]Seed 123:  94%|█████████▎| 187/200 [01:09<00:04,  2.73it/s]Seed 123:  94%|█████████▍| 188/200 [01:09<00:04,  2.71it/s]Seed 123:  94%|█████████▍| 189/200 [01:10<00:04,  2.67it/s]Seed 123:  95%|█████████▌| 190/200 [01:10<00:03,  2.69it/s]Seed 123:  96%|█████████▌| 191/200 [01:10<00:03,  2.69it/s]Seed 123:  96%|█████████▌| 192/200 [01:11<00:02,  2.70it/s]Seed 123:  96%|█████████▋| 193/200 [01:11<00:02,  2.71it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.14s/it]Seed 123:  97%|█████████▋| 194/200 [01:11<00:02,  2.73it/s]Seed 123:  98%|█████████▊| 195/200 [01:12<00:01,  2.70it/s]Seed 123:  98%|█████████▊| 196/200 [01:12<00:01,  2.69it/s]Seed 123:  98%|█████████▊| 197/200 [01:13<00:01,  2.70it/s]Seed 123:  99%|█████████▉| 198/200 [01:13<00:00,  2.72it/s]Seed 123: 100%|█████████▉| 199/200 [01:13<00:00,  2.74it/s]Seed 123: 100%|██████████| 200/200 [01:14<00:00,  2.73it/s]                                                             Seed 123: 25.5%
Seed 456:   0%|          | 0/200 [00:00<?, ?it/s]Seed 456:   0%|          | 1/200 [00:00<01:13,  2.72it/s]Seed 456:   1%|          | 2/200 [00:00<01:12,  2.72it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.04s/it]Seed 456:   2%|▏         | 3/200 [00:01<01:12,  2.71it/s]Seed 456:   2%|▏         | 4/200 [00:01<01:11,  2.75it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.84s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.32s/it]
Seed 456:   2%|▎         | 5/200 [00:01<01:09,  2.80it/s]Seed 456:   3%|▎         | 6/200 [00:02<00:58,  3.32it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2220.38it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Seed 456:   4%|▎         | 7/200 [00:02<01:01,  3.16it/s]Seed 456:   4%|▍         | 8/200 [00:02<01:06,  2.89it/s]Seed 456:   4%|▍         | 9/200 [00:03<01:07,  2.83it/s]Seed 456:   5%|▌         | 10/200 [00:03<01:08,  2.79it/s]Seed 456:   6%|▌         | 11/200 [00:03<01:08,  2.77it/s]Seed 456:   6%|▌         | 12/200 [00:04<01:08,  2.75it/s]Seed 456:   6%|▋         | 13/200 [00:04<01:09,  2.70it/s]Seed 456:   7%|▋         | 14/200 [00:04<01:08,  2.71it/s]Seed 456:   8%|▊         | 15/200 [00:05<01:08,  2.71it/s]Seed 456:   8%|▊         | 16/200 [00:05<01:08,  2.70it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.84s/it]Seed 456:   8%|▊         | 17/200 [00:06<01:07,  2.70it/s]Seed 456:   9%|▉         | 18/200 [00:06<01:08,  2.67it/s]Seed 456:  10%|▉         | 19/200 [00:06<01:07,  2.67it/s]Seed 456:  10%|█         | 20/200 [00:07<01:06,  2.69it/s]Seed 456:  10%|█         | 21/200 [00:07<01:06,  2.70it/s]Seed 456:  11%|█         | 22/200 [00:07<01:05,  2.71it/s]Seed 456:  12%|█▏        | 23/200 [00:08<01:05,  2.69it/s]Seed 456:  12%|█▏        | 24/200 [00:08<01:04,  2.71it/s]Seed 456:  12%|█▎        | 25/200 [00:09<01:04,  2.71it/s]Seed 456:  13%|█▎        | 26/200 [00:09<01:03,  2.74it/s]Seed 456:  14%|█▎        | 27/200 [00:09<01:03,  2.74it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.87s/it]Seed 456:  14%|█▍        | 28/200 [00:10<01:03,  2.71it/s]Seed 456:  14%|█▍        | 29/200 [00:10<01:02,  2.74it/s]Seed 456:  15%|█▌        | 30/200 [00:10<01:02,  2.70it/s]Seed 456:  16%|█▌        | 31/200 [00:11<01:02,  2.71it/s]Seed 456:  16%|█▌        | 32/200 [00:11<01:01,  2.72it/s]Seed 456:  16%|█▋        | 33/200 [00:12<01:01,  2.72it/s]Seed 456:  17%|█▋        | 34/200 [00:12<01:00,  2.73it/s]Seed 456:  18%|█▊        | 35/200 [00:12<01:00,  2.71it/s]Seed 456:  18%|█▊        | 36/200 [00:13<01:00,  2.70it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.72s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.75s/it]
Seed 456:  18%|█▊        | 37/200 [00:13<00:58,  2.80it/s]Seed 456:  19%|█▉        | 38/200 [00:13<00:49,  3.25it/s]Seed 456:  20%|█▉        | 39/200 [00:13<00:51,  3.12it/s]Seed 456:  20%|██        | 40/200 [00:14<00:51,  3.12it/s]Seed 456:  20%|██        | 41/200 [00:14<00:53,  2.98it/s]Seed 456:  21%|██        | 42/200 [00:15<00:54,  2.88it/s]Seed 456:  22%|██▏       | 43/200 [00:15<00:55,  2.81it/s]Seed 456:  22%|██▏       | 44/200 [00:15<00:55,  2.80it/s]Seed 456:  22%|██▎       | 45/200 [00:16<00:56,  2.75it/s]Seed 456:  23%|██▎       | 46/200 [00:16<00:56,  2.74it/s]Seed 456:  24%|██▎       | 47/200 [00:16<00:56,  2.72it/s]Seed 456:  24%|██▍       | 48/200 [00:17<00:55,  2.76it/s]Seed 456:  24%|██▍       | 49/200 [00:17<00:55,  2.73it/s]Seed 456:  25%|██▌       | 50/200 [00:17<00:54,  2.74it/s]Seed 456:  26%|██▌       | 51/200 [00:18<00:55,  2.69it/s]Seed 456:  26%|██▌       | 52/200 [00:18<00:54,  2.71it/s]Seed 456:  26%|██▋       | 53/200 [00:19<00:54,  2.70it/s]Seed 456:  27%|██▋       | 54/200 [00:19<00:54,  2.68it/s]2026-01-19 12:29:49,158 - INFO - ThalamicRelayBridge: 8 tokens with inhibitory gating
Seed 456:  28%|██▊       | 55/200 [00:19<00:53,  2.72it/s]Seed 456:  28%|██▊       | 56/200 [00:20<00:53,  2.70it/s]Seed 456:  28%|██▊       | 57/200 [00:20<00:52,  2.72it/s]Seed 456:  29%|██▉       | 58/200 [00:20<00:52,  2.71it/s]Seed 456:  30%|██▉       | 59/200 [00:21<00:52,  2.70it/s]Seed 456:  30%|███       | 60/200 [00:21<00:44,  3.12it/s]Seed 456:  30%|███       | 61/200 [00:21<00:39,  3.55it/s]Seed 456:  31%|███       | 62/200 [00:21<00:35,  3.91it/s]Seed 456:  32%|███▏      | 63/200 [00:22<00:32,  4.22it/s]Seed 456:  32%|███▏      | 64/200 [00:22<00:30,  4.46it/s]Seed 456:  32%|███▎      | 65/200 [00:22<00:29,  4.63it/s]Seed 456:  33%|███▎      | 66/200 [00:22<00:27,  4.83it/s]Seed 456:  34%|███▎      | 67/200 [00:22<00:27,  4.76it/s]Seed 456:  34%|███▍      | 68/200 [00:23<00:27,  4.88it/s]Seed 456:  34%|███▍      | 69/200 [00:23<00:26,  5.01it/s]Target embedding RMS: 0.0027
Using Thalamic Relay Bridge - Inhibitory gating

Training on 2251 samples
Validation: 2376 samples
Starting training...

ARC_EASY:   0%|                                                            | 0/1500 [00:00<?, ?it/s]Seed 456:  35%|███▌      | 70/200 [00:23<00:28,  4.54it/s]Seed 456:  36%|███▌      | 71/200 [00:23<00:32,  3.97it/s]Seed 456:  36%|███▌      | 72/200 [00:24<00:32,  3.92it/s]Seed 456:  36%|███▋      | 73/200 [00:24<00:36,  3.45it/s]ARC_EASY:   0%|                            | 0/1500 [00:01<?, ?it/s, lm=8.89, aux=0.000, gn=1020.00]ARC_EASY:   0%|                    | 1/1500 [00:01<35:24,  1.42s/it, lm=8.89, aux=0.000, gn=1020.00]Seed 456:  37%|███▋      | 74/200 [00:25<00:46,  2.71it/s]ARC_EASY:   0%|                     | 1/1500 [00:01<35:24,  1.42s/it, lm=8.95, aux=0.000, gn=980.00]ARC_EASY:   0%|                     | 2/1500 [00:01<19:42,  1.27it/s, lm=8.95, aux=0.000, gn=980.00]ARC_EASY:   0%|                    | 2/1500 [00:02<19:42,  1.27it/s, lm=7.89, aux=0.000, gn=1240.00]ARC_EASY:   0%|                    | 3/1500 [00:02<14:57,  1.67it/s, lm=7.89, aux=0.000, gn=1240.00]Seed 456:  38%|███▊      | 75/200 [00:25<00:53,  2.32it/s]ARC_EASY:   0%|                     | 3/1500 [00:02<14:57,  1.67it/s, lm=7.64, aux=0.000, gn=612.00]ARC_EASY:   0%|                     | 4/1500 [00:02<12:32,  1.99it/s, lm=7.64, aux=0.000, gn=612.00]ARC_EASY:   0%|                     | 4/1500 [00:02<12:32,  1.99it/s, lm=6.68, aux=0.000, gn=380.00]ARC_EASY:   0%|                     | 5/1500 [00:02<11:21,  2.19it/s, lm=6.68, aux=0.000, gn=380.00]Seed 456:  38%|███▊      | 76/200 [00:26<01:02,  2.00it/s]ARC_EASY:   0%|                     | 5/1500 [00:03<11:21,  2.19it/s, lm=5.64, aux=0.000, gn=684.00]ARC_EASY:   0%|                     | 6/1500 [00:03<10:39,  2.34it/s, lm=5.64, aux=0.000, gn=684.00]Seed 456:  38%|███▊      | 77/200 [00:26<01:05,  1.87it/s]ARC_EASY:   0%|                     | 6/1500 [00:03<10:39,  2.34it/s, lm=4.72, aux=0.000, gn=772.00]ARC_EASY:   0%|                     | 7/1500 [00:03<09:58,  2.50it/s, lm=4.72, aux=0.000, gn=772.00]ARC_EASY:   0%|                     | 7/1500 [00:03<09:58,  2.50it/s, lm=3.79, aux=0.000, gn=300.00]ARC_EASY:   1%|                     | 8/1500 [00:03<09:36,  2.59it/s, lm=3.79, aux=0.000, gn=300.00]Seed 456:  39%|███▉      | 78/200 [00:27<01:08,  1.78it/s]ARC_EASY:   1%|                     | 8/1500 [00:04<09:36,  2.59it/s, lm=3.53, aux=0.000, gn=752.00]ARC_EASY:   1%|▏                    | 9/1500 [00:04<09:24,  2.64it/s, lm=3.53, aux=0.000, gn=752.00]ARC_EASY:   1%|▏                    | 9/1500 [00:04<09:24,  2.64it/s, lm=2.01, aux=0.000, gn=612.00]ARC_EASY:   1%|▏                   | 10/1500 [00:04<09:08,  2.72it/s, lm=2.01, aux=0.000, gn=612.00]Seed 456:  40%|███▉      | 79/200 [00:28<01:10,  1.71it/s]ARC_EASY:   1%|▏                   | 10/1500 [00:05<09:08,  2.72it/s, lm=2.33, aux=0.000, gn=444.00]ARC_EASY:   1%|▏                   | 11/1500 [00:05<09:10,  2.71it/s, lm=2.33, aux=0.000, gn=444.00]Seed 456:  40%|████      | 80/200 [00:28<01:08,  1.75it/s]ARC_EASY:   1%|▏                   | 11/1500 [00:05<09:10,  2.71it/s, lm=1.79, aux=0.000, gn=628.00]ARC_EASY:   1%|▏                   | 12/1500 [00:05<09:09,  2.71it/s, lm=1.79, aux=0.000, gn=628.00]ARC_EASY:   1%|▏                    | 12/1500 [00:05<09:09,  2.71it/s, lm=1.05, aux=0.000, gn=99.50]ARC_EASY:   1%|▏                    | 13/1500 [00:05<09:03,  2.74it/s, lm=1.05, aux=0.000, gn=99.50]Seed 456:  40%|████      | 81/200 [00:29<01:10,  1.69it/s]ARC_EASY:   1%|▏                    | 13/1500 [00:06<09:03,  2.74it/s, lm=0.74, aux=0.000, gn=42.25]ARC_EASY:   1%|▏                    | 14/1500 [00:06<09:05,  2.72it/s, lm=0.74, aux=0.000, gn=42.25]ARC_EASY:   1%|▏                   | 14/1500 [00:06<09:05,  2.72it/s, lm=0.85, aux=0.000, gn=100.00]ARC_EASY:   1%|▏                   | 15/1500 [00:06<08:58,  2.76it/s, lm=0.85, aux=0.000, gn=100.00]Seed 456:  41%|████      | 82/200 [00:29<01:10,  1.68it/s]ARC_EASY:   1%|▏                  | 15/1500 [00:06<08:58,  2.76it/s, lm=3.92, aux=0.000, gn=1512.00]ARC_EASY:   1%|▏                  | 16/1500 [00:06<09:02,  2.73it/s, lm=3.92, aux=0.000, gn=1512.00]Seed 456:  42%|████▏     | 83/200 [00:30<01:09,  1.69it/s]ARC_EASY:   1%|▏                   | 16/1500 [00:07<09:02,  2.73it/s, lm=0.98, aux=0.000, gn=540.00]ARC_EASY:   1%|▏                   | 17/1500 [00:07<08:59,  2.75it/s, lm=0.98, aux=0.000, gn=540.00]ARC_EASY:   1%|▏                    | 17/1500 [00:07<08:59,  2.75it/s, lm=1.20, aux=0.000, gn=67.50]ARC_EASY:   1%|▎                    | 18/1500 [00:07<09:20,  2.65it/s, lm=1.20, aux=0.000, gn=67.50]Seed 456:  42%|████▏     | 84/200 [00:31<01:07,  1.71it/s]ARC_EASY:   1%|▎                    | 18/1500 [00:07<10:42,  2.31it/s, lm=1.20, aux=0.000, gn=67.50]
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1280, in main
    batch = next(iter_dl)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 398, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 207, in collate
    raise RuntimeError("each element in list of batch should be of equal size")
RuntimeError: each element in list of batch should be of equal size
Seed 456:  42%|████▎     | 85/200 [00:31<01:00,  1.90it/s]Seed 456:  43%|████▎     | 86/200 [00:31<00:55,  2.06it/s]Seed 456:  44%|████▎     | 87/200 [00:32<00:50,  2.23it/s]Seed 456:  44%|████▍     | 88/200 [00:32<00:49,  2.26it/s]Seed 456:  44%|████▍     | 89/200 [00:33<00:46,  2.39it/s]Seed 456:  45%|████▌     | 90/200 [00:33<00:45,  2.44it/s]Seed 456:  46%|████▌     | 91/200 [00:33<00:43,  2.52it/s]Seed 456:  46%|████▌     | 92/200 [00:34<00:41,  2.59it/s]Seed 456:  46%|████▋     | 93/200 [00:34<00:41,  2.61it/s]Seed 456:  47%|████▋     | 94/200 [00:34<00:40,  2.64it/s]Seed 456:  48%|████▊     | 95/200 [00:35<00:39,  2.65it/s]Seed 456:  48%|████▊     | 96/200 [00:35<00:39,  2.66it/s]Seed 456:  48%|████▊     | 97/200 [00:36<00:38,  2.66it/s]Seed 456:  49%|████▉     | 98/200 [00:36<00:38,  2.66it/s]Seed 456:  50%|████▉     | 99/200 [00:36<00:37,  2.68it/s]Seed 456:  50%|█████     | 100/200 [00:37<00:37,  2.68it/s]Seed 456:  50%|█████     | 101/200 [00:37<00:36,  2.69it/s]Seed 456:  51%|█████     | 102/200 [00:37<00:36,  2.69it/s]Seed 456:  52%|█████▏    | 103/200 [00:38<00:35,  2.70it/s]Seed 456:  52%|█████▏    | 104/200 [00:38<00:35,  2.68it/s]Seed 456:  52%|█████▎    | 105/200 [00:39<00:35,  2.67it/s]Seed 456:  53%|█████▎    | 106/200 [00:39<00:34,  2.71it/s]Seed 456:  54%|█████▎    | 107/200 [00:39<00:34,  2.69it/s]Seed 456:  54%|█████▍    | 108/200 [00:40<00:33,  2.72it/s]Seed 456:  55%|█████▍    | 109/200 [00:40<00:33,  2.69it/s]Seed 456:  55%|█████▌    | 110/200 [00:40<00:33,  2.70it/s]
[ERROR] Training interrupted by exception at step 19
[ERROR] RuntimeError: each element in list of batch should be of equal size

[EMERGENCY] Checkpoint saved to runs/reasoning_final_20260119_122501/novel_bridges/hailmary_thalamic_relay_arc_easy_seed42/emergency_checkpoint_step18.pt
[EMERGENCY] Error: RuntimeError: each element in list of batch should be of equal size
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1530, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1280, in main
    batch = next(iter_dl)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 398, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 207, in collate
    raise RuntimeError("each element in list of batch should be of equal size")
RuntimeError: each element in list of batch should be of equal size
Seed 456:  56%|█████▌    | 111/200 [00:41<00:33,  2.68it/s]Seed 456:  56%|█████▌    | 112/200 [00:41<00:33,  2.66it/s]Seed 456:  56%|█████▋    | 113/200 [00:41<00:32,  2.72it/s]Seed 456:  57%|█████▋    | 114/200 [00:42<00:32,  2.68it/s][2026-01-19 12:30:11] FAILED: hailmary_thalamic_relay_arc_easy_seed42 (exit code: 1)
Failed: hailmary_thalamic_relay_arc_easy_seed42

Seed 456:  57%|█████▊    | 115/200 [00:42<00:29,  2.89it/s][2026-01-19 12:30:12] [GPU 1] Testing HAIL MARY domain_adversarial on ARC-Easy (seed=42)
Started: hailmary_domain_adversarial_arc_easy_seed42
[2026-01-19 12:30:12] START: hailmary_domain_adversarial_arc_easy_seed42
Seed 456:  58%|█████▊    | 116/200 [00:42<00:27,  3.07it/s]Seed 456:  58%|█████▊    | 117/200 [00:43<00:28,  2.92it/s]Seed 456:  59%|█████▉    | 118/200 [00:43<00:28,  2.88it/s]Seed 456:  60%|█████▉    | 119/200 [00:44<00:29,  2.76it/s]Seed 456:  60%|██████    | 120/200 [00:44<00:30,  2.61it/s]Seed 456:  60%|██████    | 121/200 [00:44<00:30,  2.63it/s]Seed 456:  61%|██████    | 122/200 [00:45<00:30,  2.59it/s]/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Seed 456:  62%|██████▏   | 123/200 [00:45<00:30,  2.51it/s]Seed 456:  62%|██████▏   | 124/200 [00:46<00:30,  2.49it/s]Seed 456:  62%|██████▎   | 125/200 [00:46<00:30,  2.46it/s]Seed 456:  63%|██████▎   | 126/200 [00:46<00:26,  2.82it/s]Seed 456:  64%|██████▎   | 127/200 [00:47<00:26,  2.74it/s]Seed 456:  64%|██████▍   | 128/200 [00:47<00:26,  2.68it/s]Seed 456:  64%|██████▍   | 129/200 [00:47<00:27,  2.61it/s]Seed 456:  65%|██████▌   | 130/200 [00:48<00:27,  2.56it/s]Seed 456:  66%|██████▌   | 131/200 [00:48<00:26,  2.59it/s]============================================================
TELEPATHY TRAINING: ARC_EASY
============================================================

Dataset: arc_easy (4 classes)
Random baseline: 25.0%
Source layer: 31
Soft tokens: 8
Steps: 1500
Diversity weight: 0.1
============================================================
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 1572.37it/s]
Seed 456:  66%|██████▌   | 132/200 [00:49<00:26,  2.54it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Seed 456:  66%|██████▋   | 133/200 [00:49<00:25,  2.64it/s]Seed 456:  67%|██████▋   | 134/200 [00:49<00:24,  2.68it/s]Seed 456:  68%|██████▊   | 135/200 [00:50<00:24,  2.68it/s]Seed 456:  68%|██████▊   | 136/200 [00:50<00:23,  2.69it/s]Seed 456:  68%|██████▊   | 137/200 [00:50<00:23,  2.73it/s]Seed 456:  69%|██████▉   | 138/200 [00:51<00:22,  2.70it/s]Seed 456:  70%|██████▉   | 139/200 [00:51<00:22,  2.70it/s]Seed 456:  70%|███████   | 140/200 [00:52<00:22,  2.69it/s]Seed 456:  70%|███████   | 141/200 [00:52<00:21,  2.70it/s]Seed 456:  71%|███████   | 142/200 [00:52<00:21,  2.69it/s]Seed 456:  72%|███████▏  | 143/200 [00:53<00:21,  2.71it/s]Seed 456:  72%|███████▏  | 144/200 [00:53<00:20,  2.71it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:13,  4.44s/it]Seed 456:  72%|███████▎  | 145/200 [00:53<00:20,  2.71it/s]Seed 456:  73%|███████▎  | 146/200 [00:54<00:20,  2.67it/s]Seed 456:  74%|███████▎  | 147/200 [00:54<00:19,  2.69it/s]Seed 456:  74%|███████▍  | 148/200 [00:55<00:19,  2.68it/s]Seed 456:  74%|███████▍  | 149/200 [00:55<00:18,  2.73it/s]Seed 456:  75%|███████▌  | 150/200 [00:55<00:18,  2.70it/s]Seed 456:  76%|███████▌  | 151/200 [00:56<00:18,  2.70it/s]Seed 456:  76%|███████▌  | 152/200 [00:56<00:17,  2.73it/s]Seed 456:  76%|███████▋  | 153/200 [00:56<00:17,  2.71it/s]Seed 456:  77%|███████▋  | 154/200 [00:57<00:16,  2.72it/s]Seed 456:  78%|███████▊  | 155/200 [00:57<00:16,  2.72it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.17s/it]Seed 456:  78%|███████▊  | 156/200 [00:57<00:16,  2.72it/s]Seed 456:  78%|███████▊  | 157/200 [00:58<00:16,  2.69it/s]Seed 456:  79%|███████▉  | 158/200 [00:58<00:15,  2.73it/s]Seed 456:  80%|███████▉  | 159/200 [00:59<00:15,  2.72it/s]Seed 456:  80%|████████  | 160/200 [00:59<00:14,  2.71it/s]Seed 456:  80%|████████  | 161/200 [00:59<00:14,  2.68it/s]Seed 456:  81%|████████  | 162/200 [01:00<00:13,  2.72it/s]Seed 456:  82%|████████▏ | 163/200 [01:00<00:13,  2.72it/s]Seed 456:  82%|████████▏ | 164/200 [01:00<00:13,  2.73it/s]Seed 456:  82%|████████▎ | 165/200 [01:01<00:12,  2.70it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.05s/it]Seed 456:  83%|████████▎ | 166/200 [01:01<00:12,  2.70it/s]Seed 456:  84%|████████▎ | 167/200 [01:02<00:12,  2.71it/s]Seed 456:  84%|████████▍ | 168/200 [01:02<00:12,  2.61it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.89s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.36s/it]
Seed 456:  84%|████████▍ | 169/200 [01:02<00:11,  2.79it/s]Seed 456:  85%|████████▌ | 170/200 [01:02<00:09,  3.24it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2351.95it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Seed 456:  86%|████████▌ | 171/200 [01:03<00:09,  3.03it/s]Seed 456:  86%|████████▌ | 172/200 [01:03<00:09,  2.93it/s]Seed 456:  86%|████████▋ | 173/200 [01:04<00:09,  2.89it/s]Seed 456:  87%|████████▋ | 174/200 [01:04<00:09,  2.83it/s]Seed 456:  88%|████████▊ | 175/200 [01:04<00:09,  2.77it/s]Seed 456:  88%|████████▊ | 176/200 [01:05<00:08,  2.78it/s]Seed 456:  88%|████████▊ | 177/200 [01:05<00:08,  2.76it/s]Seed 456:  89%|████████▉ | 178/200 [01:05<00:08,  2.72it/s]Seed 456:  90%|████████▉ | 179/200 [01:06<00:07,  2.70it/s]Seed 456:  90%|█████████ | 180/200 [01:06<00:07,  2.71it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.83s/it]Seed 456:  90%|█████████ | 181/200 [01:07<00:07,  2.71it/s]Seed 456:  91%|█████████ | 182/200 [01:07<00:06,  2.73it/s]Seed 456:  92%|█████████▏| 183/200 [01:07<00:06,  2.68it/s]Seed 456:  92%|█████████▏| 184/200 [01:08<00:05,  2.68it/s]Seed 456:  92%|█████████▎| 185/200 [01:08<00:05,  2.70it/s]Seed 456:  93%|█████████▎| 186/200 [01:08<00:05,  2.72it/s]Seed 456:  94%|█████████▎| 187/200 [01:09<00:04,  2.67it/s]Seed 456:  94%|█████████▍| 188/200 [01:09<00:04,  2.71it/s]Seed 456:  94%|█████████▍| 189/200 [01:09<00:04,  2.66it/s]Seed 456:  95%|█████████▌| 190/200 [01:10<00:03,  2.72it/s]Seed 456:  96%|█████████▌| 191/200 [01:10<00:03,  2.67it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.87s/it]Seed 456:  96%|█████████▌| 192/200 [01:11<00:02,  2.69it/s]Seed 456:  96%|█████████▋| 193/200 [01:11<00:02,  2.71it/s]Seed 456:  97%|█████████▋| 194/200 [01:11<00:02,  2.72it/s]Seed 456:  98%|█████████▊| 195/200 [01:12<00:01,  2.70it/s]Seed 456:  98%|█████████▊| 196/200 [01:12<00:01,  2.70it/s]Seed 456:  98%|█████████▊| 197/200 [01:12<00:01,  2.70it/s]Seed 456:  99%|█████████▉| 198/200 [01:13<00:00,  2.68it/s]Seed 456: 100%|█████████▉| 199/200 [01:13<00:00,  2.69it/s]Seed 456: 100%|██████████| 200/200 [01:14<00:00,  2.70it/s]                                                           Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.71s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.76s/it]
  Seed 456: 24.5%
Llama 4-shot: 24.8% +/- 0.5%

Evaluating Mistral (4-shot)...
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2939.25it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.84s/it]2026-01-19 12:30:49,782 - INFO - DomainAdversarialBridge: 8 tokens, adv_weight=0.1
Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.71s/it]Target embedding RMS: 0.0027
Using Domain Adversarial Bridge - Gradient reversal alignment

Training on 2251 samples
Validation: 2376 samples
Starting training...

ARC_EASY:   0%|                                                            | 0/1500 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  2.95s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  3.17s/it]
ARC_EASY:   0%|                                                            | 0/1500 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1285, in main
    loss, loss_dict = train_step(
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 714, in train_step
    soft_tokens, aux_loss, diversity, z_variance = bridge_module(src_h, src_mask)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 1825, in forward
    adv_loss = self.compute_adversarial_loss(soft_tokens)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 1776, in compute_adversarial_loss
    soft_preds = self.discriminator(soft_reversed.view(-1, D)).view(B, K)  # [B, K]
RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
Seed 42:   0%|          | 0/200 [00:00<?, ?it/s]Seed 42:   0%|          | 1/200 [00:00<01:28,  2.24it/s]Seed 42:   1%|          | 2/200 [00:00<01:27,  2.27it/s]Seed 42:   2%|▏         | 3/200 [00:01<01:25,  2.29it/s]
[ERROR] Training interrupted by exception at step 1
[ERROR] RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.

[EMERGENCY] Checkpoint saved to runs/reasoning_final_20260119_122501/novel_bridges/hailmary_domain_adversarial_arc_easy_seed42/emergency_checkpoint_step0.pt
[EMERGENCY] Error: RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1530, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1285, in main
    loss, loss_dict = train_step(
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 714, in train_step
    soft_tokens, aux_loss, diversity, z_variance = bridge_module(src_h, src_mask)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 1825, in forward
    adv_loss = self.compute_adversarial_loss(soft_tokens)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 1776, in compute_adversarial_loss
    soft_preds = self.discriminator(soft_reversed.view(-1, D)).view(B, K)  # [B, K]
RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
Seed 42:   2%|▏         | 4/200 [00:01<01:24,  2.32it/s]Seed 42:   2%|▎         | 5/200 [00:02<01:23,  2.33it/s]Seed 42:   3%|▎         | 6/200 [00:02<01:23,  2.32it/s][2026-01-19 12:30:58] FAILED: hailmary_domain_adversarial_arc_easy_seed42 (exit code: 1)
Seed 42:   4%|▎         | 7/200 [00:02<01:20,  2.41it/s]Failed: hailmary_domain_adversarial_arc_easy_seed42

[2026-01-19 12:30:58] [GPU 1] Testing HAIL MARY successive_refinement on ARC-Easy (seed=42)
Seed 42:   4%|▍         | 8/200 [00:03<01:14,  2.59it/s]Started: hailmary_successive_refinement_arc_easy_seed42
[2026-01-19 12:30:58] START: hailmary_successive_refinement_arc_easy_seed42
Seed 42:   4%|▍         | 9/200 [00:03<01:16,  2.50it/s]Seed 42:   5%|▌         | 10/200 [00:04<01:15,  2.53it/s]Seed 42:   6%|▌         | 11/200 [00:04<01:18,  2.42it/s]Seed 42:   6%|▌         | 12/200 [00:05<01:20,  2.33it/s]Seed 42:   6%|▋         | 13/200 [00:05<01:20,  2.33it/s]/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Seed 42:   7%|▋         | 14/200 [00:05<01:20,  2.31it/s]Seed 42:   8%|▊         | 15/200 [00:06<01:20,  2.31it/s]Seed 42:   8%|▊         | 16/200 [00:06<01:23,  2.21it/s]Seed 42:   8%|▊         | 17/200 [00:07<01:15,  2.42it/s]Seed 42:   9%|▉         | 18/200 [00:07<01:15,  2.41it/s]Seed 42:  10%|▉         | 19/200 [00:08<01:15,  2.39it/s]Seed 42:  10%|█         | 20/200 [00:08<01:17,  2.32it/s]Seed 42:  10%|█         | 21/200 [00:08<01:16,  2.33it/s]Seed 42:  11%|█         | 22/200 [00:09<01:16,  2.32it/s]============================================================
TELEPATHY TRAINING: ARC_EASY
============================================================

Dataset: arc_easy (4 classes)
Random baseline: 25.0%
Source layer: 31
Soft tokens: 8
Steps: 1500
Diversity weight: 0.1
============================================================
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2113.00it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Seed 42:  12%|█▏        | 23/200 [00:09<01:13,  2.41it/s]Seed 42:  12%|█▏        | 24/200 [00:10<01:10,  2.48it/s]Seed 42:  12%|█▎        | 25/200 [00:10<01:12,  2.41it/s]Seed 42:  13%|█▎        | 26/200 [00:10<01:13,  2.38it/s]Seed 42:  14%|█▎        | 27/200 [00:11<01:12,  2.38it/s]Seed 42:  14%|█▍        | 28/200 [00:11<01:12,  2.37it/s]Seed 42:  14%|█▍        | 29/200 [00:12<01:11,  2.38it/s]Seed 42:  15%|█▌        | 30/200 [00:12<01:11,  2.38it/s]Seed 42:  16%|█▌        | 31/200 [00:13<01:11,  2.35it/s]Seed 42:  16%|█▌        | 32/200 [00:13<01:11,  2.36it/s]Seed 42:  16%|█▋        | 33/200 [00:13<01:10,  2.36it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:13,  4.47s/it]Seed 42:  17%|█▋        | 34/200 [00:14<01:11,  2.33it/s]Seed 42:  18%|█▊        | 35/200 [00:14<01:10,  2.35it/s]Seed 42:  18%|█▊        | 36/200 [00:15<01:09,  2.34it/s]Seed 42:  18%|█▊        | 37/200 [00:15<01:08,  2.37it/s]Seed 42:  19%|█▉        | 38/200 [00:16<01:08,  2.36it/s]Seed 42:  20%|█▉        | 39/200 [00:16<01:07,  2.38it/s]Seed 42:  20%|██        | 40/200 [00:16<01:07,  2.36it/s]Seed 42:  20%|██        | 41/200 [00:17<01:07,  2.36it/s]Seed 42:  21%|██        | 42/200 [00:17<01:07,  2.34it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.19s/it]Seed 42:  22%|██▏       | 43/200 [00:18<01:06,  2.37it/s]Seed 42:  22%|██▏       | 44/200 [00:18<01:04,  2.41it/s]Seed 42:  22%|██▎       | 45/200 [00:18<01:00,  2.54it/s]Seed 42:  23%|██▎       | 46/200 [00:19<00:59,  2.58it/s]Seed 42:  24%|██▎       | 47/200 [00:19<01:00,  2.52it/s]Seed 42:  24%|██▍       | 48/200 [00:20<01:01,  2.46it/s]Seed 42:  24%|██▍       | 49/200 [00:20<01:01,  2.44it/s]Seed 42:  25%|██▌       | 50/200 [00:20<01:02,  2.40it/s]Seed 42:  26%|██▌       | 51/200 [00:21<01:02,  2.37it/s]Seed 42:  26%|██▌       | 52/200 [00:21<01:02,  2.36it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.16s/it]Seed 42:  26%|██▋       | 53/200 [00:22<01:02,  2.36it/s]Seed 42:  27%|██▋       | 54/200 [00:22<01:02,  2.35it/s]Seed 42:  28%|██▊       | 55/200 [00:23<01:01,  2.38it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.93s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.41s/it]
Seed 42:  28%|██▊       | 56/200 [00:23<00:54,  2.67it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2371.90it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Seed 42:  28%|██▊       | 57/200 [00:23<00:52,  2.73it/s]Seed 42:  29%|██▉       | 58/200 [00:24<00:54,  2.60it/s]Seed 42:  30%|██▉       | 59/200 [00:24<00:56,  2.51it/s]Seed 42:  30%|███       | 60/200 [00:24<00:56,  2.48it/s]Seed 42:  30%|███       | 61/200 [00:25<00:57,  2.41it/s]Seed 42:  31%|███       | 62/200 [00:25<00:56,  2.42it/s]Seed 42:  32%|███▏      | 63/200 [00:26<00:57,  2.38it/s]Seed 42:  32%|███▏      | 64/200 [00:26<00:57,  2.38it/s]Seed 42:  32%|███▎      | 65/200 [00:27<00:56,  2.38it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.80s/it]Seed 42:  33%|███▎      | 66/200 [00:27<00:55,  2.42it/s]Seed 42:  34%|███▎      | 67/200 [00:27<00:55,  2.41it/s]Seed 42:  34%|███▍      | 68/200 [00:28<00:55,  2.39it/s]Seed 42:  34%|███▍      | 69/200 [00:28<00:54,  2.39it/s]Seed 42:  35%|███▌      | 70/200 [00:29<00:54,  2.39it/s]Seed 42:  36%|███▌      | 71/200 [00:29<00:54,  2.35it/s]Seed 42:  36%|███▌      | 72/200 [00:30<00:54,  2.35it/s]Seed 42:  36%|███▋      | 73/200 [00:30<00:53,  2.36it/s]Seed 42:  37%|███▋      | 74/200 [00:30<00:53,  2.36it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.88s/it]Seed 42:  38%|███▊      | 75/200 [00:31<00:53,  2.35it/s]Seed 42:  38%|███▊      | 76/200 [00:31<00:53,  2.34it/s]Seed 42:  38%|███▊      | 77/200 [00:32<00:52,  2.33it/s]Seed 42:  39%|███▉      | 78/200 [00:32<00:51,  2.36it/s]Seed 42:  40%|███▉      | 79/200 [00:33<00:51,  2.35it/s]Seed 42:  40%|████      | 80/200 [00:33<00:49,  2.40it/s]Seed 42:  40%|████      | 81/200 [00:33<00:49,  2.39it/s]Seed 42:  41%|████      | 82/200 [00:34<00:49,  2.38it/s]Seed 42:  42%|████▏     | 83/200 [00:34<00:49,  2.37it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.72s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.75s/it]
Seed 42:  42%|████▏     | 84/200 [00:34<00:43,  2.65it/s]Seed 42:  42%|████▎     | 85/200 [00:35<00:42,  2.73it/s]Seed 42:  43%|████▎     | 86/200 [00:35<00:41,  2.72it/s]Seed 42:  44%|████▎     | 87/200 [00:36<00:42,  2.65it/s]Seed 42:  44%|████▍     | 88/200 [00:36<00:46,  2.43it/s]Seed 42:  44%|████▍     | 89/200 [00:36<00:45,  2.43it/s]Seed 42:  45%|████▌     | 90/200 [00:37<00:45,  2.40it/s]Seed 42:  46%|████▌     | 91/200 [00:37<00:45,  2.37it/s]Seed 42:  46%|████▌     | 92/200 [00:38<00:45,  2.40it/s]Seed 42:  46%|████▋     | 93/200 [00:38<00:44,  2.38it/s]Seed 42:  47%|████▋     | 94/200 [00:39<00:44,  2.37it/s]Seed 42:  48%|████▊     | 95/200 [00:39<00:44,  2.37it/s]Seed 42:  48%|████▊     | 96/200 [00:39<00:44,  2.35it/s]Seed 42:  48%|████▊     | 97/200 [00:40<00:43,  2.39it/s]Seed 42:  49%|████▉     | 98/200 [00:40<00:42,  2.38it/s]Seed 42:  50%|████▉     | 99/200 [00:41<00:43,  2.34it/s]Seed 42:  50%|█████     | 100/200 [00:41<00:42,  2.36it/s]Seed 42:  50%|█████     | 101/200 [00:42<00:41,  2.36it/s]Seed 42:  51%|█████     | 102/200 [00:42<00:41,  2.38it/s]Seed 42:  52%|█████▏    | 103/200 [00:42<00:40,  2.39it/s]Seed 42:  52%|█████▏    | 104/200 [00:43<00:40,  2.38it/s]Seed 42:  52%|█████▎    | 105/200 [00:43<00:40,  2.37it/s]Seed 42:  53%|█████▎    | 106/200 [00:44<00:39,  2.37it/s]Seed 42:  54%|█████▎    | 107/200 [00:44<00:39,  2.37it/s]Seed 42:  54%|█████▍    | 108/200 [00:45<00:39,  2.35it/s]Seed 42:  55%|█████▍    | 109/200 [00:45<00:38,  2.35it/s]Seed 42:  55%|█████▌    | 110/200 [00:45<00:37,  2.37it/s]Seed 42:  56%|█████▌    | 111/200 [00:46<00:37,  2.35it/s]Seed 42:  56%|█████▌    | 112/200 [00:46<00:37,  2.37it/s]Seed 42:  56%|█████▋    | 113/200 [00:47<00:36,  2.35it/s]Seed 42:  57%|█████▋    | 114/200 [00:47<00:36,  2.36it/s]Seed 42:  57%|█████▊    | 115/200 [00:48<00:36,  2.34it/s]Seed 42:  58%|█████▊    | 116/200 [00:48<00:35,  2.35it/s]Seed 42:  58%|█████▊    | 117/200 [00:48<00:34,  2.38it/s]Seed 42:  59%|█████▉    | 118/200 [00:49<00:34,  2.35it/s]Seed 42:  60%|█████▉    | 119/200 [00:49<00:33,  2.39it/s]Seed 42:  60%|██████    | 120/200 [00:50<00:33,  2.36it/s]Seed 42:  60%|██████    | 121/200 [00:50<00:33,  2.37it/s]Seed 42:  61%|██████    | 122/200 [00:50<00:32,  2.38it/s]Seed 42:  62%|██████▏   | 123/200 [00:51<00:32,  2.37it/s]Seed 42:  62%|██████▏   | 124/200 [00:51<00:32,  2.36it/s]2026-01-19 12:31:47,194 - INFO - SuccessiveRefinementBridge: max 16 tokens, using 8
Seed 42:  62%|██████▎   | 125/200 [00:52<00:31,  2.36it/s]Seed 42:  63%|██████▎   | 126/200 [00:52<00:31,  2.38it/s]Seed 42:  64%|██████▎   | 127/200 [00:53<00:31,  2.35it/s]Seed 42:  64%|██████▍   | 128/200 [00:53<00:30,  2.35it/s]Seed 42:  64%|██████▍   | 129/200 [00:53<00:30,  2.34it/s]Seed 42:  65%|██████▌   | 130/200 [00:54<00:29,  2.35it/s]Seed 42:  66%|██████▌   | 131/200 [00:54<00:29,  2.35it/s]Seed 42:  66%|██████▌   | 132/200 [00:55<00:29,  2.33it/s]Seed 42:  66%|██████▋   | 133/200 [00:55<00:28,  2.35it/s]Seed 42:  67%|██████▋   | 134/200 [00:56<00:28,  2.35it/s]Seed 42:  68%|██████▊   | 135/200 [00:56<00:27,  2.35it/s]Seed 42:  68%|██████▊   | 136/200 [00:56<00:27,  2.36it/s]Seed 42:  68%|██████▊   | 137/200 [00:57<00:26,  2.35it/s]Seed 42:  69%|██████▉   | 138/200 [00:57<00:24,  2.48it/s]Seed 42:  70%|██████▉   | 139/200 [00:57<00:21,  2.89it/s]Seed 42:  70%|███████   | 140/200 [00:58<00:18,  3.23it/s]Seed 42:  70%|███████   | 141/200 [00:58<00:16,  3.54it/s]Seed 42:  71%|███████   | 142/200 [00:58<00:15,  3.82it/s]Seed 42:  72%|███████▏  | 143/200 [00:58<00:14,  3.98it/s]Seed 42:  72%|███████▏  | 144/200 [00:59<00:13,  4.16it/s]Seed 42:  72%|███████▎  | 145/200 [00:59<00:13,  4.13it/s]Seed 42:  73%|███████▎  | 146/200 [00:59<00:12,  4.25it/s]Seed 42:  74%|███████▎  | 147/200 [00:59<00:12,  4.36it/s]Target embedding RMS: 0.0027
Using Successive Refinement Bridge - Progressive token generation

Training on 2251 samples
Validation: 2376 samples
Starting training...

ARC_EASY:   0%|                                                            | 0/1500 [00:00<?, ?it/s]ARC_EASY:   0%|                                                            | 0/1500 [00:00<?, ?it/s]
Seed 42:  74%|███████▍  | 148/200 [01:00<00:14,  3.49it/s]Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1285, in main
    loss, loss_dict = train_step(
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 714, in train_step
    soft_tokens, aux_loss, diversity, z_variance = bridge_module(src_h, src_mask)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 1910, in forward
    src_proj = self.input_proj(src_hidden.to(self.input_proj.weight.dtype))
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1931, in __getattr__
    raise AttributeError(
AttributeError: 'Identity' object has no attribute 'weight'
Seed 42:  74%|███████▍  | 149/200 [01:00<00:16,  3.06it/s]Seed 42:  75%|███████▌  | 150/200 [01:00<00:17,  2.78it/s]Seed 42:  76%|███████▌  | 151/200 [01:01<00:18,  2.63it/s]Seed 42:  76%|███████▌  | 152/200 [01:01<00:18,  2.53it/s]Seed 42:  76%|███████▋  | 153/200 [01:02<00:18,  2.49it/s]Seed 42:  77%|███████▋  | 154/200 [01:02<00:18,  2.47it/s]Seed 42:  78%|███████▊  | 155/200 [01:03<00:18,  2.43it/s]Seed 42:  78%|███████▊  | 156/200 [01:03<00:18,  2.41it/s]Seed 42:  78%|███████▊  | 157/200 [01:03<00:18,  2.38it/s]Seed 42:  79%|███████▉  | 158/200 [01:04<00:17,  2.37it/s]Seed 42:  80%|███████▉  | 159/200 [01:04<00:17,  2.39it/s]Seed 42:  80%|████████  | 160/200 [01:05<00:16,  2.38it/s]Seed 42:  80%|████████  | 161/200 [01:05<00:16,  2.40it/s]Seed 42:  81%|████████  | 162/200 [01:06<00:15,  2.38it/s]Seed 42:  82%|████████▏ | 163/200 [01:06<00:15,  2.33it/s]Seed 42:  82%|████████▏ | 164/200 [01:06<00:15,  2.27it/s]Seed 42:  82%|████████▎ | 165/200 [01:07<00:15,  2.30it/s]Seed 42:  83%|████████▎ | 166/200 [01:07<00:14,  2.33it/s]Seed 42:  84%|████████▎ | 167/200 [01:08<00:14,  2.34it/s]Seed 42:  84%|████████▍ | 168/200 [01:08<00:13,  2.35it/s]Seed 42:  84%|████████▍ | 169/200 [01:09<00:13,  2.33it/s]Seed 42:  85%|████████▌ | 170/200 [01:09<00:12,  2.33it/s]Seed 42:  86%|████████▌ | 171/200 [01:09<00:12,  2.34it/s]
[ERROR] Training interrupted by exception at step 1
[ERROR] AttributeError: 'Identity' object has no attribute 'weight'

[EMERGENCY] Checkpoint saved to runs/reasoning_final_20260119_122501/novel_bridges/hailmary_successive_refinement_arc_easy_seed42/emergency_checkpoint_step0.pt
[EMERGENCY] Error: AttributeError: 'Identity' object has no attribute 'weight'
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1530, in <module>
Seed 42:  86%|████████▌ | 172/200 [01:10<00:11,  2.36it/s]    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1285, in main
    loss, loss_dict = train_step(
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 714, in train_step
    soft_tokens, aux_loss, diversity, z_variance = bridge_module(src_h, src_mask)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 1910, in forward
    src_proj = self.input_proj(src_hidden.to(self.input_proj.weight.dtype))
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1931, in __getattr__
    raise AttributeError(
AttributeError: 'Identity' object has no attribute 'weight'
Seed 42:  86%|████████▋ | 173/200 [01:10<00:11,  2.34it/s]Seed 42:  87%|████████▋ | 174/200 [01:11<00:11,  2.33it/s]Seed 42:  88%|████████▊ | 175/200 [01:11<00:10,  2.35it/s][2026-01-19 12:32:07] FAILED: hailmary_successive_refinement_arc_easy_seed42 (exit code: 1)
Seed 42:  88%|████████▊ | 176/200 [01:11<00:09,  2.45it/s]Failed: hailmary_successive_refinement_arc_easy_seed42

[2026-01-19 12:32:07] [GPU 1] Token Capacity Scaling on Reasoning (4, 8, 16, 32 tokens, 3 seeds)
[2026-01-19 12:32:07] [GPU 1] Testing 4 soft tokens on ARC-Easy (seed=42)
Started: token_capacity_4_seed42
Seed 42:  88%|████████▊ | 177/200 [01:12<00:08,  2.57it/s][2026-01-19 12:32:07] START: token_capacity_4_seed42
Seed 42:  89%|████████▉ | 178/200 [01:12<00:08,  2.49it/s]Seed 42:  90%|████████▉ | 179/200 [01:13<00:08,  2.42it/s]Seed 42:  90%|█████████ | 180/200 [01:13<00:08,  2.27it/s]Seed 42:  90%|█████████ | 181/200 [01:14<00:08,  2.27it/s]Seed 42:  91%|█████████ | 182/200 [01:14<00:07,  2.27it/s]/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Seed 42:  92%|█████████▏| 183/200 [01:15<00:07,  2.18it/s]Seed 42:  92%|█████████▏| 184/200 [01:15<00:07,  2.16it/s]Seed 42:  92%|█████████▎| 185/200 [01:16<00:06,  2.18it/s]Seed 42:  93%|█████████▎| 186/200 [01:16<00:05,  2.51it/s]Seed 42:  94%|█████████▎| 187/200 [01:16<00:05,  2.32it/s]Seed 42:  94%|█████████▍| 188/200 [01:17<00:05,  2.25it/s]Seed 42:  94%|█████████▍| 189/200 [01:17<00:04,  2.27it/s]Seed 42:  95%|█████████▌| 190/200 [01:18<00:04,  2.23it/s]============================================================
TELEPATHY TRAINING: ARC_EASY
============================================================

Dataset: arc_easy (4 classes)
Random baseline: 25.0%
Source layer: 31
Soft tokens: 4
Steps: 1500
Diversity weight: 0.1
============================================================
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2077.42it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Seed 42:  96%|█████████▌| 191/200 [01:18<00:04,  2.22it/s]Seed 42:  96%|█████████▌| 192/200 [01:18<00:03,  2.64it/s]Seed 42:  96%|█████████▋| 193/200 [01:19<00:02,  2.54it/s]Seed 42:  97%|█████████▋| 194/200 [01:19<00:02,  2.49it/s]Seed 42:  98%|█████████▊| 195/200 [01:20<00:02,  2.45it/s]Seed 42:  98%|█████████▊| 196/200 [01:20<00:01,  2.44it/s]Seed 42:  98%|█████████▊| 197/200 [01:20<00:01,  2.39it/s]Seed 42:  99%|█████████▉| 198/200 [01:21<00:00,  2.37it/s]Seed 42: 100%|█████████▉| 199/200 [01:21<00:00,  2.37it/s]Seed 42: 100%|██████████| 200/200 [01:22<00:00,  2.40it/s]                                                            Seed 42: 24.5%
Seed 123:   0%|          | 0/200 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:13,  4.62s/it]Seed 123:   0%|          | 1/200 [00:00<01:23,  2.37it/s]Seed 123:   1%|          | 2/200 [00:00<01:26,  2.30it/s]Seed 123:   2%|▏         | 3/200 [00:01<01:25,  2.32it/s]Seed 123:   2%|▏         | 4/200 [00:01<01:23,  2.36it/s]Seed 123:   2%|▎         | 5/200 [00:02<01:22,  2.37it/s]Seed 123:   3%|▎         | 6/200 [00:02<01:23,  2.33it/s]Seed 123:   4%|▎         | 7/200 [00:02<01:22,  2.35it/s]Seed 123:   4%|▍         | 8/200 [00:03<01:22,  2.33it/s]Seed 123:   4%|▍         | 9/200 [00:03<01:21,  2.35it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.24s/it]Seed 123:   5%|▌         | 10/200 [00:04<01:21,  2.34it/s]Seed 123:   6%|▌         | 11/200 [00:04<01:16,  2.46it/s]Seed 123:   6%|▌         | 12/200 [00:05<01:17,  2.42it/s]Seed 123:   6%|▋         | 13/200 [00:05<01:18,  2.37it/s]Seed 123:   7%|▋         | 14/200 [00:05<01:18,  2.38it/s]Seed 123:   8%|▊         | 15/200 [00:06<01:17,  2.38it/s]Seed 123:   8%|▊         | 16/200 [00:06<01:17,  2.38it/s]Seed 123:   8%|▊         | 17/200 [00:07<01:17,  2.37it/s]Seed 123:   9%|▉         | 18/200 [00:07<01:16,  2.38it/s]Seed 123:  10%|▉         | 19/200 [00:08<01:16,  2.36it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.11s/it]Seed 123:  10%|█         | 20/200 [00:08<01:16,  2.35it/s]Seed 123:  10%|█         | 21/200 [00:08<01:15,  2.36it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.89s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.40s/it]
Seed 123:  11%|█         | 22/200 [00:09<01:11,  2.47it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2063.79it/s]
Seed 123:  12%|█▏        | 23/200 [00:09<01:03,  2.79it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Seed 123:  12%|█▏        | 24/200 [00:09<01:06,  2.66it/s]Seed 123:  12%|█▎        | 25/200 [00:10<01:08,  2.54it/s]Seed 123:  13%|█▎        | 26/200 [00:10<01:09,  2.49it/s]Seed 123:  14%|█▎        | 27/200 [00:11<01:10,  2.45it/s]Seed 123:  14%|█▍        | 28/200 [00:11<01:10,  2.44it/s]Seed 123:  14%|█▍        | 29/200 [00:12<01:10,  2.42it/s]Seed 123:  15%|█▌        | 30/200 [00:12<01:11,  2.39it/s]Seed 123:  16%|█▌        | 31/200 [00:12<01:11,  2.37it/s]Seed 123:  16%|█▌        | 32/200 [00:13<01:10,  2.38it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.82s/it]Seed 123:  16%|█▋        | 33/200 [00:13<01:12,  2.30it/s]Seed 123:  17%|█▋        | 34/200 [00:14<01:11,  2.31it/s]Seed 123:  18%|█▊        | 35/200 [00:14<01:10,  2.33it/s]Seed 123:  18%|█▊        | 36/200 [00:15<01:10,  2.33it/s]Seed 123:  18%|█▊        | 37/200 [00:15<01:09,  2.34it/s]Seed 123:  19%|█▉        | 38/200 [00:15<01:08,  2.35it/s]Seed 123:  20%|█▉        | 39/200 [00:16<01:08,  2.35it/s]Seed 123:  20%|██        | 40/200 [00:16<01:07,  2.36it/s]Seed 123:  20%|██        | 41/200 [00:17<01:07,  2.36it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.89s/it]Seed 123:  21%|██        | 42/200 [00:17<01:06,  2.39it/s]Seed 123:  22%|██▏       | 43/200 [00:17<01:06,  2.38it/s]Seed 123:  22%|██▏       | 44/200 [00:18<01:05,  2.38it/s]Seed 123:  22%|██▎       | 45/200 [00:18<01:05,  2.35it/s]Seed 123:  23%|██▎       | 46/200 [00:19<01:05,  2.35it/s]Seed 123:  24%|██▎       | 47/200 [00:19<01:03,  2.40it/s]Seed 123:  24%|██▍       | 48/200 [00:20<01:04,  2.35it/s]Seed 123:  24%|██▍       | 49/200 [00:20<01:03,  2.39it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.72s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.76s/it]
Seed 123:  25%|██▌       | 50/200 [00:20<00:59,  2.51it/s]Seed 123:  26%|██▌       | 51/200 [00:21<00:53,  2.78it/s]Seed 123:  26%|██▌       | 52/200 [00:21<00:56,  2.64it/s]Seed 123:  26%|██▋       | 53/200 [00:21<00:55,  2.65it/s]Seed 123:  27%|██▋       | 54/200 [00:22<00:57,  2.55it/s]Seed 123:  28%|██▊       | 55/200 [00:22<00:57,  2.52it/s]Seed 123:  28%|██▊       | 56/200 [00:23<00:58,  2.45it/s]Seed 123:  28%|██▊       | 57/200 [00:23<00:58,  2.44it/s]Seed 123:  29%|██▉       | 58/200 [00:24<00:58,  2.41it/s]Seed 123:  30%|██▉       | 59/200 [00:24<00:58,  2.39it/s]Seed 123:  30%|███       | 60/200 [00:24<00:58,  2.38it/s]Seed 123:  30%|███       | 61/200 [00:25<00:58,  2.37it/s]Seed 123:  31%|███       | 62/200 [00:25<00:58,  2.37it/s]Seed 123:  32%|███▏      | 63/200 [00:26<00:57,  2.39it/s]Seed 123:  32%|███▏      | 64/200 [00:26<00:56,  2.39it/s]Seed 123:  32%|███▎      | 65/200 [00:27<00:57,  2.37it/s]Seed 123:  33%|███▎      | 66/200 [00:27<00:56,  2.36it/s]Seed 123:  34%|███▎      | 67/200 [00:27<00:56,  2.35it/s]Seed 123:  34%|███▍      | 68/200 [00:28<00:55,  2.38it/s]Seed 123:  34%|███▍      | 69/200 [00:28<00:52,  2.50it/s]Seed 123:  35%|███▌      | 70/200 [00:28<00:45,  2.88it/s]Seed 123:  36%|███▌      | 71/200 [00:29<00:39,  3.24it/s]Seed 123:  36%|███▌      | 72/200 [00:29<00:36,  3.54it/s]Seed 123:  36%|███▋      | 73/200 [00:29<00:33,  3.84it/s]Seed 123:  37%|███▋      | 74/200 [00:29<00:31,  3.99it/s]Seed 123:  38%|███▊      | 75/200 [00:29<00:30,  4.16it/s]Seed 123:  38%|███▊      | 76/200 [00:30<00:29,  4.14it/s]Seed 123:  38%|███▊      | 77/200 [00:30<00:28,  4.26it/s]Target embedding RMS: 0.0027

Training on 2251 samples
Validation: 2376 samples
Starting training...

ARC_EASY:   0%|                                                            | 0/1500 [00:00<?, ?it/s]Seed 123:  39%|███▉      | 78/200 [00:30<00:28,  4.29it/s]Seed 123:  40%|███▉      | 79/200 [00:31<00:36,  3.27it/s]Seed 123:  40%|████      | 80/200 [00:31<00:40,  2.93it/s]ARC_EASY:   0%|                            | 0/1500 [00:01<?, ?it/s, lm=8.85, aux=0.000, gn=1080.00]ARC_EASY:   0%|                    | 1/1500 [00:01<31:21,  1.26s/it, lm=8.85, aux=0.000, gn=1080.00]Seed 123:  40%|████      | 81/200 [00:32<00:49,  2.41it/s]ARC_EASY:   0%|                    | 1/1500 [00:01<31:21,  1.26s/it, lm=9.04, aux=0.000, gn=3296.00]ARC_EASY:   0%|                    | 2/1500 [00:01<18:17,  1.36it/s, lm=9.04, aux=0.000, gn=3296.00]ARC_EASY:   0%|                    | 2/1500 [00:01<18:17,  1.36it/s, lm=8.86, aux=0.000, gn=1576.00]ARC_EASY:   0%|                    | 3/1500 [00:01<13:49,  1.81it/s, lm=8.86, aux=0.000, gn=1576.00]Seed 123:  41%|████      | 82/200 [00:32<00:54,  2.15it/s]ARC_EASY:   0%|                    | 3/1500 [00:02<13:49,  1.81it/s, lm=8.97, aux=0.000, gn=2176.00]ARC_EASY:   0%|                    | 4/1500 [00:02<12:07,  2.06it/s, lm=8.97, aux=0.000, gn=2176.00]ARC_EASY:   0%|                    | 4/1500 [00:02<12:07,  2.06it/s, lm=7.91, aux=0.000, gn=4032.00]ARC_EASY:   0%|                    | 5/1500 [00:02<11:04,  2.25it/s, lm=7.91, aux=0.000, gn=4032.00]Seed 123:  42%|████▏     | 83/200 [00:33<01:01,  1.91it/s]ARC_EASY:   0%|                     | 5/1500 [00:03<11:04,  2.25it/s, lm=7.24, aux=0.000, gn=960.00]ARC_EASY:   0%|                     | 6/1500 [00:03<10:10,  2.45it/s, lm=7.24, aux=0.000, gn=960.00]ARC_EASY:   0%|                    | 6/1500 [00:03<10:10,  2.45it/s, lm=7.07, aux=0.000, gn=5344.00]ARC_EASY:   0%|                    | 7/1500 [00:03<09:40,  2.57it/s, lm=7.07, aux=0.000, gn=5344.00]Seed 123:  42%|████▏     | 84/200 [00:34<01:05,  1.76it/s]ARC_EASY:   0%|                    | 7/1500 [00:03<09:40,  2.57it/s, lm=6.32, aux=0.000, gn=3024.00]ARC_EASY:   1%|                    | 8/1500 [00:03<09:26,  2.64it/s, lm=6.32, aux=0.000, gn=3024.00]Seed 123:  42%|████▎     | 85/200 [00:34<01:04,  1.79it/s]ARC_EASY:   1%|                     | 8/1500 [00:04<09:26,  2.64it/s, lm=6.84, aux=0.000, gn=716.00]ARC_EASY:   1%|▏                    | 9/1500 [00:04<09:26,  2.63it/s, lm=6.84, aux=0.000, gn=716.00]ARC_EASY:   1%|▏                    | 9/1500 [00:04<09:26,  2.63it/s, lm=5.90, aux=0.000, gn=688.00]ARC_EASY:   1%|▏                   | 10/1500 [00:04<09:03,  2.74it/s, lm=5.90, aux=0.000, gn=688.00]Seed 123:  43%|████▎     | 86/200 [00:35<01:06,  1.72it/s]ARC_EASY:   1%|▏                   | 10/1500 [00:04<09:03,  2.74it/s, lm=4.40, aux=0.000, gn=482.00]ARC_EASY:   1%|▏                   | 11/1500 [00:04<09:07,  2.72it/s, lm=4.40, aux=0.000, gn=482.00]ARC_EASY:   1%|▏                   | 11/1500 [00:05<09:07,  2.72it/s, lm=3.42, aux=0.000, gn=696.00]ARC_EASY:   1%|▏                   | 12/1500 [00:05<09:00,  2.75it/s, lm=3.42, aux=0.000, gn=696.00]Seed 123:  44%|████▎     | 87/200 [00:35<01:09,  1.63it/s]ARC_EASY:   1%|▏                   | 12/1500 [00:05<09:00,  2.75it/s, lm=1.96, aux=0.000, gn=199.00]ARC_EASY:   1%|▏                   | 13/1500 [00:05<08:58,  2.76it/s, lm=1.96, aux=0.000, gn=199.00]Seed 123:  44%|████▍     | 88/200 [00:36<01:08,  1.65it/s]ARC_EASY:   1%|▏                   | 13/1500 [00:05<08:58,  2.76it/s, lm=1.80, aux=0.000, gn=222.00]ARC_EASY:   1%|▏                   | 14/1500 [00:05<08:52,  2.79it/s, lm=1.80, aux=0.000, gn=222.00]ARC_EASY:   1%|▏                   | 14/1500 [00:06<08:52,  2.79it/s, lm=1.19, aux=0.000, gn=175.00]ARC_EASY:   1%|▏                   | 15/1500 [00:06<08:49,  2.81it/s, lm=1.19, aux=0.000, gn=175.00]Seed 123:  44%|████▍     | 89/200 [00:37<01:08,  1.61it/s]ARC_EASY:   1%|▏                  | 15/1500 [00:06<08:49,  2.81it/s, lm=1.78, aux=0.000, gn=1224.00]ARC_EASY:   1%|▏                  | 16/1500 [00:06<08:54,  2.78it/s, lm=1.78, aux=0.000, gn=1224.00]ARC_EASY:   1%|▏                   | 16/1500 [00:06<08:54,  2.78it/s, lm=0.91, aux=0.000, gn=153.00]ARC_EASY:   1%|▏                   | 17/1500 [00:06<08:53,  2.78it/s, lm=0.91, aux=0.000, gn=153.00]Seed 123:  45%|████▌     | 90/200 [00:37<01:07,  1.63it/s]ARC_EASY:   1%|▏                   | 17/1500 [00:07<08:53,  2.78it/s, lm=1.18, aux=0.000, gn=216.00]ARC_EASY:   1%|▏                   | 18/1500 [00:07<08:54,  2.77it/s, lm=1.18, aux=0.000, gn=216.00]ARC_EASY:   1%|▏                   | 18/1500 [00:07<10:21,  2.38it/s, lm=1.18, aux=0.000, gn=216.00]
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1280, in main
    batch = next(iter_dl)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 398, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 207, in collate
    raise RuntimeError("each element in list of batch should be of equal size")
RuntimeError: each element in list of batch should be of equal size
Seed 123:  46%|████▌     | 91/200 [00:38<01:05,  1.66it/s]Seed 123:  46%|████▌     | 92/200 [00:38<00:58,  1.83it/s]Seed 123:  46%|████▋     | 93/200 [00:39<00:54,  1.98it/s]Seed 123:  47%|████▋     | 94/200 [00:39<00:51,  2.06it/s]Seed 123:  48%|████▊     | 95/200 [00:39<00:48,  2.15it/s]Seed 123:  48%|████▊     | 96/200 [00:40<00:46,  2.22it/s]Seed 123:  48%|████▊     | 97/200 [00:40<00:45,  2.25it/s]Seed 123:  49%|████▉     | 98/200 [00:41<00:44,  2.29it/s]Seed 123:  50%|████▉     | 99/200 [00:41<00:43,  2.32it/s]Seed 123:  50%|█████     | 100/200 [00:42<00:43,  2.31it/s]Seed 123:  50%|█████     | 101/200 [00:42<00:42,  2.33it/s]Seed 123:  51%|█████     | 102/200 [00:42<00:41,  2.35it/s]Seed 123:  52%|█████▏    | 103/200 [00:43<00:41,  2.34it/s]Seed 123:  52%|█████▏    | 104/200 [00:43<00:42,  2.26it/s]Seed 123:  52%|█████▎    | 105/200 [00:44<00:41,  2.29it/s]Seed 123:  53%|█████▎    | 106/200 [00:44<00:40,  2.31it/s]Seed 123:  54%|█████▎    | 107/200 [00:45<00:39,  2.33it/s]Seed 123:  54%|█████▍    | 108/200 [00:45<00:39,  2.34it/s]Seed 123:  55%|█████▍    | 109/200 [00:45<00:39,  2.33it/s]Seed 123:  55%|█████▌    | 110/200 [00:46<00:38,  2.33it/s]Seed 123:  56%|█████▌    | 111/200 [00:46<00:38,  2.34it/s]
[ERROR] Training interrupted by exception at step 19
[ERROR] RuntimeError: each element in list of batch should be of equal size

[EMERGENCY] Checkpoint saved to runs/reasoning_final_20260119_122501/novel_bridges/token_capacity_4_seed42/emergency_checkpoint_step18.pt
[EMERGENCY] Error: RuntimeError: each element in list of batch should be of equal size
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1530, in <module>
Seed 123:  56%|█████▌    | 112/200 [00:47<00:37,  2.36it/s]    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1280, in main
    batch = next(iter_dl)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 398, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 207, in collate
    raise RuntimeError("each element in list of batch should be of equal size")
RuntimeError: each element in list of batch should be of equal size
Seed 123:  56%|█████▋    | 113/200 [00:47<00:37,  2.35it/s]Seed 123:  57%|█████▋    | 114/200 [00:48<00:37,  2.31it/s]Seed 123:  57%|█████▊    | 115/200 [00:48<00:36,  2.34it/s][2026-01-19 12:33:07] FAILED: token_capacity_4_seed42 (exit code: 1)
Seed 123:  58%|█████▊    | 116/200 [00:48<00:34,  2.41it/s]Failed: token_capacity_4_seed42
[2026-01-19 12:33:07] [GPU 1] Testing 8 soft tokens on ARC-Easy (seed=42)
Seed 123:  58%|█████▊    | 117/200 [00:49<00:32,  2.59it/s]Started: token_capacity_8_seed42
[2026-01-19 12:33:07] START: token_capacity_8_seed42
Seed 123:  59%|█████▉    | 118/200 [00:49<00:32,  2.55it/s]Seed 123:  60%|█████▉    | 119/200 [00:50<00:32,  2.52it/s]Seed 123:  60%|██████    | 120/200 [00:50<00:33,  2.40it/s]Seed 123:  60%|██████    | 121/200 [00:51<00:34,  2.31it/s]Seed 123:  61%|██████    | 122/200 [00:51<00:33,  2.31it/s]/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Seed 123:  62%|██████▏   | 123/200 [00:51<00:33,  2.27it/s]Seed 123:  62%|██████▏   | 124/200 [00:52<00:33,  2.27it/s]Seed 123:  62%|██████▎   | 125/200 [00:52<00:32,  2.27it/s]Seed 123:  63%|██████▎   | 126/200 [00:53<00:30,  2.43it/s]Seed 123:  64%|██████▎   | 127/200 [00:53<00:29,  2.51it/s]Seed 123:  64%|██████▍   | 128/200 [00:53<00:29,  2.41it/s]Seed 123:  64%|██████▍   | 129/200 [00:54<00:30,  2.30it/s]Seed 123:  65%|██████▌   | 130/200 [00:54<00:30,  2.28it/s]Seed 123:  66%|██████▌   | 131/200 [00:55<00:30,  2.29it/s]============================================================
TELEPATHY TRAINING: ARC_EASY
============================================================

Dataset: arc_easy (4 classes)
Random baseline: 25.0%
Source layer: 31
Soft tokens: 8
Steps: 1500
Diversity weight: 0.1
============================================================
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 1435.67it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Seed 123:  66%|██████▌   | 132/200 [00:55<00:29,  2.33it/s]Seed 123:  66%|██████▋   | 133/200 [00:55<00:25,  2.62it/s]Seed 123:  67%|██████▋   | 134/200 [00:56<00:26,  2.49it/s]Seed 123:  68%|██████▊   | 135/200 [00:56<00:26,  2.48it/s]Seed 123:  68%|██████▊   | 136/200 [00:57<00:26,  2.44it/s]Seed 123:  68%|██████▊   | 137/200 [00:57<00:25,  2.43it/s]Seed 123:  69%|██████▉   | 138/200 [00:58<00:26,  2.38it/s]Seed 123:  70%|██████▉   | 139/200 [00:58<00:25,  2.38it/s]Seed 123:  70%|███████   | 140/200 [00:58<00:25,  2.39it/s]Seed 123:  70%|███████   | 141/200 [00:59<00:24,  2.37it/s]Seed 123:  71%|███████   | 142/200 [00:59<00:24,  2.37it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:13,  4.54s/it]Seed 123:  72%|███████▏  | 143/200 [01:00<00:23,  2.38it/s]Seed 123:  72%|███████▏  | 144/200 [01:00<00:23,  2.38it/s]Seed 123:  72%|███████▎  | 145/200 [01:01<00:23,  2.36it/s]Seed 123:  73%|███████▎  | 146/200 [01:01<00:22,  2.35it/s]Seed 123:  74%|███████▎  | 147/200 [01:01<00:22,  2.34it/s]Seed 123:  74%|███████▍  | 148/200 [01:02<00:21,  2.37it/s]Seed 123:  74%|███████▍  | 149/200 [01:02<00:21,  2.35it/s]Seed 123:  75%|███████▌  | 150/200 [01:03<00:21,  2.35it/s]Seed 123:  76%|███████▌  | 151/200 [01:03<00:20,  2.36it/s]Seed 123:  76%|███████▌  | 152/200 [01:04<00:20,  2.36it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.22s/it]Seed 123:  76%|███████▋  | 153/200 [01:04<00:19,  2.46it/s]Seed 123:  77%|███████▋  | 154/200 [01:04<00:19,  2.40it/s]Seed 123:  78%|███████▊  | 155/200 [01:05<00:18,  2.41it/s]Seed 123:  78%|███████▊  | 156/200 [01:05<00:18,  2.39it/s]Seed 123:  78%|███████▊  | 157/200 [01:06<00:18,  2.38it/s]Seed 123:  79%|███████▉  | 158/200 [01:06<00:17,  2.36it/s]Seed 123:  80%|███████▉  | 159/200 [01:06<00:17,  2.38it/s]Seed 123:  80%|████████  | 160/200 [01:07<00:16,  2.36it/s]Seed 123:  80%|████████  | 161/200 [01:07<00:16,  2.35it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.08s/it]Seed 123:  81%|████████  | 162/200 [01:08<00:15,  2.38it/s]Seed 123:  82%|████████▏ | 163/200 [01:08<00:15,  2.36it/s]Seed 123:  82%|████████▏ | 164/200 [01:09<00:15,  2.36it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.87s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.37s/it]
Seed 123:  82%|████████▎ | 165/200 [01:09<00:12,  2.70it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2361.66it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Seed 123:  83%|████████▎ | 166/200 [01:09<00:12,  2.69it/s]Seed 123:  84%|████████▎ | 167/200 [01:10<00:12,  2.59it/s]Seed 123:  84%|████████▍ | 168/200 [01:10<00:12,  2.52it/s]Seed 123:  84%|████████▍ | 169/200 [01:10<00:12,  2.49it/s]Seed 123:  85%|████████▌ | 170/200 [01:11<00:12,  2.44it/s]Seed 123:  86%|████████▌ | 171/200 [01:11<00:11,  2.43it/s]Seed 123:  86%|████████▌ | 172/200 [01:12<00:11,  2.41it/s]Seed 123:  86%|████████▋ | 173/200 [01:12<00:11,  2.38it/s]Seed 123:  87%|████████▋ | 174/200 [01:13<00:10,  2.38it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.81s/it]Seed 123:  88%|████████▊ | 175/200 [01:13<00:10,  2.33it/s]Seed 123:  88%|████████▊ | 176/200 [01:13<00:10,  2.32it/s]Seed 123:  88%|████████▊ | 177/200 [01:14<00:09,  2.35it/s]Seed 123:  89%|████████▉ | 178/200 [01:14<00:09,  2.37it/s]Seed 123:  90%|████████▉ | 179/200 [01:15<00:08,  2.34it/s]Seed 123:  90%|█████████ | 180/200 [01:15<00:08,  2.37it/s]Seed 123:  90%|█████████ | 181/200 [01:16<00:08,  2.36it/s]Seed 123:  91%|█████████ | 182/200 [01:16<00:07,  2.37it/s]Seed 123:  92%|█████████▏| 183/200 [01:16<00:07,  2.40it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.89s/it]Seed 123:  92%|█████████▏| 184/200 [01:17<00:06,  2.40it/s]Seed 123:  92%|█████████▎| 185/200 [01:17<00:06,  2.40it/s]Seed 123:  93%|█████████▎| 186/200 [01:18<00:05,  2.39it/s]Seed 123:  94%|█████████▎| 187/200 [01:18<00:05,  2.40it/s]Seed 123:  94%|█████████▍| 188/200 [01:18<00:05,  2.37it/s]Seed 123:  94%|█████████▍| 189/200 [01:19<00:04,  2.38it/s]Seed 123:  95%|█████████▌| 190/200 [01:19<00:04,  2.36it/s]Seed 123:  96%|█████████▌| 191/200 [01:20<00:03,  2.35it/s]Seed 123:  96%|█████████▌| 192/200 [01:20<00:03,  2.34it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.73s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.77s/it]
Seed 123:  96%|█████████▋| 193/200 [01:20<00:02,  2.65it/s]Seed 123:  97%|█████████▋| 194/200 [01:21<00:02,  2.71it/s]Seed 123:  98%|█████████▊| 195/200 [01:21<00:01,  2.68it/s]Seed 123:  98%|█████████▊| 196/200 [01:22<00:01,  2.60it/s]Seed 123:  98%|█████████▊| 197/200 [01:22<00:01,  2.51it/s]Seed 123:  99%|█████████▉| 198/200 [01:22<00:00,  2.47it/s]Seed 123: 100%|█████████▉| 199/200 [01:23<00:00,  2.41it/s]Seed 123: 100%|██████████| 200/200 [01:23<00:00,  2.42it/s]                                                             Seed 123: 29.0%
Seed 456:   0%|          | 0/200 [00:00<?, ?it/s]Seed 456:   0%|          | 1/200 [00:00<01:23,  2.38it/s]Seed 456:   1%|          | 2/200 [00:00<01:23,  2.38it/s]Seed 456:   2%|▏         | 3/200 [00:01<01:24,  2.34it/s]Seed 456:   2%|▏         | 4/200 [00:01<01:22,  2.38it/s]Seed 456:   2%|▎         | 5/200 [00:02<01:22,  2.36it/s]Seed 456:   3%|▎         | 6/200 [00:02<01:21,  2.37it/s]Seed 456:   4%|▎         | 7/200 [00:02<01:21,  2.38it/s]Seed 456:   4%|▍         | 8/200 [00:03<01:21,  2.37it/s]Seed 456:   4%|▍         | 9/200 [00:03<01:20,  2.36it/s]Seed 456:   5%|▌         | 10/200 [00:04<01:10,  2.71it/s]Seed 456:   6%|▌         | 11/200 [00:04<01:01,  3.10it/s]Seed 456:   6%|▌         | 12/200 [00:04<00:55,  3.41it/s]Seed 456:   6%|▋         | 13/200 [00:04<00:50,  3.71it/s]Seed 456:   7%|▋         | 14/200 [00:04<00:47,  3.93it/s]Seed 456:   8%|▊         | 15/200 [00:05<00:45,  4.09it/s]Seed 456:   8%|▊         | 16/200 [00:05<00:44,  4.10it/s]Seed 456:   8%|▊         | 17/200 [00:05<00:43,  4.23it/s]Seed 456:   9%|▉         | 18/200 [00:05<00:41,  4.35it/s]Target embedding RMS: 0.0027

Training on 2251 samples
Validation: 2376 samples
Starting training...

ARC_EASY:   0%|                                                            | 0/1500 [00:00<?, ?it/s]Seed 456:  10%|▉         | 19/200 [00:06<00:46,  3.93it/s]Seed 456:  10%|█         | 20/200 [00:06<00:55,  3.24it/s]Seed 456:  10%|█         | 21/200 [00:07<01:02,  2.85it/s]ARC_EASY:   0%|                             | 0/1500 [00:01<?, ?it/s, lm=8.74, aux=0.000, gn=760.00]ARC_EASY:   0%|                     | 1/1500 [00:01<29:25,  1.18s/it, lm=8.74, aux=0.000, gn=760.00]ARC_EASY:   0%|                     | 1/1500 [00:01<29:25,  1.18s/it, lm=8.70, aux=0.000, gn=860.00]ARC_EASY:   0%|                     | 2/1500 [00:01<17:25,  1.43it/s, lm=8.70, aux=0.000, gn=860.00]Seed 456:  11%|█         | 22/200 [00:07<01:16,  2.33it/s]ARC_EASY:   0%|                    | 2/1500 [00:01<17:25,  1.43it/s, lm=7.71, aux=0.000, gn=1008.00]ARC_EASY:   0%|                    | 3/1500 [00:01<13:41,  1.82it/s, lm=7.71, aux=0.000, gn=1008.00]ARC_EASY:   0%|                     | 3/1500 [00:02<13:41,  1.82it/s, lm=7.73, aux=0.000, gn=470.00]ARC_EASY:   0%|                     | 4/1500 [00:02<11:42,  2.13it/s, lm=7.73, aux=0.000, gn=470.00]Seed 456:  12%|█▏        | 23/200 [00:08<01:30,  1.97it/s]ARC_EASY:   0%|                     | 4/1500 [00:02<11:42,  2.13it/s, lm=6.92, aux=0.000, gn=576.00]ARC_EASY:   0%|                     | 5/1500 [00:02<11:05,  2.25it/s, lm=6.92, aux=0.000, gn=576.00]Seed 456:  12%|█▏        | 24/200 [00:08<01:31,  1.91it/s]ARC_EASY:   0%|                     | 5/1500 [00:03<11:05,  2.25it/s, lm=5.85, aux=0.000, gn=492.00]ARC_EASY:   0%|                     | 6/1500 [00:03<10:13,  2.44it/s, lm=5.85, aux=0.000, gn=492.00]ARC_EASY:   0%|                     | 6/1500 [00:03<10:13,  2.44it/s, lm=4.42, aux=0.000, gn=556.00]ARC_EASY:   0%|                     | 7/1500 [00:03<09:58,  2.50it/s, lm=4.42, aux=0.000, gn=556.00]Seed 456:  12%|█▎        | 25/200 [00:09<01:35,  1.83it/s]ARC_EASY:   0%|                     | 7/1500 [00:03<09:58,  2.50it/s, lm=2.84, aux=0.000, gn=696.00]ARC_EASY:   1%|                     | 8/1500 [00:03<09:36,  2.59it/s, lm=2.84, aux=0.000, gn=696.00]ARC_EASY:   1%|                     | 8/1500 [00:04<09:36,  2.59it/s, lm=2.78, aux=0.000, gn=536.00]ARC_EASY:   1%|▏                    | 9/1500 [00:04<09:18,  2.67it/s, lm=2.78, aux=0.000, gn=536.00]Seed 456:  13%|█▎        | 26/200 [00:10<01:42,  1.70it/s]ARC_EASY:   1%|▏                    | 9/1500 [00:04<09:18,  2.67it/s, lm=1.46, aux=0.000, gn=212.00]ARC_EASY:   1%|▏                   | 10/1500 [00:04<09:03,  2.74it/s, lm=1.46, aux=0.000, gn=212.00]ARC_EASY:   1%|▏                  | 10/1500 [00:04<09:03,  2.74it/s, lm=3.85, aux=0.000, gn=2304.00]ARC_EASY:   1%|▏                  | 11/1500 [00:04<09:02,  2.74it/s, lm=3.85, aux=0.000, gn=2304.00]Seed 456:  14%|█▎        | 27/200 [00:10<01:45,  1.64it/s]ARC_EASY:   1%|▏                   | 11/1500 [00:05<09:02,  2.74it/s, lm=1.85, aux=0.000, gn=776.00]ARC_EASY:   1%|▏                   | 12/1500 [00:05<09:11,  2.70it/s, lm=1.85, aux=0.000, gn=776.00]Seed 456:  14%|█▍        | 28/200 [00:11<01:44,  1.64it/s]ARC_EASY:   1%|▏                   | 12/1500 [00:05<09:11,  2.70it/s, lm=1.24, aux=0.000, gn=137.00]ARC_EASY:   1%|▏                   | 13/1500 [00:05<09:13,  2.69it/s, lm=1.24, aux=0.000, gn=137.00]ARC_EASY:   1%|▏                   | 13/1500 [00:05<09:13,  2.69it/s, lm=0.95, aux=0.000, gn=148.00]ARC_EASY:   1%|▏                   | 14/1500 [00:05<09:06,  2.72it/s, lm=0.95, aux=0.000, gn=148.00]Seed 456:  14%|█▍        | 29/200 [00:12<01:45,  1.63it/s]ARC_EASY:   1%|▏                    | 14/1500 [00:06<09:06,  2.72it/s, lm=0.76, aux=0.000, gn=78.50]ARC_EASY:   1%|▏                    | 15/1500 [00:06<08:58,  2.76it/s, lm=0.76, aux=0.000, gn=78.50]ARC_EASY:   1%|▏                   | 15/1500 [00:06<08:58,  2.76it/s, lm=1.60, aux=0.000, gn=264.00]ARC_EASY:   1%|▏                   | 16/1500 [00:06<08:58,  2.75it/s, lm=1.60, aux=0.000, gn=264.00]Seed 456:  15%|█▌        | 30/200 [00:12<01:45,  1.61it/s]ARC_EASY:   1%|▏                    | 16/1500 [00:06<08:58,  2.75it/s, lm=0.71, aux=0.000, gn=50.00]ARC_EASY:   1%|▏                    | 17/1500 [00:06<08:56,  2.77it/s, lm=0.71, aux=0.000, gn=50.00]Seed 456:  16%|█▌        | 31/200 [00:13<01:45,  1.59it/s]ARC_EASY:   1%|▏                   | 17/1500 [00:07<08:56,  2.77it/s, lm=3.42, aux=0.000, gn=352.00]ARC_EASY:   1%|▏                   | 18/1500 [00:07<09:02,  2.73it/s, lm=3.42, aux=0.000, gn=352.00]ARC_EASY:   1%|▏                   | 18/1500 [00:07<10:20,  2.39it/s, lm=3.42, aux=0.000, gn=352.00]
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1280, in main
    batch = next(iter_dl)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 398, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 207, in collate
    raise RuntimeError("each element in list of batch should be of equal size")
RuntimeError: each element in list of batch should be of equal size
Seed 456:  16%|█▌        | 32/200 [00:13<01:38,  1.71it/s]Seed 456:  16%|█▋        | 33/200 [00:14<01:29,  1.87it/s]Seed 456:  17%|█▋        | 34/200 [00:14<01:23,  1.99it/s]Seed 456:  18%|█▊        | 35/200 [00:15<01:19,  2.09it/s]Seed 456:  18%|█▊        | 36/200 [00:15<01:15,  2.18it/s]Seed 456:  18%|█▊        | 37/200 [00:15<01:14,  2.20it/s]Seed 456:  19%|█▉        | 38/200 [00:16<01:11,  2.26it/s]Seed 456:  20%|█▉        | 39/200 [00:16<01:10,  2.28it/s]Seed 456:  20%|██        | 40/200 [00:17<01:09,  2.30it/s]Seed 456:  20%|██        | 41/200 [00:17<01:08,  2.33it/s]Seed 456:  21%|██        | 42/200 [00:18<01:07,  2.35it/s]Seed 456:  22%|██▏       | 43/200 [00:18<01:06,  2.35it/s]Seed 456:  22%|██▏       | 44/200 [00:18<01:08,  2.27it/s]Seed 456:  22%|██▎       | 45/200 [00:19<01:07,  2.29it/s]Seed 456:  23%|██▎       | 46/200 [00:19<01:07,  2.29it/s]Seed 456:  24%|██▎       | 47/200 [00:20<01:06,  2.31it/s]Seed 456:  24%|██▍       | 48/200 [00:20<01:05,  2.32it/s]Seed 456:  24%|██▍       | 49/200 [00:21<01:04,  2.35it/s]Seed 456:  25%|██▌       | 50/200 [00:21<01:04,  2.34it/s]Seed 456:  26%|██▌       | 51/200 [00:21<01:03,  2.35it/s]Seed 456:  26%|██▌       | 52/200 [00:22<01:03,  2.35it/s]
[ERROR] Training interrupted by exception at step 19
[ERROR] RuntimeError: each element in list of batch should be of equal size

[EMERGENCY] Checkpoint saved to runs/reasoning_final_20260119_122501/novel_bridges/token_capacity_8_seed42/emergency_checkpoint_step18.pt
[EMERGENCY] Error: RuntimeError: each element in list of batch should be of equal size
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1530, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1280, in main
    batch = next(iter_dl)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 398, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 207, in collate
    raise RuntimeError("each element in list of batch should be of equal size")
RuntimeError: each element in list of batch should be of equal size
Seed 456:  26%|██▋       | 53/200 [00:22<01:02,  2.37it/s]Seed 456:  27%|██▋       | 54/200 [00:23<01:02,  2.35it/s]Seed 456:  28%|██▊       | 55/200 [00:23<01:01,  2.35it/s][2026-01-19 12:34:06] FAILED: token_capacity_8_seed42 (exit code: 1)
Seed 456:  28%|██▊       | 56/200 [00:24<01:00,  2.38it/s]Failed: token_capacity_8_seed42
[2026-01-19 12:34:07] [GPU 1] Testing 16 soft tokens on ARC-Easy (seed=42)
Seed 456:  28%|██▊       | 57/200 [00:24<00:55,  2.60it/s]Started: token_capacity_16_seed42
[2026-01-19 12:34:07] START: token_capacity_16_seed42
Seed 456:  29%|██▉       | 58/200 [00:24<00:55,  2.56it/s]Seed 456:  30%|██▉       | 59/200 [00:25<00:56,  2.49it/s]Seed 456:  30%|███       | 60/200 [00:25<00:58,  2.40it/s]Seed 456:  30%|███       | 61/200 [00:26<01:00,  2.29it/s]Seed 456:  31%|███       | 62/200 [00:26<00:59,  2.32it/s]/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Seed 456:  32%|███▏      | 63/200 [00:26<01:00,  2.28it/s]Seed 456:  32%|███▏      | 64/200 [00:27<01:01,  2.22it/s]Seed 456:  32%|███▎      | 65/200 [00:27<01:00,  2.22it/s]Seed 456:  33%|███▎      | 66/200 [00:28<00:55,  2.44it/s]Seed 456:  34%|███▎      | 67/200 [00:28<00:51,  2.58it/s]Seed 456:  34%|███▍      | 68/200 [00:29<00:54,  2.44it/s]Seed 456:  34%|███▍      | 69/200 [00:29<00:54,  2.41it/s]Seed 456:  35%|███▌      | 70/200 [00:29<00:55,  2.36it/s]Seed 456:  36%|███▌      | 71/200 [00:30<00:55,  2.34it/s]============================================================
TELEPATHY TRAINING: ARC_EASY
============================================================

Dataset: arc_easy (4 classes)
Random baseline: 25.0%
Source layer: 31
Soft tokens: 16
Steps: 1500
Diversity weight: 0.1
============================================================
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 1983.12it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Seed 456:  36%|███▌      | 72/200 [00:30<00:53,  2.40it/s]Seed 456:  36%|███▋      | 73/200 [00:30<00:46,  2.72it/s]Seed 456:  37%|███▋      | 74/200 [00:31<00:42,  2.97it/s]Seed 456:  38%|███▊      | 75/200 [00:31<00:44,  2.84it/s]Seed 456:  38%|███▊      | 76/200 [00:32<00:45,  2.70it/s]Seed 456:  38%|███▊      | 77/200 [00:32<00:47,  2.58it/s]Seed 456:  39%|███▉      | 78/200 [00:32<00:48,  2.50it/s]Seed 456:  40%|███▉      | 79/200 [00:33<00:49,  2.46it/s]Seed 456:  40%|████      | 80/200 [00:33<00:49,  2.42it/s]Seed 456:  40%|████      | 81/200 [00:34<00:49,  2.42it/s]Seed 456:  41%|████      | 82/200 [00:34<00:48,  2.43it/s]Seed 456:  42%|████▏     | 83/200 [00:35<00:48,  2.39it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:14,  4.75s/it]Seed 456:  42%|████▏     | 84/200 [00:35<00:48,  2.38it/s]Seed 456:  42%|████▎     | 85/200 [00:35<00:48,  2.38it/s]Seed 456:  43%|████▎     | 86/200 [00:36<00:47,  2.40it/s]Seed 456:  44%|████▎     | 87/200 [00:36<00:47,  2.38it/s]Seed 456:  44%|████▍     | 88/200 [00:37<00:47,  2.38it/s]Seed 456:  44%|████▍     | 89/200 [00:37<00:47,  2.35it/s]Seed 456:  45%|████▌     | 90/200 [00:37<00:46,  2.35it/s]Seed 456:  46%|████▌     | 91/200 [00:38<00:46,  2.35it/s]Seed 456:  46%|████▌     | 92/200 [00:38<00:45,  2.35it/s]Seed 456:  46%|████▋     | 93/200 [00:39<00:45,  2.36it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.31s/it]Seed 456:  47%|████▋     | 94/200 [00:39<00:44,  2.36it/s]Seed 456:  48%|████▊     | 95/200 [00:40<00:42,  2.44it/s]Seed 456:  48%|████▊     | 96/200 [00:40<00:43,  2.39it/s]Seed 456:  48%|████▊     | 97/200 [00:40<00:42,  2.41it/s]Seed 456:  49%|████▉     | 98/200 [00:41<00:42,  2.38it/s]Seed 456:  50%|████▉     | 99/200 [00:41<00:42,  2.39it/s]Seed 456:  50%|█████     | 100/200 [00:42<00:41,  2.38it/s]Seed 456:  50%|█████     | 101/200 [00:42<00:41,  2.39it/s]Seed 456:  51%|█████     | 102/200 [00:43<00:41,  2.37it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.14s/it]Seed 456:  52%|█████▏    | 103/200 [00:43<00:40,  2.37it/s]Seed 456:  52%|█████▏    | 104/200 [00:43<00:40,  2.36it/s]Seed 456:  52%|█████▎    | 105/200 [00:44<00:39,  2.39it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.91s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.43s/it]
Seed 456:  53%|█████▎    | 106/200 [00:44<00:35,  2.64it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2322.86it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Seed 456:  54%|█████▎    | 107/200 [00:44<00:33,  2.77it/s]Seed 456:  54%|█████▍    | 108/200 [00:45<00:34,  2.66it/s]Seed 456:  55%|█████▍    | 109/200 [00:45<00:35,  2.55it/s]Seed 456:  55%|█████▌    | 110/200 [00:46<00:36,  2.46it/s]Seed 456:  56%|█████▌    | 111/200 [00:46<00:36,  2.46it/s]Seed 456:  56%|█████▌    | 112/200 [00:46<00:36,  2.43it/s]Seed 456:  56%|█████▋    | 113/200 [00:47<00:36,  2.39it/s]Seed 456:  57%|█████▋    | 114/200 [00:47<00:36,  2.38it/s]Seed 456:  57%|█████▊    | 115/200 [00:48<00:35,  2.36it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.78s/it]Seed 456:  58%|█████▊    | 116/200 [00:48<00:35,  2.38it/s]Seed 456:  58%|█████▊    | 117/200 [00:49<00:36,  2.28it/s]Seed 456:  59%|█████▉    | 118/200 [00:49<00:35,  2.32it/s]Seed 456:  60%|█████▉    | 119/200 [00:50<00:34,  2.33it/s]Seed 456:  60%|██████    | 120/200 [00:50<00:34,  2.33it/s]Seed 456:  60%|██████    | 121/200 [00:50<00:33,  2.33it/s]Seed 456:  61%|██████    | 122/200 [00:51<00:33,  2.35it/s]Seed 456:  62%|██████▏   | 123/200 [00:51<00:32,  2.37it/s]Seed 456:  62%|██████▏   | 124/200 [00:52<00:32,  2.37it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.88s/it]Seed 456:  62%|██████▎   | 125/200 [00:52<00:31,  2.36it/s]Seed 456:  63%|██████▎   | 126/200 [00:52<00:31,  2.38it/s]Seed 456:  64%|██████▎   | 127/200 [00:53<00:30,  2.39it/s]Seed 456:  64%|██████▍   | 128/200 [00:53<00:30,  2.37it/s]Seed 456:  64%|██████▍   | 129/200 [00:54<00:29,  2.38it/s]Seed 456:  65%|██████▌   | 130/200 [00:54<00:29,  2.37it/s]Seed 456:  66%|██████▌   | 131/200 [00:55<00:29,  2.36it/s]Seed 456:  66%|██████▌   | 132/200 [00:55<00:28,  2.35it/s]Seed 456:  66%|██████▋   | 133/200 [00:55<00:28,  2.35it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.71s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.75s/it]
Seed 456:  67%|██████▋   | 134/200 [00:56<00:24,  2.67it/s]Seed 456:  68%|██████▊   | 135/200 [00:56<00:23,  2.82it/s]Seed 456:  68%|██████▊   | 136/200 [00:56<00:23,  2.69it/s]Seed 456:  68%|██████▊   | 137/200 [00:57<00:23,  2.68it/s]Seed 456:  69%|██████▉   | 138/200 [00:57<00:24,  2.56it/s]Seed 456:  70%|██████▉   | 139/200 [00:58<00:24,  2.52it/s]Seed 456:  70%|███████   | 140/200 [00:58<00:24,  2.46it/s]Seed 456:  70%|███████   | 141/200 [00:58<00:24,  2.43it/s]Seed 456:  71%|███████   | 142/200 [00:59<00:23,  2.43it/s]Seed 456:  72%|███████▏  | 143/200 [00:59<00:23,  2.40it/s]Seed 456:  72%|███████▏  | 144/200 [01:00<00:23,  2.41it/s]Seed 456:  72%|███████▎  | 145/200 [01:00<00:23,  2.38it/s]Seed 456:  73%|███████▎  | 146/200 [01:01<00:22,  2.39it/s]Seed 456:  74%|███████▎  | 147/200 [01:01<00:22,  2.40it/s]Seed 456:  74%|███████▍  | 148/200 [01:01<00:21,  2.39it/s]Seed 456:  74%|███████▍  | 149/200 [01:02<00:21,  2.41it/s]Seed 456:  75%|███████▌  | 150/200 [01:02<00:20,  2.40it/s]Seed 456:  76%|███████▌  | 151/200 [01:03<00:20,  2.40it/s]Seed 456:  76%|███████▌  | 152/200 [01:03<00:20,  2.39it/s]Seed 456:  76%|███████▋  | 153/200 [01:03<00:17,  2.75it/s]Seed 456:  77%|███████▋  | 154/200 [01:04<00:14,  3.12it/s]Seed 456:  78%|███████▊  | 155/200 [01:04<00:13,  3.46it/s]Seed 456:  78%|███████▊  | 156/200 [01:04<00:11,  3.72it/s]Seed 456:  78%|███████▊  | 157/200 [01:04<00:10,  3.94it/s]Seed 456:  79%|███████▉  | 158/200 [01:04<00:10,  4.09it/s]Seed 456:  80%|███████▉  | 159/200 [01:05<00:09,  4.11it/s]Seed 456:  80%|████████  | 160/200 [01:05<00:09,  4.26it/s]Seed 456:  80%|████████  | 161/200 [01:05<00:08,  4.37it/s]Target embedding RMS: 0.0027

Training on 2251 samples
Validation: 2376 samples
Starting training...

ARC_EASY:   0%|                                                            | 0/1500 [00:00<?, ?it/s]Seed 456:  81%|████████  | 162/200 [01:05<00:08,  4.23it/s]Seed 456:  82%|████████▏ | 163/200 [01:06<00:10,  3.41it/s]Seed 456:  82%|████████▏ | 164/200 [01:06<00:12,  3.00it/s]ARC_EASY:   0%|                            | 0/1500 [00:01<?, ?it/s, lm=10.02, aux=0.000, gn=516.00]ARC_EASY:   0%|                    | 1/1500 [00:01<31:04,  1.24s/it, lm=10.02, aux=0.000, gn=516.00]Seed 456:  82%|████████▎ | 165/200 [01:07<00:14,  2.38it/s]ARC_EASY:   0%|                    | 1/1500 [00:01<31:04,  1.24s/it, lm=10.07, aux=0.000, gn=432.00]ARC_EASY:   0%|                    | 2/1500 [00:01<18:27,  1.35it/s, lm=10.07, aux=0.000, gn=432.00]ARC_EASY:   0%|                     | 2/1500 [00:01<18:27,  1.35it/s, lm=9.44, aux=0.000, gn=324.00]ARC_EASY:   0%|                     | 3/1500 [00:01<14:13,  1.75it/s, lm=9.44, aux=0.000, gn=324.00]Seed 456:  83%|████████▎ | 166/200 [01:07<00:16,  2.09it/s]ARC_EASY:   0%|                     | 3/1500 [00:02<14:13,  1.75it/s, lm=8.30, aux=0.000, gn=408.00]ARC_EASY:   0%|                     | 4/1500 [00:02<12:36,  1.98it/s, lm=8.30, aux=0.000, gn=408.00]ARC_EASY:   0%|                     | 4/1500 [00:02<12:36,  1.98it/s, lm=7.26, aux=0.000, gn=288.00]ARC_EASY:   0%|                     | 5/1500 [00:02<11:27,  2.17it/s, lm=7.26, aux=0.000, gn=288.00]Seed 456:  84%|████████▎ | 167/200 [01:08<00:17,  1.86it/s]ARC_EASY:   0%|                     | 5/1500 [00:03<11:27,  2.17it/s, lm=6.97, aux=0.000, gn=736.00]ARC_EASY:   0%|                     | 6/1500 [00:03<10:50,  2.30it/s, lm=6.97, aux=0.000, gn=736.00]Seed 456:  84%|████████▍ | 168/200 [01:09<00:17,  1.79it/s]ARC_EASY:   0%|                     | 6/1500 [00:03<10:50,  2.30it/s, lm=6.57, aux=0.000, gn=552.00]ARC_EASY:   0%|                     | 7/1500 [00:03<10:22,  2.40it/s, lm=6.57, aux=0.000, gn=552.00]ARC_EASY:   0%|                     | 7/1500 [00:03<10:22,  2.40it/s, lm=5.93, aux=0.000, gn=424.00]ARC_EASY:   1%|                     | 8/1500 [00:03<10:03,  2.47it/s, lm=5.93, aux=0.000, gn=424.00]Seed 456:  84%|████████▍ | 169/200 [01:09<00:17,  1.74it/s]ARC_EASY:   1%|                     | 8/1500 [00:04<10:03,  2.47it/s, lm=5.48, aux=0.000, gn=704.00]ARC_EASY:   1%|▏                    | 9/1500 [00:04<09:52,  2.52it/s, lm=5.48, aux=0.000, gn=704.00]Seed 456:  85%|████████▌ | 170/200 [01:10<00:17,  1.68it/s]ARC_EASY:   1%|▏                    | 9/1500 [00:04<09:52,  2.52it/s, lm=5.03, aux=0.000, gn=828.00]ARC_EASY:   1%|▏                   | 10/1500 [00:04<09:45,  2.55it/s, lm=5.03, aux=0.000, gn=828.00]ARC_EASY:   1%|▏                   | 10/1500 [00:05<09:45,  2.55it/s, lm=4.61, aux=0.000, gn=752.00]ARC_EASY:   1%|▏                   | 11/1500 [00:05<09:33,  2.59it/s, lm=4.61, aux=0.000, gn=752.00]Seed 456:  86%|████████▌ | 171/200 [01:11<00:18,  1.59it/s]ARC_EASY:   1%|▏                   | 11/1500 [00:05<09:33,  2.59it/s, lm=5.21, aux=0.000, gn=270.00]ARC_EASY:   1%|▏                   | 12/1500 [00:05<09:37,  2.58it/s, lm=5.21, aux=0.000, gn=270.00]ARC_EASY:   1%|▏                   | 12/1500 [00:05<09:37,  2.58it/s, lm=3.52, aux=0.000, gn=748.00]ARC_EASY:   1%|▏                   | 13/1500 [00:05<09:28,  2.62it/s, lm=3.52, aux=0.000, gn=748.00]Seed 456:  86%|████████▌ | 172/200 [01:11<00:18,  1.52it/s]ARC_EASY:   1%|▏                   | 13/1500 [00:06<09:28,  2.62it/s, lm=2.42, aux=0.000, gn=792.00]ARC_EASY:   1%|▏                   | 14/1500 [00:06<09:21,  2.65it/s, lm=2.42, aux=0.000, gn=792.00]ARC_EASY:   1%|▏                   | 14/1500 [00:06<09:21,  2.65it/s, lm=1.37, aux=0.000, gn=318.00]ARC_EASY:   1%|▏                   | 15/1500 [00:06<09:29,  2.61it/s, lm=1.37, aux=0.000, gn=318.00]Seed 456:  86%|████████▋ | 173/200 [01:12<00:17,  1.56it/s]ARC_EASY:   1%|▏                   | 15/1500 [00:06<09:29,  2.61it/s, lm=1.89, aux=0.000, gn=205.00]ARC_EASY:   1%|▏                   | 16/1500 [00:06<09:30,  2.60it/s, lm=1.89, aux=0.000, gn=205.00]Seed 456:  87%|████████▋ | 174/200 [01:13<00:16,  1.53it/s]ARC_EASY:   1%|▏                   | 16/1500 [00:07<09:30,  2.60it/s, lm=1.56, aux=0.000, gn=216.00]ARC_EASY:   1%|▏                   | 17/1500 [00:07<09:39,  2.56it/s, lm=1.56, aux=0.000, gn=216.00]ARC_EASY:   1%|▏                   | 17/1500 [00:07<09:39,  2.56it/s, lm=2.28, aux=0.000, gn=298.00]ARC_EASY:   1%|▏                   | 18/1500 [00:07<09:47,  2.52it/s, lm=2.28, aux=0.000, gn=298.00]ARC_EASY:   1%|▏                   | 18/1500 [00:07<10:57,  2.25it/s, lm=2.28, aux=0.000, gn=298.00]
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1280, in main
    batch = next(iter_dl)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 398, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 207, in collate
    raise RuntimeError("each element in list of batch should be of equal size")
RuntimeError: each element in list of batch should be of equal size
Seed 456:  88%|████████▊ | 175/200 [01:13<00:16,  1.55it/s]Seed 456:  88%|████████▊ | 176/200 [01:14<00:13,  1.74it/s]Seed 456:  88%|████████▊ | 177/200 [01:14<00:12,  1.88it/s]Seed 456:  89%|████████▉ | 178/200 [01:15<00:11,  1.99it/s]Seed 456:  90%|████████▉ | 179/200 [01:15<00:10,  2.09it/s]Seed 456:  90%|█████████ | 180/200 [01:15<00:09,  2.16it/s]Seed 456:  90%|█████████ | 181/200 [01:16<00:08,  2.20it/s]Seed 456:  91%|█████████ | 182/200 [01:16<00:07,  2.26it/s]Seed 456:  92%|█████████▏| 183/200 [01:17<00:07,  2.31it/s]Seed 456:  92%|█████████▏| 184/200 [01:17<00:06,  2.30it/s]Seed 456:  92%|█████████▎| 185/200 [01:18<00:06,  2.32it/s]Seed 456:  93%|█████████▎| 186/200 [01:18<00:05,  2.35it/s]Seed 456:  94%|█████████▎| 187/200 [01:18<00:05,  2.30it/s]Seed 456:  94%|█████████▍| 188/200 [01:19<00:05,  2.28it/s]Seed 456:  94%|█████████▍| 189/200 [01:19<00:04,  2.30it/s]Seed 456:  95%|█████████▌| 190/200 [01:20<00:04,  2.31it/s]Seed 456:  96%|█████████▌| 191/200 [01:20<00:03,  2.33it/s]Seed 456:  96%|█████████▌| 192/200 [01:21<00:03,  2.37it/s]Seed 456:  96%|█████████▋| 193/200 [01:21<00:02,  2.35it/s]Seed 456:  97%|█████████▋| 194/200 [01:21<00:02,  2.36it/s]Seed 456:  98%|█████████▊| 195/200 [01:22<00:02,  2.37it/s]
[ERROR] Training interrupted by exception at step 19
[ERROR] RuntimeError: each element in list of batch should be of equal size

[EMERGENCY] Checkpoint saved to runs/reasoning_final_20260119_122501/novel_bridges/token_capacity_16_seed42/emergency_checkpoint_step18.pt
[EMERGENCY] Error: RuntimeError: each element in list of batch should be of equal size
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1530, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1280, in main
    batch = next(iter_dl)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 398, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 207, in collate
    raise RuntimeError("each element in list of batch should be of equal size")
RuntimeError: each element in list of batch should be of equal size
Seed 456:  98%|█████████▊| 196/200 [01:22<00:01,  2.34it/s]Seed 456:  98%|█████████▊| 197/200 [01:23<00:01,  2.35it/s]Seed 456:  99%|█████████▉| 198/200 [01:23<00:00,  2.34it/s]Seed 456: 100%|█████████▉| 199/200 [01:24<00:00,  2.32it/s][2026-01-19 12:35:07] FAILED: token_capacity_16_seed42 (exit code: 1)
Seed 456: 100%|██████████| 200/200 [01:24<00:00,  2.48it/s]                                                           Failed: token_capacity_16_seed42
[2026-01-19 12:35:07] [GPU 1] Testing 32 soft tokens on ARC-Easy (seed=42)
  Seed 456: 24.5%
Mistral 4-shot: 26.0% +/- 2.1%

Results saved to: runs/reasoning_final_20260119_122501/baselines/fewshot/fewshot_arc_easy_20260119_122639.json
Started: token_capacity_32_seed42
[2026-01-19 12:35:07] START: token_capacity_32_seed42
[2026-01-19 12:35:09] SUCCESS: fewshot_arc_easy
Completed: fewshot_arc_easy
[2026-01-19 12:35:09] [GPU 0] Few-shot (4-shot) on winogrande
Started: fewshot_winogrande
[2026-01-19 12:35:09] START: fewshot_winogrande
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
============================================================
TELEPATHY TRAINING: ARC_EASY
============================================================

Dataset: arc_easy (4 classes)
Random baseline: 25.0%
Source layer: 31
Soft tokens: 32
Steps: 1500
Diversity weight: 0.1
============================================================
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2220.68it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Device: cuda:0

======================================================================
FEW-SHOT BASELINE (4-shot): WINOGRANDE
======================================================================
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 1648, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 1592, in main
    results = run_fewshot_baseline(args, config, device)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 297, in run_fewshot_baseline
    train_ds = load_dataset(config["load_args"][0], config["load_args"][1],
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 2132, in load_dataset
    builder_instance = load_dataset_builder(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1853, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1729, in dataset_module_factory
    raise e1 from None
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1599, in dataset_module_factory
    dataset_readme_path = api.hf_hub_download(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 5467, in hf_hub_download
    return hf_hub_download(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1124, in _hf_hub_download_to_cache_dir
    os.makedirs(os.path.dirname(blob_path), exist_ok=True)
  File "/marlowe/apps/Mambaforge/24.3.0-0/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/marlowe/apps/Mambaforge/24.3.0-0/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
OSError: [Errno 122] Disk quota exceeded: '/projects/m000066/sujinesh/.cache/huggingface/hub/datasets--allenai--winogrande'
[2026-01-19 12:35:17] FAILED: fewshot_winogrande (exit code: 1)
Failed: fewshot_winogrande
[2026-01-19 12:35:17] [GPU 0] Few-shot (4-shot) on hellaswag
Started: fewshot_hellaswag
[2026-01-19 12:35:17] START: fewshot_hellaswag
Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:12,  4.06s/it]/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.97s/it]Device: cuda:0

======================================================================
FEW-SHOT BASELINE (4-shot): HELLASWAG
======================================================================
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 1648, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 1592, in main
    results = run_fewshot_baseline(args, config, device)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 302, in run_fewshot_baseline
    train_ds = load_dataset(config["load_args"][0],
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 2132, in load_dataset
    builder_instance = load_dataset_builder(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1853, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1729, in dataset_module_factory
    raise e1 from None
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1599, in dataset_module_factory
    dataset_readme_path = api.hf_hub_download(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 5467, in hf_hub_download
    return hf_hub_download(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1124, in _hf_hub_download_to_cache_dir
    os.makedirs(os.path.dirname(blob_path), exist_ok=True)
  File "/marlowe/apps/Mambaforge/24.3.0-0/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/marlowe/apps/Mambaforge/24.3.0-0/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
OSError: [Errno 122] Disk quota exceeded: '/projects/m000066/sujinesh/.cache/huggingface/hub/datasets--Rowan--hellaswag'
[2026-01-19 12:35:24] FAILED: fewshot_hellaswag (exit code: 1)
Failed: fewshot_hellaswag
[2026-01-19 12:35:24] [GPU 0] Few-shot (4-shot) on boolq
Started: fewshot_boolq
[2026-01-19 12:35:25] START: fewshot_boolq
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.74s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.67s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.12s/it]
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2464.34it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.65s/it]Device: cuda:0

======================================================================
FEW-SHOT BASELINE (4-shot): BOOLQ
======================================================================
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 1648, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 1592, in main
    results = run_fewshot_baseline(args, config, device)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 302, in run_fewshot_baseline
    train_ds = load_dataset(config["load_args"][0],
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 2132, in load_dataset
    builder_instance = load_dataset_builder(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1853, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1729, in dataset_module_factory
    raise e1 from None
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1599, in dataset_module_factory
    dataset_readme_path = api.hf_hub_download(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 5467, in hf_hub_download
    return hf_hub_download(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1124, in _hf_hub_download_to_cache_dir
    os.makedirs(os.path.dirname(blob_path), exist_ok=True)
  File "/marlowe/apps/Mambaforge/24.3.0-0/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/marlowe/apps/Mambaforge/24.3.0-0/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
OSError: [Errno 122] Disk quota exceeded: '/projects/m000066/sujinesh/.cache/huggingface/hub/datasets--google--boolq'
[2026-01-19 12:35:32] FAILED: fewshot_boolq (exit code: 1)
Failed: fewshot_boolq

[2026-01-19 12:35:32] [GPU 0] Running DoRA Baseline (rank=8) on ARC-Easy
Started: dora_arc_easy
[2026-01-19 12:35:32] START: dora_arc_easy
Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.64s/it]/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  3.54s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  3.57s/it]
Device: cuda:0

======================================================================
DORA BASELINE (rank=8): ARC_EASY
======================================================================

--- Seed 42 ---
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2351.51it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:06,  3.25s/it]Target embedding RMS: 0.0027

Training on 2251 samples
Validation: 2376 samples
Starting training...

ARC_EASY:   0%|                                                            | 0/1500 [00:00<?, ?it/s]ARC_EASY:   0%|                             | 0/1500 [00:01<?, ?it/s, lm=8.29, aux=0.000, gn=516.00]ARC_EASY:   0%|                     | 1/1500 [00:01<31:50,  1.27s/it, lm=8.29, aux=0.000, gn=516.00]ARC_EASY:   0%|                     | 1/1500 [00:01<31:50,  1.27s/it, lm=8.16, aux=0.000, gn=438.00]ARC_EASY:   0%|                     | 2/1500 [00:01<18:43,  1.33it/s, lm=8.16, aux=0.000, gn=438.00]ARC_EASY:   0%|                     | 2/1500 [00:02<18:43,  1.33it/s, lm=8.19, aux=0.000, gn=296.00]ARC_EASY:   0%|                     | 3/1500 [00:02<14:47,  1.69it/s, lm=8.19, aux=0.000, gn=296.00]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:06<00:03,  3.31s/it]ARC_EASY:   0%|                     | 3/1500 [00:02<14:47,  1.69it/s, lm=7.69, aux=0.000, gn=169.00]ARC_EASY:   0%|                     | 4/1500 [00:02<12:53,  1.93it/s, lm=7.69, aux=0.000, gn=169.00]ARC_EASY:   0%|                     | 4/1500 [00:02<12:53,  1.93it/s, lm=7.46, aux=0.000, gn=338.00]ARC_EASY:   0%|                     | 5/1500 [00:02<11:51,  2.10it/s, lm=7.46, aux=0.000, gn=338.00]ARC_EASY:   0%|                     | 5/1500 [00:03<11:51,  2.10it/s, lm=6.97, aux=0.000, gn=244.00]ARC_EASY:   0%|                     | 6/1500 [00:03<11:15,  2.21it/s, lm=6.97, aux=0.000, gn=244.00]ARC_EASY:   0%|                     | 6/1500 [00:03<11:15,  2.21it/s, lm=6.86, aux=0.000, gn=246.00]ARC_EASY:   0%|                     | 7/1500 [00:03<10:51,  2.29it/s, lm=6.86, aux=0.000, gn=246.00]ARC_EASY:   0%|                     | 7/1500 [00:04<10:51,  2.29it/s, lm=5.08, aux=0.000, gn=496.00]ARC_EASY:   1%|                     | 8/1500 [00:04<10:34,  2.35it/s, lm=5.08, aux=0.000, gn=496.00]ARC_EASY:   1%|                     | 8/1500 [00:04<10:34,  2.35it/s, lm=4.52, aux=0.000, gn=229.00]ARC_EASY:   1%|▏                    | 9/1500 [00:04<10:20,  2.40it/s, lm=4.52, aux=0.000, gn=229.00]ARC_EASY:   1%|▏                    | 9/1500 [00:04<10:20,  2.40it/s, lm=2.60, aux=0.000, gn=368.00]ARC_EASY:   1%|▏                   | 10/1500 [00:04<10:11,  2.44it/s, lm=2.60, aux=0.000, gn=368.00]ARC_EASY:   1%|▏                   | 10/1500 [00:05<10:11,  2.44it/s, lm=2.29, aux=0.000, gn=378.00]ARC_EASY:   1%|▏                   | 11/1500 [00:05<10:07,  2.45it/s, lm=2.29, aux=0.000, gn=378.00]ARC_EASY:   1%|▏                   | 11/1500 [00:05<10:07,  2.45it/s, lm=1.93, aux=0.000, gn=239.00]ARC_EASY:   1%|▏                   | 12/1500 [00:05<10:09,  2.44it/s, lm=1.93, aux=0.000, gn=239.00]ARC_EASY:   1%|▏                   | 12/1500 [00:06<10:09,  2.44it/s, lm=1.30, aux=0.000, gn=187.00]ARC_EASY:   1%|▏                   | 13/1500 [00:06<10:04,  2.46it/s, lm=1.30, aux=0.000, gn=187.00]ARC_EASY:   1%|▏                    | 13/1500 [00:06<10:04,  2.46it/s, lm=1.18, aux=0.000, gn=77.50]ARC_EASY:   1%|▏                    | 14/1500 [00:06<10:01,  2.47it/s, lm=1.18, aux=0.000, gn=77.50]Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  3.65s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:10<00:00,  3.56s/it]
ARC_EASY:   1%|▏                   | 14/1500 [00:06<10:01,  2.47it/s, lm=1.30, aux=0.000, gn=235.00]ARC_EASY:   1%|▏                   | 15/1500 [00:06<09:39,  2.56it/s, lm=1.30, aux=0.000, gn=235.00]ARC_EASY:   1%|▏                   | 15/1500 [00:07<09:39,  2.56it/s, lm=1.73, aux=0.000, gn=316.00]ARC_EASY:   1%|▏                   | 16/1500 [00:07<09:39,  2.56it/s, lm=1.73, aux=0.000, gn=316.00]ARC_EASY:   1%|▏                   | 16/1500 [00:07<09:39,  2.56it/s, lm=1.19, aux=0.000, gn=142.00]ARC_EASY:   1%|▏                   | 17/1500 [00:07<09:36,  2.57it/s, lm=1.19, aux=0.000, gn=142.00]Trainable parameters: 3,571,712
ARC_EASY:   1%|▏                    | 17/1500 [00:08<09:36,  2.57it/s, lm=1.37, aux=0.000, gn=29.75]ARC_EASY:   1%|▎                    | 18/1500 [00:08<09:36,  2.57it/s, lm=1.37, aux=0.000, gn=29.75]Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 1648, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 1596, in main
    results = run_dora_baseline(args, config, device)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 603, in run_dora_baseline
    label = config["label_map"][item[config["label_field"]]]
KeyError: 'E'
ARC_EASY:   1%|▎                    | 18/1500 [00:08<11:17,  2.19it/s, lm=1.37, aux=0.000, gn=29.75]
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1280, in main
    batch = next(iter_dl)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 398, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 207, in collate
    raise RuntimeError("each element in list of batch should be of equal size")
RuntimeError: each element in list of batch should be of equal size
[2026-01-19 12:35:55] FAILED: dora_arc_easy (exit code: 1)
Failed: dora_arc_easy

[2026-01-19 12:35:55] [GPU 0] Running Prompt Tuning Baseline (8 tokens) on ARC-Easy
Started: prompt_tuning_arc_easy
[2026-01-19 12:35:56] START: prompt_tuning_arc_easy
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(

[ERROR] Training interrupted by exception at step 19
[ERROR] RuntimeError: each element in list of batch should be of equal size

[EMERGENCY] Checkpoint saved to runs/reasoning_final_20260119_122501/novel_bridges/token_capacity_32_seed42/emergency_checkpoint_step18.pt
[EMERGENCY] Error: RuntimeError: each element in list of batch should be of equal size
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1530, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1280, in main
    batch = next(iter_dl)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 398, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 171, in collate
    {
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 172, in <dictcomp>
    key: collate(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 207, in collate
    raise RuntimeError("each element in list of batch should be of equal size")
RuntimeError: each element in list of batch should be of equal size
[2026-01-19 12:36:03] FAILED: token_capacity_32_seed42 (exit code: 1)
Failed: token_capacity_32_seed42

[2026-01-19 12:36:03] [GPU 1] Running Ridge Regression Baseline on ARC-Easy
Started: ridge_regression_arc_easy
[2026-01-19 12:36:03] START: ridge_regression_arc_easy
Device: cuda:0

======================================================================
PROMPT TUNING BASELINE (8 tokens): ARC_EASY
======================================================================
This proves whether Llama (sender) actually helps.

--- Seed 42 ---
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 597.65it/s]
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:06,  3.42s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:05<00:02,  2.66s/it]Device: cuda:1

======================================================================
RIDGE REGRESSION BASELINE: ARC_EASY
======================================================================
Testing linear alignment from Llama hidden states to Mistral embeddings
Lambda values to test: [0.1, 1.0, 10.0, 100.0]

Loading Llama (source) model...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2173.21it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  3.10s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  3.06s/it]
Training:   0%|          | 0/1500 [00:00<?, ?it/s]Training:   0%|          | 0/1500 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 1648, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 1598, in main
    results = run_prompt_tuning_baseline(args, config, device)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 951, in run_prompt_tuning_baseline
    label_texts = [config["label_map"][l] for l in batch[config["label_field"]].tolist()]
AttributeError: 'list' object has no attribute 'tolist'
Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:12,  4.05s/it][2026-01-19 12:36:17] FAILED: prompt_tuning_arc_easy (exit code: 1)
Failed: prompt_tuning_arc_easy

[2026-01-19 12:36:17] [GPU 0] Running Linear Probe Baseline (layer 31)
Started: linear_probe
[2026-01-19 12:36:17] START: linear_probe
Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.93s/it]/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.72s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.66s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.10s/it]
================================================================================
LINEAR PROBE BASELINE BENCHMARK
================================================================================
Model: meta-llama/Meta-Llama-3.1-8B-Instruct
Datasets: ['arc_easy', 'winogrande', 'hellaswag', 'boolq']
Layers: [31]
Pooling: last_token
Seeds: [42, 123, 456]
Output: runs/reasoning_final_20260119_122501/baselines/linear_probe
================================================================================

Loading Llama model...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2737.80it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading Mistral (target) model...
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2785.68it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:12,  4.22s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.89s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.10s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.91s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.02s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.77s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.80s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.81s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.28s/it]
Target embedding RMS: 0.0027

--- Collecting alignment data from 1000 samples ---
Collecting alignment pairs:   0%|          | 0/1000 [00:00<?, ?it/s]Collecting alignment pairs:   0%|          | 1/1000 [00:00<04:28,  3.72it/s]Collecting alignment pairs:   0%|          | 5/1000 [00:00<01:01, 16.20it/s]Collecting alignment pairs:   1%|          | 11/1000 [00:00<00:34, 28.84it/s]Collecting alignment pairs:   2%|▏         | 16/1000 [00:00<00:28, 34.73it/s]Collecting alignment pairs:   2%|▏         | 21/1000 [00:00<00:24, 39.17it/s]Collecting alignment pairs:   3%|▎         | 26/1000 [00:00<00:23, 41.90it/s]Collecting alignment pairs:   3%|▎         | 31/1000 [00:00<00:21, 44.28it/s]Collecting alignment pairs:   4%|▎         | 37/1000 [00:01<00:20, 46.59it/s]Collecting alignment pairs:   4%|▍         | 42/1000 [00:01<00:20, 46.51it/s]Collecting alignment pairs:   5%|▍         | 47/1000 [00:01<00:20, 46.51it/s]Collecting alignment pairs:   5%|▌         | 53/1000 [00:01<00:19, 47.81it/s]Collecting alignment pairs:   6%|▌         | 59/1000 [00:01<00:19, 48.83it/s]Collecting alignment pairs:   6%|▋         | 64/1000 [00:01<00:22, 41.79it/s]Collecting alignment pairs:   7%|▋         | 69/1000 [00:01<00:24, 37.69it/s]Collecting alignment pairs:   7%|▋         | 74/1000 [00:01<00:22, 40.39it/s]Collecting alignment pairs:   8%|▊         | 80/1000 [00:02<00:21, 43.41it/s]Collecting alignment pairs:   8%|▊         | 85/1000 [00:02<00:20, 44.51it/s]Collecting alignment pairs:   9%|▉         | 91/1000 [00:02<00:19, 46.03it/s]Collecting alignment pairs:  10%|▉         | 97/1000 [00:02<00:19, 46.89it/s]Collecting alignment pairs:  10%|█         | 102/1000 [00:02<00:24, 36.62it/s]Model loaded: 4096 hidden dim, 32 layers


################################################################################
# DATASET: arc_easy
################################################################################

--- Seed 42 ---

================================================================================
Dataset: arc_easy (4 classes)
================================================================================
Loading arc_easy data...
Train: 2251 samples, Test: 1000 samples

--- Layer 31 ---
  Extracting train features...
Extracting layer 31:   0%|          | 0/282 [00:00<?, ?it/s]Collecting alignment pairs:  11%|█         | 107/1000 [00:02<00:26, 33.54it/s]Collecting alignment pairs:  11%|█         | 111/1000 [00:02<00:28, 30.76it/s]Extracting layer 31:   0%|          | 1/282 [00:00<02:12,  2.13it/s]Collecting alignment pairs:  12%|█▏        | 115/1000 [00:03<00:30, 28.96it/s]Extracting layer 31:   1%|          | 3/282 [00:00<00:45,  6.11it/s]Collecting alignment pairs:  12%|█▏        | 119/1000 [00:03<00:30, 28.52it/s]Extracting layer 31:   2%|▏         | 6/282 [00:00<00:23, 11.92it/s]Collecting alignment pairs:  12%|█▏        | 122/1000 [00:03<00:32, 27.19it/s]Extracting layer 31:   3%|▎         | 9/282 [00:00<00:16, 16.47it/s]Collecting alignment pairs:  12%|█▎        | 125/1000 [00:03<00:34, 25.14it/s]Extracting layer 31:   4%|▍         | 12/282 [00:00<00:14, 18.10it/s]Collecting alignment pairs:  13%|█▎        | 128/1000 [00:03<00:36, 23.71it/s]Extracting layer 31:   6%|▌         | 16/282 [00:01<00:12, 22.13it/s]Extracting layer 31:   7%|▋         | 20/282 [00:01<00:10, 24.51it/s]Collecting alignment pairs:  13%|█▎        | 131/1000 [00:03<00:38, 22.45it/s]Extracting layer 31:   8%|▊         | 23/282 [00:01<00:10, 25.05it/s]Collecting alignment pairs:  13%|█▎        | 134/1000 [00:03<00:38, 22.44it/s]Extracting layer 31:   9%|▉         | 26/282 [00:01<00:10, 24.80it/s]Collecting alignment pairs:  14%|█▍        | 138/1000 [00:04<00:38, 22.12it/s]Extracting layer 31:  10%|█         | 29/282 [00:01<00:09, 25.86it/s]Collecting alignment pairs:  14%|█▍        | 141/1000 [00:04<00:38, 22.27it/s]Extracting layer 31:  12%|█▏        | 33/282 [00:01<00:09, 27.58it/s]Collecting alignment pairs:  14%|█▍        | 144/1000 [00:04<00:36, 23.38it/s]Extracting layer 31:  13%|█▎        | 37/282 [00:01<00:08, 28.59it/s]Collecting alignment pairs:  15%|█▍        | 147/1000 [00:04<00:37, 23.03it/s]Extracting layer 31:  15%|█▍        | 41/282 [00:01<00:07, 30.36it/s]Extracting layer 31:  16%|█▌        | 45/282 [00:02<00:08, 29.55it/s]Collecting alignment pairs:  15%|█▌        | 150/1000 [00:04<00:40, 20.90it/s]Extracting layer 31:  17%|█▋        | 49/282 [00:02<00:07, 30.06it/s]Collecting alignment pairs:  15%|█▌        | 153/1000 [00:04<00:38, 21.72it/s]Extracting layer 31:  19%|█▉        | 53/282 [00:02<00:07, 30.13it/s]Collecting alignment pairs:  16%|█▌        | 156/1000 [00:04<00:38, 21.81it/s]Extracting layer 31:  20%|██        | 57/282 [00:02<00:07, 30.24it/s]Collecting alignment pairs:  16%|█▌        | 159/1000 [00:05<00:37, 22.63it/s]Collecting alignment pairs:  16%|█▌        | 162/1000 [00:05<00:35, 23.46it/s]Extracting layer 31:  22%|██▏       | 61/282 [00:02<00:07, 30.42it/s]Extracting layer 31:  23%|██▎       | 65/282 [00:02<00:06, 31.02it/s]Collecting alignment pairs:  16%|█▋        | 165/1000 [00:05<00:37, 22.53it/s]Extracting layer 31:  24%|██▍       | 69/282 [00:02<00:07, 30.24it/s]Collecting alignment pairs:  17%|█▋        | 168/1000 [00:05<00:37, 22.48it/s]Extracting layer 31:  26%|██▌       | 73/282 [00:02<00:06, 30.10it/s]Collecting alignment pairs:  17%|█▋        | 171/1000 [00:05<00:36, 22.52it/s]Extracting layer 31:  27%|██▋       | 77/282 [00:03<00:06, 30.32it/s]Collecting alignment pairs:  17%|█▋        | 174/1000 [00:05<00:36, 22.49it/s]Extracting layer 31:  29%|██▊       | 81/282 [00:03<00:06, 31.28it/s]Collecting alignment pairs:  18%|█▊        | 177/1000 [00:05<00:37, 21.85it/s]Extracting layer 31:  30%|███       | 85/282 [00:03<00:06, 30.31it/s]Collecting alignment pairs:  18%|█▊        | 180/1000 [00:05<00:35, 22.89it/s]Extracting layer 31:  32%|███▏      | 89/282 [00:03<00:06, 31.06it/s]Collecting alignment pairs:  18%|█▊        | 183/1000 [00:06<00:35, 23.23it/s]Extracting layer 31:  33%|███▎      | 93/282 [00:03<00:06, 30.15it/s]Collecting alignment pairs:  19%|█▊        | 186/1000 [00:06<00:34, 23.38it/s]Collecting alignment pairs:  19%|█▉        | 189/1000 [00:06<00:34, 23.33it/s]Extracting layer 31:  34%|███▍      | 97/282 [00:03<00:06, 29.71it/s]Extracting layer 31:  36%|███▌      | 101/282 [00:03<00:05, 30.59it/s]Collecting alignment pairs:  19%|█▉        | 192/1000 [00:06<00:35, 22.86it/s]Collecting alignment pairs:  20%|█▉        | 195/1000 [00:06<00:34, 23.04it/s]Extracting layer 31:  37%|███▋      | 105/282 [00:04<00:06, 29.36it/s]Extracting layer 31:  38%|███▊      | 108/282 [00:04<00:06, 28.23it/s]Collecting alignment pairs:  20%|█▉        | 198/1000 [00:06<00:35, 22.35it/s]Extracting layer 31:  40%|███▉      | 112/282 [00:04<00:05, 29.12it/s]Collecting alignment pairs:  20%|██        | 201/1000 [00:06<00:35, 22.45it/s]Extracting layer 31:  41%|████      | 115/282 [00:04<00:05, 29.34it/s]Collecting alignment pairs:  20%|██        | 204/1000 [00:07<00:34, 22.77it/s]Extracting layer 31:  42%|████▏     | 118/282 [00:04<00:05, 28.61it/s]Collecting alignment pairs:  21%|██        | 207/1000 [00:07<00:35, 22.13it/s]Extracting layer 31:  43%|████▎     | 122/282 [00:04<00:05, 29.82it/s]Collecting alignment pairs:  21%|██        | 210/1000 [00:07<00:34, 22.71it/s]Extracting layer 31:  44%|████▍     | 125/282 [00:04<00:05, 27.21it/s]Collecting alignment pairs:  21%|██▏       | 213/1000 [00:07<00:34, 22.71it/s]Extracting layer 31:  45%|████▌     | 128/282 [00:04<00:05, 27.36it/s]Collecting alignment pairs:  22%|██▏       | 216/1000 [00:07<00:34, 22.42it/s]Extracting layer 31:  46%|████▋     | 131/282 [00:04<00:05, 27.39it/s]Extracting layer 31:  48%|████▊     | 134/282 [00:05<00:05, 27.73it/s]Collecting alignment pairs:  22%|██▏       | 219/1000 [00:07<00:34, 22.73it/s]Extracting layer 31:  49%|████▉     | 138/282 [00:05<00:04, 29.03it/s]Collecting alignment pairs:  22%|██▏       | 222/1000 [00:07<00:34, 22.77it/s]Extracting layer 31:  50%|█████     | 142/282 [00:05<00:04, 30.27it/s]Collecting alignment pairs:  22%|██▎       | 225/1000 [00:07<00:34, 22.31it/s]Extracting layer 31:  52%|█████▏    | 146/282 [00:05<00:04, 29.21it/s]Collecting alignment pairs:  23%|██▎       | 228/1000 [00:08<00:35, 21.64it/s]Extracting layer 31:  53%|█████▎    | 149/282 [00:05<00:04, 28.26it/s]Collecting alignment pairs:  23%|██▎       | 231/1000 [00:08<00:34, 22.06it/s]Extracting layer 31:  54%|█████▍    | 152/282 [00:05<00:04, 28.13it/s]Collecting alignment pairs:  23%|██▎       | 234/1000 [00:08<00:33, 22.76it/s]Extracting layer 31:  55%|█████▌    | 156/282 [00:05<00:04, 29.39it/s]Collecting alignment pairs:  24%|██▎       | 237/1000 [00:08<00:33, 23.01it/s]Extracting layer 31:  57%|█████▋    | 160/282 [00:05<00:04, 29.10it/s]Collecting alignment pairs:  24%|██▍       | 240/1000 [00:08<00:34, 22.15it/s]Extracting layer 31:  58%|█████▊    | 164/282 [00:06<00:03, 29.51it/s]Collecting alignment pairs:  24%|██▍       | 243/1000 [00:08<00:33, 22.65it/s]Extracting layer 31:  60%|█████▉    | 168/282 [00:06<00:03, 30.03it/s]Collecting alignment pairs:  25%|██▍       | 246/1000 [00:08<00:33, 22.83it/s]Extracting layer 31:  61%|██████    | 172/282 [00:06<00:03, 28.03it/s]Collecting alignment pairs:  25%|██▍       | 249/1000 [00:09<00:33, 22.62it/s]Extracting layer 31:  62%|██████▏   | 175/282 [00:06<00:03, 27.46it/s]Collecting alignment pairs:  25%|██▌       | 252/1000 [00:09<00:33, 22.34it/s]Extracting layer 31:  63%|██████▎   | 178/282 [00:06<00:03, 27.54it/s]Collecting alignment pairs:  26%|██▌       | 255/1000 [00:09<00:34, 21.51it/s]Extracting layer 31:  65%|██████▍   | 182/282 [00:06<00:03, 28.41it/s]Extracting layer 31:  66%|██████▌   | 185/282 [00:06<00:03, 28.81it/s]Collecting alignment pairs:  26%|██▌       | 258/1000 [00:09<00:33, 21.96it/s]Extracting layer 31:  67%|██████▋   | 189/282 [00:06<00:03, 28.46it/s]Collecting alignment pairs:  26%|██▌       | 261/1000 [00:09<00:34, 21.25it/s]Extracting layer 31:  68%|██████▊   | 192/282 [00:07<00:03, 28.31it/s]Collecting alignment pairs:  26%|██▋       | 264/1000 [00:09<00:33, 21.78it/s]Extracting layer 31:  69%|██████▉   | 195/282 [00:07<00:03, 27.93it/s]Collecting alignment pairs:  27%|██▋       | 267/1000 [00:09<00:34, 21.54it/s]Extracting layer 31:  71%|███████   | 199/282 [00:07<00:02, 28.92it/s]Collecting alignment pairs:  27%|██▋       | 270/1000 [00:10<00:34, 21.45it/s]Extracting layer 31:  72%|███████▏  | 203/282 [00:07<00:02, 29.62it/s]Collecting alignment pairs:  27%|██▋       | 273/1000 [00:10<00:33, 21.81it/s]Extracting layer 31:  73%|███████▎  | 207/282 [00:07<00:02, 30.27it/s]Collecting alignment pairs:  28%|██▊       | 276/1000 [00:10<00:31, 22.63it/s]Extracting layer 31:  75%|███████▍  | 211/282 [00:07<00:02, 31.01it/s]Extracting layer 31:  76%|███████▌  | 215/282 [00:07<00:02, 30.73it/s]Collecting alignment pairs:  28%|██▊       | 279/1000 [00:10<00:34, 20.79it/s]Collecting alignment pairs:  28%|██▊       | 282/1000 [00:10<00:33, 21.53it/s]Extracting layer 31:  78%|███████▊  | 219/282 [00:07<00:02, 29.54it/s]Collecting alignment pairs:  28%|██▊       | 285/1000 [00:10<00:31, 22.56it/s]Extracting layer 31:  79%|███████▊  | 222/282 [00:08<00:02, 29.27it/s]Extracting layer 31:  80%|███████▉  | 225/282 [00:08<00:02, 28.39it/s]Collecting alignment pairs:  29%|██▉       | 288/1000 [00:10<00:32, 22.24it/s]Extracting layer 31:  81%|████████  | 228/282 [00:08<00:01, 28.31it/s]Collecting alignment pairs:  29%|██▉       | 291/1000 [00:10<00:31, 22.38it/s]Extracting layer 31:  82%|████████▏ | 231/282 [00:08<00:01, 28.07it/s]Collecting alignment pairs:  29%|██▉       | 294/1000 [00:11<00:32, 21.88it/s]Extracting layer 31:  83%|████████▎ | 235/282 [00:08<00:01, 27.70it/s]Collecting alignment pairs:  30%|██▉       | 297/1000 [00:11<00:30, 23.04it/s]Extracting layer 31:  85%|████████▍ | 239/282 [00:08<00:01, 29.34it/s]Collecting alignment pairs:  30%|███       | 300/1000 [00:11<00:30, 22.91it/s]Extracting layer 31:  86%|████████▌ | 242/282 [00:08<00:01, 28.92it/s]Collecting alignment pairs:  30%|███       | 303/1000 [00:11<00:29, 23.32it/s]Extracting layer 31:  87%|████████▋ | 246/282 [00:08<00:01, 29.95it/s]Collecting alignment pairs:  31%|███       | 306/1000 [00:11<00:29, 23.84it/s]Extracting layer 31:  88%|████████▊ | 249/282 [00:09<00:01, 28.47it/s]Collecting alignment pairs:  31%|███       | 309/1000 [00:11<00:29, 23.35it/s]Extracting layer 31:  90%|████████▉ | 253/282 [00:09<00:01, 28.94it/s]Collecting alignment pairs:  31%|███       | 312/1000 [00:11<00:30, 22.46it/s]Extracting layer 31:  91%|█████████ | 257/282 [00:09<00:00, 30.05it/s]Collecting alignment pairs:  32%|███▏      | 315/1000 [00:12<00:30, 22.53it/s]Extracting layer 31:  93%|█████████▎| 261/282 [00:09<00:00, 28.51it/s]Collecting alignment pairs:  32%|███▏      | 318/1000 [00:12<00:29, 23.11it/s]Extracting layer 31:  94%|█████████▎| 264/282 [00:09<00:00, 28.85it/s]Extracting layer 31:  95%|█████████▍| 267/282 [00:09<00:00, 28.98it/s]Collecting alignment pairs:  32%|███▏      | 321/1000 [00:12<00:29, 23.00it/s]Extracting layer 31:  96%|█████████▌| 270/282 [00:09<00:00, 28.81it/s]Collecting alignment pairs:  32%|███▏      | 324/1000 [00:12<00:28, 23.86it/s]Extracting layer 31:  97%|█████████▋| 273/282 [00:09<00:00, 28.75it/s]Collecting alignment pairs:  33%|███▎      | 327/1000 [00:12<00:30, 22.29it/s]Extracting layer 31:  98%|█████████▊| 276/282 [00:09<00:00, 28.43it/s]Collecting alignment pairs:  33%|███▎      | 330/1000 [00:12<00:29, 22.57it/s]Extracting layer 31:  99%|█████████▉| 280/282 [00:10<00:00, 29.49it/s]Extracting layer 31: 100%|██████████| 282/282 [00:10<00:00, 27.74it/s]
Collecting alignment pairs:  33%|███▎      | 333/1000 [00:12<00:30, 22.01it/s]  Extracting test features...
Extracting layer 31:   0%|          | 0/125 [00:00<?, ?it/s]Collecting alignment pairs:  34%|███▎      | 336/1000 [00:12<00:28, 23.01it/s]Extracting layer 31:   2%|▏         | 3/125 [00:00<00:04, 29.65it/s]Collecting alignment pairs:  34%|███▍      | 339/1000 [00:13<00:27, 23.67it/s]Extracting layer 31:   5%|▍         | 6/125 [00:00<00:04, 26.96it/s]Extracting layer 31:   7%|▋         | 9/125 [00:00<00:04, 27.62it/s]Collecting alignment pairs:  34%|███▍      | 342/1000 [00:13<00:30, 21.52it/s]Extracting layer 31:  10%|█         | 13/125 [00:00<00:03, 28.06it/s]Collecting alignment pairs:  34%|███▍      | 345/1000 [00:13<00:29, 22.40it/s]Extracting layer 31:  14%|█▎        | 17/125 [00:00<00:03, 29.25it/s]Collecting alignment pairs:  35%|███▍      | 348/1000 [00:13<00:29, 22.05it/s]Extracting layer 31:  16%|█▌        | 20/125 [00:00<00:03, 28.55it/s]Collecting alignment pairs:  35%|███▌      | 351/1000 [00:13<00:27, 23.68it/s]Extracting layer 31:  18%|█▊        | 23/125 [00:00<00:03, 28.56it/s]Collecting alignment pairs:  35%|███▌      | 354/1000 [00:13<00:28, 22.92it/s]Extracting layer 31:  21%|██        | 26/125 [00:00<00:03, 28.97it/s]Collecting alignment pairs:  36%|███▌      | 357/1000 [00:13<00:27, 22.97it/s]Extracting layer 31:  24%|██▍       | 30/125 [00:01<00:03, 29.44it/s]Collecting alignment pairs:  36%|███▌      | 360/1000 [00:13<00:28, 22.80it/s]Extracting layer 31:  27%|██▋       | 34/125 [00:01<00:03, 29.73it/s]Collecting alignment pairs:  36%|███▋      | 363/1000 [00:14<00:26, 23.86it/s]Extracting layer 31:  30%|██▉       | 37/125 [00:01<00:03, 28.01it/s]Collecting alignment pairs:  37%|███▋      | 366/1000 [00:14<00:27, 23.44it/s]Extracting layer 31:  32%|███▏      | 40/125 [00:01<00:03, 27.92it/s]Extracting layer 31:  34%|███▍      | 43/125 [00:01<00:03, 27.05it/s]Collecting alignment pairs:  37%|███▋      | 369/1000 [00:14<00:27, 22.75it/s]Extracting layer 31:  38%|███▊      | 47/125 [00:01<00:02, 28.11it/s]Collecting alignment pairs:  37%|███▋      | 372/1000 [00:14<00:27, 22.50it/s]Extracting layer 31:  40%|████      | 50/125 [00:01<00:02, 28.10it/s]Collecting alignment pairs:  38%|███▊      | 375/1000 [00:14<00:27, 23.00it/s]Extracting layer 31:  42%|████▏     | 53/125 [00:01<00:02, 27.08it/s]Collecting alignment pairs:  38%|███▊      | 378/1000 [00:14<00:27, 22.94it/s]Extracting layer 31:  46%|████▌     | 57/125 [00:02<00:02, 28.97it/s]Collecting alignment pairs:  38%|███▊      | 381/1000 [00:14<00:27, 22.79it/s]Extracting layer 31:  48%|████▊     | 60/125 [00:02<00:02, 28.82it/s]Collecting alignment pairs:  38%|███▊      | 384/1000 [00:15<00:27, 22.43it/s]Extracting layer 31:  51%|█████     | 64/125 [00:02<00:02, 29.27it/s]Collecting alignment pairs:  39%|███▊      | 387/1000 [00:15<00:26, 23.45it/s]Extracting layer 31:  54%|█████▍    | 68/125 [00:02<00:01, 30.23it/s]Collecting alignment pairs:  39%|███▉      | 390/1000 [00:15<00:26, 22.79it/s]Extracting layer 31:  58%|█████▊    | 72/125 [00:02<00:01, 30.36it/s]Collecting alignment pairs:  39%|███▉      | 393/1000 [00:15<00:27, 22.12it/s]Extracting layer 31:  61%|██████    | 76/125 [00:02<00:01, 30.63it/s]Collecting alignment pairs:  40%|███▉      | 396/1000 [00:15<00:26, 22.79it/s]Extracting layer 31:  64%|██████▍   | 80/125 [00:02<00:01, 31.26it/s]Collecting alignment pairs:  40%|███▉      | 399/1000 [00:15<00:26, 22.89it/s]Extracting layer 31:  67%|██████▋   | 84/125 [00:02<00:01, 31.11it/s]Collecting alignment pairs:  40%|████      | 402/1000 [00:15<00:25, 23.07it/s]Extracting layer 31:  70%|███████   | 88/125 [00:03<00:01, 31.16it/s]Collecting alignment pairs:  40%|████      | 405/1000 [00:15<00:25, 23.16it/s]Extracting layer 31:  74%|███████▎  | 92/125 [00:03<00:01, 31.74it/s]Collecting alignment pairs:  41%|████      | 408/1000 [00:16<00:24, 23.71it/s]Extracting layer 31:  77%|███████▋  | 96/125 [00:03<00:00, 30.47it/s]Collecting alignment pairs:  41%|████      | 411/1000 [00:16<00:25, 22.97it/s]Extracting layer 31:  80%|████████  | 100/125 [00:03<00:00, 30.99it/s]Collecting alignment pairs:  41%|████▏     | 414/1000 [00:16<00:24, 24.14it/s]Extracting layer 31:  83%|████████▎ | 104/125 [00:03<00:00, 31.46it/s]Collecting alignment pairs:  42%|████▏     | 417/1000 [00:16<00:24, 23.83it/s]Extracting layer 31:  86%|████████▋ | 108/125 [00:03<00:00, 31.01it/s]Collecting alignment pairs:  42%|████▏     | 420/1000 [00:16<00:25, 22.55it/s]Extracting layer 31:  90%|████████▉ | 112/125 [00:03<00:00, 29.23it/s]Extracting layer 31:  92%|█████████▏| 115/125 [00:03<00:00, 28.01it/s]Collecting alignment pairs:  42%|████▏     | 423/1000 [00:16<00:27, 20.95it/s]Extracting layer 31:  94%|█████████▍| 118/125 [00:04<00:00, 27.43it/s]Collecting alignment pairs:  43%|████▎     | 426/1000 [00:16<00:26, 21.78it/s]Extracting layer 31:  97%|█████████▋| 121/125 [00:04<00:00, 26.73it/s]Collecting alignment pairs:  43%|████▎     | 429/1000 [00:17<00:25, 22.68it/s]Extracting layer 31:  99%|█████████▉| 124/125 [00:04<00:00, 26.90it/s]Extracting layer 31: 100%|██████████| 125/125 [00:04<00:00, 29.05it/s]
Collecting alignment pairs:  43%|████▎     | 432/1000 [00:17<00:25, 22.35it/s]Collecting alignment pairs:  44%|████▎     | 435/1000 [00:17<00:23, 23.75it/s]/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.
  warnings.warn(
Collecting alignment pairs:  44%|████▍     | 438/1000 [00:17<00:24, 23.06it/s]/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
Collecting alignment pairs:  44%|████▍     | 441/1000 [00:17<00:24, 23.23it/s]Collecting alignment pairs:  44%|████▍     | 444/1000 [00:17<00:23, 23.85it/s]Collecting alignment pairs:  45%|████▍     | 447/1000 [00:17<00:23, 23.69it/s]Collecting alignment pairs:  45%|████▌     | 450/1000 [00:17<00:23, 23.62it/s]Collecting alignment pairs:  45%|████▌     | 453/1000 [00:18<00:23, 23.53it/s]Collecting alignment pairs:  46%|████▌     | 456/1000 [00:18<00:21, 25.04it/s]Collecting alignment pairs:  46%|████▌     | 459/1000 [00:18<00:22, 24.58it/s]Collecting alignment pairs:  46%|████▌     | 462/1000 [00:18<00:21, 24.61it/s]Collecting alignment pairs:  46%|████▋     | 465/1000 [00:18<00:22, 24.18it/s]Collecting alignment pairs:  47%|████▋     | 468/1000 [00:18<00:22, 24.16it/s]Collecting alignment pairs:  47%|████▋     | 471/1000 [00:18<00:21, 25.00it/s]Collecting alignment pairs:  47%|████▋     | 474/1000 [00:18<00:22, 23.74it/s]Collecting alignment pairs:  48%|████▊     | 477/1000 [00:18<00:21, 24.71it/s]Collecting alignment pairs:  48%|████▊     | 480/1000 [00:19<00:22, 23.56it/s]Collecting alignment pairs:  48%|████▊     | 483/1000 [00:19<00:21, 24.14it/s]Collecting alignment pairs:  49%|████▊     | 486/1000 [00:19<00:20, 24.93it/s]Collecting alignment pairs:  49%|████▉     | 489/1000 [00:19<00:21, 24.00it/s]Collecting alignment pairs:  49%|████▉     | 492/1000 [00:19<00:20, 24.55it/s]Collecting alignment pairs:  50%|████▉     | 495/1000 [00:19<00:20, 24.30it/s]Collecting alignment pairs:  50%|████▉     | 498/1000 [00:19<00:21, 23.55it/s]Collecting alignment pairs:  50%|█████     | 501/1000 [00:20<00:21, 23.59it/s]Collecting alignment pairs:  50%|█████     | 504/1000 [00:20<00:21, 23.60it/s]Collecting alignment pairs:  51%|█████     | 507/1000 [00:20<00:20, 24.32it/s]Collecting alignment pairs:  51%|█████     | 510/1000 [00:20<00:20, 23.85it/s]Collecting alignment pairs:  51%|█████▏    | 513/1000 [00:20<00:20, 23.85it/s]Collecting alignment pairs:  52%|█████▏    | 516/1000 [00:20<00:19, 24.62it/s]Collecting alignment pairs:  52%|█████▏    | 519/1000 [00:20<00:19, 24.14it/s]Collecting alignment pairs:  52%|█████▏    | 522/1000 [00:20<00:19, 24.62it/s]Collecting alignment pairs:  52%|█████▎    | 525/1000 [00:20<00:20, 23.69it/s]Collecting alignment pairs:  53%|█████▎    | 528/1000 [00:21<00:19, 24.15it/s]Collecting alignment pairs:  53%|█████▎    | 531/1000 [00:21<00:19, 24.16it/s]Collecting alignment pairs:  53%|█████▎    | 534/1000 [00:21<00:19, 23.94it/s]Collecting alignment pairs:  54%|█████▎    | 537/1000 [00:21<00:18, 24.53it/s]Collecting alignment pairs:  54%|█████▍    | 540/1000 [00:21<00:19, 23.98it/s]Collecting alignment pairs:  54%|█████▍    | 543/1000 [00:21<00:18, 24.94it/s]Collecting alignment pairs:  55%|█████▍    | 546/1000 [00:21<00:18, 24.94it/s]Collecting alignment pairs:  55%|█████▍    | 549/1000 [00:21<00:18, 24.96it/s]/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
Collecting alignment pairs:  55%|█████▌    | 552/1000 [00:22<00:18, 23.96it/s]Collecting alignment pairs:  56%|█████▌    | 555/1000 [00:22<00:18, 23.92it/s]Collecting alignment pairs:  56%|█████▌    | 558/1000 [00:22<00:18, 24.22it/s]Collecting alignment pairs:  56%|█████▌    | 561/1000 [00:22<00:17, 24.85it/s]Collecting alignment pairs:  56%|█████▋    | 564/1000 [00:22<00:17, 25.01it/s]Collecting alignment pairs:  57%|█████▋    | 567/1000 [00:22<00:18, 23.83it/s]Collecting alignment pairs:  57%|█████▋    | 570/1000 [00:22<00:18, 23.82it/s]Collecting alignment pairs:  57%|█████▋    | 573/1000 [00:22<00:17, 23.99it/s]Collecting alignment pairs:  58%|█████▊    | 576/1000 [00:23<00:16, 25.49it/s]Collecting alignment pairs:  58%|█████▊    | 579/1000 [00:23<00:17, 24.39it/s]Collecting alignment pairs:  58%|█████▊    | 582/1000 [00:23<00:17, 24.40it/s]Collecting alignment pairs:  58%|█████▊    | 585/1000 [00:23<00:17, 24.12it/s]Collecting alignment pairs:  59%|█████▉    | 588/1000 [00:23<00:16, 24.83it/s]Collecting alignment pairs:  59%|█████▉    | 591/1000 [00:23<00:17, 23.18it/s]Collecting alignment pairs:  59%|█████▉    | 594/1000 [00:23<00:18, 22.11it/s]Collecting alignment pairs:  60%|█████▉    | 597/1000 [00:24<00:18, 21.95it/s]Collecting alignment pairs:  60%|██████    | 601/1000 [00:24<00:17, 23.42it/s]Collecting alignment pairs:  60%|██████    | 604/1000 [00:24<00:16, 24.22it/s]Collecting alignment pairs:  61%|██████    | 607/1000 [00:24<00:16, 23.44it/s]Collecting alignment pairs:  61%|██████    | 610/1000 [00:24<00:16, 23.89it/s]Collecting alignment pairs:  61%|██████▏   | 613/1000 [00:24<00:16, 24.08it/s]Collecting alignment pairs:  62%|██████▏   | 616/1000 [00:24<00:15, 24.51it/s]Collecting alignment pairs:  62%|██████▏   | 619/1000 [00:24<00:15, 24.45it/s]Collecting alignment pairs:  62%|██████▏   | 622/1000 [00:25<00:15, 24.50it/s]Collecting alignment pairs:  62%|██████▎   | 625/1000 [00:25<00:14, 25.35it/s]Collecting alignment pairs:  63%|██████▎   | 628/1000 [00:25<00:15, 24.45it/s]Collecting alignment pairs:  63%|██████▎   | 631/1000 [00:25<00:14, 25.05it/s]Collecting alignment pairs:  63%|██████▎   | 634/1000 [00:25<00:14, 25.07it/s]Collecting alignment pairs:  64%|██████▎   | 637/1000 [00:25<00:14, 24.81it/s]Collecting alignment pairs:  64%|██████▍   | 640/1000 [00:25<00:14, 24.62it/s]Collecting alignment pairs:  64%|██████▍   | 643/1000 [00:25<00:14, 24.73it/s]Collecting alignment pairs:  65%|██████▍   | 646/1000 [00:25<00:14, 24.10it/s]Collecting alignment pairs:  65%|██████▍   | 649/1000 [00:26<00:14, 23.85it/s]Collecting alignment pairs:  65%|██████▌   | 652/1000 [00:26<00:14, 24.85it/s]/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
Collecting alignment pairs:  66%|██████▌   | 655/1000 [00:26<00:13, 24.67it/s]Collecting alignment pairs:  66%|██████▌   | 658/1000 [00:26<00:13, 25.49it/s]Collecting alignment pairs:  66%|██████▌   | 661/1000 [00:26<00:14, 24.15it/s]Collecting alignment pairs:  66%|██████▋   | 664/1000 [00:26<00:13, 24.35it/s]Collecting alignment pairs:  67%|██████▋   | 667/1000 [00:26<00:13, 24.99it/s]Collecting alignment pairs:  67%|██████▋   | 670/1000 [00:26<00:12, 25.62it/s]Collecting alignment pairs:  67%|██████▋   | 673/1000 [00:27<00:13, 24.11it/s]Collecting alignment pairs:  68%|██████▊   | 676/1000 [00:27<00:13, 24.68it/s]Collecting alignment pairs:  68%|██████▊   | 679/1000 [00:27<00:13, 24.61it/s]Collecting alignment pairs:  68%|██████▊   | 682/1000 [00:27<00:12, 25.59it/s]Collecting alignment pairs:  68%|██████▊   | 685/1000 [00:27<00:13, 24.20it/s]Collecting alignment pairs:  69%|██████▉   | 688/1000 [00:27<00:12, 24.34it/s]Collecting alignment pairs:  69%|██████▉   | 691/1000 [00:27<00:12, 25.23it/s]Collecting alignment pairs:  69%|██████▉   | 694/1000 [00:27<00:12, 24.29it/s]Collecting alignment pairs:  70%|██████▉   | 697/1000 [00:28<00:12, 25.18it/s]Collecting alignment pairs:  70%|███████   | 700/1000 [00:28<00:12, 24.56it/s]Collecting alignment pairs:  70%|███████   | 703/1000 [00:28<00:12, 24.46it/s]Collecting alignment pairs:  71%|███████   | 706/1000 [00:28<00:12, 23.64it/s]Collecting alignment pairs:  71%|███████   | 709/1000 [00:28<00:12, 23.84it/s]Collecting alignment pairs:  71%|███████   | 712/1000 [00:28<00:11, 24.98it/s]Collecting alignment pairs:  72%|███████▏  | 715/1000 [00:28<00:11, 24.44it/s]Collecting alignment pairs:  72%|███████▏  | 718/1000 [00:28<00:11, 24.29it/s]Collecting alignment pairs:  72%|███████▏  | 721/1000 [00:29<00:11, 24.66it/s]Collecting alignment pairs:  72%|███████▏  | 724/1000 [00:29<00:10, 25.16it/s]Collecting alignment pairs:  73%|███████▎  | 727/1000 [00:29<00:11, 23.71it/s]Collecting alignment pairs:  73%|███████▎  | 730/1000 [00:29<00:11, 24.46it/s]Collecting alignment pairs:  73%|███████▎  | 733/1000 [00:29<00:11, 24.19it/s]Collecting alignment pairs:  74%|███████▎  | 736/1000 [00:29<00:11, 23.89it/s]Collecting alignment pairs:  74%|███████▍  | 739/1000 [00:29<00:10, 24.61it/s]Collecting alignment pairs:  74%|███████▍  | 742/1000 [00:29<00:10, 25.37it/s]Collecting alignment pairs:  74%|███████▍  | 745/1000 [00:30<00:10, 24.08it/s]Collecting alignment pairs:  75%|███████▍  | 748/1000 [00:30<00:10, 24.48it/s]Collecting alignment pairs:  75%|███████▌  | 751/1000 [00:30<00:10, 23.91it/s]Collecting alignment pairs:  75%|███████▌  | 754/1000 [00:30<00:09, 24.88it/s]Collecting alignment pairs:  76%|███████▌  | 757/1000 [00:30<00:09, 24.65it/s]/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
Collecting alignment pairs:  76%|███████▌  | 760/1000 [00:30<00:09, 25.21it/s]Collecting alignment pairs:  76%|███████▋  | 763/1000 [00:30<00:09, 24.11it/s]Collecting alignment pairs:  77%|███████▋  | 766/1000 [00:30<00:09, 25.05it/s]Collecting alignment pairs:  77%|███████▋  | 769/1000 [00:30<00:09, 24.23it/s]Collecting alignment pairs:  77%|███████▋  | 772/1000 [00:31<00:09, 24.32it/s]Collecting alignment pairs:  78%|███████▊  | 775/1000 [00:31<00:09, 24.97it/s]Collecting alignment pairs:  78%|███████▊  | 778/1000 [00:31<00:09, 24.41it/s]Collecting alignment pairs:  78%|███████▊  | 781/1000 [00:31<00:08, 24.65it/s]Collecting alignment pairs:  78%|███████▊  | 784/1000 [00:31<00:08, 24.16it/s]Collecting alignment pairs:  79%|███████▊  | 787/1000 [00:31<00:08, 24.51it/s]Collecting alignment pairs:  79%|███████▉  | 790/1000 [00:31<00:08, 23.69it/s]Collecting alignment pairs:  79%|███████▉  | 793/1000 [00:31<00:08, 23.73it/s]Collecting alignment pairs:  80%|███████▉  | 796/1000 [00:32<00:08, 24.46it/s]Collecting alignment pairs:  80%|███████▉  | 799/1000 [00:32<00:08, 24.32it/s]Collecting alignment pairs:  80%|████████  | 802/1000 [00:32<00:08, 24.24it/s]Collecting alignment pairs:  80%|████████  | 805/1000 [00:32<00:07, 24.92it/s]Collecting alignment pairs:  81%|████████  | 808/1000 [00:32<00:07, 24.31it/s]Collecting alignment pairs:  81%|████████  | 811/1000 [00:32<00:07, 25.01it/s]Collecting alignment pairs:  81%|████████▏ | 814/1000 [00:32<00:07, 24.40it/s]Collecting alignment pairs:  82%|████████▏ | 817/1000 [00:32<00:07, 24.55it/s]Collecting alignment pairs:  82%|████████▏ | 820/1000 [00:33<00:07, 24.59it/s]Collecting alignment pairs:  82%|████████▏ | 823/1000 [00:33<00:07, 24.56it/s]Collecting alignment pairs:  83%|████████▎ | 826/1000 [00:33<00:06, 25.04it/s]Collecting alignment pairs:  83%|████████▎ | 829/1000 [00:33<00:07, 23.98it/s]Collecting alignment pairs:  83%|████████▎ | 832/1000 [00:33<00:06, 25.48it/s]Collecting alignment pairs:  84%|████████▎ | 835/1000 [00:33<00:06, 24.62it/s]Collecting alignment pairs:  84%|████████▍ | 838/1000 [00:33<00:06, 23.76it/s]Collecting alignment pairs:  84%|████████▍ | 841/1000 [00:33<00:06, 24.77it/s]Collecting alignment pairs:  84%|████████▍ | 844/1000 [00:34<00:06, 24.11it/s]Collecting alignment pairs:  85%|████████▍ | 847/1000 [00:34<00:06, 23.84it/s]Collecting alignment pairs:  85%|████████▌ | 850/1000 [00:34<00:06, 23.76it/s]Collecting alignment pairs:  85%|████████▌ | 853/1000 [00:34<00:06, 24.48it/s]/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
Collecting alignment pairs:  86%|████████▌ | 856/1000 [00:34<00:05, 24.83it/s]Collecting alignment pairs:  86%|████████▌ | 859/1000 [00:34<00:05, 24.08it/s]Collecting alignment pairs:  86%|████████▌ | 862/1000 [00:34<00:05, 23.44it/s]Collecting alignment pairs:  86%|████████▋ | 865/1000 [00:34<00:05, 24.05it/s]Collecting alignment pairs:  87%|████████▋ | 868/1000 [00:35<00:05, 25.00it/s]Collecting alignment pairs:  87%|████████▋ | 871/1000 [00:35<00:05, 24.18it/s]Collecting alignment pairs:  87%|████████▋ | 874/1000 [00:35<00:05, 25.09it/s]Collecting alignment pairs:  88%|████████▊ | 877/1000 [00:35<00:05, 23.94it/s]Collecting alignment pairs:  88%|████████▊ | 880/1000 [00:35<00:05, 23.92it/s]Collecting alignment pairs:  88%|████████▊ | 883/1000 [00:35<00:04, 24.67it/s]Collecting alignment pairs:  89%|████████▊ | 886/1000 [00:35<00:04, 24.90it/s]Collecting alignment pairs:  89%|████████▉ | 889/1000 [00:35<00:04, 23.71it/s]Collecting alignment pairs:  89%|████████▉ | 892/1000 [00:36<00:04, 24.40it/s]Collecting alignment pairs:  90%|████████▉ | 895/1000 [00:36<00:04, 24.32it/s]Collecting alignment pairs:  90%|████████▉ | 898/1000 [00:36<00:04, 24.08it/s]Collecting alignment pairs:  90%|█████████ | 902/1000 [00:36<00:03, 24.95it/s]Collecting alignment pairs:  90%|█████████ | 905/1000 [00:36<00:03, 25.48it/s]Collecting alignment pairs:  91%|█████████ | 908/1000 [00:36<00:03, 24.04it/s]Collecting alignment pairs:  91%|█████████ | 911/1000 [00:36<00:03, 24.83it/s]Collecting alignment pairs:  91%|█████████▏| 914/1000 [00:36<00:03, 25.20it/s]Collecting alignment pairs:  92%|█████████▏| 917/1000 [00:37<00:03, 24.19it/s]Collecting alignment pairs:  92%|█████████▏| 920/1000 [00:37<00:03, 24.74it/s]Collecting alignment pairs:  92%|█████████▏| 923/1000 [00:37<00:03, 25.27it/s]Collecting alignment pairs:  93%|█████████▎| 926/1000 [00:37<00:02, 25.19it/s]Collecting alignment pairs:  93%|█████████▎| 929/1000 [00:37<00:02, 25.28it/s]Collecting alignment pairs:  93%|█████████▎| 932/1000 [00:37<00:02, 25.07it/s]Collecting alignment pairs:  94%|█████████▎| 935/1000 [00:37<00:02, 24.37it/s]Collecting alignment pairs:  94%|█████████▍| 938/1000 [00:37<00:02, 23.80it/s]Collecting alignment pairs:  94%|█████████▍| 941/1000 [00:38<00:02, 24.83it/s]Collecting alignment pairs:  94%|█████████▍| 944/1000 [00:38<00:02, 24.13it/s]Collecting alignment pairs:  95%|█████████▍| 947/1000 [00:38<00:02, 25.10it/s]Collecting alignment pairs:  95%|█████████▌| 950/1000 [00:38<00:02, 24.99it/s]Collecting alignment pairs:  95%|█████████▌| 953/1000 [00:38<00:01, 24.72it/s]Collecting alignment pairs:  96%|█████████▌| 956/1000 [00:38<00:01, 24.53it/s]Collecting alignment pairs:  96%|█████████▌| 959/1000 [00:38<00:01, 24.16it/s]Collecting alignment pairs:  96%|█████████▌| 962/1000 [00:38<00:01, 24.57it/s]/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
Collecting alignment pairs:  96%|█████████▋| 965/1000 [00:38<00:01, 24.46it/s]Collecting alignment pairs:  97%|█████████▋| 968/1000 [00:39<00:01, 24.99it/s]Collecting alignment pairs:  97%|█████████▋| 971/1000 [00:39<00:01, 24.58it/s]Collecting alignment pairs:  97%|█████████▋| 974/1000 [00:39<00:01, 24.42it/s]Collecting alignment pairs:  98%|█████████▊| 977/1000 [00:39<00:00, 25.27it/s]Collecting alignment pairs:  98%|█████████▊| 980/1000 [00:39<00:00, 24.32it/s]Collecting alignment pairs:  98%|█████████▊| 983/1000 [00:39<00:00, 23.39it/s]Collecting alignment pairs:  99%|█████████▊| 986/1000 [00:39<00:00, 24.44it/s]Collecting alignment pairs:  99%|█████████▉| 989/1000 [00:39<00:00, 24.37it/s]Collecting alignment pairs:  99%|█████████▉| 992/1000 [00:40<00:00, 23.66it/s]Collecting alignment pairs: 100%|█████████▉| 995/1000 [00:40<00:00, 24.63it/s]Collecting alignment pairs: 100%|█████████▉| 998/1000 [00:40<00:00, 23.74it/s]Collecting alignment pairs: 100%|██████████| 1000/1000 [00:40<00:00, 24.74it/s]
Source matrix X: (1000, 4096)
Target matrix Y: (1000, 4096)

============================================================
Seed 42
============================================================

--- Lambda = 0.1 ---
Weight matrix W: (4096, 4096)
  W norm: 0.3378
  W mean: -0.000000, std: 0.000082
Evaluating lambda=0.1:   0%|          | 0/200 [00:00<?, ?it/s]Evaluating lambda=0.1:   0%|          | 0/200 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 1648, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 1604, in main
    results = run_ridge_regression_baseline(args, config, device)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_baselines.py", line 1457, in run_ridge_regression_baseline
    combined_embeds = torch.cat([primer_embeds, soft_token], dim=1)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cuda:1! (when checking argument for argument tensors in method wrapper_CUDA_cat)
[2026-01-19 12:37:21] FAILED: ridge_regression_arc_easy (exit code: 1)
Failed: ridge_regression_arc_easy

[2026-01-19 12:37:22] [GPU 1] Running Latency Benchmarks
  Training LogisticRegression...
  Train Acc: 99.8%
  CV Acc: 25.1% +/- 2.9%
  Test Acc: 26.9%
  F1 Score: 20.4%

Best layer: 31 with 26.9% accuracy

--- Seed 123 ---

================================================================================
Dataset: arc_easy (4 classes)
================================================================================
Loading arc_easy data...
Train: 2251 samples, Test: 1000 samples

--- Layer 31 ---
  Extracting train features...
Extracting layer 31:   0%|          | 0/282 [00:00<?, ?it/s]Extracting layer 31:   2%|▏         | 5/282 [00:00<00:06, 46.09it/s]Extracting layer 31:   4%|▎         | 10/282 [00:00<00:06, 41.25it/s]Extracting layer 31:   5%|▌         | 15/282 [00:00<00:06, 41.33it/s]Extracting layer 31:   7%|▋         | 20/282 [00:00<00:06, 39.49it/s]Extracting layer 31:   9%|▉         | 26/282 [00:00<00:05, 43.69it/s]Extracting layer 31:  11%|█         | 31/282 [00:00<00:05, 43.29it/s]Extracting layer 31:  13%|█▎        | 36/282 [00:00<00:05, 43.50it/s]Extracting layer 31:  15%|█▍        | 41/282 [00:00<00:05, 44.73it/s]Extracting layer 31:  16%|█▋        | 46/282 [00:01<00:05, 44.06it/s]Extracting layer 31:  18%|█▊        | 51/282 [00:01<00:05, 44.40it/s]Extracting layer 31:  20%|██        | 57/282 [00:01<00:04, 47.03it/s]Extracting layer 31:  22%|██▏       | 62/282 [00:01<00:04, 47.11it/s]Extracting layer 31:  24%|██▍       | 67/282 [00:01<00:04, 47.12it/s]Extracting layer 31:  26%|██▌       | 72/282 [00:01<00:04, 46.24it/s]Extracting layer 31:  27%|██▋       | 77/282 [00:01<00:04, 44.62it/s]Extracting layer 31:  29%|██▉       | 82/282 [00:01<00:04, 44.64it/s]Extracting layer 31:  31%|███       | 87/282 [00:01<00:04, 45.10it/s]Extracting layer 31:  33%|███▎      | 92/282 [00:02<00:04, 45.09it/s]Extracting layer 31:  34%|███▍      | 97/282 [00:02<00:04, 44.31it/s]Extracting layer 31:  36%|███▌      | 102/282 [00:02<00:04, 44.05it/s]Extracting layer 31:  38%|███▊      | 107/282 [00:02<00:04, 41.84it/s]Extracting layer 31:  40%|███▉      | 112/282 [00:02<00:03, 43.03it/s]Extracting layer 31:  41%|████▏     | 117/282 [00:02<00:03, 43.56it/s]Extracting layer 31:  43%|████▎     | 122/282 [00:02<00:03, 42.09it/s]Extracting layer 31:  45%|████▌     | 127/282 [00:02<00:03, 41.76it/s]Extracting layer 31:  47%|████▋     | 132/282 [00:03<00:03, 42.26it/s]Extracting layer 31:  49%|████▊     | 137/282 [00:03<00:03, 43.45it/s][2026-01-19 12:37:27] [GPU 1] No checkpoint found, running latency benchmark without bridge
Extracting layer 31:  50%|█████     | 142/282 [00:03<00:03, 41.61it/s]Started: latency_benchmark_no_checkpoint
[2026-01-19 12:37:27] START: latency_benchmark_no_checkpoint
Extracting layer 31:  52%|█████▏    | 147/282 [00:03<00:03, 38.93it/s]Extracting layer 31:  54%|█████▎    | 151/282 [00:03<00:03, 35.57it/s]Extracting layer 31:  55%|█████▍    | 155/282 [00:03<00:03, 33.19it/s]Extracting layer 31:  56%|█████▋    | 159/282 [00:03<00:03, 31.81it/s]Extracting layer 31:  58%|█████▊    | 163/282 [00:03<00:03, 31.54it/s]Extracting layer 31:  59%|█████▉    | 167/282 [00:04<00:03, 31.24it/s]Extracting layer 31:  61%|██████    | 171/282 [00:04<00:03, 30.38it/s]Extracting layer 31:  62%|██████▏   | 175/282 [00:04<00:03, 29.27it/s]Extracting layer 31:  63%|██████▎   | 178/282 [00:04<00:03, 29.19it/s]Extracting layer 31:  64%|██████▍   | 181/282 [00:04<00:03, 28.56it/s]Extracting layer 31:  65%|██████▌   | 184/282 [00:04<00:03, 27.67it/s]Extracting layer 31:  66%|██████▋   | 187/282 [00:04<00:03, 26.82it/s]Extracting layer 31:  67%|██████▋   | 190/282 [00:04<00:03, 26.27it/s]Extracting layer 31:  68%|██████▊   | 193/282 [00:05<00:03, 24.45it/s]Extracting layer 31:  70%|██████▉   | 196/282 [00:05<00:03, 25.55it/s]Extracting layer 31:  71%|███████   | 199/282 [00:05<00:03, 25.89it/s]Extracting layer 31:  72%|███████▏  | 202/282 [00:05<00:02, 26.95it/s]Extracting layer 31:  73%|███████▎  | 206/282 [00:05<00:02, 27.93it/s]Extracting layer 31:  74%|███████▍  | 210/282 [00:05<00:02, 29.03it/s]Extracting layer 31:  76%|███████▌  | 213/282 [00:05<00:02, 27.21it/s]/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Extracting layer 31:  77%|███████▋  | 216/282 [00:05<00:02, 26.68it/s]Extracting layer 31:  78%|███████▊  | 219/282 [00:06<00:02, 27.05it/s]Extracting layer 31:  79%|███████▊  | 222/282 [00:06<00:02, 26.84it/s]Extracting layer 31:  80%|███████▉  | 225/282 [00:06<00:02, 26.49it/s]Extracting layer 31:  81%|████████  | 228/282 [00:06<00:01, 27.02it/s]Extracting layer 31:  82%|████████▏ | 231/282 [00:06<00:01, 25.84it/s]Extracting layer 31:  83%|████████▎ | 234/282 [00:06<00:01, 26.66it/s]Extracting layer 31:  84%|████████▍ | 237/282 [00:06<00:01, 26.08it/s]Extracting layer 31:  85%|████████▌ | 240/282 [00:06<00:01, 26.94it/s]Extracting layer 31:  86%|████████▌ | 243/282 [00:06<00:01, 27.11it/s]Extracting layer 31:  87%|████████▋ | 246/282 [00:07<00:01, 26.77it/s]Extracting layer 31:  88%|████████▊ | 249/282 [00:07<00:01, 26.32it/s]Extracting layer 31:  90%|████████▉ | 253/282 [00:07<00:01, 27.88it/s]Extracting layer 31:  91%|█████████ | 256/282 [00:07<00:01, 25.72it/s]Extracting layer 31:  92%|█████████▏| 259/282 [00:07<00:00, 26.28it/s]Extracting layer 31:  93%|█████████▎| 262/282 [00:07<00:00, 26.99it/s]Extracting layer 31:  94%|█████████▍| 265/282 [00:07<00:00, 27.30it/s]Extracting layer 31:  95%|█████████▌| 268/282 [00:07<00:00, 25.39it/s]Extracting layer 31:  96%|█████████▌| 271/282 [00:08<00:00, 23.89it/s]Extracting layer 31:  97%|█████████▋| 274/282 [00:08<00:00, 25.11it/s]Extracting layer 31:  98%|█████████▊| 277/282 [00:08<00:00, 26.30it/s]Extracting layer 31: 100%|█████████▉| 281/282 [00:08<00:00, 27.03it/s]Extracting layer 31: 100%|██████████| 282/282 [00:08<00:00, 33.52it/s]
  Extracting test features...
Extracting layer 31:   0%|          | 0/125 [00:00<?, ?it/s]Extracting layer 31:   2%|▏         | 3/125 [00:00<00:04, 26.50it/s]Extracting layer 31:   6%|▌         | 7/125 [00:00<00:03, 30.27it/s]Extracting layer 31:   9%|▉         | 11/125 [00:00<00:04, 27.38it/s]Extracting layer 31:  12%|█▏        | 15/125 [00:00<00:03, 29.68it/s]Extracting layer 31:  15%|█▌        | 19/125 [00:00<00:03, 28.97it/s]Extracting layer 31:  18%|█▊        | 22/125 [00:00<00:03, 27.45it/s]Extracting layer 31:  20%|██        | 25/125 [00:00<00:03, 27.28it/s]Extracting layer 31:  23%|██▎       | 29/125 [00:01<00:03, 28.97it/s]Extracting layer 31:  26%|██▋       | 33/125 [00:01<00:03, 30.51it/s]Extracting layer 31:  30%|███       | 38/125 [00:01<00:02, 35.64it/s]Extracting layer 31:  34%|███▎      | 42/125 [00:01<00:02, 33.21it/s]Device: cuda:1
GPU: NVIDIA H100 80GB HBM3

======================================================================
LATENCY BENCHMARK
======================================================================
Loading Llama...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 1600.42it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Extracting layer 31:  37%|███▋      | 46/125 [00:01<00:02, 32.53it/s]Extracting layer 31:  40%|████      | 50/125 [00:01<00:02, 29.39it/s]Extracting layer 31:  43%|████▎     | 54/125 [00:01<00:02, 29.12it/s]Extracting layer 31:  46%|████▌     | 57/125 [00:01<00:02, 28.64it/s]Extracting layer 31:  49%|████▉     | 61/125 [00:02<00:02, 29.71it/s]Extracting layer 31:  52%|█████▏    | 65/125 [00:02<00:01, 30.59it/s]Extracting layer 31:  55%|█████▌    | 69/125 [00:02<00:01, 30.08it/s]Extracting layer 31:  58%|█████▊    | 73/125 [00:02<00:01, 30.14it/s]Extracting layer 31:  62%|██████▏   | 77/125 [00:02<00:01, 29.82it/s]Extracting layer 31:  64%|██████▍   | 80/125 [00:02<00:01, 29.69it/s]Extracting layer 31:  67%|██████▋   | 84/125 [00:02<00:01, 30.18it/s]Extracting layer 31:  70%|███████   | 88/125 [00:02<00:01, 29.59it/s]Extracting layer 31:  74%|███████▎  | 92/125 [00:03<00:01, 30.07it/s]Extracting layer 31:  77%|███████▋  | 96/125 [00:03<00:00, 29.38it/s]Extracting layer 31:  80%|████████  | 100/125 [00:03<00:00, 29.99it/s]Extracting layer 31:  83%|████████▎ | 104/125 [00:03<00:00, 30.50it/s]Extracting layer 31:  86%|████████▋ | 108/125 [00:03<00:00, 29.18it/s]Extracting layer 31:  90%|████████▉ | 112/125 [00:03<00:00, 30.60it/s]Extracting layer 31:  93%|█████████▎| 116/125 [00:03<00:00, 30.02it/s]Extracting layer 31:  96%|█████████▌| 120/125 [00:04<00:00, 30.47it/s]Extracting layer 31:  99%|█████████▉| 124/125 [00:04<00:00, 29.72it/s]Extracting layer 31: 100%|██████████| 125/125 [00:04<00:00, 29.93it/s]
/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:13,  4.37s/it]/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.17s/it]/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.17s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.96s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.42s/it]
Loading Mistral...
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2490.19it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.91s/it]/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.93s/it]/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.82s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.85s/it]
Loading SST-2 dataset...
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_benchmarks.py", line 658, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_benchmarks.py", line 626, in main
    results = run_latency_benchmark(args, device)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_benchmarks.py", line 130, in run_latency_benchmark
    ds = load_dataset("glue", "sst2", split="validation")
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 2132, in load_dataset
    builder_instance = load_dataset_builder(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1853, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1729, in dataset_module_factory
    raise e1 from None
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1599, in dataset_module_factory
    dataset_readme_path = api.hf_hub_download(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 5467, in hf_hub_download
    return hf_hub_download(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1167, in _hf_hub_download_to_cache_dir
    with WeakFileLock(lock_path):
  File "/marlowe/apps/Mambaforge/24.3.0-0/lib/python3.10/contextlib.py", line 135, in __enter__
    return next(self.gen)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_fixes.py", line 109, in WeakFileLock
    lock.acquire(timeout=min(log_interval, timeout - elapsed_time) if timeout else log_interval)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/filelock/_api.py", line 332, in acquire
    self._acquire()
  File "/users/sujinesh/.local/lib/python3.10/site-packages/filelock/_unix.py", line 44, in _acquire
    fd = os.open(self.lock_file, open_flags, self._context.mode)
OSError: [Errno 122] Disk quota exceeded: '/projects/m000066/sujinesh/.cache/huggingface/hub/.locks/datasets--glue/274c0b2c4c5524fe09285a8b7d945fe98a1dfe7a.lock'
[2026-01-19 12:38:02] FAILED: latency_benchmark_no_checkpoint (exit code: 1)
Failed: latency_benchmark_no_checkpoint

[2026-01-19 12:38:02] [GPU 1] Running Batched Latency Benchmark (batch sizes: 1, 4, 8, 16)
Started: batched_latency_benchmark
[2026-01-19 12:38:02] START: batched_latency_benchmark
  Training LogisticRegression...
  Train Acc: 99.8%
  CV Acc: 24.9% +/- 1.5%
  Test Acc: 24.3%
  F1 Score: 20.1%

Best layer: 31 with 24.3% accuracy

--- Seed 456 ---

================================================================================
Dataset: arc_easy (4 classes)
================================================================================
Loading arc_easy data...
Train: 2251 samples, Test: 1000 samples

--- Layer 31 ---
  Extracting train features...
Extracting layer 31:   0%|          | 0/282 [00:00<?, ?it/s]/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Extracting layer 31:   1%|▏         | 4/282 [00:00<00:09, 29.77it/s]Extracting layer 31:   2%|▏         | 7/282 [00:00<00:10, 27.13it/s]Extracting layer 31:   4%|▎         | 10/282 [00:00<00:10, 26.39it/s]Extracting layer 31:   5%|▍         | 13/282 [00:00<00:10, 26.18it/s]Extracting layer 31:   6%|▌         | 17/282 [00:00<00:09, 26.81it/s]Extracting layer 31:   7%|▋         | 20/282 [00:00<00:09, 27.00it/s]Extracting layer 31:   8%|▊         | 23/282 [00:00<00:09, 26.83it/s]Extracting layer 31:  10%|▉         | 27/282 [00:00<00:08, 28.55it/s]Extracting layer 31:  11%|█         | 31/282 [00:01<00:08, 29.33it/s]Extracting layer 31:  12%|█▏        | 35/282 [00:01<00:08, 29.89it/s]Extracting layer 31:  13%|█▎        | 38/282 [00:01<00:08, 29.51it/s]Extracting layer 31:  15%|█▍        | 41/282 [00:01<00:08, 29.04it/s]Extracting layer 31:  16%|█▌        | 44/282 [00:01<00:08, 27.09it/s]Extracting layer 31:  17%|█▋        | 48/282 [00:01<00:07, 29.77it/s]Extracting layer 31:  18%|█▊        | 52/282 [00:01<00:07, 30.57it/s]Extracting layer 31:  20%|█▉        | 56/282 [00:01<00:07, 29.98it/s]Extracting layer 31:  21%|██▏       | 60/282 [00:02<00:07, 29.59it/s]Extracting layer 31:  22%|██▏       | 63/282 [00:02<00:07, 29.05it/s]Extracting layer 31:  23%|██▎       | 66/282 [00:02<00:07, 28.07it/s]Extracting layer 31:  24%|██▍       | 69/282 [00:02<00:07, 28.50it/s]Extracting layer 31:  26%|██▌       | 73/282 [00:02<00:07, 29.48it/s]Extracting layer 31:  27%|██▋       | 76/282 [00:02<00:07, 29.11it/s]Extracting layer 31:  28%|██▊       | 79/282 [00:02<00:07, 28.49it/s]Extracting layer 31:  29%|██▉       | 82/282 [00:02<00:07, 27.56it/s]Extracting layer 31:  30%|███       | 86/282 [00:03<00:06, 28.56it/s]Extracting layer 31:  32%|███▏      | 90/282 [00:03<00:06, 29.20it/s]Extracting layer 31:  33%|███▎      | 93/282 [00:03<00:06, 28.87it/s]Extracting layer 31:  34%|███▍      | 97/282 [00:03<00:06, 28.53it/s]Extracting layer 31:  36%|███▌      | 101/282 [00:03<00:06, 29.78it/s]Extracting layer 31:  37%|███▋      | 105/282 [00:03<00:05, 32.23it/s]Extracting layer 31:  39%|███▊      | 109/282 [00:03<00:05, 30.15it/s]Device: cuda:1
GPU: NVIDIA H100 80GB HBM3

======================================================================
BATCHED LATENCY BENCHMARK
======================================================================
Loading Llama...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 1461.81it/s]
Extracting layer 31:  40%|████      | 113/282 [00:03<00:05, 30.38it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Extracting layer 31:  41%|████▏     | 117/282 [00:04<00:05, 29.64it/s]Extracting layer 31:  43%|████▎     | 121/282 [00:04<00:05, 29.02it/s]Extracting layer 31:  44%|████▍     | 125/282 [00:04<00:05, 28.90it/s]Extracting layer 31:  45%|████▌     | 128/282 [00:04<00:05, 29.13it/s]Extracting layer 31:  47%|████▋     | 132/282 [00:04<00:05, 28.87it/s]Extracting layer 31:  48%|████▊     | 136/282 [00:04<00:04, 30.45it/s]Extracting layer 31:  50%|████▉     | 140/282 [00:04<00:04, 29.65it/s]Extracting layer 31:  51%|█████     | 144/282 [00:04<00:04, 30.54it/s]Extracting layer 31:  52%|█████▏    | 148/282 [00:05<00:04, 30.05it/s]Extracting layer 31:  54%|█████▍    | 152/282 [00:05<00:04, 30.41it/s]Extracting layer 31:  55%|█████▌    | 156/282 [00:05<00:04, 30.38it/s]Extracting layer 31:  57%|█████▋    | 160/282 [00:05<00:04, 29.79it/s]Extracting layer 31:  58%|█████▊    | 164/282 [00:05<00:03, 30.21it/s]Extracting layer 31:  60%|█████▉    | 168/282 [00:05<00:03, 29.77it/s]Extracting layer 31:  61%|██████    | 171/282 [00:05<00:03, 28.85it/s]Extracting layer 31:  62%|██████▏   | 175/282 [00:05<00:03, 29.97it/s]Extracting layer 31:  63%|██████▎   | 179/282 [00:06<00:03, 29.49it/s]Extracting layer 31:  65%|██████▍   | 182/282 [00:06<00:03, 28.76it/s]Extracting layer 31:  66%|██████▌   | 186/282 [00:06<00:03, 29.80it/s]Extracting layer 31:  67%|██████▋   | 189/282 [00:06<00:03, 29.76it/s]Extracting layer 31:  68%|██████▊   | 192/282 [00:06<00:03, 27.29it/s]Extracting layer 31:  70%|██████▉   | 196/282 [00:06<00:03, 28.45it/s]Extracting layer 31:  71%|███████   | 200/282 [00:06<00:02, 29.94it/s]Extracting layer 31:  72%|███████▏  | 204/282 [00:06<00:02, 29.98it/s]Extracting layer 31:  74%|███████▍  | 208/282 [00:07<00:02, 30.75it/s]Extracting layer 31:  75%|███████▌  | 212/282 [00:07<00:02, 28.35it/s]Extracting layer 31:  77%|███████▋  | 216/282 [00:07<00:02, 29.82it/s]Extracting layer 31:  78%|███████▊  | 220/282 [00:07<00:02, 30.33it/s]Extracting layer 31:  79%|███████▉  | 224/282 [00:07<00:01, 30.23it/s]Extracting layer 31:  81%|████████  | 228/282 [00:07<00:01, 29.88it/s]Extracting layer 31:  82%|████████▏ | 232/282 [00:07<00:01, 30.16it/s]Extracting layer 31:  84%|████████▎ | 236/282 [00:08<00:01, 29.75it/s]Extracting layer 31:  85%|████████▍ | 239/282 [00:08<00:01, 29.80it/s]Extracting layer 31:  86%|████████▌ | 243/282 [00:08<00:01, 30.10it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:13,  4.43s/it]Extracting layer 31:  88%|████████▊ | 247/282 [00:08<00:01, 29.58it/s]Extracting layer 31:  89%|████████▉ | 251/282 [00:08<00:01, 30.39it/s]Extracting layer 31:  90%|█████████ | 255/282 [00:08<00:00, 31.44it/s]Extracting layer 31:  92%|█████████▏| 259/282 [00:08<00:00, 28.73it/s]Extracting layer 31:  93%|█████████▎| 263/282 [00:08<00:00, 30.26it/s]Extracting layer 31:  95%|█████████▍| 267/282 [00:09<00:00, 29.46it/s]Extracting layer 31:  96%|█████████▌| 270/282 [00:09<00:00, 29.59it/s]Extracting layer 31:  97%|█████████▋| 273/282 [00:09<00:00, 28.96it/s]Extracting layer 31:  98%|█████████▊| 277/282 [00:09<00:00, 30.12it/s]Extracting layer 31: 100%|██████████| 282/282 [00:09<00:00, 32.91it/s]Extracting layer 31: 100%|██████████| 282/282 [00:09<00:00, 29.47it/s]
  Extracting test features...
Extracting layer 31:   0%|          | 0/125 [00:00<?, ?it/s]Extracting layer 31:   3%|▎         | 4/125 [00:00<00:03, 31.88it/s]Extracting layer 31:   6%|▋         | 8/125 [00:00<00:04, 28.07it/s]Extracting layer 31:   9%|▉         | 11/125 [00:00<00:04, 27.56it/s]Extracting layer 31:  11%|█         | 14/125 [00:00<00:03, 28.38it/s]Extracting layer 31:  14%|█▍        | 18/125 [00:00<00:03, 29.31it/s]Extracting layer 31:  18%|█▊        | 22/125 [00:00<00:03, 30.62it/s]Extracting layer 31:  21%|██        | 26/125 [00:00<00:03, 31.36it/s]Extracting layer 31:  24%|██▍       | 30/125 [00:00<00:03, 31.37it/s]Extracting layer 31:  27%|██▋       | 34/125 [00:01<00:03, 29.80it/s]Extracting layer 31:  30%|███       | 38/125 [00:01<00:02, 30.91it/s]Extracting layer 31:  34%|███▎      | 42/125 [00:01<00:02, 31.11it/s]Extracting layer 31:  37%|███▋      | 46/125 [00:01<00:02, 31.27it/s]Extracting layer 31:  40%|████      | 50/125 [00:01<00:02, 30.45it/s]Extracting layer 31:  43%|████▎     | 54/125 [00:01<00:02, 29.53it/s]Extracting layer 31:  46%|████▌     | 57/125 [00:01<00:02, 29.40it/s]Extracting layer 31:  49%|████▉     | 61/125 [00:02<00:02, 30.20it/s]Extracting layer 31:  52%|█████▏    | 65/125 [00:02<00:02, 29.68it/s]Extracting layer 31:  55%|█████▌    | 69/125 [00:02<00:01, 30.06it/s]Extracting layer 31:  58%|█████▊    | 73/125 [00:02<00:01, 29.94it/s]Extracting layer 31:  61%|██████    | 76/125 [00:02<00:01, 28.83it/s]Extracting layer 31:  64%|██████▍   | 80/125 [00:02<00:01, 30.34it/s]Extracting layer 31:  67%|██████▋   | 84/125 [00:02<00:01, 31.31it/s]Extracting layer 31:  70%|███████   | 88/125 [00:02<00:01, 30.99it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.29s/it]Extracting layer 31:  74%|███████▎  | 92/125 [00:03<00:01, 30.77it/s]Extracting layer 31:  77%|███████▋  | 96/125 [00:03<00:00, 31.82it/s]Extracting layer 31:  80%|████████  | 100/125 [00:03<00:00, 29.65it/s]Extracting layer 31:  83%|████████▎ | 104/125 [00:03<00:00, 30.17it/s]Extracting layer 31:  86%|████████▋ | 108/125 [00:03<00:00, 29.43it/s]Extracting layer 31:  89%|████████▉ | 111/125 [00:03<00:00, 29.55it/s]Extracting layer 31:  92%|█████████▏| 115/125 [00:03<00:00, 29.41it/s]Extracting layer 31:  94%|█████████▍| 118/125 [00:03<00:00, 29.16it/s]Extracting layer 31:  98%|█████████▊| 122/125 [00:04<00:00, 29.82it/s]Extracting layer 31: 100%|██████████| 125/125 [00:04<00:00, 29.39it/s]Extracting layer 31: 100%|██████████| 125/125 [00:04<00:00, 30.02it/s]
/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.17s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.98s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.45s/it]
/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
Loading Mistral...
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2378.17it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.85s/it]/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.91s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.81s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.83s/it]
/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_benchmarks.py", line 658, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_benchmarks.py", line 628, in main
    results = run_batched_benchmark(args, device)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_benchmarks.py", line 253, in run_batched_benchmark
    ds = load_dataset("glue", "sst2", split="validation")
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 2132, in load_dataset
    builder_instance = load_dataset_builder(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1853, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1729, in dataset_module_factory
    raise e1 from None
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1599, in dataset_module_factory
    dataset_readme_path = api.hf_hub_download(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 5467, in hf_hub_download
    return hf_hub_download(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1167, in _hf_hub_download_to_cache_dir
    with WeakFileLock(lock_path):
  File "/marlowe/apps/Mambaforge/24.3.0-0/lib/python3.10/contextlib.py", line 135, in __enter__
    return next(self.gen)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_fixes.py", line 109, in WeakFileLock
    lock.acquire(timeout=min(log_interval, timeout - elapsed_time) if timeout else log_interval)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/filelock/_api.py", line 332, in acquire
    self._acquire()
  File "/users/sujinesh/.local/lib/python3.10/site-packages/filelock/_unix.py", line 44, in _acquire
    fd = os.open(self.lock_file, open_flags, self._context.mode)
OSError: [Errno 122] Disk quota exceeded: '/projects/m000066/sujinesh/.cache/huggingface/hub/.locks/datasets--glue/274c0b2c4c5524fe09285a8b7d945fe98a1dfe7a.lock'
[2026-01-19 12:38:37] FAILED: batched_latency_benchmark (exit code: 1)
Failed: batched_latency_benchmark

[2026-01-19 12:38:37] [GPU 1] Running Memory Benchmark
Started: memory_benchmark
[2026-01-19 12:38:37] START: memory_benchmark
/users/sujinesh/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
  Training LogisticRegression...
  Train Acc: 99.8%
  CV Acc: 24.7% +/- 2.6%
  Test Acc: 26.7%
  F1 Score: 21.5%

Best layer: 31 with 26.7% accuracy


################################################################################
# DATASET: winogrande
################################################################################

--- Seed 42 ---

================================================================================
Dataset: winogrande (2 classes)
================================================================================
Loading winogrande data...
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/linear_probe_baseline.py", line 1177, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/linear_probe_baseline.py", line 1152, in main
    results = run_full_benchmark(
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/linear_probe_baseline.py", line 864, in run_full_benchmark
    seed_results = run_layer_sweep(
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/linear_probe_baseline.py", line 572, in run_layer_sweep
    train_texts, train_labels = load_dataset_by_name(
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/linear_probe_baseline.py", line 209, in load_dataset_by_name
    ds = load_dataset(config["hf_name"][0], config["hf_name"][1], split=split, trust_remote_code=True)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 2132, in load_dataset
    builder_instance = load_dataset_builder(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1853, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1729, in dataset_module_factory
    raise e1 from None
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1599, in dataset_module_factory
    dataset_readme_path = api.hf_hub_download(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 5467, in hf_hub_download
    return hf_hub_download(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1124, in _hf_hub_download_to_cache_dir
    os.makedirs(os.path.dirname(blob_path), exist_ok=True)
  File "/marlowe/apps/Mambaforge/24.3.0-0/lib/python3.10/os.py", line 215, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/marlowe/apps/Mambaforge/24.3.0-0/lib/python3.10/os.py", line 225, in makedirs
    mkdir(name, mode)
OSError: [Errno 122] Disk quota exceeded: '/projects/m000066/sujinesh/.cache/huggingface/hub/datasets--allenai--winogrande'
Device: cuda:1
GPU: NVIDIA H100 80GB HBM3

======================================================================
MEMORY BENCHMARK
======================================================================

--- Direct Mistral Inference ---
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 1967.31it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s][2026-01-19 12:38:45] FAILED: linear_probe (exit code: 1)
Failed: linear_probe

[2026-01-19 12:38:45] [GPU 0] Running Text Relay Baseline on ARC-Easy
Started: text_relay_arc_easy
[2026-01-19 12:38:45] START: text_relay_arc_easy
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading checkpoint shards:  33%|███▎      | 1/3 [00:04<00:08,  4.01s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.73s/it]Device: cuda:0

======================================================================
TEXT RELAY BASELINE (Llama->Mistral): ARC_EASY
======================================================================
Llama generates text hint, Mistral classifies based on hint.

--- Seed 42 ---
Loading Llama (sender)...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2085.16it/s]
Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  3.01s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  3.23s/it]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  Peak memory: 0 MB

--- LoRA Training (rank=8) ---
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2657.43it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.99s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.78s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.04s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.82s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.96s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.68s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.72s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.80s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.24s/it]
Loading Mistral (receiver)...
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2825.08it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]  Peak memory: 0 MB, Trainable: 3,407,872

--- Bridge Training (8 tokens) ---
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 1845.27it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.76s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.96s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:04,  4.04s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.11s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.81s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.84s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.90s/it]Text relay (seed 42):   0%|          | 0/200 [00:00<?, ?it/s]/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.77s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.22s/it]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2250.57it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Text relay (seed 42):   0%|          | 1/200 [00:02<08:45,  2.64s/it]Text relay (seed 42):   1%|          | 2/200 [00:04<07:58,  2.42s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.79s/it]Text relay (seed 42):   2%|▏         | 3/200 [00:07<07:42,  2.35s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.83s/it]Text relay (seed 42):   2%|▏         | 4/200 [00:09<07:34,  2.32s/it]Text relay (seed 42):   2%|▎         | 5/200 [00:11<07:32,  2.32s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.74s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.76s/it]
Text relay (seed 42):   3%|▎         | 6/200 [00:13<07:16,  2.25s/it]Text relay (seed 42):   4%|▎         | 7/200 [00:16<07:13,  2.25s/it]Text relay (seed 42):   4%|▍         | 8/200 [00:18<07:11,  2.25s/it]Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_benchmarks.py", line 658, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_benchmarks.py", line 630, in main
    results = run_memory_benchmark(args, device)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_benchmarks.py", line 477, in run_memory_benchmark
    outputs = mistral(inputs_embeds=latents, labels=inputs.input_ids)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py", line 1095, in forward
    loss = loss_fct(shift_logits, shift_labels)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py", line 1293, in forward
    return F.cross_entropy(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/functional.py", line 3479, in cross_entropy
    return torch._C._nn.cross_entropy_loss(
ValueError: Expected input batch_size (7) to match target batch_size (1).
Text relay (seed 42):   4%|▍         | 9/200 [00:20<07:07,  2.24s/it][2026-01-19 12:39:42] FAILED: memory_benchmark (exit code: 1)
Failed: memory_benchmark

[2026-01-19 12:39:42] [GPU 1] Running Throughput Benchmark
Started: throughput_benchmark_no_checkpoint
[2026-01-19 12:39:42] START: throughput_benchmark_no_checkpoint
Text relay (seed 42):   5%|▌         | 10/200 [00:22<07:01,  2.22s/it]/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Text relay (seed 42):   6%|▌         | 11/200 [00:25<07:15,  2.30s/it]Text relay (seed 42):   6%|▌         | 12/200 [00:27<07:19,  2.34s/it]Device: cuda:1
GPU: NVIDIA H100 80GB HBM3

======================================================================
THROUGHPUT BENCHMARK
======================================================================
Loading Llama...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 1731.39it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Text relay (seed 42):   6%|▋         | 13/200 [00:29<07:02,  2.26s/it]Text relay (seed 42):   7%|▋         | 14/200 [00:31<06:56,  2.24s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:13,  4.43s/it]Text relay (seed 42):   8%|▊         | 15/200 [00:34<06:55,  2.25s/it]Text relay (seed 42):   8%|▊         | 16/200 [00:36<06:53,  2.24s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.14s/it]Text relay (seed 42):   8%|▊         | 17/200 [00:38<06:50,  2.24s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.04s/it]Text relay (seed 42):   9%|▉         | 18/200 [00:41<06:52,  2.27s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  2.88s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.35s/it]
Loading Mistral...
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 1782.79it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Text relay (seed 42):  10%|▉         | 19/200 [00:42<06:28,  2.15s/it]Text relay (seed 42):  10%|█         | 20/200 [00:45<06:31,  2.17s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.75s/it]Text relay (seed 42):  10%|█         | 21/200 [00:47<06:33,  2.20s/it]Text relay (seed 42):  11%|█         | 22/200 [00:49<06:34,  2.21s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.86s/it]Text relay (seed 42):  12%|█▏        | 23/200 [00:51<06:34,  2.23s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.77s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.79s/it]
Text relay (seed 42):  12%|█▏        | 24/200 [00:53<06:24,  2.18s/it]Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_benchmarks.py", line 658, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_benchmarks.py", line 632, in main
    results = run_throughput_benchmark(args, device)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_benchmarks.py", line 522, in run_throughput_benchmark
    ds = load_dataset("glue", "sst2", split="validation")
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 2132, in load_dataset
    builder_instance = load_dataset_builder(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1853, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1729, in dataset_module_factory
    raise e1 from None
  File "/users/sujinesh/.local/lib/python3.10/site-packages/datasets/load.py", line 1599, in dataset_module_factory
    dataset_readme_path = api.hf_hub_download(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/hf_api.py", line 5467, in hf_hub_download
    return hf_hub_download(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1167, in _hf_hub_download_to_cache_dir
    with WeakFileLock(lock_path):
  File "/marlowe/apps/Mambaforge/24.3.0-0/lib/python3.10/contextlib.py", line 135, in __enter__
    return next(self.gen)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/huggingface_hub/utils/_fixes.py", line 109, in WeakFileLock
    lock.acquire(timeout=min(log_interval, timeout - elapsed_time) if timeout else log_interval)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/filelock/_api.py", line 332, in acquire
    self._acquire()
  File "/users/sujinesh/.local/lib/python3.10/site-packages/filelock/_unix.py", line 44, in _acquire
    fd = os.open(self.lock_file, open_flags, self._context.mode)
OSError: [Errno 122] Disk quota exceeded: '/projects/m000066/sujinesh/.cache/huggingface/hub/.locks/datasets--glue/274c0b2c4c5524fe09285a8b7d945fe98a1dfe7a.lock'
Text relay (seed 42):  12%|█▎        | 25/200 [00:55<06:14,  2.14s/it][2026-01-19 12:40:17] FAILED: throughput_benchmark_no_checkpoint (exit code: 1)
Failed: throughput_benchmark_no_checkpoint
[2026-01-19 12:40:17] [GPU 1] All experiments completed
Text relay (seed 42):  13%|█▎        | 26/200 [00:57<05:21,  1.85s/it]Text relay (seed 42):  14%|█▎        | 27/200 [00:58<04:40,  1.62s/it]Text relay (seed 42):  14%|█▍        | 28/200 [00:59<04:12,  1.47s/it]Text relay (seed 42):  14%|█▍        | 29/200 [01:00<03:52,  1.36s/it]Text relay (seed 42):  15%|█▌        | 30/200 [01:01<03:37,  1.28s/it]Text relay (seed 42):  16%|█▌        | 31/200 [01:02<03:27,  1.23s/it]Text relay (seed 42):  16%|█▌        | 32/200 [01:03<03:20,  1.19s/it]Text relay (seed 42):  16%|█▋        | 33/200 [01:04<03:14,  1.16s/it]Text relay (seed 42):  17%|█▋        | 34/200 [01:05<03:10,  1.15s/it]Text relay (seed 42):  18%|█▊        | 35/200 [01:07<03:07,  1.13s/it]Text relay (seed 42):  18%|█▊        | 36/200 [01:08<03:04,  1.13s/it]Text relay (seed 42):  18%|█▊        | 37/200 [01:09<03:02,  1.12s/it]Text relay (seed 42):  19%|█▉        | 38/200 [01:10<03:00,  1.12s/it]Text relay (seed 42):  20%|█▉        | 39/200 [01:11<03:00,  1.12s/it]Text relay (seed 42):  20%|██        | 40/200 [01:12<02:58,  1.12s/it]Text relay (seed 42):  20%|██        | 41/200 [01:13<02:58,  1.12s/it]Text relay (seed 42):  21%|██        | 42/200 [01:14<02:56,  1.12s/it]Text relay (seed 42):  22%|██▏       | 43/200 [01:15<02:54,  1.11s/it]Text relay (seed 42):  22%|██▏       | 44/200 [01:17<02:53,  1.11s/it]Text relay (seed 42):  22%|██▎       | 45/200 [01:18<02:52,  1.11s/it]Text relay (seed 42):  23%|██▎       | 46/200 [01:19<02:50,  1.11s/it]Text relay (seed 42):  24%|██▎       | 47/200 [01:20<02:49,  1.11s/it]Text relay (seed 42):  24%|██▍       | 48/200 [01:21<02:48,  1.11s/it]Text relay (seed 42):  24%|██▍       | 49/200 [01:22<02:47,  1.11s/it]Text relay (seed 42):  25%|██▌       | 50/200 [01:23<02:45,  1.11s/it]Text relay (seed 42):  26%|██▌       | 51/200 [01:24<02:44,  1.11s/it]Text relay (seed 42):  26%|██▌       | 52/200 [01:25<02:43,  1.10s/it]Text relay (seed 42):  26%|██▋       | 53/200 [01:27<02:41,  1.10s/it]Text relay (seed 42):  27%|██▋       | 54/200 [01:28<02:40,  1.10s/it]Text relay (seed 42):  28%|██▊       | 55/200 [01:29<02:39,  1.10s/it]Text relay (seed 42):  28%|██▊       | 56/200 [01:30<02:38,  1.10s/it]Text relay (seed 42):  28%|██▊       | 57/200 [01:31<02:38,  1.11s/it]Text relay (seed 42):  29%|██▉       | 58/200 [01:32<02:37,  1.11s/it]Text relay (seed 42):  30%|██▉       | 59/200 [01:33<02:36,  1.11s/it]Text relay (seed 42):  30%|███       | 60/200 [01:34<02:34,  1.11s/it]Text relay (seed 42):  30%|███       | 61/200 [01:35<02:33,  1.10s/it]Text relay (seed 42):  31%|███       | 62/200 [01:36<02:32,  1.11s/it]Text relay (seed 42):  32%|███▏      | 63/200 [01:38<02:31,  1.11s/it]Text relay (seed 42):  32%|███▏      | 64/200 [01:39<02:30,  1.10s/it]Text relay (seed 42):  32%|███▎      | 65/200 [01:40<02:28,  1.10s/it]Text relay (seed 42):  33%|███▎      | 66/200 [01:41<02:28,  1.11s/it]Text relay (seed 42):  34%|███▎      | 67/200 [01:42<02:27,  1.11s/it]Text relay (seed 42):  34%|███▍      | 68/200 [01:43<02:26,  1.11s/it]Text relay (seed 42):  34%|███▍      | 69/200 [01:44<02:25,  1.11s/it]Text relay (seed 42):  35%|███▌      | 70/200 [01:45<02:23,  1.11s/it]Text relay (seed 42):  36%|███▌      | 71/200 [01:46<02:22,  1.10s/it]Text relay (seed 42):  36%|███▌      | 72/200 [01:48<02:21,  1.10s/it]Text relay (seed 42):  36%|███▋      | 73/200 [01:49<02:20,  1.10s/it]Text relay (seed 42):  37%|███▋      | 74/200 [01:50<02:19,  1.11s/it]Text relay (seed 42):  38%|███▊      | 75/200 [01:51<02:18,  1.11s/it]Text relay (seed 42):  38%|███▊      | 76/200 [01:52<02:17,  1.11s/it]Text relay (seed 42):  38%|███▊      | 77/200 [01:53<02:15,  1.11s/it]Text relay (seed 42):  39%|███▉      | 78/200 [01:54<02:14,  1.10s/it]Text relay (seed 42):  40%|███▉      | 79/200 [01:55<02:13,  1.10s/it]Text relay (seed 42):  40%|████      | 80/200 [01:56<02:12,  1.11s/it]Text relay (seed 42):  40%|████      | 81/200 [01:58<02:11,  1.11s/it]Text relay (seed 42):  41%|████      | 82/200 [01:59<02:10,  1.10s/it]Text relay (seed 42):  42%|████▏     | 83/200 [02:00<02:09,  1.10s/it]Text relay (seed 42):  42%|████▏     | 84/200 [02:01<02:07,  1.10s/it]Text relay (seed 42):  42%|████▎     | 85/200 [02:02<02:06,  1.10s/it]Text relay (seed 42):  43%|████▎     | 86/200 [02:03<02:05,  1.10s/it]Text relay (seed 42):  44%|████▎     | 87/200 [02:04<02:04,  1.10s/it]Text relay (seed 42):  44%|████▍     | 88/200 [02:05<02:03,  1.10s/it]Text relay (seed 42):  44%|████▍     | 89/200 [02:06<02:02,  1.10s/it]Text relay (seed 42):  45%|████▌     | 90/200 [02:07<02:01,  1.10s/it]Text relay (seed 42):  46%|████▌     | 91/200 [02:09<02:00,  1.10s/it]Text relay (seed 42):  46%|████▌     | 92/200 [02:10<01:59,  1.10s/it]Text relay (seed 42):  46%|████▋     | 93/200 [02:11<01:58,  1.11s/it]Text relay (seed 42):  47%|████▋     | 94/200 [02:12<01:57,  1.11s/it]Text relay (seed 42):  48%|████▊     | 95/200 [02:13<01:56,  1.11s/it]Text relay (seed 42):  48%|████▊     | 96/200 [02:14<01:55,  1.11s/it]Text relay (seed 42):  48%|████▊     | 97/200 [02:15<01:53,  1.10s/it]Text relay (seed 42):  49%|████▉     | 98/200 [02:16<01:52,  1.10s/it]Text relay (seed 42):  50%|████▉     | 99/200 [02:17<01:51,  1.10s/it]Text relay (seed 42):  50%|█████     | 100/200 [02:18<01:50,  1.10s/it]Text relay (seed 42):  50%|█████     | 101/200 [02:20<01:49,  1.10s/it]Text relay (seed 42):  51%|█████     | 102/200 [02:21<01:47,  1.10s/it]Text relay (seed 42):  52%|█████▏    | 103/200 [02:22<01:46,  1.10s/it]Text relay (seed 42):  52%|█████▏    | 104/200 [02:23<01:45,  1.10s/it]Text relay (seed 42):  52%|█████▎    | 105/200 [02:24<01:44,  1.10s/it]Text relay (seed 42):  53%|█████▎    | 106/200 [02:25<01:43,  1.11s/it]Text relay (seed 42):  54%|█████▎    | 107/200 [02:26<01:42,  1.11s/it]Text relay (seed 42):  54%|█████▍    | 108/200 [02:27<01:41,  1.10s/it]Text relay (seed 42):  55%|█████▍    | 109/200 [02:28<01:40,  1.10s/it]Text relay (seed 42):  55%|█████▌    | 110/200 [02:29<01:39,  1.10s/it]Text relay (seed 42):  56%|█████▌    | 111/200 [02:31<01:38,  1.10s/it]Text relay (seed 42):  56%|█████▌    | 112/200 [02:32<01:36,  1.10s/it]Text relay (seed 42):  56%|█████▋    | 113/200 [02:33<01:35,  1.10s/it]Text relay (seed 42):  57%|█████▋    | 114/200 [02:34<01:34,  1.10s/it]Text relay (seed 42):  57%|█████▊    | 115/200 [02:35<01:33,  1.10s/it]Text relay (seed 42):  58%|█████▊    | 116/200 [02:36<01:32,  1.10s/it]Text relay (seed 42):  58%|█████▊    | 117/200 [02:37<01:31,  1.10s/it]Text relay (seed 42):  59%|█████▉    | 118/200 [02:38<01:30,  1.10s/it]Text relay (seed 42):  60%|█████▉    | 119/200 [02:39<01:31,  1.12s/it]Text relay (seed 42):  60%|██████    | 120/200 [02:41<01:30,  1.13s/it]Text relay (seed 42):  60%|██████    | 121/200 [02:42<01:28,  1.12s/it]Text relay (seed 42):  61%|██████    | 122/200 [02:43<01:26,  1.11s/it]Text relay (seed 42):  62%|██████▏   | 123/200 [02:44<01:25,  1.12s/it]Text relay (seed 42):  62%|██████▏   | 124/200 [02:45<01:24,  1.11s/it]Text relay (seed 42):  62%|██████▎   | 125/200 [02:46<01:23,  1.11s/it]Text relay (seed 42):  63%|██████▎   | 126/200 [02:47<01:21,  1.11s/it]Text relay (seed 42):  64%|██████▎   | 127/200 [02:48<01:20,  1.10s/it]Text relay (seed 42):  64%|██████▍   | 128/200 [02:49<01:19,  1.11s/it]Text relay (seed 42):  64%|██████▍   | 129/200 [02:51<01:18,  1.11s/it]Text relay (seed 42):  65%|██████▌   | 130/200 [02:52<01:17,  1.10s/it]Text relay (seed 42):  66%|██████▌   | 131/200 [02:53<01:16,  1.10s/it]Text relay (seed 42):  66%|██████▌   | 132/200 [02:54<01:15,  1.10s/it]Text relay (seed 42):  66%|██████▋   | 133/200 [02:55<01:13,  1.10s/it]Text relay (seed 42):  67%|██████▋   | 134/200 [02:56<01:12,  1.10s/it]Text relay (seed 42):  68%|██████▊   | 135/200 [02:57<01:11,  1.11s/it]Text relay (seed 42):  68%|██████▊   | 136/200 [02:58<01:10,  1.11s/it]Text relay (seed 42):  68%|██████▊   | 137/200 [02:59<01:09,  1.11s/it]Text relay (seed 42):  69%|██████▉   | 138/200 [03:01<01:08,  1.11s/it]Text relay (seed 42):  70%|██████▉   | 139/200 [03:02<01:07,  1.11s/it]Text relay (seed 42):  70%|███████   | 140/200 [03:03<01:06,  1.11s/it]Text relay (seed 42):  70%|███████   | 141/200 [03:04<01:05,  1.10s/it]Text relay (seed 42):  71%|███████   | 142/200 [03:05<01:04,  1.10s/it]Text relay (seed 42):  72%|███████▏  | 143/200 [03:06<01:02,  1.10s/it]Text relay (seed 42):  72%|███████▏  | 144/200 [03:07<01:01,  1.10s/it]Text relay (seed 42):  72%|███████▎  | 145/200 [03:08<01:00,  1.10s/it]Text relay (seed 42):  73%|███████▎  | 146/200 [03:09<00:59,  1.10s/it]Text relay (seed 42):  74%|███████▎  | 147/200 [03:10<00:58,  1.11s/it]Text relay (seed 42):  74%|███████▍  | 148/200 [03:12<00:57,  1.11s/it]Text relay (seed 42):  74%|███████▍  | 149/200 [03:13<00:56,  1.11s/it]Text relay (seed 42):  75%|███████▌  | 150/200 [03:14<00:55,  1.10s/it]Text relay (seed 42):  76%|███████▌  | 151/200 [03:15<00:54,  1.10s/it]Text relay (seed 42):  76%|███████▌  | 152/200 [03:16<00:53,  1.11s/it]Text relay (seed 42):  76%|███████▋  | 153/200 [03:17<00:51,  1.11s/it]Text relay (seed 42):  77%|███████▋  | 154/200 [03:18<00:50,  1.10s/it]Text relay (seed 42):  78%|███████▊  | 155/200 [03:19<00:49,  1.10s/it]Text relay (seed 42):  78%|███████▊  | 156/200 [03:20<00:48,  1.10s/it]Text relay (seed 42):  78%|███████▊  | 157/200 [03:21<00:47,  1.10s/it]Text relay (seed 42):  79%|███████▉  | 158/200 [03:23<00:46,  1.10s/it]Text relay (seed 42):  80%|███████▉  | 159/200 [03:24<00:45,  1.10s/it]Text relay (seed 42):  80%|████████  | 160/200 [03:25<00:44,  1.10s/it]Text relay (seed 42):  80%|████████  | 161/200 [03:26<00:42,  1.10s/it]Text relay (seed 42):  81%|████████  | 162/200 [03:27<00:41,  1.10s/it]Text relay (seed 42):  82%|████████▏ | 163/200 [03:28<00:40,  1.10s/it]Text relay (seed 42):  82%|████████▏ | 164/200 [03:29<00:39,  1.10s/it]Text relay (seed 42):  82%|████████▎ | 165/200 [03:30<00:38,  1.10s/it]Text relay (seed 42):  83%|████████▎ | 166/200 [03:31<00:37,  1.10s/it]Text relay (seed 42):  84%|████████▎ | 167/200 [03:33<00:36,  1.11s/it]Text relay (seed 42):  84%|████████▍ | 168/200 [03:34<00:35,  1.11s/it]Text relay (seed 42):  84%|████████▍ | 169/200 [03:35<00:34,  1.11s/it]Text relay (seed 42):  85%|████████▌ | 170/200 [03:36<00:33,  1.11s/it]Text relay (seed 42):  86%|████████▌ | 171/200 [03:37<00:32,  1.11s/it]Text relay (seed 42):  86%|████████▌ | 172/200 [03:38<00:30,  1.11s/it]Text relay (seed 42):  86%|████████▋ | 173/200 [03:39<00:29,  1.10s/it]Text relay (seed 42):  87%|████████▋ | 174/200 [03:40<00:28,  1.11s/it]Text relay (seed 42):  88%|████████▊ | 175/200 [03:41<00:27,  1.11s/it]Text relay (seed 42):  88%|████████▊ | 176/200 [03:42<00:26,  1.11s/it]Text relay (seed 42):  88%|████████▊ | 177/200 [03:44<00:25,  1.11s/it]Text relay (seed 42):  89%|████████▉ | 178/200 [03:45<00:24,  1.11s/it]Text relay (seed 42):  90%|████████▉ | 179/200 [03:46<00:23,  1.11s/it]Text relay (seed 42):  90%|█████████ | 180/200 [03:47<00:22,  1.11s/it]Text relay (seed 42):  90%|█████████ | 181/200 [03:48<00:21,  1.11s/it]Text relay (seed 42):  91%|█████████ | 182/200 [03:49<00:19,  1.11s/it]Text relay (seed 42):  92%|█████████▏| 183/200 [03:50<00:18,  1.10s/it]Text relay (seed 42):  92%|█████████▏| 184/200 [03:51<00:17,  1.10s/it]Text relay (seed 42):  92%|█████████▎| 185/200 [03:52<00:16,  1.10s/it]Text relay (seed 42):  93%|█████████▎| 186/200 [03:54<00:15,  1.10s/it]Text relay (seed 42):  94%|█████████▎| 187/200 [03:55<00:14,  1.10s/it]Text relay (seed 42):  94%|█████████▍| 188/200 [03:56<00:13,  1.10s/it]Text relay (seed 42):  94%|█████████▍| 189/200 [03:57<00:12,  1.10s/it]Text relay (seed 42):  95%|█████████▌| 190/200 [03:58<00:11,  1.10s/it]Text relay (seed 42):  96%|█████████▌| 191/200 [03:59<00:09,  1.10s/it]Text relay (seed 42):  96%|█████████▌| 192/200 [04:00<00:08,  1.10s/it]Text relay (seed 42):  96%|█████████▋| 193/200 [04:01<00:07,  1.10s/it]Text relay (seed 42):  97%|█████████▋| 194/200 [04:02<00:06,  1.10s/it]Text relay (seed 42):  98%|█████████▊| 195/200 [04:03<00:05,  1.10s/it]Text relay (seed 42):  98%|█████████▊| 196/200 [04:05<00:04,  1.10s/it]Text relay (seed 42):  98%|█████████▊| 197/200 [04:06<00:03,  1.10s/it]Text relay (seed 42):  99%|█████████▉| 198/200 [04:07<00:02,  1.10s/it]Text relay (seed 42): 100%|█████████▉| 199/200 [04:08<00:01,  1.10s/it]Text relay (seed 42): 100%|██████████| 200/200 [04:09<00:00,  1.10s/it]Text relay (seed 42): 100%|██████████| 200/200 [04:09<00:00,  1.25s/it]
Seed 42: 23.5% (47/200)
  Example hints generated by Llama:
    Text: Which statement best explains why photosynthesis is the foundation of most food webs?...
    Hint: A - A scientific explanation of a natural phenomenon
B - A personal experience or anecdote
C - A persuasive argument or opinion
D - A historical account or event
Answer: A - A scientific explanation of a natural phenomenon
Explanation: This
    True: A

    Text: Which piece of safety equipment is used to keep mold spores from entering the respiratory system?...
    Hint: The answer is not a mask.
A) A respirator is used to keep mold spores from entering the respiratory system.
B) A respirator is used to keep mold spores from entering the respiratory system.
C) A respirator is used
    True: B

    Text: Meiosis is a type of cell division in which germ cells divide to produce haploid cells. Where does m...
    Hint: A, B, C, D
Answer: B
Explanation: The text is about a scientific topic, specifically a biological process. The question is asking for a location, which is a common type of question in science. Therefore, the category is
    True: D


--- Seed 123 ---
Loading Llama (sender)...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2759.86it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:06,  2.02s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.99s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.96s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.39s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.61s/it]
Loading Mistral (receiver)...
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2832.08it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:03,  1.88s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:03<00:01,  1.91s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.94s/it]
Text relay (seed 123):   0%|          | 0/200 [00:00<?, ?it/s]/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Text relay (seed 123):   0%|          | 1/200 [00:01<03:44,  1.13s/it]Text relay (seed 123):   1%|          | 2/200 [00:02<03:40,  1.11s/it]Text relay (seed 123):   2%|▏         | 3/200 [00:03<03:37,  1.11s/it]Text relay (seed 123):   2%|▏         | 4/200 [00:04<03:36,  1.10s/it]Text relay (seed 123):   2%|▎         | 5/200 [00:05<03:34,  1.10s/it]Text relay (seed 123):   3%|▎         | 6/200 [00:06<03:33,  1.10s/it]Text relay (seed 123):   4%|▎         | 7/200 [00:07<03:32,  1.10s/it]Text relay (seed 123):   4%|▍         | 8/200 [00:08<03:31,  1.10s/it]Text relay (seed 123):   4%|▍         | 9/200 [00:09<03:31,  1.11s/it]Text relay (seed 123):   5%|▌         | 10/200 [00:11<03:31,  1.11s/it]Text relay (seed 123):   6%|▌         | 11/200 [00:12<03:30,  1.11s/it]Text relay (seed 123):   6%|▌         | 12/200 [00:13<03:29,  1.11s/it]Text relay (seed 123):   6%|▋         | 13/200 [00:14<03:28,  1.11s/it]Text relay (seed 123):   7%|▋         | 14/200 [00:15<03:30,  1.13s/it]Text relay (seed 123):   8%|▊         | 15/200 [00:16<03:28,  1.13s/it]Text relay (seed 123):   8%|▊         | 16/200 [00:17<03:29,  1.14s/it]Text relay (seed 123):   8%|▊         | 17/200 [00:18<03:27,  1.13s/it]Text relay (seed 123):   9%|▉         | 18/200 [00:20<03:25,  1.13s/it]Text relay (seed 123):  10%|▉         | 19/200 [00:21<03:23,  1.12s/it]Text relay (seed 123):  10%|█         | 20/200 [00:22<03:21,  1.12s/it]Text relay (seed 123):  10%|█         | 21/200 [00:23<03:21,  1.12s/it]Text relay (seed 123):  11%|█         | 22/200 [00:24<03:19,  1.12s/it]Text relay (seed 123):  12%|█▏        | 23/200 [00:25<03:17,  1.12s/it]Text relay (seed 123):  12%|█▏        | 24/200 [00:26<03:16,  1.12s/it]Text relay (seed 123):  12%|█▎        | 25/200 [00:27<03:14,  1.11s/it]Text relay (seed 123):  13%|█▎        | 26/200 [00:29<03:13,  1.11s/it]Text relay (seed 123):  14%|█▎        | 27/200 [00:30<03:12,  1.11s/it]Text relay (seed 123):  14%|█▍        | 28/200 [00:31<03:10,  1.11s/it]Text relay (seed 123):  14%|█▍        | 29/200 [00:32<03:09,  1.11s/it]Text relay (seed 123):  15%|█▌        | 30/200 [00:33<03:09,  1.11s/it]Text relay (seed 123):  16%|█▌        | 31/200 [00:34<03:08,  1.11s/it]Text relay (seed 123):  16%|█▌        | 32/200 [00:35<03:06,  1.11s/it]Text relay (seed 123):  16%|█▋        | 33/200 [00:36<03:05,  1.11s/it]Text relay (seed 123):  17%|█▋        | 34/200 [00:37<03:04,  1.11s/it]Text relay (seed 123):  18%|█▊        | 35/200 [00:39<03:03,  1.11s/it]Text relay (seed 123):  18%|█▊        | 36/200 [00:40<03:02,  1.11s/it]Text relay (seed 123):  18%|█▊        | 37/200 [00:41<03:01,  1.11s/it]Text relay (seed 123):  19%|█▉        | 38/200 [00:42<03:00,  1.11s/it]Text relay (seed 123):  20%|█▉        | 39/200 [00:43<02:58,  1.11s/it]Text relay (seed 123):  20%|██        | 40/200 [00:44<02:57,  1.11s/it]Text relay (seed 123):  20%|██        | 41/200 [00:45<02:56,  1.11s/it]Text relay (seed 123):  21%|██        | 42/200 [00:46<02:55,  1.11s/it]Text relay (seed 123):  22%|██▏       | 43/200 [00:47<02:55,  1.12s/it]Text relay (seed 123):  22%|██▏       | 44/200 [00:49<02:54,  1.12s/it]Text relay (seed 123):  22%|██▎       | 45/200 [00:50<02:52,  1.11s/it]Text relay (seed 123):  23%|██▎       | 46/200 [00:51<02:51,  1.12s/it]Text relay (seed 123):  24%|██▎       | 47/200 [00:52<02:50,  1.12s/it]Text relay (seed 123):  24%|██▍       | 48/200 [00:53<02:50,  1.12s/it]Text relay (seed 123):  24%|██▍       | 49/200 [00:54<02:48,  1.12s/it]Text relay (seed 123):  25%|██▌       | 50/200 [00:55<02:47,  1.12s/it]Text relay (seed 123):  26%|██▌       | 51/200 [00:56<02:45,  1.11s/it]Text relay (seed 123):  26%|██▌       | 52/200 [00:57<02:44,  1.11s/it]Text relay (seed 123):  26%|██▋       | 53/200 [00:59<02:43,  1.11s/it]Text relay (seed 123):  27%|██▋       | 54/200 [01:00<02:42,  1.11s/it]Text relay (seed 123):  28%|██▊       | 55/200 [01:01<02:40,  1.11s/it]Text relay (seed 123):  28%|██▊       | 56/200 [01:02<02:39,  1.11s/it]Text relay (seed 123):  28%|██▊       | 57/200 [01:03<02:38,  1.11s/it]Text relay (seed 123):  29%|██▉       | 58/200 [01:04<02:36,  1.10s/it]Text relay (seed 123):  30%|██▉       | 59/200 [01:05<02:35,  1.10s/it]Text relay (seed 123):  30%|███       | 60/200 [01:06<02:34,  1.10s/it]Text relay (seed 123):  30%|███       | 61/200 [01:07<02:33,  1.10s/it]Text relay (seed 123):  31%|███       | 62/200 [01:09<02:32,  1.11s/it]Text relay (seed 123):  32%|███▏      | 63/200 [01:10<02:32,  1.11s/it]Text relay (seed 123):  32%|███▏      | 64/200 [01:11<02:30,  1.11s/it]Text relay (seed 123):  32%|███▎      | 65/200 [01:12<02:29,  1.11s/it]Text relay (seed 123):  33%|███▎      | 66/200 [01:13<02:28,  1.11s/it]Text relay (seed 123):  34%|███▎      | 67/200 [01:14<02:27,  1.11s/it]Text relay (seed 123):  34%|███▍      | 68/200 [01:15<02:26,  1.11s/it]Text relay (seed 123):  34%|███▍      | 69/200 [01:16<02:25,  1.11s/it]Text relay (seed 123):  35%|███▌      | 70/200 [01:17<02:25,  1.12s/it]Text relay (seed 123):  36%|███▌      | 71/200 [01:19<02:24,  1.12s/it]Text relay (seed 123):  36%|███▌      | 72/200 [01:20<02:22,  1.11s/it]Text relay (seed 123):  36%|███▋      | 73/200 [01:21<02:21,  1.11s/it]Text relay (seed 123):  37%|███▋      | 74/200 [01:22<02:20,  1.12s/it]Text relay (seed 123):  38%|███▊      | 75/200 [01:23<02:19,  1.12s/it]Text relay (seed 123):  38%|███▊      | 76/200 [01:24<02:18,  1.12s/it]Text relay (seed 123):  38%|███▊      | 77/200 [01:25<02:16,  1.11s/it]Text relay (seed 123):  39%|███▉      | 78/200 [01:26<02:15,  1.11s/it]Text relay (seed 123):  40%|███▉      | 79/200 [01:27<02:14,  1.11s/it]Text relay (seed 123):  40%|████      | 80/200 [01:29<02:13,  1.11s/it]Text relay (seed 123):  40%|████      | 81/200 [01:30<02:12,  1.11s/it]Text relay (seed 123):  41%|████      | 82/200 [01:31<02:11,  1.11s/it]Text relay (seed 123):  42%|████▏     | 83/200 [01:32<02:09,  1.11s/it]Text relay (seed 123):  42%|████▏     | 84/200 [01:33<02:08,  1.11s/it]Text relay (seed 123):  42%|████▎     | 85/200 [01:34<02:07,  1.11s/it]Text relay (seed 123):  43%|████▎     | 86/200 [01:35<02:06,  1.11s/it]Text relay (seed 123):  44%|████▎     | 87/200 [01:36<02:05,  1.11s/it]Text relay (seed 123):  44%|████▍     | 88/200 [01:37<02:04,  1.11s/it]Text relay (seed 123):  44%|████▍     | 89/200 [01:39<02:03,  1.11s/it]Text relay (seed 123):  45%|████▌     | 90/200 [01:40<02:01,  1.11s/it]Text relay (seed 123):  46%|████▌     | 91/200 [01:41<02:01,  1.11s/it]Text relay (seed 123):  46%|████▌     | 92/200 [01:42<01:59,  1.11s/it]Text relay (seed 123):  46%|████▋     | 93/200 [01:43<01:58,  1.11s/it]Text relay (seed 123):  47%|████▋     | 94/200 [01:44<01:57,  1.11s/it]Text relay (seed 123):  48%|████▊     | 95/200 [01:45<01:56,  1.11s/it]Text relay (seed 123):  48%|████▊     | 96/200 [01:46<01:55,  1.11s/it]Text relay (seed 123):  48%|████▊     | 97/200 [01:47<01:55,  1.12s/it]Text relay (seed 123):  49%|████▉     | 98/200 [01:49<01:54,  1.12s/it]Text relay (seed 123):  50%|████▉     | 99/200 [01:50<01:52,  1.12s/it]Text relay (seed 123):  50%|█████     | 100/200 [01:51<01:51,  1.12s/it]Text relay (seed 123):  50%|█████     | 101/200 [01:52<01:50,  1.11s/it]Text relay (seed 123):  51%|█████     | 102/200 [01:53<01:49,  1.11s/it]Text relay (seed 123):  52%|█████▏    | 103/200 [01:54<01:48,  1.12s/it]Text relay (seed 123):  52%|█████▏    | 104/200 [01:55<01:48,  1.13s/it]Text relay (seed 123):  52%|█████▎    | 105/200 [01:56<01:46,  1.12s/it]Text relay (seed 123):  53%|█████▎    | 106/200 [01:58<01:45,  1.12s/it]Text relay (seed 123):  54%|█████▎    | 107/200 [01:59<01:44,  1.12s/it]Text relay (seed 123):  54%|█████▍    | 108/200 [02:00<01:42,  1.12s/it]Text relay (seed 123):  55%|█████▍    | 109/200 [02:01<01:41,  1.12s/it]Text relay (seed 123):  55%|█████▌    | 110/200 [02:02<01:40,  1.12s/it]Text relay (seed 123):  56%|█████▌    | 111/200 [02:03<01:39,  1.12s/it]Text relay (seed 123):  56%|█████▌    | 112/200 [02:04<01:38,  1.11s/it]Text relay (seed 123):  56%|█████▋    | 113/200 [02:05<01:36,  1.11s/it]Text relay (seed 123):  57%|█████▋    | 114/200 [02:06<01:35,  1.11s/it]Text relay (seed 123):  57%|█████▊    | 115/200 [02:08<01:34,  1.11s/it]Text relay (seed 123):  58%|█████▊    | 116/200 [02:09<01:33,  1.11s/it]Text relay (seed 123):  58%|█████▊    | 117/200 [02:10<01:32,  1.11s/it]Text relay (seed 123):  59%|█████▉    | 118/200 [02:11<01:31,  1.11s/it]Text relay (seed 123):  60%|█████▉    | 119/200 [02:12<01:29,  1.11s/it]Text relay (seed 123):  60%|██████    | 120/200 [02:13<01:28,  1.11s/it]Text relay (seed 123):  60%|██████    | 121/200 [02:14<01:27,  1.11s/it]Text relay (seed 123):  61%|██████    | 122/200 [02:15<01:27,  1.12s/it]Text relay (seed 123):  62%|██████▏   | 123/200 [02:16<01:26,  1.13s/it]Text relay (seed 123):  62%|██████▏   | 124/200 [02:18<01:25,  1.12s/it]Text relay (seed 123):  62%|██████▎   | 125/200 [02:19<01:23,  1.12s/it]Text relay (seed 123):  63%|██████▎   | 126/200 [02:20<01:22,  1.12s/it]Text relay (seed 123):  64%|██████▎   | 127/200 [02:21<01:21,  1.11s/it]Text relay (seed 123):  64%|██████▍   | 128/200 [02:22<01:20,  1.11s/it]Text relay (seed 123):  64%|██████▍   | 129/200 [02:23<01:19,  1.11s/it]Text relay (seed 123):  65%|██████▌   | 130/200 [02:24<01:17,  1.11s/it]Text relay (seed 123):  66%|██████▌   | 131/200 [02:25<01:16,  1.11s/it]Text relay (seed 123):  66%|██████▌   | 132/200 [02:26<01:15,  1.11s/it]Text relay (seed 123):  66%|██████▋   | 133/200 [02:28<01:14,  1.11s/it]Text relay (seed 123):  67%|██████▋   | 134/200 [02:29<01:13,  1.11s/it]Text relay (seed 123):  68%|██████▊   | 135/200 [02:30<01:12,  1.11s/it]Text relay (seed 123):  68%|██████▊   | 136/200 [02:31<01:11,  1.11s/it]Text relay (seed 123):  68%|██████▊   | 137/200 [02:32<01:10,  1.11s/it]Text relay (seed 123):  69%|██████▉   | 138/200 [02:33<01:08,  1.11s/it]Text relay (seed 123):  70%|██████▉   | 139/200 [02:34<01:07,  1.11s/it]Text relay (seed 123):  70%|███████   | 140/200 [02:35<01:06,  1.11s/it]Text relay (seed 123):  70%|███████   | 141/200 [02:36<01:05,  1.11s/it]Text relay (seed 123):  71%|███████   | 142/200 [02:38<01:04,  1.11s/it]Text relay (seed 123):  72%|███████▏  | 143/200 [02:39<01:03,  1.11s/it]Text relay (seed 123):  72%|███████▏  | 144/200 [02:40<01:02,  1.11s/it]Text relay (seed 123):  72%|███████▎  | 145/200 [02:41<01:01,  1.11s/it]Text relay (seed 123):  73%|███████▎  | 146/200 [02:42<01:00,  1.12s/it]Text relay (seed 123):  74%|███████▎  | 147/200 [02:43<00:59,  1.12s/it]Text relay (seed 123):  74%|███████▍  | 148/200 [02:44<00:57,  1.11s/it]Text relay (seed 123):  74%|███████▍  | 149/200 [02:45<00:56,  1.11s/it]Text relay (seed 123):  75%|███████▌  | 150/200 [02:47<00:56,  1.12s/it]Text relay (seed 123):  76%|███████▌  | 151/200 [02:48<00:54,  1.12s/it]Text relay (seed 123):  76%|███████▌  | 152/200 [02:49<00:53,  1.12s/it]Text relay (seed 123):  76%|███████▋  | 153/200 [02:50<00:52,  1.12s/it]Text relay (seed 123):  77%|███████▋  | 154/200 [02:51<00:51,  1.12s/it]Text relay (seed 123):  78%|███████▊  | 155/200 [02:52<00:50,  1.11s/it]Text relay (seed 123):  78%|███████▊  | 156/200 [02:53<00:48,  1.11s/it]Text relay (seed 123):  78%|███████▊  | 157/200 [02:54<00:47,  1.11s/it]Text relay (seed 123):  79%|███████▉  | 158/200 [02:55<00:46,  1.12s/it]Text relay (seed 123):  80%|███████▉  | 159/200 [02:57<00:45,  1.12s/it]Text relay (seed 123):  80%|████████  | 160/200 [02:58<00:44,  1.12s/it]Text relay (seed 123):  80%|████████  | 161/200 [02:59<00:43,  1.11s/it]Text relay (seed 123):  81%|████████  | 162/200 [03:00<00:42,  1.11s/it]Text relay (seed 123):  82%|████████▏ | 163/200 [03:01<00:41,  1.11s/it]Text relay (seed 123):  82%|████████▏ | 164/200 [03:02<00:39,  1.11s/it]Text relay (seed 123):  82%|████████▎ | 165/200 [03:03<00:38,  1.11s/it]Text relay (seed 123):  83%|████████▎ | 166/200 [03:04<00:37,  1.11s/it]Text relay (seed 123):  84%|████████▎ | 167/200 [03:05<00:36,  1.11s/it]Text relay (seed 123):  84%|████████▍ | 168/200 [03:07<00:35,  1.11s/it]Text relay (seed 123):  84%|████████▍ | 169/200 [03:08<00:34,  1.11s/it]Text relay (seed 123):  85%|████████▌ | 170/200 [03:09<00:33,  1.11s/it]Text relay (seed 123):  86%|████████▌ | 171/200 [03:10<00:32,  1.11s/it]Text relay (seed 123):  86%|████████▌ | 172/200 [03:11<00:31,  1.11s/it]Text relay (seed 123):  86%|████████▋ | 173/200 [03:12<00:29,  1.11s/it]Text relay (seed 123):  87%|████████▋ | 174/200 [03:13<00:28,  1.11s/it]Text relay (seed 123):  88%|████████▊ | 175/200 [03:14<00:27,  1.11s/it]Text relay (seed 123):  88%|████████▊ | 176/200 [03:15<00:26,  1.11s/it]Text relay (seed 123):  88%|████████▊ | 177/200 [03:17<00:25,  1.12s/it]Text relay (seed 123):  89%|████████▉ | 178/200 [03:18<00:24,  1.11s/it]Text relay (seed 123):  90%|████████▉ | 179/200 [03:19<00:23,  1.11s/it]Text relay (seed 123):  90%|█████████ | 180/200 [03:20<00:22,  1.11s/it]Text relay (seed 123):  90%|█████████ | 181/200 [03:21<00:21,  1.11s/it]Text relay (seed 123):  91%|█████████ | 182/200 [03:22<00:19,  1.11s/it]Text relay (seed 123):  92%|█████████▏| 183/200 [03:23<00:18,  1.11s/it]Text relay (seed 123):  92%|█████████▏| 184/200 [03:24<00:17,  1.11s/it]Text relay (seed 123):  92%|█████████▎| 185/200 [03:25<00:16,  1.11s/it]Text relay (seed 123):  93%|█████████▎| 186/200 [03:27<00:15,  1.11s/it]Text relay (seed 123):  94%|█████████▎| 187/200 [03:28<00:14,  1.11s/it]Text relay (seed 123):  94%|█████████▍| 188/200 [03:29<00:13,  1.11s/it]Text relay (seed 123):  94%|█████████▍| 189/200 [03:30<00:12,  1.11s/it]Text relay (seed 123):  95%|█████████▌| 190/200 [03:31<00:11,  1.11s/it]Text relay (seed 123):  96%|█████████▌| 191/200 [03:32<00:10,  1.11s/it]Text relay (seed 123):  96%|█████████▌| 192/200 [03:33<00:08,  1.11s/it]Text relay (seed 123):  96%|█████████▋| 193/200 [03:34<00:07,  1.11s/it]Text relay (seed 123):  97%|█████████▋| 194/200 [03:35<00:06,  1.12s/it]Text relay (seed 123):  98%|█████████▊| 195/200 [03:37<00:05,  1.12s/it]Text relay (seed 123):  98%|█████████▊| 196/200 [03:38<00:04,  1.12s/it]Text relay (seed 123):  98%|█████████▊| 197/200 [03:39<00:03,  1.11s/it]Text relay (seed 123):  99%|█████████▉| 198/200 [03:40<00:02,  1.11s/it]Text relay (seed 123): 100%|█████████▉| 199/200 [03:41<00:01,  1.11s/it]Text relay (seed 123): 100%|██████████| 200/200 [03:42<00:00,  1.11s/it]Text relay (seed 123): 100%|██████████| 200/200 [03:42<00:00,  1.11s/it]
Seed 123: 23.5% (47/200)
  Example hints generated by Llama:
    Text: Which statement best explains why photosynthesis is the foundation of most food webs?...
    Hint: A - A scientific explanation of a natural phenomenon
B - A personal experience or anecdote
C - A persuasive argument or opinion
D - A historical account or event
Answer: A - A scientific explanation of a natural phenomenon
Explanation: This
    True: A

    Text: Which piece of safety equipment is used to keep mold spores from entering the respiratory system?...
    Hint: The answer is not a mask.
A) A respirator is used to keep mold spores from entering the respiratory system.
B) A respirator is used to keep mold spores from entering the respiratory system.
C) A respirator is used
    True: B

    Text: Meiosis is a type of cell division in which germ cells divide to produce haploid cells. Where does m...
    Hint: A, B, C, D
Answer: B
Explanation: The text is about a scientific topic, specifically a biological process. The question is asking for a location, which is a common type of question in science. Therefore, the category is
    True: D


--- Seed 456 ---
Loading Llama (sender)...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2174.34it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:05,  2.00s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:04<00:04,  2.01s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.98s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.62s/it]
Loading Mistral (receiver)...
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2128.73it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:03,  1.90s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:03<00:01,  1.92s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.87s/it]
Text relay (seed 456):   0%|          | 0/200 [00:00<?, ?it/s]/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Text relay (seed 456):   0%|          | 1/200 [00:01<03:46,  1.14s/it]Text relay (seed 456):   1%|          | 2/200 [00:02<03:41,  1.12s/it]Text relay (seed 456):   2%|▏         | 3/200 [00:03<03:39,  1.11s/it]Text relay (seed 456):   2%|▏         | 4/200 [00:04<03:36,  1.11s/it]Text relay (seed 456):   2%|▎         | 5/200 [00:05<03:35,  1.10s/it]Text relay (seed 456):   3%|▎         | 6/200 [00:06<03:33,  1.10s/it]Text relay (seed 456):   4%|▎         | 7/200 [00:07<03:32,  1.10s/it]Text relay (seed 456):   4%|▍         | 8/200 [00:08<03:30,  1.10s/it]Text relay (seed 456):   4%|▍         | 9/200 [00:09<03:29,  1.10s/it]Text relay (seed 456):   5%|▌         | 10/200 [00:11<03:28,  1.10s/it]Text relay (seed 456):   6%|▌         | 11/200 [00:12<03:27,  1.10s/it]Text relay (seed 456):   6%|▌         | 12/200 [00:13<03:26,  1.10s/it]Text relay (seed 456):   6%|▋         | 13/200 [00:14<03:25,  1.10s/it]Text relay (seed 456):   7%|▋         | 14/200 [00:15<03:23,  1.10s/it]Text relay (seed 456):   8%|▊         | 15/200 [00:16<03:22,  1.10s/it]Text relay (seed 456):   8%|▊         | 16/200 [00:17<03:21,  1.10s/it]Text relay (seed 456):   8%|▊         | 17/200 [00:18<03:23,  1.11s/it]Text relay (seed 456):   9%|▉         | 18/200 [00:19<03:22,  1.11s/it]Text relay (seed 456):  10%|▉         | 19/200 [00:21<03:22,  1.12s/it]Text relay (seed 456):  10%|█         | 20/200 [00:22<03:20,  1.11s/it]Text relay (seed 456):  10%|█         | 21/200 [00:23<03:18,  1.11s/it]Text relay (seed 456):  11%|█         | 22/200 [00:24<03:16,  1.10s/it]Text relay (seed 456):  12%|█▏        | 23/200 [00:25<03:14,  1.10s/it]Text relay (seed 456):  12%|█▏        | 24/200 [00:26<03:13,  1.10s/it]Text relay (seed 456):  12%|█▎        | 25/200 [00:27<03:12,  1.10s/it]Text relay (seed 456):  13%|█▎        | 26/200 [00:28<03:11,  1.10s/it]Text relay (seed 456):  14%|█▎        | 27/200 [00:29<03:10,  1.10s/it]Text relay (seed 456):  14%|█▍        | 28/200 [00:30<03:10,  1.11s/it]Text relay (seed 456):  14%|█▍        | 29/200 [00:31<03:08,  1.10s/it]Text relay (seed 456):  15%|█▌        | 30/200 [00:33<03:07,  1.10s/it]Text relay (seed 456):  16%|█▌        | 31/200 [00:34<03:06,  1.10s/it]Text relay (seed 456):  16%|█▌        | 32/200 [00:35<03:04,  1.10s/it]Text relay (seed 456):  16%|█▋        | 33/200 [00:36<03:03,  1.10s/it]Text relay (seed 456):  17%|█▋        | 34/200 [00:37<03:03,  1.10s/it]Text relay (seed 456):  18%|█▊        | 35/200 [00:38<03:02,  1.10s/it]Text relay (seed 456):  18%|█▊        | 36/200 [00:39<03:01,  1.11s/it]Text relay (seed 456):  18%|█▊        | 37/200 [00:40<03:00,  1.11s/it]Text relay (seed 456):  19%|█▉        | 38/200 [00:41<02:59,  1.11s/it]Text relay (seed 456):  20%|█▉        | 39/200 [00:43<02:58,  1.11s/it]Text relay (seed 456):  20%|██        | 40/200 [00:44<02:57,  1.11s/it]Text relay (seed 456):  20%|██        | 41/200 [00:45<02:56,  1.11s/it]Text relay (seed 456):  21%|██        | 42/200 [00:46<02:55,  1.11s/it]Text relay (seed 456):  22%|██▏       | 43/200 [00:47<02:55,  1.12s/it]Text relay (seed 456):  22%|██▏       | 44/200 [00:48<02:54,  1.12s/it]Text relay (seed 456):  22%|██▎       | 45/200 [00:49<02:52,  1.11s/it]Text relay (seed 456):  23%|██▎       | 46/200 [00:50<02:52,  1.12s/it]Text relay (seed 456):  24%|██▎       | 47/200 [00:51<02:50,  1.12s/it]Text relay (seed 456):  24%|██▍       | 48/200 [00:53<02:49,  1.12s/it]Text relay (seed 456):  24%|██▍       | 49/200 [00:54<02:48,  1.11s/it]Text relay (seed 456):  25%|██▌       | 50/200 [00:55<02:46,  1.11s/it]Text relay (seed 456):  26%|██▌       | 51/200 [00:56<02:45,  1.11s/it]Text relay (seed 456):  26%|██▌       | 52/200 [00:57<02:44,  1.11s/it]Text relay (seed 456):  26%|██▋       | 53/200 [00:58<02:43,  1.11s/it]Text relay (seed 456):  27%|██▋       | 54/200 [00:59<02:42,  1.11s/it]Text relay (seed 456):  28%|██▊       | 55/200 [01:00<02:42,  1.12s/it]Text relay (seed 456):  28%|██▊       | 56/200 [01:02<02:41,  1.12s/it]Text relay (seed 456):  28%|██▊       | 57/200 [01:03<02:39,  1.12s/it]Text relay (seed 456):  29%|██▉       | 58/200 [01:04<02:38,  1.12s/it]Text relay (seed 456):  30%|██▉       | 59/200 [01:05<02:37,  1.12s/it]Text relay (seed 456):  30%|███       | 60/200 [01:06<02:36,  1.12s/it]Text relay (seed 456):  30%|███       | 61/200 [01:07<02:34,  1.12s/it]Text relay (seed 456):  31%|███       | 62/200 [01:08<02:33,  1.11s/it]Text relay (seed 456):  32%|███▏      | 63/200 [01:09<02:32,  1.11s/it]Text relay (seed 456):  32%|███▏      | 64/200 [01:10<02:30,  1.11s/it]Text relay (seed 456):  32%|███▎      | 65/200 [01:12<02:29,  1.11s/it]Text relay (seed 456):  33%|███▎      | 66/200 [01:13<02:28,  1.11s/it]Text relay (seed 456):  34%|███▎      | 67/200 [01:14<02:27,  1.11s/it]Text relay (seed 456):  34%|███▍      | 68/200 [01:15<02:26,  1.11s/it]Text relay (seed 456):  34%|███▍      | 69/200 [01:16<02:25,  1.11s/it]Text relay (seed 456):  35%|███▌      | 70/200 [01:17<02:24,  1.11s/it]Text relay (seed 456):  36%|███▌      | 71/200 [01:18<02:23,  1.11s/it]Text relay (seed 456):  36%|███▌      | 72/200 [01:19<02:22,  1.11s/it]Text relay (seed 456):  36%|███▋      | 73/200 [01:20<02:22,  1.12s/it]Text relay (seed 456):  37%|███▋      | 74/200 [01:22<02:20,  1.12s/it]Text relay (seed 456):  38%|███▊      | 75/200 [01:23<02:19,  1.12s/it]Text relay (seed 456):  38%|███▊      | 76/200 [01:24<02:18,  1.12s/it]Text relay (seed 456):  38%|███▊      | 77/200 [01:25<02:17,  1.12s/it]Text relay (seed 456):  39%|███▉      | 78/200 [01:26<02:16,  1.12s/it]Text relay (seed 456):  40%|███▉      | 79/200 [01:27<02:14,  1.12s/it]Text relay (seed 456):  40%|████      | 80/200 [01:28<02:13,  1.12s/it]Text relay (seed 456):  40%|████      | 81/200 [01:29<02:12,  1.11s/it]Text relay (seed 456):  41%|████      | 82/200 [01:30<02:11,  1.12s/it]Text relay (seed 456):  42%|████▏     | 83/200 [01:32<02:10,  1.11s/it]Text relay (seed 456):  42%|████▏     | 84/200 [01:33<02:09,  1.11s/it]Text relay (seed 456):  42%|████▎     | 85/200 [01:34<02:08,  1.11s/it]Text relay (seed 456):  43%|████▎     | 86/200 [01:35<02:07,  1.11s/it]Text relay (seed 456):  44%|████▎     | 87/200 [01:36<02:05,  1.11s/it]Text relay (seed 456):  44%|████▍     | 88/200 [01:37<02:04,  1.12s/it]Text relay (seed 456):  44%|████▍     | 89/200 [01:38<02:03,  1.11s/it]Text relay (seed 456):  45%|████▌     | 90/200 [01:39<02:02,  1.11s/it]Text relay (seed 456):  46%|████▌     | 91/200 [01:40<02:01,  1.11s/it]Text relay (seed 456):  46%|████▌     | 92/200 [01:42<01:59,  1.11s/it]Text relay (seed 456):  46%|████▋     | 93/200 [01:43<01:58,  1.11s/it]Text relay (seed 456):  47%|████▋     | 94/200 [01:44<01:57,  1.11s/it]Text relay (seed 456):  48%|████▊     | 95/200 [01:45<01:56,  1.11s/it]Text relay (seed 456):  48%|████▊     | 96/200 [01:46<01:55,  1.11s/it]Text relay (seed 456):  48%|████▊     | 97/200 [01:47<01:54,  1.11s/it]Text relay (seed 456):  49%|████▉     | 98/200 [01:48<01:53,  1.11s/it]Text relay (seed 456):  50%|████▉     | 99/200 [01:49<01:52,  1.11s/it]Text relay (seed 456):  50%|█████     | 100/200 [01:50<01:51,  1.12s/it]Text relay (seed 456):  50%|█████     | 101/200 [01:52<01:50,  1.12s/it]Text relay (seed 456):  51%|█████     | 102/200 [01:53<01:49,  1.12s/it]Text relay (seed 456):  52%|█████▏    | 103/200 [01:54<01:48,  1.11s/it]Text relay (seed 456):  52%|█████▏    | 104/200 [01:55<01:46,  1.11s/it]Text relay (seed 456):  52%|█████▎    | 105/200 [01:56<01:45,  1.11s/it]Text relay (seed 456):  53%|█████▎    | 106/200 [01:57<01:44,  1.11s/it]Text relay (seed 456):  54%|█████▎    | 107/200 [01:58<01:43,  1.11s/it]Text relay (seed 456):  54%|█████▍    | 108/200 [01:59<01:42,  1.11s/it]Text relay (seed 456):  55%|█████▍    | 109/200 [02:01<01:41,  1.12s/it]Text relay (seed 456):  55%|█████▌    | 110/200 [02:02<01:41,  1.13s/it]Text relay (seed 456):  56%|█████▌    | 111/200 [02:03<01:39,  1.12s/it]Text relay (seed 456):  56%|█████▌    | 112/200 [02:04<01:38,  1.12s/it]Text relay (seed 456):  56%|█████▋    | 113/200 [02:05<01:36,  1.11s/it]Text relay (seed 456):  57%|█████▋    | 114/200 [02:06<01:35,  1.11s/it]Text relay (seed 456):  57%|█████▊    | 115/200 [02:07<01:34,  1.11s/it]Text relay (seed 456):  58%|█████▊    | 116/200 [02:08<01:33,  1.11s/it]Text relay (seed 456):  58%|█████▊    | 117/200 [02:09<01:31,  1.11s/it]Text relay (seed 456):  59%|█████▉    | 118/200 [02:11<01:30,  1.11s/it]Text relay (seed 456):  60%|█████▉    | 119/200 [02:12<01:29,  1.11s/it]Text relay (seed 456):  60%|██████    | 120/200 [02:13<01:29,  1.12s/it]Text relay (seed 456):  60%|██████    | 121/200 [02:14<01:28,  1.12s/it]Text relay (seed 456):  61%|██████    | 122/200 [02:15<01:27,  1.12s/it]Text relay (seed 456):  62%|██████▏   | 123/200 [02:16<01:25,  1.12s/it]Text relay (seed 456):  62%|██████▏   | 124/200 [02:17<01:24,  1.11s/it]Text relay (seed 456):  62%|██████▎   | 125/200 [02:18<01:24,  1.13s/it]Text relay (seed 456):  63%|██████▎   | 126/200 [02:19<01:22,  1.12s/it]Text relay (seed 456):  64%|██████▎   | 127/200 [02:21<01:22,  1.13s/it]Text relay (seed 456):  64%|██████▍   | 128/200 [02:22<01:20,  1.12s/it]Text relay (seed 456):  64%|██████▍   | 129/200 [02:23<01:19,  1.12s/it]Text relay (seed 456):  65%|██████▌   | 130/200 [02:24<01:18,  1.12s/it]Text relay (seed 456):  66%|██████▌   | 131/200 [02:25<01:17,  1.12s/it]Text relay (seed 456):  66%|██████▌   | 132/200 [02:26<01:15,  1.12s/it]Text relay (seed 456):  66%|██████▋   | 133/200 [02:27<01:14,  1.12s/it]Text relay (seed 456):  67%|██████▋   | 134/200 [02:28<01:13,  1.12s/it]Text relay (seed 456):  68%|██████▊   | 135/200 [02:30<01:12,  1.12s/it]Text relay (seed 456):  68%|██████▊   | 136/200 [02:31<01:11,  1.12s/it]Text relay (seed 456):  68%|██████▊   | 137/200 [02:32<01:10,  1.12s/it]Text relay (seed 456):  69%|██████▉   | 138/200 [02:33<01:09,  1.11s/it]Text relay (seed 456):  70%|██████▉   | 139/200 [02:34<01:07,  1.11s/it]Text relay (seed 456):  70%|███████   | 140/200 [02:35<01:06,  1.11s/it]Text relay (seed 456):  70%|███████   | 141/200 [02:36<01:05,  1.11s/it]Text relay (seed 456):  71%|███████   | 142/200 [02:37<01:04,  1.11s/it]Text relay (seed 456):  72%|███████▏  | 143/200 [02:38<01:03,  1.11s/it]Text relay (seed 456):  72%|███████▏  | 144/200 [02:40<01:02,  1.11s/it]Text relay (seed 456):  72%|███████▎  | 145/200 [02:41<01:00,  1.11s/it]Text relay (seed 456):  73%|███████▎  | 146/200 [02:42<00:59,  1.11s/it]Text relay (seed 456):  74%|███████▎  | 147/200 [02:43<00:58,  1.11s/it]Text relay (seed 456):  74%|███████▍  | 148/200 [02:44<00:57,  1.11s/it]Text relay (seed 456):  74%|███████▍  | 149/200 [02:45<00:56,  1.11s/it]Text relay (seed 456):  75%|███████▌  | 150/200 [02:46<00:55,  1.10s/it]Text relay (seed 456):  76%|███████▌  | 151/200 [02:47<00:54,  1.10s/it]Text relay (seed 456):  76%|███████▌  | 152/200 [02:48<00:53,  1.11s/it]Text relay (seed 456):  76%|███████▋  | 153/200 [02:50<00:52,  1.11s/it]Text relay (seed 456):  77%|███████▋  | 154/200 [02:51<00:51,  1.12s/it]Text relay (seed 456):  78%|███████▊  | 155/200 [02:52<00:50,  1.11s/it]Text relay (seed 456):  78%|███████▊  | 156/200 [02:53<00:48,  1.11s/it]Text relay (seed 456):  78%|███████▊  | 157/200 [02:54<00:47,  1.11s/it]Text relay (seed 456):  79%|███████▉  | 158/200 [02:55<00:46,  1.11s/it]Text relay (seed 456):  80%|███████▉  | 159/200 [02:56<00:45,  1.10s/it]Text relay (seed 456):  80%|████████  | 160/200 [02:57<00:44,  1.10s/it]Text relay (seed 456):  80%|████████  | 161/200 [02:58<00:42,  1.10s/it]Text relay (seed 456):  81%|████████  | 162/200 [02:59<00:41,  1.10s/it]Text relay (seed 456):  82%|████████▏ | 163/200 [03:01<00:40,  1.10s/it]Text relay (seed 456):  82%|████████▏ | 164/200 [03:02<00:39,  1.10s/it]Text relay (seed 456):  82%|████████▎ | 165/200 [03:03<00:38,  1.10s/it]Text relay (seed 456):  83%|████████▎ | 166/200 [03:04<00:37,  1.10s/it]Text relay (seed 456):  84%|████████▎ | 167/200 [03:05<00:36,  1.10s/it]Text relay (seed 456):  84%|████████▍ | 168/200 [03:06<00:35,  1.10s/it]Text relay (seed 456):  84%|████████▍ | 169/200 [03:07<00:34,  1.10s/it]Text relay (seed 456):  85%|████████▌ | 170/200 [03:08<00:33,  1.10s/it]Text relay (seed 456):  86%|████████▌ | 171/200 [03:09<00:32,  1.10s/it]Text relay (seed 456):  86%|████████▌ | 172/200 [03:10<00:30,  1.10s/it]Text relay (seed 456):  86%|████████▋ | 173/200 [03:12<00:29,  1.10s/it]Text relay (seed 456):  87%|████████▋ | 174/200 [03:13<00:28,  1.10s/it]Text relay (seed 456):  88%|████████▊ | 175/200 [03:14<00:27,  1.10s/it]Text relay (seed 456):  88%|████████▊ | 176/200 [03:15<00:26,  1.11s/it]Text relay (seed 456):  88%|████████▊ | 177/200 [03:16<00:25,  1.11s/it]Text relay (seed 456):  89%|████████▉ | 178/200 [03:17<00:24,  1.11s/it]Text relay (seed 456):  90%|████████▉ | 179/200 [03:18<00:23,  1.11s/it]Text relay (seed 456):  90%|█████████ | 180/200 [03:19<00:22,  1.11s/it]Text relay (seed 456):  90%|█████████ | 181/200 [03:20<00:21,  1.12s/it]Text relay (seed 456):  91%|█████████ | 182/200 [03:22<00:20,  1.12s/it]Text relay (seed 456):  92%|█████████▏| 183/200 [03:23<00:18,  1.12s/it]Text relay (seed 456):  92%|█████████▏| 184/200 [03:24<00:17,  1.11s/it]Text relay (seed 456):  92%|█████████▎| 185/200 [03:25<00:16,  1.11s/it]Text relay (seed 456):  93%|█████████▎| 186/200 [03:26<00:15,  1.11s/it]Text relay (seed 456):  94%|█████████▎| 187/200 [03:27<00:14,  1.11s/it]Text relay (seed 456):  94%|█████████▍| 188/200 [03:28<00:13,  1.11s/it]Text relay (seed 456):  94%|█████████▍| 189/200 [03:29<00:12,  1.10s/it]Text relay (seed 456):  95%|█████████▌| 190/200 [03:30<00:11,  1.11s/it]Text relay (seed 456):  96%|█████████▌| 191/200 [03:32<00:09,  1.11s/it]Text relay (seed 456):  96%|█████████▌| 192/200 [03:33<00:08,  1.12s/it]Text relay (seed 456):  96%|█████████▋| 193/200 [03:34<00:07,  1.12s/it]Text relay (seed 456):  97%|█████████▋| 194/200 [03:35<00:06,  1.11s/it]Text relay (seed 456):  98%|█████████▊| 195/200 [03:36<00:05,  1.11s/it]Text relay (seed 456):  98%|█████████▊| 196/200 [03:37<00:04,  1.11s/it]Text relay (seed 456):  98%|█████████▊| 197/200 [03:38<00:03,  1.11s/it]Text relay (seed 456):  99%|█████████▉| 198/200 [03:39<00:02,  1.10s/it]Text relay (seed 456): 100%|█████████▉| 199/200 [03:40<00:01,  1.10s/it]Text relay (seed 456): 100%|██████████| 200/200 [03:42<00:00,  1.11s/it]Text relay (seed 456): 100%|██████████| 200/200 [03:42<00:00,  1.11s/it]
Seed 456: 23.5% (47/200)
  Example hints generated by Llama:
    Text: Which statement best explains why photosynthesis is the foundation of most food webs?...
    Hint: A - A scientific explanation of a natural phenomenon
B - A personal experience or anecdote
C - A persuasive argument or opinion
D - A historical account or event
Answer: A - A scientific explanation of a natural phenomenon
Explanation: This
    True: A

    Text: Which piece of safety equipment is used to keep mold spores from entering the respiratory system?...
    Hint: The answer is not a mask.
A) A respirator is used to keep mold spores from entering the respiratory system.
B) A respirator is used to keep mold spores from entering the respiratory system.
C) A respirator is used
    True: B

    Text: Meiosis is a type of cell division in which germ cells divide to produce haploid cells. Where does m...
    Hint: A, B, C, D
Answer: B
Explanation: The text is about a scientific topic, specifically a biological process. The question is asking for a location, which is a common type of question in science. Therefore, the category is
    True: D


Text Relay (Llama->Mistral): 23.5% +/- 0.0%
Random baseline: 25.0%

Results saved to: runs/reasoning_final_20260119_122501/baselines/text_relay/text_relay_arc_easy_20260119_123851.json
[2026-01-19 12:51:24] SUCCESS: text_relay_arc_easy
Completed: text_relay_arc_easy

[2026-01-19 12:51:24] [GPU 0] Running Ensemble Baseline on ARC-Easy
Started: ensemble_arc_easy
[2026-01-19 12:51:24] START: ensemble_arc_easy
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Device: cuda:0

======================================================================
ENSEMBLE BASELINE: ARC_EASY
======================================================================
Testing whether ensembling Llama + Mistral achieves bridge performance.
Testing alpha values: [0.3, 0.5, 0.7]

Collecting logits from Llama...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2390.60it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:06,  2.01s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:04<00:04,  2.01s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.99s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.63s/it]
Evaluating Llama:   0%|          | 0/200 [00:00<?, ?it/s]Evaluating Llama:   0%|          | 1/200 [00:00<01:01,  3.22it/s]Evaluating Llama:   4%|▎         | 7/200 [00:00<00:09, 19.95it/s]Evaluating Llama:   6%|▋         | 13/200 [00:00<00:06, 30.62it/s]Evaluating Llama:  10%|▉         | 19/200 [00:00<00:04, 37.75it/s]Evaluating Llama:  12%|█▎        | 25/200 [00:00<00:04, 42.62it/s]Evaluating Llama:  16%|█▌        | 31/200 [00:00<00:03, 46.01it/s]Evaluating Llama:  18%|█▊        | 37/200 [00:00<00:03, 48.32it/s]Evaluating Llama:  22%|██▏       | 43/200 [00:01<00:03, 50.02it/s]Evaluating Llama:  24%|██▍       | 49/200 [00:01<00:02, 50.41it/s]Evaluating Llama:  28%|██▊       | 55/200 [00:01<00:02, 51.22it/s]Evaluating Llama:  30%|███       | 61/200 [00:01<00:02, 52.00it/s]Evaluating Llama:  34%|███▎      | 67/200 [00:01<00:02, 52.51it/s]Evaluating Llama:  36%|███▋      | 73/200 [00:01<00:02, 52.93it/s]Evaluating Llama:  40%|███▉      | 79/200 [00:01<00:02, 53.06it/s]Evaluating Llama:  42%|████▎     | 85/200 [00:01<00:02, 53.23it/s]Evaluating Llama:  46%|████▌     | 91/200 [00:02<00:02, 53.35it/s]Evaluating Llama:  48%|████▊     | 97/200 [00:02<00:01, 53.33it/s]Evaluating Llama:  52%|█████▏    | 103/200 [00:02<00:01, 53.45it/s]Evaluating Llama:  55%|█████▍    | 109/200 [00:02<00:01, 53.34it/s]Evaluating Llama:  57%|█████▊    | 115/200 [00:02<00:01, 53.48it/s]Evaluating Llama:  60%|██████    | 121/200 [00:02<00:01, 53.51it/s]Evaluating Llama:  64%|██████▎   | 127/200 [00:02<00:01, 53.55it/s]Evaluating Llama:  66%|██████▋   | 133/200 [00:02<00:01, 53.64it/s]Evaluating Llama:  70%|██████▉   | 139/200 [00:02<00:01, 53.72it/s]Evaluating Llama:  72%|███████▎  | 145/200 [00:03<00:01, 53.78it/s]Evaluating Llama:  76%|███████▌  | 151/200 [00:03<00:00, 53.80it/s]Evaluating Llama:  78%|███████▊  | 157/200 [00:03<00:00, 53.87it/s]Evaluating Llama:  82%|████████▏ | 163/200 [00:03<00:00, 53.73it/s]Evaluating Llama:  84%|████████▍ | 169/200 [00:03<00:00, 53.67it/s]Evaluating Llama:  88%|████████▊ | 175/200 [00:03<00:00, 53.70it/s]Evaluating Llama:  90%|█████████ | 181/200 [00:03<00:00, 53.70it/s]Evaluating Llama:  94%|█████████▎| 187/200 [00:03<00:00, 53.84it/s]Evaluating Llama:  96%|█████████▋| 193/200 [00:03<00:00, 53.89it/s]Evaluating Llama: 100%|█████████▉| 199/200 [00:04<00:00, 53.89it/s]Evaluating Llama: 100%|██████████| 200/200 [00:04<00:00, 49.59it/s]
Llama individual: 21.0% (42/200)

Collecting logits from Mistral...
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2016.82it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:02<00:04,  2.30s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:04<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.00s/it]
Evaluating Mistral:   0%|          | 0/200 [00:00<?, ?it/s]Evaluating Mistral:   2%|▎         | 5/200 [00:00<00:04, 44.43it/s]Evaluating Mistral:   5%|▌         | 10/200 [00:00<00:04, 45.58it/s]Evaluating Mistral:   8%|▊         | 15/200 [00:00<00:04, 46.15it/s]Evaluating Mistral:  10%|█         | 20/200 [00:00<00:03, 45.02it/s]Evaluating Mistral:  12%|█▎        | 25/200 [00:00<00:03, 45.52it/s]Evaluating Mistral:  15%|█▌        | 30/200 [00:00<00:03, 45.85it/s]Evaluating Mistral:  18%|█▊        | 35/200 [00:00<00:03, 45.98it/s]Evaluating Mistral:  20%|██        | 40/200 [00:00<00:03, 46.17it/s]Evaluating Mistral:  22%|██▎       | 45/200 [00:00<00:03, 46.33it/s]Evaluating Mistral:  25%|██▌       | 50/200 [00:01<00:03, 46.44it/s]Evaluating Mistral:  28%|██▊       | 55/200 [00:01<00:03, 46.57it/s]Evaluating Mistral:  30%|███       | 60/200 [00:01<00:03, 46.63it/s]Evaluating Mistral:  32%|███▎      | 65/200 [00:01<00:02, 46.62it/s]Evaluating Mistral:  35%|███▌      | 70/200 [00:01<00:02, 46.55it/s]Evaluating Mistral:  38%|███▊      | 75/200 [00:01<00:02, 46.73it/s]Evaluating Mistral:  40%|████      | 80/200 [00:01<00:02, 46.82it/s]Evaluating Mistral:  42%|████▎     | 85/200 [00:01<00:02, 46.46it/s]Evaluating Mistral:  45%|████▌     | 90/200 [00:01<00:02, 46.38it/s]Evaluating Mistral:  48%|████▊     | 95/200 [00:02<00:02, 46.51it/s]Evaluating Mistral:  50%|█████     | 100/200 [00:02<00:02, 46.66it/s]Evaluating Mistral:  52%|█████▎    | 105/200 [00:02<00:02, 46.63it/s]Evaluating Mistral:  55%|█████▌    | 110/200 [00:02<00:01, 46.62it/s]Evaluating Mistral:  57%|█████▊    | 115/200 [00:02<00:01, 46.66it/s]Evaluating Mistral:  60%|██████    | 120/200 [00:02<00:01, 46.74it/s]Evaluating Mistral:  62%|██████▎   | 125/200 [00:02<00:01, 46.85it/s]Evaluating Mistral:  65%|██████▌   | 130/200 [00:02<00:01, 46.80it/s]Evaluating Mistral:  68%|██████▊   | 135/200 [00:02<00:01, 46.88it/s]Evaluating Mistral:  70%|███████   | 140/200 [00:03<00:01, 46.96it/s]Evaluating Mistral:  72%|███████▎  | 145/200 [00:03<00:01, 47.09it/s]Evaluating Mistral:  75%|███████▌  | 150/200 [00:03<00:01, 46.84it/s]Evaluating Mistral:  78%|███████▊  | 155/200 [00:03<00:00, 46.79it/s]Evaluating Mistral:  80%|████████  | 160/200 [00:03<00:00, 46.89it/s]Evaluating Mistral:  82%|████████▎ | 165/200 [00:03<00:00, 46.79it/s]Evaluating Mistral:  85%|████████▌ | 170/200 [00:03<00:00, 46.79it/s]Evaluating Mistral:  88%|████████▊ | 175/200 [00:03<00:00, 46.76it/s]Evaluating Mistral:  90%|█████████ | 180/200 [00:03<00:00, 46.77it/s]Evaluating Mistral:  92%|█████████▎| 185/200 [00:03<00:00, 46.86it/s]Evaluating Mistral:  95%|█████████▌| 190/200 [00:04<00:00, 46.89it/s]Evaluating Mistral:  98%|█████████▊| 195/200 [00:04<00:00, 46.80it/s]Evaluating Mistral: 100%|██████████| 200/200 [00:04<00:00, 46.79it/s]Evaluating Mistral: 100%|██████████| 200/200 [00:04<00:00, 46.57it/s]
Mistral individual: 24.0% (48/200)

--------------------------------------------------
Computing ensemble accuracies...
--------------------------------------------------
Ensemble (alpha=0.3): 26.0% (52/200)
Ensemble (alpha=0.5): 25.0% (50/200)
Ensemble (alpha=0.7): 24.0% (48/200)

--- Probability-space ensemble (softmax then average) ---
Prob Ensemble (alpha=0.3): 25.0% (50/200)
Prob Ensemble (alpha=0.5): 25.0% (50/200)
Prob Ensemble (alpha=0.7): 24.5% (49/200)

==================================================
BEST ENSEMBLE: alpha=0.3, accuracy=26.0%
==================================================

Results saved to: runs/reasoning_final_20260119_122501/baselines/ensemble/ensemble_arc_easy_20260119_125129.json
[2026-01-19 12:51:54] SUCCESS: ensemble_arc_easy
Completed: ensemble_arc_easy
[2026-01-19 12:51:54] [GPU 0] All evaluations completed
[2026-01-19 12:51:54] GPU 0 finished
[2026-01-19 12:51:54] GPU 1 finished

==============================================================
AGGREGATING REASONING RESULTS
==============================================================
======================================================================
REASONING BENCHMARK RESULTS (Publication Ready)
======================================================================

ZERO-SHOT BASELINE (no training):
----------------------------------------
  arc_easy     | Llama      | 21.0%
  arc_easy     | Mistral    | 24.0%

FEW-SHOT BASELINE (4-shot):
----------------------------------------
  arc_easy     | Llama      | 24.8% +/- 0.5%
  arc_easy     | Mistral    | 26.0% +/- 2.1%

DORA BASELINE (rank=8, SOTA 2024):
----------------------------------------

PROMPT TUNING BASELINE (8 tokens, no sender):
----------------------------------------

NOVEL BRIDGES (ARC-Easy):
----------------------------------------

HAIL MARY BRIDGES (ARC-Easy):
----------------------------------------

TOKEN CAPACITY (ARC-Easy):
----------------------------------------

LATENCY BENCHMARKS:
----------------------------------------

BATCHED LATENCY (samples/sec by batch size):
----------------------------------------
======================================================================

==============================================================
EXPERIMENT SUMMARY
==============================================================
Total experiments run: 0
Successful: 0
Failed: 0
Skipped (already completed): 0

Registry summary:
{
  "total": 32,
  "completed": 4,
  "failed": 26,
  "pending": 0,
  "running": 2,
  "needs_rerun": 0,
  "by_error_category": {
    "unknown": 25,
    "keyerror": 1
  }
}
==============================================================
[main 1a6e228] Reasoning experiments: job 151015 - 0/0 succeeded, 0 skipped
 38 files changed, 2482 insertions(+), 16 deletions(-)
 create mode 100644 runs/reasoning_final_20260119_122501/baselines/dora_arc_easy.log
 create mode 100644 runs/reasoning_final_20260119_122501/baselines/ensemble/ensemble_arc_easy_20260119_125129.json
 create mode 100644 runs/reasoning_final_20260119_122501/baselines/ensemble_arc_easy.log
 create mode 100644 runs/reasoning_final_20260119_122501/baselines/fewshot/fewshot_arc_easy_20260119_122639.json
 create mode 100644 runs/reasoning_final_20260119_122501/baselines/fewshot_arc_easy.log
 create mode 100644 runs/reasoning_final_20260119_122501/baselines/fewshot_boolq.log
 create mode 100644 runs/reasoning_final_20260119_122501/baselines/fewshot_hellaswag.log
 create mode 100644 runs/reasoning_final_20260119_122501/baselines/fewshot_winogrande.log
 create mode 100644 runs/reasoning_final_20260119_122501/baselines/linear_probe.log
 create mode 100644 runs/reasoning_final_20260119_122501/baselines/linear_probe/arc_easy_results.json
 create mode 100644 runs/reasoning_final_20260119_122501/baselines/prompt_tuning_arc_easy.log
 create mode 100644 runs/reasoning_final_20260119_122501/baselines/ridge_regression_arc_easy.log
 create mode 100644 runs/reasoning_final_20260119_122501/baselines/text_relay/text_relay_arc_easy_20260119_123851.json
 create mode 100644 runs/reasoning_final_20260119_122501/baselines/text_relay_arc_easy.log
 create mode 100644 runs/reasoning_final_20260119_122501/baselines/zeroshot/zeroshot_arc_easy_20260119_122510.json
 create mode 100644 runs/reasoning_final_20260119_122501/baselines/zeroshot_arc_easy.log
 create mode 100644 runs/reasoning_final_20260119_122501/baselines/zeroshot_boolq.log
 create mode 100644 runs/reasoning_final_20260119_122501/baselines/zeroshot_hellaswag.log
 create mode 100644 runs/reasoning_final_20260119_122501/baselines/zeroshot_winogrande.log
 create mode 100644 runs/reasoning_final_20260119_122501/benchmarks/batched_latency.log
 create mode 100644 runs/reasoning_final_20260119_122501/benchmarks/latency.log
 create mode 100644 runs/reasoning_final_20260119_122501/benchmarks/memory.log
 create mode 100644 runs/reasoning_final_20260119_122501/benchmarks/throughput.log
 create mode 100644 runs/reasoning_final_20260119_122501/experiment_errors.log
 create mode 100644 runs/reasoning_final_20260119_122501/novel_bridges/flow_matching_arc_easy_seed42.log
 create mode 100644 runs/reasoning_final_20260119_122501/novel_bridges/hailmary_cross_modal_distillation_arc_easy_seed42.log
 create mode 100644 runs/reasoning_final_20260119_122501/novel_bridges/hailmary_domain_adversarial_arc_easy_seed42.log
 create mode 100644 runs/reasoning_final_20260119_122501/novel_bridges/hailmary_mine_arc_easy_seed42.log
 create mode 100644 runs/reasoning_final_20260119_122501/novel_bridges/hailmary_mixture_of_depths_arc_easy_seed42.log
 create mode 100644 runs/reasoning_final_20260119_122501/novel_bridges/hailmary_successive_refinement_arc_easy_seed42.log
 create mode 100644 runs/reasoning_final_20260119_122501/novel_bridges/hailmary_thalamic_relay_arc_easy_seed42.log
 create mode 100644 runs/reasoning_final_20260119_122501/novel_bridges/optimal_transport_arc_easy_seed42.log
 create mode 100644 runs/reasoning_final_20260119_122501/novel_bridges/token_capacity_16_seed42.log
 create mode 100644 runs/reasoning_final_20260119_122501/novel_bridges/token_capacity_32_seed42.log
 create mode 100644 runs/reasoning_final_20260119_122501/novel_bridges/token_capacity_4_seed42.log
 create mode 100644 runs/reasoning_final_20260119_122501/novel_bridges/token_capacity_8_seed42.log
 create mode 100644 runs/reasoning_final_20260119_122501/reasoning_results_summary.json
[2026-01-19 12:51:55] Git push attempt 1 of 3
[2026-01-19 12:51:56] Git push successful

==============================================================
REASONING EXPERIMENTS COMPLETED (Publication Ready)
==============================================================
Job ID: 151015
End time: Mon Jan 19 12:51:56 PM PST 2026
Total runtime: 1615 seconds (0h 26m)

KEY EXPERIMENTS:
  1. Standard bridge on reasoning? (hail_mary)
  2. Zero-shot baseline? (baselines/zeroshot/)
  3. Few-shot baseline (4-shot)? (baselines/fewshot/)
  4. DoRA baseline (SOTA 2024)? (baselines/dora/)
  5. Prompt tuning (does sender help)? (baselines/prompt_tuning/)
  6. Linear probe upper bound? (baselines/linear_probe/)
  7. Novel bridges help? (novel_bridges/)
  8. More tokens help? (token_capacity: 4, 8, 16, 32)
  9. Latency advantage? (benchmarks/latency)
 10. Batched throughput scaling? (benchmarks/batched) - MLSys Critical

Results: runs/reasoning_final_20260119_122501
==============================================================
[2026-01-19 12:51:56] Job ending with exit code: 0
On branch main
Your branch is up to date with 'origin/main'.

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	runs/reasoning_final_151015.err
	runs/reasoning_final_151015.log

nothing added to commit but untracked files present (use "git add" to track)
[2026-01-19 12:51:57] Git push attempt 1 of 3
[2026-01-19 12:51:58] Git push successful
