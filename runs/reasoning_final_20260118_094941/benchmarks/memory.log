/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Device: cuda:1
GPU: NVIDIA H100 80GB HBM3

======================================================================
MEMORY BENCHMARK
======================================================================

--- Direct Mistral Inference ---
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 1864.41it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:05<00:11,  5.60s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:10<00:05,  5.09s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:14<00:00,  4.72s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:14<00:00,  4.87s/it]
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  Peak memory: 0 MB

--- LoRA Training (rank=8) ---
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2129.45it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:04<00:09,  4.69s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:09<00:04,  4.64s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:13<00:00,  4.67s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:13<00:00,  4.67s/it]
  Peak memory: 0 MB, Trainable: 3,407,872

--- Bridge Training (8 tokens) ---
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2069.73it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:14,  4.69s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:09<00:09,  4.98s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:14<00:04,  4.80s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.42s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.94s/it]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2227.46it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:04<00:09,  4.60s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:09<00:04,  4.66s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:14<00:00,  4.77s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:14<00:00,  4.74s/it]
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_benchmarks.py", line 658, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_benchmarks.py", line 630, in main
    results = run_memory_benchmark(args, device)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_benchmarks.py", line 477, in run_memory_benchmark
    outputs = mistral(inputs_embeds=latents, labels=inputs.input_ids)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py", line 1095, in forward
    loss = loss_fct(shift_logits, shift_labels)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py", line 1293, in forward
    return F.cross_entropy(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/functional.py", line 3479, in cross_entropy
    return torch._C._nn.cross_entropy_loss(
ValueError: Expected input batch_size (7) to match target batch_size (1).
