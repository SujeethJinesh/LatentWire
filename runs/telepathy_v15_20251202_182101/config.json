{
    "run_id": "telepathy_v15_20251202_182101",
    "phase": 15,
    "approach": "FSQ-Telepathy (Finite Scalar Quantization)",
    "source_model": "meta-llama/Meta-Llama-3.1-8B-Instruct",
    "target_model": "mistralai/Mistral-7B-Instruct-v0.3",
    "source_layer": 16,
    "soft_tokens": 128,
    "depth": 4,
    "heads": 8,
    "fsq_levels": [8, 8, 8, 8, 8, 8, 8, 8],
    "effective_codebook": 16777216,
    "steps": 3000,
    "batch_size": 2,
    "lr": "2e-4",
    "warmup_steps": 100,
    "num_gpus": 2,
    "key_changes": [
        "FSQ replaces VQ (no codebook collapse)",
        "8^8 = 16M effective codes",
        "Pure LM loss training",
        "1-step inference (no diffusion)"
    ]
}
