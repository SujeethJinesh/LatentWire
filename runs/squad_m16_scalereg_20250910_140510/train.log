Loading dataset subset...
Loading SQuAD subset...
Llama hidden size: 2048, Qwen hidden size: 896
⚠️  No valid checkpoint found to resume; starting fresh.
Epoch 1/5
  step 10/512 | loss_L=3.3816 | loss_Q=5.4898 | scale_pen(L)=4.7091e-07 | scale_pen(Q)=3.1258e-07 | grad_norm=126.82 | sec/step~2.66
  step 20/512 | loss_L=2.7419 | loss_Q=3.2123 | scale_pen(L)=6.5779e-07 | scale_pen(Q)=6.0633e-07 | grad_norm=10.31 | sec/step~2.32
  step 30/512 | loss_L=2.7086 | loss_Q=2.8428 | scale_pen(L)=8.7070e-07 | scale_pen(Q)=5.6260e-07 | grad_norm=7.08 | sec/step~2.22
  step 40/512 | loss_L=2.6640 | loss_Q=2.7749 | scale_pen(L)=1.1246e-06 | scale_pen(Q)=4.6171e-07 | grad_norm=4.81 | sec/step~2.17
  step 50/512 | loss_L=2.1300 | loss_Q=2.1770 | scale_pen(L)=1.2719e-06 | scale_pen(Q)=3.6529e-07 | grad_norm=4.65 | sec/step~2.15
  step 60/512 | loss_L=2.4284 | loss_Q=2.5500 | scale_pen(L)=1.3682e-06 | scale_pen(Q)=2.8407e-07 | grad_norm=4.40 | sec/step~2.17
  step 70/512 | loss_L=2.1054 | loss_Q=2.0712 | scale_pen(L)=1.4993e-06 | scale_pen(Q)=3.9633e-07 | grad_norm=3.58 | sec/step~2.17
  step 80/512 | loss_L=2.5018 | loss_Q=2.2995 | scale_pen(L)=1.6943e-06 | scale_pen(Q)=5.0870e-07 | grad_norm=3.44 | sec/step~2.16
  step 90/512 | loss_L=2.3527 | loss_Q=2.1444 | scale_pen(L)=1.8619e-06 | scale_pen(Q)=5.3539e-07 | grad_norm=3.18 | sec/step~2.16
  step 100/512 | loss_L=1.9497 | loss_Q=1.9378 | scale_pen(L)=1.9137e-06 | scale_pen(Q)=4.9284e-07 | grad_norm=2.84 | sec/step~2.16
  [debug:L] a.scale=0.9986 | Z.std=0.9993 Z.mean||=15.9890 | p.std=0.5643 p.mean||=25.5358
  [debug:Q] a.scale=1.0007 | Z.std=0.9993 Z.mean||=15.9890 | p.std=0.5778 p.mean||=17.2912
  step 110/512 | loss_L=2.4488 | loss_Q=2.2870 | scale_pen(L)=1.8278e-06 | scale_pen(Q)=4.5012e-07 | grad_norm=3.72 | sec/step~2.13
  step 120/512 | loss_L=1.7241 | loss_Q=1.6731 | scale_pen(L)=1.7228e-06 | scale_pen(Q)=4.2442e-07 | grad_norm=2.35 | sec/step~2.11
  step 130/512 | loss_L=2.3953 | loss_Q=2.1356 | scale_pen(L)=1.6878e-06 | scale_pen(Q)=3.7999e-07 | grad_norm=2.62 | sec/step~2.13
  step 140/512 | loss_L=1.7028 | loss_Q=1.5980 | scale_pen(L)=1.4802e-06 | scale_pen(Q)=3.1445e-07 | grad_norm=2.60 | sec/step~2.12
  step 150/512 | loss_L=2.2892 | loss_Q=2.1805 | scale_pen(L)=1.2380e-06 | scale_pen(Q)=2.2545e-07 | grad_norm=3.43 | sec/step~2.10
  step 160/512 | loss_L=1.9247 | loss_Q=1.6996 | scale_pen(L)=1.1243e-06 | scale_pen(Q)=1.3718e-07 | grad_norm=2.31 | sec/step~2.11
  step 170/512 | loss_L=1.7628 | loss_Q=1.6071 | scale_pen(L)=1.0027e-06 | scale_pen(Q)=1.0398e-07 | grad_norm=2.36 | sec/step~2.11
  step 180/512 | loss_L=2.0584 | loss_Q=2.0725 | scale_pen(L)=9.1336e-07 | scale_pen(Q)=9.5770e-08 | grad_norm=2.83 | sec/step~2.11
  step 190/512 | loss_L=1.6229 | loss_Q=1.5422 | scale_pen(L)=7.5647e-07 | scale_pen(Q)=9.2334e-08 | grad_norm=2.10 | sec/step~2.12
  step 200/512 | loss_L=1.6753 | loss_Q=1.5606 | scale_pen(L)=6.5306e-07 | scale_pen(Q)=8.0361e-08 | grad_norm=2.63 | sec/step~2.12
  [debug:L] a.scale=0.9992 | Z.std=0.9994 Z.mean||=15.9895 | p.std=0.5725 p.mean||=25.9034
  [debug:Q] a.scale=1.0003 | Z.std=0.9994 Z.mean||=15.9895 | p.std=0.5806 p.mean||=17.3750
  step 210/512 | loss_L=1.5783 | loss_Q=1.5606 | scale_pen(L)=4.7830e-07 | scale_pen(Q)=4.1554e-08 | grad_norm=1.96 | sec/step~2.12
  step 220/512 | loss_L=1.7201 | loss_Q=1.6164 | scale_pen(L)=3.7202e-07 | scale_pen(Q)=6.0782e-09 | grad_norm=2.22 | sec/step~2.12
  step 230/512 | loss_L=1.5963 | loss_Q=1.5602 | scale_pen(L)=3.6098e-07 | scale_pen(Q)=3.5527e-09 | grad_norm=3.13 | sec/step~2.12
  step 240/512 | loss_L=1.6781 | loss_Q=1.6804 | scale_pen(L)=3.6450e-07 | scale_pen(Q)=3.7549e-08 | grad_norm=2.23 | sec/step~2.11
  step 250/512 | loss_L=1.6733 | loss_Q=1.7140 | scale_pen(L)=2.6712e-07 | scale_pen(Q)=1.0207e-07 | grad_norm=2.18 | sec/step~2.12
  step 260/512 | loss_L=1.7648 | loss_Q=1.8597 | scale_pen(L)=2.2977e-07 | scale_pen(Q)=1.8142e-07 | grad_norm=2.33 | sec/step~2.11
  step 270/512 | loss_L=1.8678 | loss_Q=1.8889 | scale_pen(L)=1.9047e-07 | scale_pen(Q)=2.8223e-07 | grad_norm=2.49 | sec/step~2.10
  step 280/512 | loss_L=1.6630 | loss_Q=1.5952 | scale_pen(L)=2.0187e-07 | scale_pen(Q)=4.2148e-07 | grad_norm=1.96 | sec/step~2.10
  step 290/512 | loss_L=1.9295 | loss_Q=1.9117 | scale_pen(L)=1.7778e-07 | scale_pen(Q)=5.3182e-07 | grad_norm=2.63 | sec/step~2.10
  step 300/512 | loss_L=1.9390 | loss_Q=1.8369 | scale_pen(L)=1.9439e-07 | scale_pen(Q)=6.8346e-07 | grad_norm=2.26 | sec/step~2.10
  [debug:L] a.scale=0.9996 | Z.std=0.9994 Z.mean||=15.9911 | p.std=0.5797 p.mean||=26.2258
  [debug:Q] a.scale=0.9992 | Z.std=0.9994 Z.mean||=15.9911 | p.std=0.5867 p.mean||=17.5560
  step 310/512 | loss_L=1.4728 | loss_Q=1.5241 | scale_pen(L)=1.6495e-07 | scale_pen(Q)=9.1576e-07 | grad_norm=1.76 | sec/step~2.10
  step 320/512 | loss_L=1.9821 | loss_Q=2.0862 | scale_pen(L)=1.6836e-07 | scale_pen(Q)=1.0491e-06 | grad_norm=2.28 | sec/step~2.11
  step 330/512 | loss_L=1.8240 | loss_Q=1.7835 | scale_pen(L)=1.7448e-07 | scale_pen(Q)=1.1986e-06 | grad_norm=1.86 | sec/step~2.12
  step 340/512 | loss_L=1.4559 | loss_Q=1.5178 | scale_pen(L)=1.6836e-07 | scale_pen(Q)=1.3572e-06 | grad_norm=1.78 | sec/step~2.11
  step 350/512 | loss_L=1.5710 | loss_Q=1.6225 | scale_pen(L)=1.5996e-07 | scale_pen(Q)=1.3795e-06 | grad_norm=2.07 | sec/step~2.12
  step 360/512 | loss_L=1.4544 | loss_Q=1.4930 | scale_pen(L)=1.5312e-07 | scale_pen(Q)=1.5097e-06 | grad_norm=1.57 | sec/step~2.10
  step 370/512 | loss_L=1.3996 | loss_Q=1.4365 | scale_pen(L)=1.5205e-07 | scale_pen(Q)=1.6825e-06 | grad_norm=2.00 | sec/step~2.11
  step 380/512 | loss_L=1.3663 | loss_Q=1.3960 | scale_pen(L)=1.6331e-07 | scale_pen(Q)=1.7206e-06 | grad_norm=1.76 | sec/step~2.10
  step 390/512 | loss_L=1.6132 | loss_Q=1.6608 | scale_pen(L)=1.9313e-07 | scale_pen(Q)=1.9770e-06 | grad_norm=1.56 | sec/step~2.11
  step 400/512 | loss_L=1.2660 | loss_Q=1.2519 | scale_pen(L)=2.0456e-07 | scale_pen(Q)=2.1075e-06 | grad_norm=1.38 | sec/step~2.13
  [debug:L] a.scale=0.9995 | Z.std=0.9995 Z.mean||=15.9918 | p.std=0.5848 p.mean||=26.4565
  [debug:Q] a.scale=0.9985 | Z.std=0.9995 Z.mean||=15.9918 | p.std=0.5903 p.mean||=17.6617
  step 410/512 | loss_L=1.2372 | loss_Q=1.2428 | scale_pen(L)=2.0011e-07 | scale_pen(Q)=2.2050e-06 | grad_norm=2.04 | sec/step~2.12
  step 420/512 | loss_L=1.5112 | loss_Q=1.5051 | scale_pen(L)=2.4134e-07 | scale_pen(Q)=2.1888e-06 | grad_norm=1.58 | sec/step~2.11
  step 430/512 | loss_L=1.7363 | loss_Q=1.7528 | scale_pen(L)=2.7500e-07 | scale_pen(Q)=2.3114e-06 | grad_norm=1.57 | sec/step~2.10
  step 440/512 | loss_L=1.5447 | loss_Q=1.5337 | scale_pen(L)=2.2465e-07 | scale_pen(Q)=2.4849e-06 | grad_norm=1.60 | sec/step~2.10
  step 450/512 | loss_L=1.6554 | loss_Q=1.6830 | scale_pen(L)=2.4717e-07 | scale_pen(Q)=2.5582e-06 | grad_norm=1.72 | sec/step~2.11
  step 460/512 | loss_L=1.4359 | loss_Q=1.4958 | scale_pen(L)=2.0585e-07 | scale_pen(Q)=2.6219e-06 | grad_norm=1.53 | sec/step~2.11
  step 470/512 | loss_L=1.2776 | loss_Q=1.3555 | scale_pen(L)=2.3552e-07 | scale_pen(Q)=2.8544e-06 | grad_norm=1.46 | sec/step~2.12
  step 480/512 | loss_L=1.1560 | loss_Q=1.2485 | scale_pen(L)=2.3465e-07 | scale_pen(Q)=2.9817e-06 | grad_norm=1.34 | sec/step~2.14
  step 490/512 | loss_L=2.1127 | loss_Q=2.0958 | scale_pen(L)=1.5920e-07 | scale_pen(Q)=3.2192e-06 | grad_norm=2.30 | sec/step~2.12
  step 500/512 | loss_L=1.4351 | loss_Q=1.3519 | scale_pen(L)=1.3727e-07 | scale_pen(Q)=3.1001e-06 | grad_norm=1.54 | sec/step~2.13
  [debug:L] a.scale=0.9996 | Z.std=0.9995 Z.mean||=15.9919 | p.std=0.5921 p.mean||=26.7818
  [debug:Q] a.scale=0.9982 | Z.std=0.9995 Z.mean||=15.9919 | p.std=0.5953 p.mean||=17.8120
  ✅ Saved checkpoint at step 500
  step 510/512 | loss_L=1.8119 | loss_Q=1.7803 | scale_pen(L)=1.4616e-07 | scale_pen(Q)=3.2690e-06 | grad_norm=1.81 | sec/step~2.12
  step 512/512 | loss_L=1.8607 | loss_Q=1.7674 | scale_pen(L)=1.4484e-07 | scale_pen(Q)=3.2859e-06 | grad_norm=1.51 | sec/step~2.13
  [debug:L] a.scale=0.9996 | Z.std=0.9995 Z.mean||=15.9925 | p.std=0.5940 p.mean||=26.8666
  [debug:Q] a.scale=0.9982 | Z.std=0.9995 Z.mean||=15.9925 | p.std=0.5968 p.mean||=17.8554
Epoch 2/5
  step 10/512 | loss_L=1.5949 | loss_Q=1.5591 | scale_pen(L)=2.0483e-07 | scale_pen(Q)=3.5259e-06 | grad_norm=1.69 | sec/step~2.11
  step 20/512 | loss_L=1.1973 | loss_Q=1.1441 | scale_pen(L)=2.8982e-07 | scale_pen(Q)=3.8070e-06 | grad_norm=1.39 | sec/step~2.11
  step 30/512 | loss_L=1.5550 | loss_Q=1.6300 | scale_pen(L)=3.1298e-07 | scale_pen(Q)=3.8196e-06 | grad_norm=1.70 | sec/step~2.12
  step 40/512 | loss_L=1.7558 | loss_Q=1.7659 | scale_pen(L)=2.6478e-07 | scale_pen(Q)=3.8584e-06 | grad_norm=1.59 | sec/step~2.13
  step 50/512 | loss_L=1.5702 | loss_Q=1.5549 | scale_pen(L)=2.2195e-07 | scale_pen(Q)=4.2208e-06 | grad_norm=1.48 | sec/step~2.11
  step 60/512 | loss_L=1.4945 | loss_Q=1.5161 | scale_pen(L)=1.9745e-07 | scale_pen(Q)=4.2056e-06 | grad_norm=1.75 | sec/step~2.12
  step 70/512 | loss_L=1.7546 | loss_Q=1.6854 | scale_pen(L)=1.8551e-07 | scale_pen(Q)=4.5074e-06 | grad_norm=1.88 | sec/step~2.11
  step 80/512 | loss_L=1.2691 | loss_Q=1.2916 | scale_pen(L)=1.5943e-07 | scale_pen(Q)=4.6793e-06 | grad_norm=1.27 | sec/step~2.10
  step 90/512 | loss_L=1.4317 | loss_Q=1.4365 | scale_pen(L)=1.5233e-07 | scale_pen(Q)=4.7736e-06 | grad_norm=1.67 | sec/step~2.11
  step 100/512 | loss_L=1.6996 | loss_Q=1.6446 | scale_pen(L)=1.4429e-07 | scale_pen(Q)=4.8408e-06 | grad_norm=2.03 | sec/step~2.09
  [debug:L] a.scale=0.9996 | Z.std=0.9995 Z.mean||=15.9923 | p.std=0.5991 p.mean||=27.0939
  [debug:Q] a.scale=0.9978 | Z.std=0.9995 Z.mean||=15.9923 | p.std=0.5993 p.mean||=17.9294
  step 110/512 | loss_L=1.2855 | loss_Q=1.2352 | scale_pen(L)=1.3665e-07 | scale_pen(Q)=5.0061e-06 | grad_norm=1.42 | sec/step~2.10
  step 120/512 | loss_L=1.4297 | loss_Q=1.4184 | scale_pen(L)=1.2088e-07 | scale_pen(Q)=5.4081e-06 | grad_norm=1.30 | sec/step~2.10
  step 130/512 | loss_L=1.3378 | loss_Q=1.3947 | scale_pen(L)=1.3293e-07 | scale_pen(Q)=5.7233e-06 | grad_norm=1.20 | sec/step~2.11
  step 140/512 | loss_L=1.3729 | loss_Q=1.3410 | scale_pen(L)=1.4285e-07 | scale_pen(Q)=5.8720e-06 | grad_norm=1.39 | sec/step~2.10
  step 150/512 | loss_L=1.2723 | loss_Q=1.3355 | scale_pen(L)=1.3463e-07 | scale_pen(Q)=6.7063e-06 | grad_norm=1.49 | sec/step~2.10
  step 160/512 | loss_L=1.2556 | loss_Q=1.2173 | scale_pen(L)=1.1567e-07 | scale_pen(Q)=7.3624e-06 | grad_norm=1.71 | sec/step~2.13
  step 170/512 | loss_L=1.9524 | loss_Q=2.0507 | scale_pen(L)=1.1968e-07 | scale_pen(Q)=7.2182e-06 | grad_norm=1.97 | sec/step~2.12
  step 180/512 | loss_L=1.4587 | loss_Q=1.5275 | scale_pen(L)=1.0916e-07 | scale_pen(Q)=7.1362e-06 | grad_norm=1.51 | sec/step~2.11
  step 190/512 | loss_L=1.6183 | loss_Q=1.6224 | scale_pen(L)=1.0040e-07 | scale_pen(Q)=7.3628e-06 | grad_norm=1.24 | sec/step~2.10
  step 200/512 | loss_L=1.2262 | loss_Q=1.2394 | scale_pen(L)=1.0066e-07 | scale_pen(Q)=7.5336e-06 | grad_norm=1.11 | sec/step~2.11
  [debug:L] a.scale=0.9997 | Z.std=0.9995 Z.mean||=15.9921 | p.std=0.6035 p.mean||=27.2850
  [debug:Q] a.scale=0.9973 | Z.std=0.9995 Z.mean||=15.9921 | p.std=0.6026 p.mean||=18.0283
  step 210/512 | loss_L=1.3886 | loss_Q=1.4449 | scale_pen(L)=8.7508e-08 | scale_pen(Q)=7.5319e-06 | grad_norm=1.35 | sec/step~2.10
  step 220/512 | loss_L=1.4064 | loss_Q=1.3834 | scale_pen(L)=8.4329e-08 | scale_pen(Q)=7.7979e-06 | grad_norm=1.79 | sec/step~2.10
  step 230/512 | loss_L=1.6960 | loss_Q=1.6780 | scale_pen(L)=7.9552e-08 | scale_pen(Q)=7.9219e-06 | grad_norm=1.48 | sec/step~2.10
  step 240/512 | loss_L=1.7335 | loss_Q=1.7413 | scale_pen(L)=8.2675e-08 | scale_pen(Q)=7.9142e-06 | grad_norm=2.00 | sec/step~2.10
  step 250/512 | loss_L=1.7133 | loss_Q=1.8430 | scale_pen(L)=1.0599e-07 | scale_pen(Q)=7.7163e-06 | grad_norm=1.54 | sec/step~2.10
  step 260/512 | loss_L=1.4270 | loss_Q=1.3985 | scale_pen(L)=9.9909e-08 | scale_pen(Q)=7.6964e-06 | grad_norm=1.44 | sec/step~2.10
  step 270/512 | loss_L=1.2885 | loss_Q=1.3048 | scale_pen(L)=7.2230e-08 | scale_pen(Q)=7.5778e-06 | grad_norm=1.24 | sec/step~2.10
  step 280/512 | loss_L=1.3038 | loss_Q=1.3590 | scale_pen(L)=6.1748e-08 | scale_pen(Q)=7.7086e-06 | grad_norm=1.26 | sec/step~2.10
  step 290/512 | loss_L=1.2692 | loss_Q=1.2432 | scale_pen(L)=5.4843e-08 | scale_pen(Q)=7.6327e-06 | grad_norm=1.38 | sec/step~2.10
  step 300/512 | loss_L=1.6145 | loss_Q=1.5991 | scale_pen(L)=5.4398e-08 | scale_pen(Q)=7.1349e-06 | grad_norm=1.21 | sec/step~2.10
  [debug:L] a.scale=0.9998 | Z.std=0.9996 Z.mean||=15.9927 | p.std=0.6070 p.mean||=27.4411
  [debug:Q] a.scale=0.9973 | Z.std=0.9996 Z.mean||=15.9927 | p.std=0.6069 p.mean||=18.1540
  step 310/512 | loss_L=1.3295 | loss_Q=1.3203 | scale_pen(L)=4.1505e-08 | scale_pen(Q)=7.3140e-06 | grad_norm=1.37 | sec/step~2.10
  step 320/512 | loss_L=1.3472 | loss_Q=1.4413 | scale_pen(L)=1.7810e-08 | scale_pen(Q)=7.4578e-06 | grad_norm=1.49 | sec/step~2.10
  step 330/512 | loss_L=1.3745 | loss_Q=1.3773 | scale_pen(L)=1.3343e-08 | scale_pen(Q)=7.7793e-06 | grad_norm=1.21 | sec/step~2.10
  step 340/512 | loss_L=1.4741 | loss_Q=1.5049 | scale_pen(L)=9.9200e-09 | scale_pen(Q)=7.7123e-06 | grad_norm=1.26 | sec/step~2.10
  step 350/512 | loss_L=1.6357 | loss_Q=1.6199 | scale_pen(L)=1.7762e-08 | scale_pen(Q)=7.3679e-06 | grad_norm=1.47 | sec/step~2.11
  step 360/512 | loss_L=1.8284 | loss_Q=1.7435 | scale_pen(L)=7.8874e-09 | scale_pen(Q)=7.8089e-06 | grad_norm=2.03 | sec/step~2.11
  step 370/512 | loss_L=1.3820 | loss_Q=1.3601 | scale_pen(L)=1.5997e-08 | scale_pen(Q)=8.2193e-06 | grad_norm=1.39 | sec/step~2.10
  step 380/512 | loss_L=1.6147 | loss_Q=1.6446 | scale_pen(L)=2.8273e-08 | scale_pen(Q)=8.6016e-06 | grad_norm=1.32 | sec/step~2.10
  step 390/512 | loss_L=1.2567 | loss_Q=1.2715 | scale_pen(L)=5.4453e-08 | scale_pen(Q)=8.5670e-06 | grad_norm=1.15 | sec/step~2.11
  step 400/512 | loss_L=1.3080 | loss_Q=1.2193 | scale_pen(L)=4.9217e-08 | scale_pen(Q)=8.5102e-06 | grad_norm=1.26 | sec/step~2.10
  [debug:L] a.scale=0.9998 | Z.std=0.9995 Z.mean||=15.9922 | p.std=0.6112 p.mean||=27.6298
  [debug:Q] a.scale=0.9971 | Z.std=0.9995 Z.mean||=15.9922 | p.std=0.6085 p.mean||=18.2023
  step 410/512 | loss_L=1.3960 | loss_Q=1.3774 | scale_pen(L)=4.8847e-08 | scale_pen(Q)=8.9955e-06 | grad_norm=1.37 | sec/step~2.11
  step 420/512 | loss_L=1.7321 | loss_Q=1.7444 | scale_pen(L)=3.3702e-08 | scale_pen(Q)=9.2929e-06 | grad_norm=1.77 | sec/step~2.10
  step 430/512 | loss_L=1.2581 | loss_Q=1.2313 | scale_pen(L)=2.1169e-08 | scale_pen(Q)=9.4179e-06 | grad_norm=1.61 | sec/step~2.10
  step 440/512 | loss_L=1.3371 | loss_Q=1.3767 | scale_pen(L)=1.7620e-08 | scale_pen(Q)=8.7304e-06 | grad_norm=1.31 | sec/step~2.10
  step 450/512 | loss_L=1.0755 | loss_Q=1.0760 | scale_pen(L)=3.5814e-08 | scale_pen(Q)=8.2665e-06 | grad_norm=1.31 | sec/step~2.11
  step 460/512 | loss_L=1.8729 | loss_Q=1.9203 | scale_pen(L)=2.6304e-08 | scale_pen(Q)=8.2541e-06 | grad_norm=1.85 | sec/step~2.11
  step 470/512 | loss_L=1.2704 | loss_Q=1.3027 | scale_pen(L)=6.4556e-09 | scale_pen(Q)=8.4831e-06 | grad_norm=1.11 | sec/step~2.10
  step 480/512 | loss_L=1.4110 | loss_Q=1.4002 | scale_pen(L)=2.3022e-09 | scale_pen(Q)=8.4533e-06 | grad_norm=1.23 | sec/step~2.10
  ✅ Saved checkpoint at step 1000
  step 490/512 | loss_L=1.6827 | loss_Q=1.6019 | scale_pen(L)=3.1592e-09 | scale_pen(Q)=8.4925e-06 | grad_norm=1.48 | sec/step~2.10
  step 500/512 | loss_L=1.3133 | loss_Q=1.4212 | scale_pen(L)=9.3007e-09 | scale_pen(Q)=8.4630e-06 | grad_norm=1.30 | sec/step~2.11
  [debug:L] a.scale=0.9999 | Z.std=0.9995 Z.mean||=15.9916 | p.std=0.6154 p.mean||=27.8133
  [debug:Q] a.scale=0.9971 | Z.std=0.9995 Z.mean||=15.9916 | p.std=0.6108 p.mean||=18.2689
  step 510/512 | loss_L=1.2538 | loss_Q=1.2326 | scale_pen(L)=5.2792e-09 | scale_pen(Q)=8.5436e-06 | grad_norm=1.29 | sec/step~2.10
  step 512/512 | loss_L=1.2161 | loss_Q=1.1924 | scale_pen(L)=3.5456e-09 | scale_pen(Q)=8.5238e-06 | grad_norm=0.95 | sec/step~2.11
  [debug:L] a.scale=0.9999 | Z.std=0.9996 Z.mean||=15.9928 | p.std=0.6163 p.mean||=27.8553
  [debug:Q] a.scale=0.9971 | Z.std=0.9996 Z.mean||=15.9928 | p.std=0.6136 p.mean||=18.3555
Epoch 3/5
  step 10/512 | loss_L=1.3226 | loss_Q=1.3566 | scale_pen(L)=1.4552e-09 | scale_pen(Q)=8.6664e-06 | grad_norm=2.01 | sec/step~2.11
  step 20/512 | loss_L=1.2790 | loss_Q=1.2949 | scale_pen(L)=3.6380e-10 | scale_pen(Q)=8.7005e-06 | grad_norm=1.64 | sec/step~2.10
  step 30/512 | loss_L=1.5780 | loss_Q=1.5273 | scale_pen(L)=4.2988e-11 | scale_pen(Q)=8.8321e-06 | grad_norm=1.22 | sec/step~2.11
  step 40/512 | loss_L=1.6419 | loss_Q=1.7181 | scale_pen(L)=3.3842e-09 | scale_pen(Q)=9.1142e-06 | grad_norm=1.60 | sec/step~2.10
  step 50/512 | loss_L=1.4330 | loss_Q=1.3695 | scale_pen(L)=6.0318e-09 | scale_pen(Q)=9.0295e-06 | grad_norm=1.88 | sec/step~2.11
  step 60/512 | loss_L=1.3659 | loss_Q=1.3157 | scale_pen(L)=6.3317e-09 | scale_pen(Q)=8.6149e-06 | grad_norm=1.65 | sec/step~2.11
  step 70/512 | loss_L=1.8490 | loss_Q=1.8186 | scale_pen(L)=1.3690e-08 | scale_pen(Q)=8.2956e-06 | grad_norm=1.79 | sec/step~2.11
  step 80/512 | loss_L=1.5368 | loss_Q=1.5087 | scale_pen(L)=1.8162e-08 | scale_pen(Q)=8.2111e-06 | grad_norm=1.65 | sec/step~2.11
  step 90/512 | loss_L=1.6080 | loss_Q=1.5106 | scale_pen(L)=2.1500e-08 | scale_pen(Q)=8.6962e-06 | grad_norm=1.37 | sec/step~2.10
  step 100/512 | loss_L=1.7098 | loss_Q=1.7556 | scale_pen(L)=2.2027e-08 | scale_pen(Q)=8.4800e-06 | grad_norm=1.69 | sec/step~2.10
  [debug:L] a.scale=0.9999 | Z.std=0.9995 Z.mean||=15.9917 | p.std=0.6193 p.mean||=27.9843
  [debug:Q] a.scale=0.9971 | Z.std=0.9995 Z.mean||=15.9917 | p.std=0.6153 p.mean||=18.4020
  step 110/512 | loss_L=1.3688 | loss_Q=1.4433 | scale_pen(L)=2.0515e-08 | scale_pen(Q)=8.5109e-06 | grad_norm=1.28 | sec/step~2.10
  step 120/512 | loss_L=1.5988 | loss_Q=1.6459 | scale_pen(L)=1.7858e-08 | scale_pen(Q)=8.7114e-06 | grad_norm=1.45 | sec/step~2.10
  step 130/512 | loss_L=1.5073 | loss_Q=1.4865 | scale_pen(L)=9.7075e-09 | scale_pen(Q)=8.4162e-06 | grad_norm=1.54 | sec/step~2.10
  step 140/512 | loss_L=1.4046 | loss_Q=1.3734 | scale_pen(L)=1.0486e-08 | scale_pen(Q)=7.8844e-06 | grad_norm=1.80 | sec/step~2.10
  step 150/512 | loss_L=1.5016 | loss_Q=1.3999 | scale_pen(L)=1.4197e-08 | scale_pen(Q)=7.5929e-06 | grad_norm=1.29 | sec/step~2.11
  step 160/512 | loss_L=1.3436 | loss_Q=1.3239 | scale_pen(L)=1.8501e-08 | scale_pen(Q)=7.8076e-06 | grad_norm=1.41 | sec/step~2.11
  step 170/512 | loss_L=1.2755 | loss_Q=1.3310 | scale_pen(L)=2.0927e-08 | scale_pen(Q)=8.0395e-06 | grad_norm=1.26 | sec/step~2.10
  step 180/512 | loss_L=1.1743 | loss_Q=1.1778 | scale_pen(L)=9.0382e-09 | scale_pen(Q)=8.4041e-06 | grad_norm=2.42 | sec/step~2.10
  step 190/512 | loss_L=1.6091 | loss_Q=1.5566 | scale_pen(L)=6.0782e-09 | scale_pen(Q)=7.9323e-06 | grad_norm=1.45 | sec/step~2.10
  step 200/512 | loss_L=1.4160 | loss_Q=1.4421 | scale_pen(L)=1.4689e-09 | scale_pen(Q)=7.1502e-06 | grad_norm=1.14 | sec/step~2.10
  [debug:L] a.scale=1.0000 | Z.std=0.9994 Z.mean||=15.9910 | p.std=0.6226 p.mean||=28.1272
  [debug:Q] a.scale=0.9973 | Z.std=0.9994 Z.mean||=15.9910 | p.std=0.6175 p.mean||=18.4672
  step 210/512 | loss_L=1.4740 | loss_Q=1.4775 | scale_pen(L)=3.4584e-10 | scale_pen(Q)=6.5977e-06 | grad_norm=1.44 | sec/step~2.10
  step 220/512 | loss_L=1.2689 | loss_Q=1.3230 | scale_pen(L)=1.4211e-10 | scale_pen(Q)=6.9348e-06 | grad_norm=1.66 | sec/step~2.11
  step 230/512 | loss_L=1.1840 | loss_Q=1.1265 | scale_pen(L)=5.1572e-10 | scale_pen(Q)=6.8978e-06 | grad_norm=0.98 | sec/step~2.10
  step 240/512 | loss_L=1.3693 | loss_Q=1.3403 | scale_pen(L)=7.0037e-10 | scale_pen(Q)=6.8571e-06 | grad_norm=1.19 | sec/step~2.11
  step 250/512 | loss_L=1.8882 | loss_Q=1.7864 | scale_pen(L)=1.2557e-10 | scale_pen(Q)=7.0942e-06 | grad_norm=1.61 | sec/step~2.15
  step 260/512 | loss_L=1.4492 | loss_Q=1.4920 | scale_pen(L)=3.6745e-09 | scale_pen(Q)=7.9313e-06 | grad_norm=1.60 | sec/step~2.19
  step 270/512 | loss_L=1.4492 | loss_Q=1.4580 | scale_pen(L)=4.8136e-09 | scale_pen(Q)=8.6068e-06 | grad_norm=1.45 | sec/step~2.18
  step 280/512 | loss_L=1.5348 | loss_Q=1.4330 | scale_pen(L)=6.8741e-09 | scale_pen(Q)=9.6335e-06 | grad_norm=1.16 | sec/step~2.19
  step 290/512 | loss_L=1.5346 | loss_Q=1.5001 | scale_pen(L)=9.6254e-09 | scale_pen(Q)=9.9254e-06 | grad_norm=1.61 | sec/step~2.19
  step 300/512 | loss_L=1.3740 | loss_Q=1.3913 | scale_pen(L)=1.5474e-08 | scale_pen(Q)=1.0095e-05 | grad_norm=1.39 | sec/step~2.19
  [debug:L] a.scale=0.9999 | Z.std=0.9994 Z.mean||=15.9905 | p.std=0.6256 p.mean||=28.2569
  [debug:Q] a.scale=0.9968 | Z.std=0.9994 Z.mean||=15.9905 | p.std=0.6196 p.mean||=18.5293
  step 310/512 | loss_L=1.1514 | loss_Q=1.2063 | scale_pen(L)=3.0437e-08 | scale_pen(Q)=9.6217e-06 | grad_norm=1.17 | sec/step~2.18
  step 320/512 | loss_L=1.4304 | loss_Q=1.3704 | scale_pen(L)=2.8675e-08 | scale_pen(Q)=9.0191e-06 | grad_norm=1.18 | sec/step~2.19
  step 330/512 | loss_L=1.4364 | loss_Q=1.3685 | scale_pen(L)=1.6622e-08 | scale_pen(Q)=8.0974e-06 | grad_norm=1.07 | sec/step~2.19
  step 340/512 | loss_L=1.2807 | loss_Q=1.3294 | scale_pen(L)=1.2238e-08 | scale_pen(Q)=7.7810e-06 | grad_norm=1.29 | sec/step~2.19
  step 350/512 | loss_L=1.7578 | loss_Q=1.6889 | scale_pen(L)=5.9856e-09 | scale_pen(Q)=8.4349e-06 | grad_norm=1.34 | sec/step~2.19
  step 360/512 | loss_L=1.6467 | loss_Q=1.6279 | scale_pen(L)=9.4392e-09 | scale_pen(Q)=9.1373e-06 | grad_norm=1.79 | sec/step~2.19
  step 370/512 | loss_L=1.6844 | loss_Q=1.7680 | scale_pen(L)=3.5955e-09 | scale_pen(Q)=9.7054e-06 | grad_norm=1.64 | sec/step~2.19
  step 380/512 | loss_L=1.1991 | loss_Q=1.2141 | scale_pen(L)=1.2158e-09 | scale_pen(Q)=9.5074e-06 | grad_norm=1.04 | sec/step~2.19
  step 390/512 | loss_L=1.6044 | loss_Q=1.5203 | scale_pen(L)=2.2454e-09 | scale_pen(Q)=9.5471e-06 | grad_norm=1.51 | sec/step~2.19
  step 400/512 | loss_L=1.4130 | loss_Q=1.3748 | scale_pen(L)=3.5385e-09 | scale_pen(Q)=9.6999e-06 | grad_norm=1.13 | sec/step~2.19
  [debug:L] a.scale=0.9999 | Z.std=0.9994 Z.mean||=15.9903 | p.std=0.6294 p.mean||=28.4244
  [debug:Q] a.scale=0.9969 | Z.std=0.9994 Z.mean||=15.9903 | p.std=0.6246 p.mean||=18.6794
  step 410/512 | loss_L=1.3396 | loss_Q=1.3414 | scale_pen(L)=2.8649e-09 | scale_pen(Q)=1.0049e-05 | grad_norm=1.08 | sec/step~2.19
  step 420/512 | loss_L=1.3053 | loss_Q=1.3080 | scale_pen(L)=7.4284e-09 | scale_pen(Q)=1.0003e-05 | grad_norm=1.22 | sec/step~2.19
  step 430/512 | loss_L=1.2592 | loss_Q=1.3473 | scale_pen(L)=1.9613e-09 | scale_pen(Q)=9.4022e-06 | grad_norm=1.22 | sec/step~2.18
  step 440/512 | loss_L=1.3769 | loss_Q=1.3657 | scale_pen(L)=9.3861e-10 | scale_pen(Q)=9.5343e-06 | grad_norm=1.25 | sec/step~2.19
  step 450/512 | loss_L=1.1723 | loss_Q=1.1495 | scale_pen(L)=1.5817e-10 | scale_pen(Q)=9.7199e-06 | grad_norm=1.25 | sec/step~2.19
  step 460/512 | loss_L=1.4097 | loss_Q=1.5103 | scale_pen(L)=2.9420e-09 | scale_pen(Q)=1.0547e-05 | grad_norm=1.15 | sec/step~2.19
  step 470/512 | loss_L=1.4256 | loss_Q=1.4023 | scale_pen(L)=7.5108e-09 | scale_pen(Q)=1.0771e-05 | grad_norm=1.10 | sec/step~2.19
  ✅ Saved checkpoint at step 1500
  step 480/512 | loss_L=1.5331 | loss_Q=1.4539 | scale_pen(L)=1.9553e-08 | scale_pen(Q)=1.0443e-05 | grad_norm=1.66 | sec/step~2.18
  step 490/512 | loss_L=1.3505 | loss_Q=1.3259 | scale_pen(L)=1.0245e-09 | scale_pen(Q)=9.5398e-06 | grad_norm=1.21 | sec/step~2.18
  step 500/512 | loss_L=1.4343 | loss_Q=1.5558 | scale_pen(L)=1.1511e-12 | scale_pen(Q)=9.0736e-06 | grad_norm=1.23 | sec/step~2.19
  [debug:L] a.scale=1.0000 | Z.std=0.9993 Z.mean||=15.9889 | p.std=0.6312 p.mean||=28.4996
  [debug:Q] a.scale=0.9970 | Z.std=0.9993 Z.mean||=15.9889 | p.std=0.6265 p.mean||=18.7335
  step 510/512 | loss_L=1.2251 | loss_Q=1.1989 | scale_pen(L)=8.1174e-10 | scale_pen(Q)=8.8836e-06 | grad_norm=1.11 | sec/step~2.20
  step 512/512 | loss_L=1.6978 | loss_Q=1.5855 | scale_pen(L)=7.9149e-10 | scale_pen(Q)=8.9170e-06 | grad_norm=1.27 | sec/step~2.20
  [debug:L] a.scale=1.0000 | Z.std=0.9994 Z.mean||=15.9897 | p.std=0.6321 p.mean||=28.5407
  [debug:Q] a.scale=0.9970 | Z.std=0.9994 Z.mean||=15.9897 | p.std=0.6274 p.mean||=18.7604
Epoch 4/5
  step 10/512 | loss_L=1.3084 | loss_Q=1.3308 | scale_pen(L)=9.6065e-10 | scale_pen(Q)=9.9311e-06 | grad_norm=1.30 | sec/step~2.20
  step 20/512 | loss_L=1.3615 | loss_Q=1.3830 | scale_pen(L)=6.6973e-09 | scale_pen(Q)=1.0336e-05 | grad_norm=1.28 | sec/step~2.20
  step 30/512 | loss_L=1.7574 | loss_Q=1.7754 | scale_pen(L)=1.9754e-08 | scale_pen(Q)=1.0479e-05 | grad_norm=1.18 | sec/step~2.20
  step 40/512 | loss_L=1.1754 | loss_Q=1.1865 | scale_pen(L)=4.1993e-08 | scale_pen(Q)=1.0709e-05 | grad_norm=1.05 | sec/step~2.19
  step 50/512 | loss_L=1.4636 | loss_Q=1.4602 | scale_pen(L)=1.2002e-08 | scale_pen(Q)=1.0975e-05 | grad_norm=1.14 | sec/step~2.19
  step 60/512 | loss_L=1.5184 | loss_Q=1.5663 | scale_pen(L)=7.0037e-10 | scale_pen(Q)=1.0550e-05 | grad_norm=1.45 | sec/step~2.19
  step 70/512 | loss_L=1.3527 | loss_Q=1.3634 | scale_pen(L)=1.1639e-10 | scale_pen(Q)=1.0289e-05 | grad_norm=1.45 | sec/step~2.19
  step 80/512 | loss_L=1.0317 | loss_Q=1.0768 | scale_pen(L)=3.9633e-10 | scale_pen(Q)=1.0432e-05 | grad_norm=1.13 | sec/step~2.19
  step 90/512 | loss_L=1.4837 | loss_Q=1.4225 | scale_pen(L)=6.6917e-10 | scale_pen(Q)=1.0690e-05 | grad_norm=1.56 | sec/step~2.19
  step 100/512 | loss_L=1.3368 | loss_Q=1.3986 | scale_pen(L)=2.9878e-10 | scale_pen(Q)=1.1482e-05 | grad_norm=1.12 | sec/step~2.20
  [debug:L] a.scale=1.0000 | Z.std=0.9993 Z.mean||=15.9880 | p.std=0.6346 p.mean||=28.6497
  [debug:Q] a.scale=0.9966 | Z.std=0.9993 Z.mean||=15.9880 | p.std=0.6277 p.mean||=18.7700
  step 110/512 | loss_L=1.4099 | loss_Q=1.4080 | scale_pen(L)=4.9552e-09 | scale_pen(Q)=1.1795e-05 | grad_norm=1.17 | sec/step~2.19
  step 120/512 | loss_L=1.5251 | loss_Q=1.5993 | scale_pen(L)=6.2670e-12 | scale_pen(Q)=1.2046e-05 | grad_norm=1.41 | sec/step~2.19
  step 130/512 | loss_L=1.1266 | loss_Q=1.1613 | scale_pen(L)=4.1069e-12 | scale_pen(Q)=1.2608e-05 | grad_norm=1.15 | sec/step~2.19
  step 140/512 | loss_L=1.4110 | loss_Q=1.4333 | scale_pen(L)=5.5245e-09 | scale_pen(Q)=1.2480e-05 | grad_norm=1.41 | sec/step~2.19
  step 150/512 | loss_L=1.7192 | loss_Q=1.6227 | scale_pen(L)=5.8663e-09 | scale_pen(Q)=1.3005e-05 | grad_norm=1.33 | sec/step~2.18
  step 160/512 | loss_L=1.1619 | loss_Q=1.1464 | scale_pen(L)=2.5441e-08 | scale_pen(Q)=1.3798e-05 | grad_norm=1.34 | sec/step~2.19
  step 170/512 | loss_L=1.5655 | loss_Q=1.5888 | scale_pen(L)=6.5476e-08 | scale_pen(Q)=1.4788e-05 | grad_norm=1.74 | sec/step~2.19
  step 180/512 | loss_L=1.8342 | loss_Q=1.7557 | scale_pen(L)=9.8034e-08 | scale_pen(Q)=1.4681e-05 | grad_norm=1.78 | sec/step~2.19
  step 190/512 | loss_L=1.1835 | loss_Q=1.2060 | scale_pen(L)=1.7008e-07 | scale_pen(Q)=1.4250e-05 | grad_norm=1.17 | sec/step~2.19
  step 200/512 | loss_L=1.2625 | loss_Q=1.2321 | scale_pen(L)=1.2803e-07 | scale_pen(Q)=1.3614e-05 | grad_norm=1.18 | sec/step~2.20
  [debug:L] a.scale=0.9996 | Z.std=0.9993 Z.mean||=15.9880 | p.std=0.6381 p.mean||=28.8057
  [debug:Q] a.scale=0.9963 | Z.std=0.9993 Z.mean||=15.9880 | p.std=0.6330 p.mean||=18.9287
  step 210/512 | loss_L=1.1378 | loss_Q=1.1800 | scale_pen(L)=1.2092e-07 | scale_pen(Q)=1.3671e-05 | grad_norm=1.27 | sec/step~2.19
  step 220/512 | loss_L=1.2236 | loss_Q=1.2856 | scale_pen(L)=1.7653e-07 | scale_pen(Q)=1.4153e-05 | grad_norm=1.14 | sec/step~2.19
  step 230/512 | loss_L=1.3163 | loss_Q=1.2747 | scale_pen(L)=1.6817e-07 | scale_pen(Q)=1.3893e-05 | grad_norm=1.06 | sec/step~2.19
  step 240/512 | loss_L=0.9999 | loss_Q=1.0130 | scale_pen(L)=1.7703e-07 | scale_pen(Q)=1.2496e-05 | grad_norm=1.33 | sec/step~2.19
  step 250/512 | loss_L=1.1857 | loss_Q=1.1247 | scale_pen(L)=1.7235e-07 | scale_pen(Q)=1.1344e-05 | grad_norm=1.41 | sec/step~2.20
  step 260/512 | loss_L=1.4697 | loss_Q=1.4419 | scale_pen(L)=1.1113e-07 | scale_pen(Q)=1.2320e-05 | grad_norm=1.23 | sec/step~2.19
  step 270/512 | loss_L=1.2347 | loss_Q=1.2037 | scale_pen(L)=1.3477e-07 | scale_pen(Q)=1.3359e-05 | grad_norm=1.12 | sec/step~2.19
  step 280/512 | loss_L=1.2591 | loss_Q=1.2302 | scale_pen(L)=1.8622e-07 | scale_pen(Q)=1.3774e-05 | grad_norm=1.09 | sec/step~2.19
  step 290/512 | loss_L=1.0890 | loss_Q=1.0654 | scale_pen(L)=3.1205e-07 | scale_pen(Q)=1.3121e-05 | grad_norm=1.29 | sec/step~2.19
  step 300/512 | loss_L=1.0418 | loss_Q=1.0399 | scale_pen(L)=5.2118e-07 | scale_pen(Q)=1.2660e-05 | grad_norm=1.53 | sec/step~2.19
  [debug:L] a.scale=0.9993 | Z.std=0.9993 Z.mean||=15.9881 | p.std=0.6409 p.mean||=28.9237
  [debug:Q] a.scale=0.9964 | Z.std=0.9993 Z.mean||=15.9881 | p.std=0.6354 p.mean||=18.9980
  step 310/512 | loss_L=1.3465 | loss_Q=1.3635 | scale_pen(L)=4.8941e-07 | scale_pen(Q)=1.3860e-05 | grad_norm=1.48 | sec/step~2.19
  step 320/512 | loss_L=1.3730 | loss_Q=1.3699 | scale_pen(L)=3.4637e-07 | scale_pen(Q)=1.4763e-05 | grad_norm=1.19 | sec/step~2.19
  step 330/512 | loss_L=1.1350 | loss_Q=1.1192 | scale_pen(L)=2.4380e-07 | scale_pen(Q)=1.5415e-05 | grad_norm=1.19 | sec/step~2.19
  step 340/512 | loss_L=1.2900 | loss_Q=1.3478 | scale_pen(L)=2.5259e-07 | scale_pen(Q)=1.4995e-05 | grad_norm=1.09 | sec/step~2.18
  step 350/512 | loss_L=1.2361 | loss_Q=1.3050 | scale_pen(L)=2.4794e-07 | scale_pen(Q)=1.4015e-05 | grad_norm=1.75 | sec/step~2.19
  step 360/512 | loss_L=1.2468 | loss_Q=1.2390 | scale_pen(L)=2.3000e-07 | scale_pen(Q)=1.3331e-05 | grad_norm=1.13 | sec/step~2.19
  step 370/512 | loss_L=1.2902 | loss_Q=1.2491 | scale_pen(L)=1.3498e-07 | scale_pen(Q)=1.3173e-05 | grad_norm=1.69 | sec/step~2.19
  step 380/512 | loss_L=1.1516 | loss_Q=1.2595 | scale_pen(L)=8.4363e-08 | scale_pen(Q)=1.2435e-05 | grad_norm=1.29 | sec/step~2.19
  step 390/512 | loss_L=1.1902 | loss_Q=1.1490 | scale_pen(L)=8.2298e-08 | scale_pen(Q)=1.2472e-05 | grad_norm=1.15 | sec/step~2.20
  step 400/512 | loss_L=1.3650 | loss_Q=1.3812 | scale_pen(L)=5.7699e-08 | scale_pen(Q)=1.2939e-05 | grad_norm=1.23 | sec/step~2.19
  [debug:L] a.scale=0.9998 | Z.std=0.9991 Z.mean||=15.9858 | p.std=0.6428 p.mean||=29.0067
  [debug:Q] a.scale=0.9964 | Z.std=0.9991 Z.mean||=15.9858 | p.std=0.6369 p.mean||=19.0427
  step 410/512 | loss_L=1.5055 | loss_Q=1.5295 | scale_pen(L)=2.7516e-08 | scale_pen(Q)=1.2800e-05 | grad_norm=1.50 | sec/step~2.19
  step 420/512 | loss_L=1.7952 | loss_Q=1.7743 | scale_pen(L)=2.6692e-08 | scale_pen(Q)=1.3189e-05 | grad_norm=1.37 | sec/step~2.18
  step 430/512 | loss_L=1.0169 | loss_Q=0.9434 | scale_pen(L)=5.2441e-08 | scale_pen(Q)=1.3620e-05 | grad_norm=1.29 | sec/step~2.19
  step 440/512 | loss_L=1.1173 | loss_Q=1.1256 | scale_pen(L)=8.3638e-08 | scale_pen(Q)=1.3346e-05 | grad_norm=1.08 | sec/step~2.19
  step 450/512 | loss_L=1.7155 | loss_Q=1.7113 | scale_pen(L)=9.0962e-08 | scale_pen(Q)=1.2309e-05 | grad_norm=1.28 | sec/step~2.19
  step 460/512 | loss_L=1.1752 | loss_Q=1.1738 | scale_pen(L)=1.2897e-07 | scale_pen(Q)=1.2752e-05 | grad_norm=1.00 | sec/step~2.20
  ✅ Saved checkpoint at step 2000
  step 470/512 | loss_L=1.0842 | loss_Q=1.1082 | scale_pen(L)=1.2854e-07 | scale_pen(Q)=1.2933e-05 | grad_norm=1.08 | sec/step~2.20
  step 480/512 | loss_L=1.1711 | loss_Q=1.1217 | scale_pen(L)=1.7136e-07 | scale_pen(Q)=1.3378e-05 | grad_norm=1.66 | sec/step~2.18
  step 490/512 | loss_L=1.1525 | loss_Q=1.1108 | scale_pen(L)=2.4498e-07 | scale_pen(Q)=1.4109e-05 | grad_norm=1.55 | sec/step~2.19
  step 500/512 | loss_L=1.2504 | loss_Q=1.2227 | scale_pen(L)=2.4280e-07 | scale_pen(Q)=1.3101e-05 | grad_norm=1.08 | sec/step~2.19
  [debug:L] a.scale=0.9995 | Z.std=0.9991 Z.mean||=15.9850 | p.std=0.6448 p.mean||=29.0915
  [debug:Q] a.scale=0.9964 | Z.std=0.9991 Z.mean||=15.9850 | p.std=0.6395 p.mean||=19.1196
  step 510/512 | loss_L=1.3479 | loss_Q=1.3446 | scale_pen(L)=3.1633e-07 | scale_pen(Q)=1.2432e-05 | grad_norm=1.34 | sec/step~2.19
  step 512/512 | loss_L=1.2455 | loss_Q=1.3235 | scale_pen(L)=3.4567e-07 | scale_pen(Q)=1.2257e-05 | grad_norm=1.06 | sec/step~2.19
  [debug:L] a.scale=0.9994 | Z.std=0.9991 Z.mean||=15.9853 | p.std=0.6449 p.mean||=29.0968
  [debug:Q] a.scale=0.9965 | Z.std=0.9991 Z.mean||=15.9853 | p.std=0.6399 p.mean||=19.1310
Epoch 5/5
  step 10/512 | loss_L=1.3071 | loss_Q=1.4252 | scale_pen(L)=4.0660e-07 | scale_pen(Q)=1.2023e-05 | grad_norm=1.52 | sec/step~2.18
  step 20/512 | loss_L=1.2742 | loss_Q=1.3289 | scale_pen(L)=3.1258e-07 | scale_pen(Q)=1.2099e-05 | grad_norm=1.09 | sec/step~2.18
  step 30/512 | loss_L=1.2829 | loss_Q=1.2479 | scale_pen(L)=3.1646e-07 | scale_pen(Q)=1.2553e-05 | grad_norm=1.16 | sec/step~2.19
  step 40/512 | loss_L=1.0118 | loss_Q=0.9776 | scale_pen(L)=3.5669e-07 | scale_pen(Q)=1.3266e-05 | grad_norm=2.76 | sec/step~2.19
  step 50/512 | loss_L=1.1192 | loss_Q=1.1071 | scale_pen(L)=3.4295e-07 | scale_pen(Q)=1.3954e-05 | grad_norm=1.84 | sec/step~2.17
  step 60/512 | loss_L=1.0073 | loss_Q=1.0382 | scale_pen(L)=2.7983e-07 | scale_pen(Q)=1.4306e-05 | grad_norm=1.51 | sec/step~2.13
  step 70/512 | loss_L=1.9135 | loss_Q=2.0170 | scale_pen(L)=3.2715e-07 | scale_pen(Q)=1.4199e-05 | grad_norm=1.37 | sec/step~2.11
  step 80/512 | loss_L=1.2851 | loss_Q=1.2978 | scale_pen(L)=3.9460e-07 | scale_pen(Q)=1.4094e-05 | grad_norm=1.14 | sec/step~2.10
  step 90/512 | loss_L=1.2565 | loss_Q=1.2485 | scale_pen(L)=4.8625e-07 | scale_pen(Q)=1.4307e-05 | grad_norm=1.33 | sec/step~2.10
  step 100/512 | loss_L=1.5874 | loss_Q=1.5309 | scale_pen(L)=5.3863e-07 | scale_pen(Q)=1.3950e-05 | grad_norm=1.21 | sec/step~2.10
  [debug:L] a.scale=0.9993 | Z.std=0.9990 Z.mean||=15.9840 | p.std=0.6458 p.mean||=29.1291
  [debug:Q] a.scale=0.9963 | Z.std=0.9990 Z.mean||=15.9840 | p.std=0.6407 p.mean||=19.1543
  step 110/512 | loss_L=1.1648 | loss_Q=1.1572 | scale_pen(L)=5.3915e-07 | scale_pen(Q)=1.2986e-05 | grad_norm=1.27 | sec/step~2.10
  step 120/512 | loss_L=1.6530 | loss_Q=1.5468 | scale_pen(L)=5.2723e-07 | scale_pen(Q)=1.3097e-05 | grad_norm=1.39 | sec/step~2.10
  step 130/512 | loss_L=1.6126 | loss_Q=1.5289 | scale_pen(L)=5.8873e-07 | scale_pen(Q)=1.3924e-05 | grad_norm=1.32 | sec/step~2.10
  step 140/512 | loss_L=1.3646 | loss_Q=1.3918 | scale_pen(L)=7.4438e-07 | scale_pen(Q)=1.4404e-05 | grad_norm=1.49 | sec/step~2.10
  step 150/512 | loss_L=1.1792 | loss_Q=1.2108 | scale_pen(L)=6.7776e-07 | scale_pen(Q)=1.3621e-05 | grad_norm=1.54 | sec/step~2.10
  step 160/512 | loss_L=1.8454 | loss_Q=1.8751 | scale_pen(L)=7.8842e-07 | scale_pen(Q)=1.3662e-05 | grad_norm=1.69 | sec/step~2.10
  step 170/512 | loss_L=1.3466 | loss_Q=1.3553 | scale_pen(L)=8.8398e-07 | scale_pen(Q)=1.4924e-05 | grad_norm=1.26 | sec/step~2.10
  step 180/512 | loss_L=1.1361 | loss_Q=1.0835 | scale_pen(L)=8.2136e-07 | scale_pen(Q)=1.4906e-05 | grad_norm=0.95 | sec/step~2.10
  step 190/512 | loss_L=1.1851 | loss_Q=1.1916 | scale_pen(L)=6.4902e-07 | scale_pen(Q)=1.5013e-05 | grad_norm=1.56 | sec/step~2.10
  step 200/512 | loss_L=1.1975 | loss_Q=1.2589 | scale_pen(L)=5.3452e-07 | scale_pen(Q)=1.5228e-05 | grad_norm=1.32 | sec/step~2.12
  [debug:L] a.scale=0.9993 | Z.std=0.9990 Z.mean||=15.9834 | p.std=0.6494 p.mean||=29.2902
  [debug:Q] a.scale=0.9961 | Z.std=0.9990 Z.mean||=15.9834 | p.std=0.6429 p.mean||=19.2202
  step 210/512 | loss_L=1.3790 | loss_Q=1.3870 | scale_pen(L)=5.1869e-07 | scale_pen(Q)=1.5123e-05 | grad_norm=1.52 | sec/step~2.12
  step 220/512 | loss_L=1.2425 | loss_Q=1.3145 | scale_pen(L)=3.3490e-07 | scale_pen(Q)=1.5851e-05 | grad_norm=1.35 | sec/step~2.11
  step 230/512 | loss_L=1.2739 | loss_Q=1.3134 | scale_pen(L)=1.8535e-07 | scale_pen(Q)=1.7481e-05 | grad_norm=1.48 | sec/step~2.11
  step 240/512 | loss_L=1.0441 | loss_Q=1.0474 | scale_pen(L)=1.2233e-07 | scale_pen(Q)=1.6625e-05 | grad_norm=1.01 | sec/step~2.10
  step 250/512 | loss_L=1.3414 | loss_Q=1.2813 | scale_pen(L)=1.7210e-07 | scale_pen(Q)=1.5991e-05 | grad_norm=1.22 | sec/step~2.10
  step 260/512 | loss_L=1.1748 | loss_Q=1.2589 | scale_pen(L)=2.0742e-07 | scale_pen(Q)=1.5400e-05 | grad_norm=1.53 | sec/step~2.10
  step 270/512 | loss_L=1.2356 | loss_Q=1.2707 | scale_pen(L)=2.9123e-07 | scale_pen(Q)=1.4754e-05 | grad_norm=1.45 | sec/step~2.13
  step 280/512 | loss_L=1.6767 | loss_Q=1.6374 | scale_pen(L)=3.4834e-07 | scale_pen(Q)=1.6038e-05 | grad_norm=1.48 | sec/step~2.12
  step 290/512 | loss_L=1.5698 | loss_Q=1.5673 | scale_pen(L)=2.6136e-07 | scale_pen(Q)=1.5678e-05 | grad_norm=1.15 | sec/step~2.18
  step 300/512 | loss_L=1.3464 | loss_Q=1.3390 | scale_pen(L)=2.1976e-07 | scale_pen(Q)=1.4845e-05 | grad_norm=1.10 | sec/step~2.24
  [debug:L] a.scale=0.9995 | Z.std=0.9988 Z.mean||=15.9809 | p.std=0.6514 p.mean||=29.3752
  [debug:Q] a.scale=0.9961 | Z.std=0.9988 Z.mean||=15.9809 | p.std=0.6456 p.mean||=19.3000
  step 310/512 | loss_L=0.9970 | loss_Q=1.0696 | scale_pen(L)=1.3856e-07 | scale_pen(Q)=1.4414e-05 | grad_norm=1.15 | sec/step~2.25
  step 320/512 | loss_L=1.3567 | loss_Q=1.3210 | scale_pen(L)=7.2230e-08 | scale_pen(Q)=1.4107e-05 | grad_norm=1.15 | sec/step~2.25
  step 330/512 | loss_L=1.2508 | loss_Q=1.2066 | scale_pen(L)=9.2551e-08 | scale_pen(Q)=1.4476e-05 | grad_norm=1.39 | sec/step~2.28
  step 340/512 | loss_L=1.3690 | loss_Q=1.2955 | scale_pen(L)=1.5863e-07 | scale_pen(Q)=1.4146e-05 | grad_norm=1.30 | sec/step~2.23
  step 350/512 | loss_L=1.3173 | loss_Q=1.4035 | scale_pen(L)=8.4571e-08 | scale_pen(Q)=1.4967e-05 | grad_norm=1.36 | sec/step~2.24
  step 360/512 | loss_L=1.5527 | loss_Q=1.5314 | scale_pen(L)=8.7755e-08 | scale_pen(Q)=1.5350e-05 | grad_norm=1.27 | sec/step~2.24
  step 370/512 | loss_L=1.6125 | loss_Q=1.6177 | scale_pen(L)=1.5112e-07 | scale_pen(Q)=1.5429e-05 | grad_norm=1.47 | sec/step~2.25
  step 380/512 | loss_L=1.3303 | loss_Q=1.2599 | scale_pen(L)=2.1250e-07 | scale_pen(Q)=1.6405e-05 | grad_norm=1.07 | sec/step~2.24
  step 390/512 | loss_L=1.4780 | loss_Q=1.3823 | scale_pen(L)=2.6264e-07 | scale_pen(Q)=1.8026e-05 | grad_norm=1.29 | sec/step~2.24
  step 400/512 | loss_L=1.2067 | loss_Q=1.2712 | scale_pen(L)=4.4828e-07 | scale_pen(Q)=1.7621e-05 | grad_norm=1.12 | sec/step~2.24
  [debug:L] a.scale=0.9993 | Z.std=0.9988 Z.mean||=15.9805 | p.std=0.6537 p.mean||=29.4716
  [debug:Q] a.scale=0.9958 | Z.std=0.9988 Z.mean||=15.9805 | p.std=0.6472 p.mean||=19.3482
  step 410/512 | loss_L=1.2642 | loss_Q=1.2131 | scale_pen(L)=4.4876e-07 | scale_pen(Q)=1.4816e-05 | grad_norm=1.00 | sec/step~2.24
  step 420/512 | loss_L=1.4692 | loss_Q=1.4412 | scale_pen(L)=3.5684e-07 | scale_pen(Q)=1.2180e-05 | grad_norm=1.29 | sec/step~2.23
  step 430/512 | loss_L=1.1622 | loss_Q=1.1349 | scale_pen(L)=4.2536e-07 | scale_pen(Q)=1.1780e-05 | grad_norm=1.20 | sec/step~2.23
  step 440/512 | loss_L=0.9438 | loss_Q=0.9775 | scale_pen(L)=4.8136e-07 | scale_pen(Q)=1.2064e-05 | grad_norm=1.10 | sec/step~2.23
  step 450/512 | loss_L=1.1818 | loss_Q=1.1647 | scale_pen(L)=6.2920e-07 | scale_pen(Q)=1.2758e-05 | grad_norm=1.42 | sec/step~2.23
  ✅ Saved checkpoint at step 2500
  step 460/512 | loss_L=0.9736 | loss_Q=0.9743 | scale_pen(L)=6.4556e-07 | scale_pen(Q)=1.3435e-05 | grad_norm=1.37 | sec/step~2.23
  step 470/512 | loss_L=1.3568 | loss_Q=1.3309 | scale_pen(L)=7.8980e-07 | scale_pen(Q)=1.4161e-05 | grad_norm=1.25 | sec/step~2.23
  step 480/512 | loss_L=1.4053 | loss_Q=1.4014 | scale_pen(L)=1.1236e-06 | scale_pen(Q)=1.3301e-05 | grad_norm=1.38 | sec/step~2.24
  step 490/512 | loss_L=1.6762 | loss_Q=1.5386 | scale_pen(L)=1.0037e-06 | scale_pen(Q)=1.2894e-05 | grad_norm=1.14 | sec/step~2.25
  step 500/512 | loss_L=1.2946 | loss_Q=1.2844 | scale_pen(L)=9.3895e-07 | scale_pen(Q)=1.1855e-05 | grad_norm=1.53 | sec/step~2.24
  [debug:L] a.scale=0.9990 | Z.std=0.9987 Z.mean||=15.9787 | p.std=0.6558 p.mean||=29.5637
  [debug:Q] a.scale=0.9966 | Z.std=0.9987 Z.mean||=15.9787 | p.std=0.6496 p.mean||=19.4175
  step 510/512 | loss_L=1.5635 | loss_Q=1.4858 | scale_pen(L)=9.1234e-07 | scale_pen(Q)=1.1052e-05 | grad_norm=1.47 | sec/step~2.25
  step 512/512 | loss_L=1.4612 | loss_Q=1.4642 | scale_pen(L)=9.6067e-07 | scale_pen(Q)=1.0991e-05 | grad_norm=1.35 | sec/step~2.25
  [debug:L] a.scale=0.9990 | Z.std=0.9986 Z.mean||=15.9781 | p.std=0.6550 p.mean||=29.5224
  [debug:Q] a.scale=0.9967 | Z.std=0.9986 Z.mean||=15.9781 | p.std=0.6501 p.mean||=19.4307
Saved encoder, adapters, and state to runs/squad_m16_scalereg_20250910_140510/ckpt
