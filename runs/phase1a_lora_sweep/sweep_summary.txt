Phase 1a + LoRA Sweep
Started: Wed Oct 15 22:40:01 PDT 2025
================================================
Model: meta-llama/Meta-Llama-3.1-8B-Instruct
Dataset: squad
Samples: 5000 (PCA: 4000)
Epochs:  2
Batch:   36
Compression: 4096 -> 1024
Adapter LR: 5e-4
Loss: Cosine (1.0) + MSE (0.1)
