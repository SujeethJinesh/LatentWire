=== Resume Hero Stage B Training (Schedule Fix) ===
Run tag: hero_resume
Checkpoint directory: runs/hero_resume/ckpt_stageb (using --auto_resume)
Epochs: 8 (extended for consolidation)

SCHEDULE FIXES (based on v1 analysis):
  - LATENT_KEEP_END: 1.0 → 0.85 (freeze at sweet spot)
  - EPOCHS extended to 8 (consolidate with frozen dropout)
  - Peak checkpointing: train.py saves '_best' automatically

Analysis showed peak at keep_prob=0.6-0.85:
  - Peak: 19.4% first_acc at keep_prob=0.613
  - 26 steps achieved ≥10% (all at keep_prob 0.55-0.82)
  - Final eval (keep_prob=1.0) only 4.4% - model never learned full latents

Retained from v1:
  - FIRST_TOKEN_CE_WEIGHT=11.0
  - KD_WEIGHT=0.5
  - OOM fixes: expandable_segments, KD_TEACHER_CHUNK=1
  - Performance: TEXT_TEACHER_CHUNK=4

torch: 2.4.0+cu121 cuda: 12.1 available: True
CUDA_VISIBLE_DEVICES: 0,1,2,3
PYTORCH_CUDA_ALLOC_CONF: expandable_segments:True

=== Stage B: Training with frozen dropout (keep_prob→0.85) ===

/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading dataset subset...
Loading SQuAD subset...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 6136.51it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:05,  1.96s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.80s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.62s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.33s/it]
[meta-llama/Meta-Llama-3.1-8B-Instruct] hf_device_map: {'model.embed_tokens': 0, 'model.rotary_emb': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 2, 'model.layers.17': 2, 'model.layers.18': 2, 'model.layers.19': 2, 'model.layers.20': 2, 'model.layers.21': 2, 'model.layers.22': 2, 'model.layers.23': 2, 'model.layers.24': 3, 'model.layers.25': 3, 'model.layers.26': 3, 'model.layers.27': 3, 'model.layers.28': 3, 'model.layers.29': 3, 'model.layers.30': 3, 'model.layers.31': 3, 'model.norm': 3, 'lm_head': 3}
trainable params: 41,943,040 || all params: 8,072,204,288 || trainable%: 0.5196
/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.
  warnings.warn(
trainable params: 272,801,792 || all params: 8,345,006,080 || trainable%: 3.2690
Llama hidden size: 4096
[DeviceMap] Llama: {'model.embed_tokens': 0, 'model.rotary_emb': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 2, 'model.layers.17': 2, 'model.layers.18': 2, 'model.layers.19': 2, 'model.layers.20': 2, 'model.layers.21': 2, 'model.layers.22': 2, 'model.layers.23': 2, 'model.layers.24': 3, 'model.layers.25': 3, 'model.layers.26': 3, 'model.layers.27': 3, 'model.layers.28': 3, 'model.layers.29': 3, 'model.layers.30': 3, 'model.layers.31': 3, 'model.norm': 3, 'lm_head': 3}
[INFO] llama anchor tokens: 3
⏪ Resuming from: runs/hero_resume/ckpt_stageb/state.pt
   -> loaded encoder/adapters/deep_prefix/refiner FROM state.pt
[DEBUG] Optimizer state devices:
  param_dev=cuda:0 state_devs={'step': 'cuda:0', 'exp_avg': 'cuda:0', 'exp_avg_sq': 'cuda:0'}
  param_dev=cuda:0 state_devs={'step': 'cuda:0', 'exp_avg': 'cuda:0', 'exp_avg_sq': 'cuda:0'}
  param_dev=cuda:0 state_devs={'step': 'cuda:0', 'exp_avg': 'cuda:0', 'exp_avg_sq': 'cuda:0'}
  param_dev=cuda:0 state_devs={'step': 'cuda:0', 'exp_avg': 'cuda:0', 'exp_avg_sq': 'cuda:0'}
  param_dev=cuda:0 state_devs={'step': 'cuda:0', 'exp_avg': 'cuda:0', 'exp_avg_sq': 'cuda:0'}
  param_dev=cuda:0 state_devs={'step': 'cuda:0', 'exp_avg': 'cuda:0', 'exp_avg_sq': 'cuda:0'}
  param_dev=cuda:0 state_devs={'step': 'cuda:0', 'exp_avg': 'cuda:0', 'exp_avg_sq': 'cuda:0'}
  param_dev=cuda:0 state_devs={'step': 'cuda:0', 'exp_avg': 'cuda:0', 'exp_avg_sq': 'cuda:0'}
   -> restored optimizer state
   -> restored RNG state
   -> start_epoch=4, global_step=2225
[warmup] alternating text/latent for first 890 steps
Epoch 5/8
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
We detected that you are passing `past_key_values` as a tuple of tuples. This is deprecated and will be removed in v4.47. Please convert your cache or use an appropriate `Cache` class (https://huggingface.co/docs/transformers/kv_cache#legacy-cache-format)
  step  10/445 | grad_norm=2.28 | sec/step~8.22 | keep=0.59 | K=8 | llama(L): tf=12.2330 first=16.1430 kCE=12.6427 KD=3.0748 acc=0.000 state=41.1632 align=0.0000 latA=0.8295 latP=0.2010 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  20/445 | (tail text) | align=0.0002 | text_tf=10.6699 | latent_scale=1.00
  step  20/445 | grad_norm=0.74 | sec/step~10.85 | keep=0.59 | K=8 | llama(T): tf=12.1086 first=12.9126 kCE=10.7888 KD=0.0000 acc=0.000 state=42.2881 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  30/445 | grad_norm=0.90 | sec/step~9.24 | keep=0.59 | K=8 | llama(L): tf=10.4233 first=9.3394 kCE=11.3289 KD=3.4865 acc=0.028 state=36.9467 align=0.0000 latA=0.8187 latP=0.2028 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  40/445 | grad_norm=0.54 | sec/step~8.13 | keep=0.59 | K=8 | llama(L): tf=10.1744 first=9.1199 kCE=11.3976 KD=3.3402 acc=0.000 state=20.7813 align=0.0000 latA=0.8308 latP=0.2021 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  50/445 | grad_norm=0.41 | sec/step~8.21 | keep=0.59 | K=8 | llama(L): tf=9.8094 first=9.0093 kCE=11.5959 KD=2.9720 acc=0.000 state=18.0979 align=0.0000 latA=0.8317 latP=0.2110 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  60/445 | grad_norm=1.85 | sec/step~8.11 | keep=0.59 | K=8 | llama(L): tf=9.9317 first=9.3910 kCE=11.9815 KD=3.8815 acc=0.028 state=17.0353 align=0.0000 latA=0.8379 latP=0.1998 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  70/445 | grad_norm=0.65 | sec/step~8.76 | keep=0.59 | K=8 | llama(L): tf=10.3480 first=8.4256 kCE=12.5042 KD=3.1763 acc=0.028 state=17.7230 align=0.0000 latA=0.8207 latP=0.1856 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  🌟 NEW PEAK: first_acc=13.9% at step 2302 → saved to runs/hero_resume/ckpt_stageb_best
  step  80/445 | grad_norm=0.95 | sec/step~8.33 | keep=0.60 | K=8 | llama(L): tf=10.5392 first=7.3191 kCE=13.1400 KD=3.3634 acc=0.083 state=16.1309 align=0.0000 latA=0.8177 latP=0.1978 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  🌟 NEW PEAK: first_acc=16.7% at step 2313 → saved to runs/hero_resume/ckpt_stageb_best
  step  90/445 | grad_norm=0.44 | sec/step~7.77 | keep=0.60 | K=8 | llama(L): tf=10.3523 first=7.9762 kCE=13.2363 KD=5.6278 acc=0.056 state=14.3508 align=0.0000 latA=0.8367 latP=0.1793 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  100/445 | grad_norm=0.40 | sec/step~8.28 | keep=0.60 | K=8 | llama(L): tf=10.5768 first=7.9224 kCE=13.4391 KD=3.0424 acc=0.056 state=13.6011 align=0.0000 latA=0.8351 latP=0.1810 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  101/445 | (tail text) | align=0.0003 | text_tf=10.6855 | latent_scale=1.00
  step  110/445 | grad_norm=0.22 | sec/step~9.00 | keep=0.60 | K=8 | llama(L): tf=10.5952 first=8.0299 kCE=13.2750 KD=3.0009 acc=0.056 state=14.0702 align=0.0000 latA=0.8288 latP=0.1878 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  120/445 | grad_norm=0.84 | sec/step~8.34 | keep=0.60 | K=8 | llama(L): tf=10.4674 first=7.6085 kCE=12.9105 KD=3.8379 acc=0.111 state=13.4139 align=0.0000 latA=0.8246 latP=0.2035 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  125/445 | (tail text) | align=0.0003 | text_tf=10.4937 | latent_scale=1.00
  step  127/445 | (tail text) | align=0.0003 | text_tf=10.6877 | latent_scale=1.00
  step  130/445 | grad_norm=0.77 | sec/step~8.27 | keep=0.60 | K=8 | llama(L): tf=10.2875 first=6.8473 kCE=12.8772 KD=5.0360 acc=0.111 state=11.3040 align=0.0000 latA=0.7993 latP=0.1915 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  140/445 | grad_norm=0.49 | sec/step~8.21 | keep=0.60 | K=8 | llama(L): tf=10.1515 first=7.7389 kCE=13.3480 KD=3.6975 acc=0.028 state=9.3362 align=0.0000 latA=0.8324 latP=0.1858 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  150/445 | grad_norm=1.02 | sec/step~8.07 | keep=0.60 | K=8 | llama(L): tf=10.3091 first=7.9263 kCE=13.4119 KD=3.2294 acc=0.028 state=8.6799 align=0.0000 latA=0.8282 latP=0.1734 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  160/445 | grad_norm=0.26 | sec/step~8.30 | keep=0.60 | K=8 | llama(L): tf=9.7815 first=7.5225 kCE=13.2573 KD=2.9164 acc=0.111 state=7.6488 align=0.0000 latA=0.8250 latP=0.1709 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  170/445 | grad_norm=0.13 | sec/step~8.49 | keep=0.60 | K=8 | llama(L): tf=10.3270 first=7.7367 kCE=13.2065 KD=2.9892 acc=0.028 state=5.9146 align=0.0000 latA=0.8222 latP=0.1803 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  180/445 | grad_norm=0.77 | sec/step~8.00 | keep=0.61 | K=8 | llama(L): tf=10.4038 first=7.8904 kCE=13.1037 KD=4.1048 acc=0.000 state=2.0037 align=0.0000 latA=0.8376 latP=0.1829 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  190/445 | grad_norm=0.42 | sec/step~8.19 | keep=0.61 | K=8 | llama(L): tf=10.2828 first=7.4366 kCE=13.3517 KD=4.4504 acc=0.028 state=5.0721 align=0.0000 latA=0.8099 latP=0.1684 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  200/445 | grad_norm=0.65 | sec/step~8.34 | keep=0.61 | K=8 | llama(L): tf=10.3487 first=7.2116 kCE=13.3019 KD=3.3041 acc=0.083 state=2.7943 align=0.0000 latA=0.8078 latP=0.1694 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  210/445 | grad_norm=0.79 | sec/step~8.31 | keep=0.61 | K=8 | llama(L): tf=10.3076 first=7.2856 kCE=12.8837 KD=3.4832 acc=0.056 state=2.7352 align=0.0000 latA=0.8106 latP=0.1843 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  220/445 | grad_norm=0.34 | sec/step~8.40 | keep=0.61 | K=8 | llama(L): tf=10.0391 first=7.8505 kCE=12.8084 KD=2.9239 acc=0.000 state=2.5724 align=0.0000 latA=0.8487 latP=0.1764 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  230/445 | grad_norm=0.22 | sec/step~9.41 | keep=0.61 | K=8 | llama(L): tf=9.3813 first=7.1867 kCE=12.1401 KD=2.6791 acc=0.083 state=7.7943 align=0.0000 latA=0.8059 latP=0.1828 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  240/445 | grad_norm=1.07 | sec/step~7.89 | keep=0.61 | K=8 | llama(L): tf=9.7266 first=7.1989 kCE=12.4765 KD=3.8634 acc=0.028 state=0.7411 align=0.0000 latA=0.8042 latP=0.1695 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  250/445 | grad_norm=1.58 | sec/step~8.17 | keep=0.61 | K=8 | llama(L): tf=9.6882 first=7.8827 kCE=12.1604 KD=2.7659 acc=0.000 state=0.7591 align=0.0000 latA=0.8331 latP=0.1742 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  260/445 | grad_norm=0.59 | sec/step~8.22 | keep=0.61 | K=8 | llama(L): tf=9.6323 first=7.9798 kCE=12.4340 KD=3.3041 acc=0.028 state=1.9762 align=0.0000 latA=0.8355 latP=0.1640 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  270/445 | (tail text) | align=0.0003 | text_tf=9.2225 | latent_scale=1.00
  step  270/445 | grad_norm=0.55 | sec/step~6.80 | keep=0.62 | K=8 | llama(T): tf=9.0522 first=7.6128 kCE=11.7270 KD=0.0000 acc=0.083 state=0.2408 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  280/445 | grad_norm=0.28 | sec/step~8.23 | keep=0.62 | K=8 | llama(L): tf=9.6820 first=7.8434 kCE=11.6762 KD=4.7053 acc=0.000 state=0.7148 align=0.0000 latA=0.8269 latP=0.1663 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  290/445 | grad_norm=0.19 | sec/step~8.18 | keep=0.62 | K=8 | llama(L): tf=8.6844 first=6.6786 kCE=11.0163 KD=2.6245 acc=0.083 state=0.0756 align=0.0000 latA=0.8016 latP=0.1687 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  291/445 | (tail text) | align=0.0003 | text_tf=10.0735 | latent_scale=1.00
  step  298/445 | (tail text) | align=0.0002 | text_tf=9.4121 | latent_scale=1.00
  step  300/445 | grad_norm=0.67 | sec/step~8.23 | keep=0.62 | K=8 | llama(L): tf=9.1661 first=7.6048 kCE=11.2896 KD=2.9571 acc=0.000 state=0.1422 align=0.0000 latA=0.8378 latP=0.1662 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  310/445 | grad_norm=0.63 | sec/step~8.69 | keep=0.62 | K=8 | llama(L): tf=9.4917 first=7.4199 kCE=10.7755 KD=2.7644 acc=0.056 state=0.7185 align=0.0000 latA=0.8132 latP=0.1765 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  320/445 | grad_norm=0.74 | sec/step~9.32 | keep=0.62 | K=8 | llama(L): tf=9.2391 first=7.4882 kCE=10.6126 KD=2.9404 acc=0.083 state=5.0998 align=0.0000 latA=0.8253 latP=0.1697 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  330/445 | grad_norm=0.61 | sec/step~8.00 | keep=0.62 | K=8 | llama(L): tf=9.3712 first=7.3207 kCE=10.3938 KD=2.9620 acc=0.056 state=0.2405 align=0.0000 latA=0.8061 latP=0.1615 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  340/445 | grad_norm=0.24 | sec/step~7.81 | keep=0.62 | K=8 | llama(L): tf=9.1753 first=7.0635 kCE=10.0087 KD=3.0758 acc=0.139 state=0.0729 align=0.0000 latA=0.7866 latP=0.1765 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  350/445 | grad_norm=0.22 | sec/step~9.16 | keep=0.63 | K=8 | llama(L): tf=9.1893 first=7.4256 kCE=9.6552 KD=3.0886 acc=0.056 state=4.1317 align=0.0000 latA=0.8161 latP=0.1780 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  360/445 | grad_norm=1.11 | sec/step~8.38 | keep=0.63 | K=8 | llama(L): tf=9.3490 first=7.7012 kCE=9.8450 KD=2.8637 acc=0.056 state=0.2670 align=0.0000 latA=0.8124 latP=0.1682 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  369/445 | (tail text) | align=0.0003 | text_tf=9.6686 | latent_scale=1.00
  step  370/445 | grad_norm=0.50 | sec/step~8.29 | keep=0.63 | K=8 | llama(L): tf=9.0828 first=7.3689 kCE=9.5662 KD=3.3293 acc=0.028 state=0.3980 align=0.0000 latA=0.8083 latP=0.1664 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  380/445 | grad_norm=0.77 | sec/step~8.10 | keep=0.63 | K=8 | llama(L): tf=8.6826 first=6.7988 kCE=9.2731 KD=3.4471 acc=0.111 state=0.0256 align=0.0000 latA=0.7867 latP=0.1795 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  390/445 | grad_norm=0.80 | sec/step~8.03 | keep=0.63 | K=8 | llama(L): tf=9.1196 first=7.7987 kCE=9.1294 KD=4.3696 acc=0.083 state=0.0240 align=0.0000 latA=0.8286 latP=0.1536 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  395/445 | (tail text) | align=0.0003 | text_tf=9.9580 | latent_scale=1.00
  step  400/445 | grad_norm=0.53 | sec/step~8.46 | keep=0.63 | K=8 | llama(L): tf=8.9276 first=7.4651 kCE=8.6851 KD=3.5647 acc=0.083 state=0.7925 align=0.0000 latA=0.8145 latP=0.1744 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  410/445 | grad_norm=0.19 | sec/step~8.15 | keep=0.63 | K=8 | llama(L): tf=8.5784 first=7.5370 kCE=8.2189 KD=2.7787 acc=0.083 state=0.1369 align=0.0000 latA=0.8125 latP=0.1687 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  420/445 | grad_norm=1.33 | sec/step~8.36 | keep=0.63 | K=8 | llama(L): tf=8.6246 first=8.0240 kCE=8.1575 KD=3.9153 acc=0.000 state=0.1628 align=0.0000 latA=0.8265 latP=0.1608 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  428/445 | (tail text) | align=0.0002 | text_tf=9.8793 | latent_scale=1.00
  step  430/445 | grad_norm=1.03 | sec/step~8.05 | keep=0.63 | K=8 | llama(L): tf=8.7385 first=7.2618 kCE=7.9245 KD=3.7718 acc=0.111 state=0.2283 align=0.0000 latA=0.7999 latP=0.1643 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  440/445 | grad_norm=0.74 | sec/step~8.99 | keep=0.64 | K=8 | llama(L): tf=9.0949 first=7.7666 kCE=7.7369 KD=3.1662 acc=0.000 state=0.4204 align=0.0000 latA=0.8231 latP=0.1563 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  445/445 | grad_norm=0.26 | sec/step~6.03 | keep=0.64 | K=8 | llama(L): tf=8.8543 first=7.0745 kCE=7.0360 KD=3.7633 acc=0.062 state=0.0265 align=0.0000 latA=0.8068 latP=0.1490 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
[checkpoint] Freed 3.6KB before save.
[checkpoint] Saved latest: encoder.pt, state.pt, config.json, adapter_llama.pt, deep_prefix_llama.pt, refiner.pt, training_stats.json
[checkpoint] Freed 0.0B after save (non-canonical).
  ✅ Saved (and pruned to) latest at step 2670
Epoch 6/8
  step  10/445 | grad_norm=0.70 | sec/step~8.38 | keep=0.64 | K=8 | llama(L): tf=8.8810 first=7.2213 kCE=7.1645 KD=2.8489 acc=0.111 state=0.2128 align=0.0000 latA=0.7992 latP=0.1624 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  20/445 | grad_norm=0.69 | sec/step~9.85 | keep=0.64 | K=8 | llama(L): tf=9.1907 first=7.7779 kCE=7.0497 KD=3.7532 acc=0.028 state=3.2423 align=0.0000 latA=0.8217 latP=0.1629 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  30/445 | grad_norm=0.42 | sec/step~8.34 | keep=0.64 | K=8 | llama(L): tf=9.4459 first=7.9760 kCE=6.5554 KD=2.8470 acc=0.000 state=0.1628 align=0.0000 latA=0.8343 latP=0.1401 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  37/445 | (tail text) | align=0.0003 | text_tf=9.7577 | latent_scale=1.00
  step  40/445 | grad_norm=0.26 | sec/step~8.24 | keep=0.64 | K=8 | llama(L): tf=8.7388 first=7.3625 kCE=6.6705 KD=4.0707 acc=0.056 state=0.1808 align=0.0000 latA=0.8146 latP=0.1533 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  50/445 | grad_norm=0.14 | sec/step~8.15 | keep=0.64 | K=8 | llama(L): tf=8.6749 first=7.3110 kCE=7.0724 KD=3.1446 acc=0.056 state=0.1185 align=0.0000 latA=0.8044 latP=0.1653 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  60/445 | grad_norm=0.90 | sec/step~8.58 | keep=0.64 | K=8 | llama(L): tf=9.4201 first=6.8032 kCE=6.6670 KD=3.0511 acc=0.111 state=0.5716 align=0.0000 latA=0.7950 latP=0.1549 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  70/445 | grad_norm=0.88 | sec/step~8.42 | keep=0.65 | K=8 | llama(L): tf=9.0798 first=7.7382 kCE=7.2807 KD=3.5721 acc=0.056 state=0.6519 align=0.0000 latA=0.7979 latP=0.1844 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  74/445 | (tail text) | align=0.0003 | text_tf=9.5570 | latent_scale=1.00
  step  80/445 | grad_norm=1.05 | sec/step~9.73 | keep=0.65 | K=8 | llama(L): tf=8.7945 first=6.8911 kCE=7.0531 KD=3.4863 acc=0.083 state=5.8076 align=0.0000 latA=0.8096 latP=0.1767 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  90/445 | grad_norm=0.63 | sec/step~8.95 | keep=0.65 | K=8 | llama(L): tf=9.0075 first=7.8872 kCE=6.8495 KD=3.4397 acc=0.028 state=0.1732 align=0.0000 latA=0.8240 latP=0.1619 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  100/445 | grad_norm=0.28 | sec/step~8.80 | keep=0.65 | K=8 | llama(L): tf=8.7945 first=7.1882 kCE=6.8995 KD=3.0322 acc=0.111 state=0.0698 align=0.0000 latA=0.7930 latP=0.1700 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  110/445 | grad_norm=0.28 | sec/step~8.67 | keep=0.65 | K=8 | llama(L): tf=9.3028 first=7.6140 kCE=7.0135 KD=4.2844 acc=0.028 state=0.0646 align=0.0000 latA=0.8251 latP=0.1587 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  120/445 | grad_norm=1.35 | sec/step~7.97 | keep=0.65 | K=8 | llama(L): tf=8.7107 first=7.2311 kCE=6.5665 KD=2.8991 acc=0.083 state=0.0222 align=0.0000 latA=0.8026 latP=0.1520 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  130/445 | grad_norm=1.13 | sec/step~8.20 | keep=0.65 | K=8 | llama(L): tf=8.6668 first=6.9720 kCE=6.6403 KD=2.4736 acc=0.028 state=0.2672 align=0.0000 latA=0.7832 latP=0.1482 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  140/445 | grad_norm=1.11 | sec/step~8.30 | keep=0.65 | K=8 | llama(L): tf=8.7450 first=7.0575 kCE=6.5653 KD=2.8391 acc=0.083 state=0.1480 align=0.0000 latA=0.7876 latP=0.1429 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  150/445 | grad_norm=0.41 | sec/step~8.23 | keep=0.66 | K=8 | llama(L): tf=8.5931 first=7.3767 kCE=6.5135 KD=3.2121 acc=0.056 state=0.1225 align=0.0000 latA=0.7893 latP=0.1379 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  154/445 | (tail text) | align=0.0003 | text_tf=9.5459 | latent_scale=1.00
  step  160/445 | grad_norm=0.58 | sec/step~8.75 | keep=0.66 | K=8 | llama(L): tf=8.6950 first=7.3468 kCE=6.4029 KD=2.9914 acc=0.056 state=0.2802 align=0.0000 latA=0.8001 latP=0.1521 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  170/445 | grad_norm=0.47 | sec/step~8.09 | keep=0.66 | K=8 | llama(L): tf=8.3405 first=6.7674 kCE=6.4228 KD=2.8563 acc=0.083 state=0.0466 align=0.0000 latA=0.7630 latP=0.1491 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  180/445 | grad_norm=2.67 | sec/step~9.41 | keep=0.66 | K=8 | llama(L): tf=9.1168 first=7.7900 kCE=7.0537 KD=4.4630 acc=0.000 state=2.7940 align=0.0000 latA=0.8275 latP=0.1609 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  190/445 | grad_norm=0.67 | sec/step~8.34 | keep=0.66 | K=8 | llama(L): tf=8.7235 first=8.1089 kCE=6.3329 KD=3.1335 acc=0.028 state=0.0418 align=0.0000 latA=0.8138 latP=0.1468 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  193/445 | (tail text) | align=0.0003 | text_tf=9.8898 | latent_scale=1.00
  step  200/445 | grad_norm=1.05 | sec/step~8.28 | keep=0.66 | K=8 | llama(L): tf=8.5920 first=7.8857 kCE=6.6615 KD=3.0157 acc=0.000 state=0.2385 align=0.0000 latA=0.8068 latP=0.1687 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  210/445 | grad_norm=0.66 | sec/step~8.15 | keep=0.66 | K=8 | llama(L): tf=8.5298 first=7.1459 kCE=6.1495 KD=5.3198 acc=0.083 state=0.0392 align=0.0000 latA=0.7780 latP=0.1378 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  220/445 | grad_norm=0.49 | sec/step~8.50 | keep=0.67 | K=8 | llama(L): tf=8.5235 first=7.2475 kCE=6.6272 KD=2.9428 acc=0.083 state=0.0783 align=0.0000 latA=0.8022 latP=0.1492 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  230/445 | grad_norm=0.34 | sec/step~8.36 | keep=0.67 | K=8 | llama(L): tf=8.5549 first=7.8359 kCE=6.4110 KD=3.0045 acc=0.056 state=0.0948 align=0.0000 latA=0.8078 latP=0.1386 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  240/445 | (tail text) | align=0.0003 | text_tf=9.7694 | latent_scale=1.00
  step  240/445 | grad_norm=1.38 | sec/step~6.85 | keep=0.67 | K=8 | llama(T): tf=8.5418 first=7.1562 kCE=6.6904 KD=0.0000 acc=0.028 state=0.1199 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  250/445 | grad_norm=1.09 | sec/step~8.20 | keep=0.67 | K=8 | llama(L): tf=8.9602 first=8.3311 kCE=6.8844 KD=3.2154 acc=0.000 state=0.0185 align=0.0000 latA=0.8400 latP=0.1437 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  260/445 | grad_norm=0.90 | sec/step~8.42 | keep=0.67 | K=8 | llama(L): tf=8.7421 first=7.7847 kCE=6.3568 KD=2.9815 acc=0.056 state=0.1402 align=0.0000 latA=0.8273 latP=0.1375 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  270/445 | grad_norm=0.39 | sec/step~8.74 | keep=0.67 | K=8 | llama(L): tf=8.5106 first=7.5174 kCE=6.5405 KD=2.9106 acc=0.056 state=0.8945 align=0.0000 latA=0.7929 latP=0.1492 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  280/445 | grad_norm=0.27 | sec/step~8.93 | keep=0.67 | K=8 | llama(L): tf=8.6150 first=7.2687 kCE=5.8268 KD=3.5476 acc=0.056 state=0.3524 align=0.0000 latA=0.8113 latP=0.1268 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  290/445 | grad_norm=0.26 | sec/step~8.46 | keep=0.67 | K=8 | llama(L): tf=8.4370 first=7.5689 kCE=6.3426 KD=3.4565 acc=0.056 state=0.0435 align=0.0000 latA=0.8018 latP=0.1486 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  300/445 | grad_norm=1.39 | sec/step~8.33 | keep=0.68 | K=8 | llama(L): tf=8.9349 first=7.7989 kCE=6.3432 KD=2.8222 acc=0.083 state=0.0597 align=0.0000 latA=0.7969 latP=0.1356 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  🌟 NEW PEAK: first_acc=19.4% at step 2976 → saved to runs/hero_resume/ckpt_stageb_best
  step  310/445 | grad_norm=0.42 | sec/step~9.36 | keep=0.68 | K=8 | llama(L): tf=8.6362 first=7.5000 kCE=5.6055 KD=2.7587 acc=0.056 state=2.9590 align=0.0000 latA=0.8061 latP=0.1216 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  320/445 | grad_norm=1.02 | sec/step~8.00 | keep=0.68 | K=8 | llama(L): tf=8.8190 first=7.5701 kCE=6.4936 KD=3.1095 acc=0.167 state=0.0178 align=0.0000 latA=0.8055 latP=0.1505 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  330/445 | grad_norm=0.83 | sec/step~7.94 | keep=0.68 | K=8 | llama(L): tf=8.7080 first=7.4756 kCE=6.4755 KD=3.7150 acc=0.056 state=0.0180 align=0.0000 latA=0.7962 latP=0.1461 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  340/445 | grad_norm=0.37 | sec/step~8.89 | keep=0.68 | K=8 | llama(L): tf=8.0716 first=7.5479 kCE=6.0139 KD=3.5389 acc=0.083 state=0.6683 align=0.0000 latA=0.8112 latP=0.1350 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  350/445 | grad_norm=0.26 | sec/step~7.99 | keep=0.68 | K=8 | llama(L): tf=8.5493 first=7.5189 kCE=6.1524 KD=4.1067 acc=0.028 state=0.0716 align=0.0000 latA=0.8003 latP=0.1394 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  360/445 | grad_norm=0.95 | sec/step~8.11 | keep=0.68 | K=8 | llama(L): tf=8.4322 first=6.6248 kCE=6.5870 KD=3.0047 acc=0.111 state=0.2086 align=0.0000 latA=0.7682 latP=0.1631 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  370/445 | grad_norm=1.29 | sec/step~9.02 | keep=0.69 | K=8 | llama(L): tf=8.5371 first=7.1285 kCE=6.1255 KD=3.1184 acc=0.056 state=1.2237 align=0.0000 latA=0.8017 latP=0.1347 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  380/445 | grad_norm=0.83 | sec/step~10.05 | keep=0.69 | K=8 | llama(L): tf=8.9716 first=7.9900 kCE=5.9363 KD=3.1772 acc=0.000 state=5.0360 align=0.0000 latA=0.8176 latP=0.1320 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  390/445 | grad_norm=0.70 | sec/step~9.33 | keep=0.69 | K=8 | llama(L): tf=8.7377 first=6.7749 kCE=6.4014 KD=2.8025 acc=0.000 state=0.5699 align=0.0000 latA=0.7920 latP=0.1380 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  400/445 | grad_norm=0.62 | sec/step~8.15 | keep=0.69 | K=8 | llama(L): tf=8.0908 first=6.6513 kCE=6.0473 KD=3.3885 acc=0.056 state=0.1248 align=0.0000 latA=0.7930 latP=0.1416 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  410/445 | grad_norm=0.27 | sec/step~9.20 | keep=0.69 | K=8 | llama(L): tf=8.4511 first=7.4247 kCE=6.5007 KD=3.3298 acc=0.028 state=0.3849 align=0.0000 latA=0.7845 latP=0.1539 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  420/445 | grad_norm=0.81 | sec/step~8.40 | keep=0.69 | K=8 | llama(L): tf=8.7333 first=7.7016 kCE=6.5207 KD=3.8554 acc=0.028 state=0.0482 align=0.0000 latA=0.8070 latP=0.1448 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  430/445 | grad_norm=0.95 | sec/step~8.35 | keep=0.69 | K=8 | llama(L): tf=9.1183 first=7.6354 kCE=6.6135 KD=3.1593 acc=0.028 state=0.2047 align=0.0000 latA=0.8093 latP=0.1411 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  438/445 | (tail text) | align=0.0002 | text_tf=9.3792 | latent_scale=1.00
  step  440/445 | grad_norm=0.86 | sec/step~8.97 | keep=0.70 | K=8 | llama(L): tf=8.5193 first=6.9347 kCE=6.3223 KD=3.0198 acc=0.083 state=0.1368 align=0.0000 latA=0.7930 latP=0.1340 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  445/445 | grad_norm=0.15 | sec/step~5.02 | keep=0.70 | K=8 | llama(L): tf=8.9344 first=7.5804 kCE=6.6097 KD=2.8444 acc=0.062 state=0.0349 align=0.0000 latA=0.7926 latP=0.1291 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
[checkpoint] Freed 0.0B before save.
[checkpoint] Saved latest: encoder.pt, state.pt, config.json, adapter_llama.pt, deep_prefix_llama.pt, refiner.pt, training_stats.json
[checkpoint] Freed 0.0B after save (non-canonical).
  ✅ Saved (and pruned to) latest at step 3115
Epoch 7/8
  step  10/445 | grad_norm=1.39 | sec/step~7.99 | keep=0.70 | K=8 | llama(L): tf=8.6662 first=7.0132 kCE=6.3614 KD=2.7444 acc=0.000 state=0.0224 align=0.0000 latA=0.7849 latP=0.1429 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  20/445 | grad_norm=1.55 | sec/step~8.21 | keep=0.70 | K=8 | llama(L): tf=8.9665 first=7.1354 kCE=6.5415 KD=2.7962 acc=0.056 state=0.1809 align=0.0000 latA=0.7895 latP=0.1476 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  30/445 | grad_norm=0.67 | sec/step~8.20 | keep=0.70 | K=8 | llama(L): tf=8.8939 first=7.7769 kCE=6.2454 KD=3.6354 acc=0.056 state=0.0465 align=0.0000 latA=0.8115 latP=0.1368 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  40/445 | grad_norm=0.61 | sec/step~8.21 | keep=0.70 | K=8 | llama(L): tf=8.6314 first=7.0877 kCE=5.9755 KD=3.1632 acc=0.028 state=0.0646 align=0.0000 latA=0.7910 latP=0.1335 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  50/445 | grad_norm=0.66 | sec/step~8.80 | keep=0.70 | K=8 | llama(L): tf=8.4897 first=7.2348 kCE=5.9248 KD=3.2517 acc=0.083 state=1.2873 align=0.0000 latA=0.8017 latP=0.1341 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  60/445 | grad_norm=2.33 | sec/step~8.34 | keep=0.71 | K=8 | llama(L): tf=8.2903 first=7.3885 kCE=6.2122 KD=3.3889 acc=0.028 state=0.1537 align=0.0000 latA=0.7907 latP=0.1538 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  67/445 | (tail text) | align=0.0003 | text_tf=9.1299 | latent_scale=1.00
  step  70/445 | grad_norm=1.39 | sec/step~8.28 | keep=0.71 | K=8 | llama(L): tf=8.7662 first=7.7200 kCE=6.0316 KD=2.8295 acc=0.083 state=0.0556 align=0.0000 latA=0.8073 latP=0.1359 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  80/445 | grad_norm=0.98 | sec/step~9.55 | keep=0.71 | K=8 | llama(L): tf=8.1755 first=7.4389 kCE=6.1170 KD=3.1392 acc=0.056 state=5.5276 align=0.0000 latA=0.8043 latP=0.1621 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  90/445 | grad_norm=1.40 | sec/step~9.21 | keep=0.71 | K=8 | llama(L): tf=8.3870 first=7.2871 kCE=5.8321 KD=2.7543 acc=0.056 state=2.9134 align=0.0000 latA=0.7834 latP=0.1243 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  100/445 | grad_norm=0.59 | sec/step~8.36 | keep=0.71 | K=8 | llama(L): tf=8.3797 first=7.2595 kCE=6.4105 KD=3.4418 acc=0.028 state=0.0856 align=0.0000 latA=0.7858 latP=0.1508 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  110/445 | grad_norm=0.67 | sec/step~8.27 | keep=0.71 | K=8 | llama(L): tf=8.5867 first=7.2398 kCE=6.0111 KD=2.7079 acc=0.083 state=0.0914 align=0.0000 latA=0.7991 latP=0.1356 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  120/445 | grad_norm=2.60 | sec/step~8.61 | keep=0.71 | K=8 | llama(L): tf=8.4938 first=6.9881 kCE=6.3538 KD=3.0288 acc=0.028 state=0.2563 align=0.0000 latA=0.7902 latP=0.1459 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  130/445 | grad_norm=1.06 | sec/step~8.27 | keep=0.72 | K=8 | llama(L): tf=8.9763 first=8.3772 kCE=6.1703 KD=2.9081 acc=0.028 state=0.0374 align=0.0000 latA=0.8316 latP=0.1342 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  137/445 | (tail text) | align=0.0002 | text_tf=9.4525 | latent_scale=1.00
  step  140/445 | grad_norm=1.42 | sec/step~8.61 | keep=0.72 | K=8 | llama(L): tf=7.9846 first=6.4814 kCE=6.2643 KD=2.7552 acc=0.083 state=0.0932 align=0.0000 latA=0.7657 latP=0.1516 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  145/445 | (tail text) | align=0.0003 | text_tf=9.2785 | latent_scale=1.00
  step  150/445 | grad_norm=1.01 | sec/step~9.16 | keep=0.72 | K=8 | llama(L): tf=8.5920 first=7.6919 kCE=6.0759 KD=2.7099 acc=0.056 state=0.9553 align=0.0000 latA=0.8088 latP=0.1296 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  160/445 | grad_norm=0.52 | sec/step~8.21 | keep=0.72 | K=8 | llama(L): tf=8.5928 first=7.3256 kCE=6.1542 KD=2.4593 acc=0.028 state=0.1138 align=0.0000 latA=0.8040 latP=0.1404 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  170/445 | grad_norm=0.45 | sec/step~8.27 | keep=0.72 | K=8 | llama(L): tf=8.5642 first=7.3474 kCE=5.9323 KD=2.9890 acc=0.028 state=0.0234 align=0.0000 latA=0.7890 latP=0.1349 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  180/445 | grad_norm=2.10 | sec/step~8.87 | keep=0.72 | K=8 | llama(L): tf=8.5535 first=7.2719 kCE=5.7565 KD=4.1196 acc=0.083 state=0.3528 align=0.0000 latA=0.7983 latP=0.1356 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  190/445 | grad_norm=0.82 | sec/step~9.46 | keep=0.73 | K=8 | llama(L): tf=8.6198 first=7.3433 kCE=5.5964 KD=3.0434 acc=0.056 state=1.0688 align=0.0000 latA=0.7709 latP=0.1432 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  200/445 | grad_norm=0.68 | sec/step~8.04 | keep=0.73 | K=8 | llama(L): tf=8.2476 first=7.7196 kCE=6.3370 KD=3.0143 acc=0.028 state=0.0220 align=0.0000 latA=0.7996 latP=0.1555 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  210/445 | grad_norm=0.96 | sec/step~8.36 | keep=0.73 | K=8 | llama(L): tf=8.7063 first=7.0748 kCE=5.7991 KD=2.6621 acc=0.083 state=0.0674 align=0.0000 latA=0.8016 latP=0.1380 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  220/445 | grad_norm=0.63 | sec/step~8.65 | keep=0.73 | K=8 | llama(L): tf=8.6273 first=7.3444 kCE=5.9176 KD=3.2229 acc=0.000 state=0.4983 align=0.0000 latA=0.7995 latP=0.1371 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  230/445 | grad_norm=0.28 | sec/step~8.34 | keep=0.73 | K=8 | llama(L): tf=8.2607 first=7.3679 kCE=5.8651 KD=3.1974 acc=0.056 state=0.1219 align=0.0000 latA=0.7842 latP=0.1403 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  240/445 | grad_norm=2.17 | sec/step~8.01 | keep=0.73 | K=8 | llama(L): tf=8.7536 first=7.7802 kCE=5.8660 KD=3.1696 acc=0.000 state=0.0229 align=0.0000 latA=0.7973 latP=0.1332 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  244/445 | (tail text) | align=0.0003 | text_tf=9.2074 | latent_scale=1.00
  step  250/445 | grad_norm=1.86 | sec/step~8.30 | keep=0.74 | K=8 | llama(L): tf=8.9623 first=7.4826 kCE=6.0244 KD=2.9169 acc=0.056 state=0.5161 align=0.0000 latA=0.8062 latP=0.1281 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  260/445 | grad_norm=1.05 | sec/step~8.57 | keep=0.74 | K=8 | llama(L): tf=8.1007 first=7.4690 kCE=5.8932 KD=2.9697 acc=0.056 state=0.1310 align=0.0000 latA=0.7953 latP=0.1448 | scale_pen(llama)=3.1974e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  270/445 | grad_norm=1.14 | sec/step~8.55 | keep=0.74 | K=8 | llama(L): tf=8.0327 first=6.8748 kCE=5.8413 KD=2.8787 acc=0.056 state=0.1041 align=0.0000 latA=0.7959 latP=0.1396 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  279/445 | (tail text) | align=0.0002 | text_tf=9.0519 | latent_scale=1.00
  step  280/445 | grad_norm=0.26 | sec/step~8.14 | keep=0.74 | K=8 | llama(L): tf=8.2756 first=7.1635 kCE=5.9979 KD=2.8736 acc=0.028 state=0.0990 align=0.0000 latA=0.7860 latP=0.1413 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  285/445 | (tail text) | align=0.0003 | text_tf=9.2710 | latent_scale=1.00
  step  290/445 | grad_norm=0.21 | sec/step~9.49 | keep=0.74 | K=8 | llama(L): tf=8.4357 first=6.9991 kCE=6.6816 KD=3.6650 acc=0.083 state=4.1379 align=0.0000 latA=0.7877 latP=0.1528 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  296/445 | (tail text) | align=0.0003 | text_tf=9.4728 | latent_scale=1.00
  step  300/445 | grad_norm=1.49 | sec/step~8.58 | keep=0.74 | K=8 | llama(L): tf=8.4306 first=7.9679 kCE=5.2756 KD=2.8620 acc=0.000 state=0.3318 align=0.0000 latA=0.8067 latP=0.1249 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  310/445 | grad_norm=0.74 | sec/step~9.05 | keep=0.75 | K=8 | llama(L): tf=8.5092 first=7.3850 kCE=5.4448 KD=2.5759 acc=0.056 state=2.2063 align=0.0000 latA=0.7864 latP=0.1236 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  320/445 | grad_norm=0.67 | sec/step~8.88 | keep=0.75 | K=8 | llama(L): tf=8.4276 first=7.6687 kCE=6.1835 KD=3.1189 acc=0.028 state=0.9078 align=0.0000 latA=0.7937 latP=0.1557 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  330/445 | grad_norm=0.91 | sec/step~8.88 | keep=0.75 | K=8 | llama(L): tf=8.5785 first=7.9228 kCE=5.5966 KD=3.0724 acc=0.056 state=0.1246 align=0.0000 latA=0.7872 latP=0.1307 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  340/445 | grad_norm=0.41 | sec/step~8.24 | keep=0.75 | K=8 | llama(L): tf=8.1235 first=6.8326 kCE=6.0348 KD=2.5228 acc=0.111 state=0.1699 align=0.0000 latA=0.7659 latP=0.1469 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  350/445 | grad_norm=0.65 | sec/step~9.34 | keep=0.75 | K=8 | llama(L): tf=8.4655 first=7.3096 kCE=5.7834 KD=3.4869 acc=0.000 state=1.2558 align=0.0000 latA=0.7995 latP=0.1389 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  360/445 | grad_norm=0.83 | sec/step~8.15 | keep=0.75 | K=8 | llama(L): tf=8.2609 first=7.4328 kCE=6.3152 KD=3.3067 acc=0.056 state=0.0565 align=0.0000 latA=0.7844 latP=0.1545 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  370/445 | grad_norm=2.36 | sec/step~8.28 | keep=0.76 | K=8 | llama(L): tf=8.6661 first=7.3342 kCE=5.9860 KD=4.9117 acc=0.083 state=0.0305 align=0.0000 latA=0.7838 latP=0.1338 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  380/445 | grad_norm=0.42 | sec/step~9.26 | keep=0.76 | K=8 | llama(L): tf=8.6576 first=7.4304 kCE=6.3078 KD=2.8129 acc=0.028 state=1.0037 align=0.0000 latA=0.8091 latP=0.1495 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  390/445 | grad_norm=0.50 | sec/step~8.23 | keep=0.76 | K=8 | llama(L): tf=8.1955 first=6.7682 kCE=6.1402 KD=3.9458 acc=0.139 state=0.0415 align=0.0000 latA=0.7482 latP=0.1388 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  400/445 | grad_norm=0.30 | sec/step~9.27 | keep=0.76 | K=8 | llama(L): tf=8.8923 first=7.4425 kCE=6.3276 KD=2.8665 acc=0.028 state=0.9749 align=0.0000 latA=0.8047 latP=0.1457 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  410/445 | grad_norm=0.32 | sec/step~9.00 | keep=0.76 | K=8 | llama(L): tf=8.6014 first=7.9331 kCE=6.3203 KD=2.8662 acc=0.056 state=0.3290 align=0.0000 latA=0.8151 latP=0.1494 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  420/445 | grad_norm=1.39 | sec/step~8.06 | keep=0.76 | K=8 | llama(L): tf=7.9022 first=6.8584 kCE=5.5490 KD=2.5482 acc=0.139 state=0.0320 align=0.0000 latA=0.7602 latP=0.1383 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  430/445 | grad_norm=0.55 | sec/step~9.30 | keep=0.77 | K=8 | llama(L): tf=8.6659 first=7.4975 kCE=5.6457 KD=3.2071 acc=0.083 state=0.7865 align=0.0000 latA=0.7675 latP=0.1219 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  440/445 | grad_norm=0.83 | sec/step~8.10 | keep=0.77 | K=8 | llama(L): tf=8.1559 first=6.7714 kCE=6.0835 KD=3.3391 acc=0.056 state=0.0909 align=0.0000 latA=0.7564 latP=0.1458 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  445/445 | grad_norm=0.71 | sec/step~5.07 | keep=0.77 | K=8 | llama(L): tf=7.9992 first=6.4324 kCE=5.2997 KD=2.8293 acc=0.188 state=0.0547 align=0.0000 latA=0.7490 latP=0.1079 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
[checkpoint] Freed 0.0B before save.
[checkpoint] Saved latest: encoder.pt, state.pt, config.json, adapter_llama.pt, deep_prefix_llama.pt, refiner.pt, training_stats.json
[checkpoint] Freed 0.0B after save (non-canonical).
  ✅ Saved (and pruned to) latest at step 3560
Epoch 8/8
  step  10/445 | grad_norm=0.88 | sec/step~8.26 | keep=0.77 | K=8 | llama(L): tf=8.6521 first=7.8567 kCE=5.1858 KD=2.6452 acc=0.111 state=0.0382 align=0.0000 latA=0.7924 latP=0.1078 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  20/445 | grad_norm=0.62 | sec/step~8.16 | keep=0.77 | K=8 | llama(L): tf=8.3177 first=7.2317 kCE=5.4454 KD=2.7399 acc=0.083 state=0.0209 align=0.0000 latA=0.8021 latP=0.1150 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  30/445 | grad_norm=0.61 | sec/step~9.11 | keep=0.77 | K=8 | llama(L): tf=8.3324 first=7.3701 kCE=5.6017 KD=2.6435 acc=0.056 state=0.4277 align=0.0000 latA=0.7724 latP=0.1309 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  40/445 | grad_norm=0.62 | sec/step~8.19 | keep=0.77 | K=8 | llama(L): tf=8.2139 first=7.4093 kCE=5.5083 KD=2.6139 acc=0.028 state=0.0392 align=0.0000 latA=0.7994 latP=0.1209 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  50/445 | grad_norm=0.70 | sec/step~8.77 | keep=0.78 | K=8 | llama(L): tf=8.6020 first=7.3619 kCE=5.7205 KD=3.1643 acc=0.028 state=0.1529 align=0.0000 latA=0.7810 latP=0.1263 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  57/445 | (tail text) | align=0.0002 | text_tf=9.0195 | latent_scale=1.00
  step  60/445 | grad_norm=1.61 | sec/step~8.27 | keep=0.78 | K=8 | llama(L): tf=8.3283 first=7.0729 kCE=5.9534 KD=4.1916 acc=0.167 state=0.2698 align=0.0000 latA=0.7687 latP=0.1541 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  70/445 | grad_norm=2.56 | sec/step~8.99 | keep=0.78 | K=8 | llama(L): tf=7.9135 first=7.2296 kCE=5.0666 KD=2.8024 acc=0.028 state=0.4023 align=0.0000 latA=0.7858 latP=0.1168 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  74/445 | (tail text) | align=0.0003 | text_tf=9.7314 | latent_scale=1.00
  step  80/445 | grad_norm=1.06 | sec/step~8.30 | keep=0.78 | K=8 | llama(L): tf=8.0921 first=7.5603 kCE=5.5835 KD=2.9268 acc=0.028 state=0.1745 align=0.0000 latA=0.7965 latP=0.1467 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  90/445 | grad_norm=0.57 | sec/step~8.94 | keep=0.78 | K=8 | llama(L): tf=8.5423 first=7.9518 kCE=5.2347 KD=2.8849 acc=0.028 state=0.6964 align=0.0000 latA=0.8066 latP=0.1324 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  95/445 | (tail text) | align=0.0003 | text_tf=9.3989 | latent_scale=1.00
  step  100/445 | grad_norm=2.38 | sec/step~8.11 | keep=0.79 | K=8 | llama(L): tf=8.4557 first=7.2826 kCE=5.2069 KD=2.7297 acc=0.028 state=0.0245 align=0.0000 latA=0.7654 latP=0.1171 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  110/445 | grad_norm=0.47 | sec/step~8.88 | keep=0.79 | K=8 | llama(L): tf=8.6054 first=7.1658 kCE=5.9370 KD=3.6393 acc=0.083 state=0.0541 align=0.0000 latA=0.7757 latP=0.1343 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  120/445 | grad_norm=3.45 | sec/step~8.30 | keep=0.79 | K=8 | llama(L): tf=8.1042 first=7.5399 kCE=5.4623 KD=3.8790 acc=0.083 state=0.0257 align=0.0000 latA=0.7875 latP=0.1205 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  130/445 | grad_norm=1.20 | sec/step~8.60 | keep=0.79 | K=8 | llama(L): tf=8.4808 first=6.7599 kCE=5.7226 KD=2.6349 acc=0.083 state=0.0447 align=0.0000 latA=0.7579 latP=0.1383 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  140/445 | grad_norm=1.99 | sec/step~9.16 | keep=0.79 | K=8 | llama(L): tf=7.9546 first=7.1389 kCE=5.5821 KD=2.5233 acc=0.111 state=0.6193 align=0.0000 latA=0.7690 latP=0.1407 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  150/445 | grad_norm=1.42 | sec/step~9.09 | keep=0.79 | K=8 | llama(L): tf=8.6415 first=7.7779 kCE=5.1640 KD=3.4124 acc=0.000 state=2.5486 align=0.0000 latA=0.8110 latP=0.1120 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  160/445 | grad_norm=0.64 | sec/step~8.66 | keep=0.80 | K=8 | llama(L): tf=8.1141 first=6.9369 kCE=5.7171 KD=2.6686 acc=0.111 state=0.2872 align=0.0000 latA=0.7513 latP=0.1363 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  170/445 | grad_norm=0.63 | sec/step~9.67 | keep=0.80 | K=8 | llama(L): tf=8.2934 first=7.4542 kCE=5.3133 KD=2.9188 acc=0.028 state=2.2285 align=0.0000 latA=0.7929 latP=0.1236 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  180/445 | grad_norm=3.10 | sec/step~9.11 | keep=0.80 | K=8 | llama(L): tf=8.7513 first=7.3266 kCE=5.5349 KD=4.7552 acc=0.056 state=0.6505 align=0.0000 latA=0.7551 latP=0.1244 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  190/445 | grad_norm=1.37 | sec/step~8.81 | keep=0.80 | K=8 | llama(L): tf=8.3316 first=7.2775 kCE=5.3622 KD=2.7803 acc=0.028 state=0.4602 align=0.0000 latA=0.7784 latP=0.1221 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  200/445 | grad_norm=1.36 | sec/step~8.44 | keep=0.80 | K=8 | llama(L): tf=8.3084 first=7.3874 kCE=5.7187 KD=3.7854 acc=0.083 state=0.1261 align=0.0000 latA=0.7944 latP=0.1357 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  210/445 | grad_norm=0.63 | sec/step~9.37 | keep=0.81 | K=8 | llama(L): tf=8.5960 first=6.8487 kCE=5.5956 KD=3.0470 acc=0.083 state=1.9676 align=0.0000 latA=0.7616 latP=0.1269 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  220/445 | grad_norm=0.42 | sec/step~8.12 | keep=0.81 | K=8 | llama(L): tf=8.3126 first=7.1308 kCE=5.7794 KD=2.8025 acc=0.056 state=0.0676 align=0.0000 latA=0.7618 latP=0.1463 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  230/445 | grad_norm=0.24 | sec/step~8.11 | keep=0.81 | K=8 | llama(L): tf=8.4692 first=7.7031 kCE=4.9683 KD=2.7687 acc=0.028 state=0.0445 align=0.0000 latA=0.8049 latP=0.1046 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  240/445 | grad_norm=1.70 | sec/step~8.36 | keep=0.81 | K=8 | llama(L): tf=8.7566 first=8.0035 kCE=5.4970 KD=2.8752 acc=0.028 state=0.1070 align=0.0000 latA=0.8002 latP=0.1348 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  250/445 | grad_norm=0.88 | sec/step~9.01 | keep=0.81 | K=8 | llama(L): tf=8.1586 first=7.8826 kCE=5.5026 KD=2.9607 acc=0.111 state=0.4413 align=0.0000 latA=0.7832 latP=0.1284 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  260/445 | grad_norm=1.34 | sec/step~8.89 | keep=0.81 | K=8 | llama(L): tf=8.7793 first=7.7619 kCE=5.5530 KD=2.8159 acc=0.028 state=0.1286 align=0.0000 latA=0.7920 latP=0.1209 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  270/445 | grad_norm=0.93 | sec/step~7.96 | keep=0.82 | K=8 | llama(L): tf=8.1820 first=6.8276 kCE=5.5790 KD=2.8556 acc=0.028 state=0.0266 align=0.0000 latA=0.7498 latP=0.1339 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  🌟 NEW PEAK: first_acc=22.2% at step 3831 → saved to runs/hero_resume/ckpt_stageb_best
  step  280/445 | grad_norm=0.50 | sec/step~9.80 | keep=0.82 | K=8 | llama(L): tf=8.6358 first=7.7248 kCE=5.6371 KD=3.0588 acc=0.000 state=4.9534 align=0.0000 latA=0.7800 latP=0.1404 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  290/445 | grad_norm=0.21 | sec/step~8.17 | keep=0.82 | K=8 | llama(L): tf=8.6161 first=7.3419 kCE=5.5124 KD=2.8293 acc=0.111 state=0.0562 align=0.0000 latA=0.7606 latP=0.1221 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  300/445 | grad_norm=0.96 | sec/step~8.40 | keep=0.82 | K=8 | llama(L): tf=8.1820 first=7.0997 kCE=5.5413 KD=2.5673 acc=0.028 state=0.0292 align=0.0000 latA=0.7843 latP=0.1467 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  310/445 | grad_norm=1.29 | sec/step~8.56 | keep=0.82 | K=8 | llama(L): tf=8.0963 first=7.0704 kCE=5.4962 KD=3.3862 acc=0.083 state=0.1012 align=0.0000 latA=0.7617 latP=0.1327 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  320/445 | grad_norm=0.99 | sec/step~8.17 | keep=0.83 | K=8 | llama(L): tf=8.3096 first=7.2644 kCE=5.5565 KD=3.0624 acc=0.083 state=0.0528 align=0.0000 latA=0.7835 latP=0.1318 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  330/445 | grad_norm=0.46 | sec/step~9.41 | keep=0.83 | K=8 | llama(L): tf=8.1832 first=7.3698 kCE=5.5032 KD=2.7096 acc=0.111 state=1.8776 align=0.0000 latA=0.7726 latP=0.1349 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  340/445 | grad_norm=0.38 | sec/step~8.29 | keep=0.83 | K=8 | llama(L): tf=8.3108 first=6.4740 kCE=5.1723 KD=3.8233 acc=0.083 state=0.0801 align=0.0000 latA=0.7477 latP=0.1232 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  350/445 | grad_norm=0.39 | sec/step~7.95 | keep=0.83 | K=8 | llama(L): tf=8.1850 first=7.5336 kCE=5.3547 KD=4.8411 acc=0.056 state=0.0244 align=0.0000 latA=0.7818 latP=0.1317 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  360/445 | grad_norm=1.51 | sec/step~9.02 | keep=0.83 | K=8 | llama(L): tf=8.5870 first=7.5440 kCE=5.5252 KD=3.0897 acc=0.083 state=0.7121 align=0.0000 latA=0.7834 latP=0.1198 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  370/445 | grad_norm=1.16 | sec/step~8.49 | keep=0.84 | K=8 | llama(L): tf=8.6062 first=6.8873 kCE=6.3127 KD=2.8790 acc=0.111 state=0.1357 align=0.0000 latA=0.7598 latP=0.1498 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  380/445 | grad_norm=0.90 | sec/step~8.45 | keep=0.84 | K=8 | llama(L): tf=8.5341 first=7.2197 kCE=5.3407 KD=3.0317 acc=0.056 state=0.0502 align=0.0000 latA=0.7715 latP=0.1151 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  390/445 | grad_norm=0.78 | sec/step~7.91 | keep=0.84 | K=8 | llama(L): tf=8.4190 first=7.3041 kCE=5.2884 KD=2.7737 acc=0.000 state=0.0233 align=0.0000 latA=0.7759 latP=0.1125 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  400/445 | grad_norm=0.42 | sec/step~8.39 | keep=0.84 | K=8 | llama(L): tf=8.3455 first=7.6615 kCE=5.3164 KD=2.5567 acc=0.056 state=0.1153 align=0.0000 latA=0.7763 latP=0.1268 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  404/445 | (tail text) | align=0.0003 | text_tf=9.3918 | latent_scale=1.00
  step  410/445 | grad_norm=0.25 | sec/step~8.28 | keep=0.84 | K=8 | llama(L): tf=8.3654 first=7.5840 kCE=6.0654 KD=2.8532 acc=0.056 state=0.1000 align=0.0000 latA=0.7755 latP=0.1504 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  420/445 | grad_norm=1.02 | sec/step~8.13 | keep=0.85 | K=8 | llama(L): tf=8.4719 first=7.3774 kCE=5.0262 KD=2.6234 acc=0.083 state=0.0269 align=0.0000 latA=0.7981 latP=0.1176 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  430/445 | grad_norm=0.77 | sec/step~8.49 | keep=0.85 | K=8 | llama(L): tf=8.3373 first=7.3088 kCE=5.3181 KD=2.3006 acc=0.000 state=0.0316 align=0.0000 latA=0.7797 latP=0.1276 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  440/445 | grad_norm=0.49 | sec/step~8.75 | keep=0.85 | K=8 | llama(L): tf=8.3571 first=7.8827 kCE=5.5545 KD=2.9029 acc=0.083 state=0.0636 align=0.0000 latA=0.7983 latP=0.1338 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  445/445 | grad_norm=0.51 | sec/step~4.62 | keep=0.85 | K=8 | llama(L): tf=8.2774 first=6.1438 kCE=5.2800 KD=4.3173 acc=0.188 state=0.1423 align=0.0000 latA=0.7134 latP=0.1063 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
[checkpoint] Freed 0.0B before save.
[checkpoint] Saved latest: encoder.pt, state.pt, config.json, adapter_llama.pt, deep_prefix_llama.pt, refiner.pt, training_stats.json
[checkpoint] Freed 0.0B after save (non-canonical).
  ✅ Saved (and pruned to) latest at step 4005
Epoch 9/8
  step  10/445 | grad_norm=1.35 | sec/step~8.13 | keep=0.85 | K=8 | llama(L): tf=8.5799 first=7.3610 kCE=5.2566 KD=2.6336 acc=0.083 state=0.1034 align=0.0000 latA=0.7863 latP=0.1164 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  20/445 | grad_norm=0.72 | sec/step~7.76 | keep=0.85 | K=8 | llama(L): tf=8.5587 first=6.6821 kCE=5.4821 KD=2.6938 acc=0.056 state=0.0247 align=0.0000 latA=0.7612 latP=0.1179 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  28/445 | (tail text) | align=0.0003 | text_tf=9.2965 | latent_scale=1.00
  step  30/445 | grad_norm=0.82 | sec/step~8.20 | keep=0.85 | K=8 | llama(L): tf=8.3791 first=7.5584 kCE=4.9768 KD=2.9349 acc=0.000 state=0.0462 align=0.0000 latA=0.7863 latP=0.1106 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  40/445 | grad_norm=0.50 | sec/step~8.72 | keep=0.85 | K=8 | llama(L): tf=8.2096 first=7.1967 kCE=5.3065 KD=2.8271 acc=0.083 state=0.1141 align=0.0000 latA=0.7631 latP=0.1216 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  50/445 | grad_norm=0.22 | sec/step~7.94 | keep=0.85 | K=8 | llama(L): tf=8.3957 first=7.3602 kCE=5.2077 KD=2.8776 acc=0.056 state=0.0583 align=0.0000 latA=0.7845 latP=0.1293 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  57/445 | (tail text) | align=0.0002 | text_tf=8.7029 | latent_scale=1.00
  step  60/445 | grad_norm=1.25 | sec/step~8.23 | keep=0.85 | K=8 | llama(L): tf=7.9040 first=7.3732 kCE=5.3285 KD=3.3423 acc=0.083 state=0.0272 align=0.0000 latA=0.7779 latP=0.1252 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  70/445 | grad_norm=1.29 | sec/step~8.26 | keep=0.85 | K=8 | llama(L): tf=8.2621 first=7.4629 kCE=5.6523 KD=2.6846 acc=0.083 state=0.3325 align=0.0000 latA=0.7829 latP=0.1334 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  80/445 | grad_norm=0.85 | sec/step~7.99 | keep=0.85 | K=8 | llama(L): tf=8.0388 first=7.2854 kCE=5.0860 KD=2.5986 acc=0.028 state=0.0255 align=0.0000 latA=0.7745 latP=0.1200 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  90/445 | grad_norm=1.43 | sec/step~8.42 | keep=0.85 | K=8 | llama(L): tf=8.3524 first=7.2239 kCE=5.7867 KD=2.9718 acc=0.167 state=0.0265 align=0.0000 latA=0.7723 latP=0.1334 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  95/445 | (tail text) | align=0.0002 | text_tf=8.7108 | latent_scale=1.00
  step  100/445 | grad_norm=0.67 | sec/step~8.58 | keep=0.85 | K=8 | llama(L): tf=8.2800 first=8.0270 kCE=5.2231 KD=2.6210 acc=0.028 state=0.0762 align=0.0000 latA=0.8121 latP=0.1230 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  🌟 NEW PEAK: first_acc=25.0% at step 4113 → saved to runs/hero_resume/ckpt_stageb_best
  step  110/445 | grad_norm=0.26 | sec/step~8.39 | keep=0.85 | K=8 | llama(L): tf=8.2842 first=7.2182 kCE=5.3182 KD=2.6767 acc=0.028 state=0.0926 align=0.0000 latA=0.7737 latP=0.1388 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  120/445 | grad_norm=1.99 | sec/step~8.27 | keep=0.85 | K=8 | llama(L): tf=8.4929 first=7.5072 kCE=5.5201 KD=2.7651 acc=0.028 state=0.0249 align=0.0000 latA=0.7951 latP=0.1537 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  130/445 | grad_norm=0.53 | sec/step~8.85 | keep=0.85 | K=8 | llama(L): tf=8.3865 first=6.9785 kCE=5.5206 KD=2.7050 acc=0.056 state=0.5039 align=0.0000 latA=0.7500 latP=0.1267 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  140/445 | grad_norm=1.67 | sec/step~8.22 | keep=0.85 | K=8 | llama(L): tf=8.0691 first=7.0510 kCE=5.0821 KD=2.6214 acc=0.028 state=0.0222 align=0.0000 latA=0.7599 latP=0.1422 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  150/445 | grad_norm=0.82 | sec/step~8.42 | keep=0.85 | K=8 | llama(L): tf=8.1038 first=7.2613 kCE=5.1617 KD=2.9695 acc=0.056 state=0.1031 align=0.0000 latA=0.7853 latP=0.1372 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  160/445 | grad_norm=0.66 | sec/step~8.55 | keep=0.85 | K=8 | llama(L): tf=8.3825 first=7.3472 kCE=5.5626 KD=3.7154 acc=0.028 state=0.0246 align=0.0000 latA=0.7700 latP=0.1331 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  170/445 | grad_norm=0.27 | sec/step~8.35 | keep=0.85 | K=8 | llama(L): tf=8.1239 first=7.7162 kCE=5.2072 KD=2.5659 acc=0.028 state=0.0232 align=0.0000 latA=0.7943 latP=0.1476 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  180/445 | grad_norm=1.24 | sec/step~9.01 | keep=0.85 | K=8 | llama(L): tf=7.8956 first=7.3889 kCE=5.1056 KD=3.3249 acc=0.028 state=0.5717 align=0.0000 latA=0.7827 latP=0.1221 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  182/445 | (tail text) | align=0.0003 | text_tf=9.0083 | latent_scale=1.00
  step  190/445 | grad_norm=1.66 | sec/step~8.22 | keep=0.85 | K=8 | llama(L): tf=8.2112 first=7.2733 kCE=5.1293 KD=3.9324 acc=0.083 state=0.0287 align=0.0000 latA=0.7555 latP=0.1149 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  199/445 | (tail text) | align=0.0003 | text_tf=8.8739 | latent_scale=1.00
  step  200/445 | grad_norm=0.81 | sec/step~7.88 | keep=0.85 | K=8 | llama(L): tf=8.4709 first=7.7210 kCE=5.2713 KD=3.3654 acc=0.028 state=0.0236 align=0.0000 latA=0.7755 latP=0.1156 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  210/445 | grad_norm=0.47 | sec/step~8.01 | keep=0.85 | K=8 | llama(L): tf=8.3487 first=7.6200 kCE=5.7958 KD=2.4166 acc=0.056 state=0.0261 align=0.0000 latA=0.7871 latP=0.1465 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  220/445 | grad_norm=0.55 | sec/step~8.31 | keep=0.85 | K=8 | llama(L): tf=8.3960 first=6.9732 kCE=5.3673 KD=2.4832 acc=0.083 state=0.0384 align=0.0000 latA=0.7459 latP=0.1287 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  230/445 | grad_norm=0.78 | sec/step~8.25 | keep=0.85 | K=8 | llama(L): tf=8.6195 first=6.8018 kCE=5.2288 KD=3.5774 acc=0.028 state=0.0244 align=0.0000 latA=0.7528 latP=0.1175 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  240/445 | grad_norm=2.10 | sec/step~9.33 | keep=0.85 | K=8 | llama(L): tf=7.8973 first=6.6594 kCE=4.9204 KD=2.5839 acc=0.083 state=0.5228 align=0.0000 latA=0.7493 latP=0.1132 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  250/445 | grad_norm=0.51 | sec/step~10.40 | keep=0.85 | K=8 | llama(L): tf=8.1891 first=7.2005 kCE=5.4395 KD=3.4268 acc=0.056 state=4.2146 align=0.0000 latA=0.7705 latP=0.1611 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  260/445 | grad_norm=1.35 | sec/step~8.99 | keep=0.85 | K=8 | llama(L): tf=8.4254 first=7.3147 kCE=4.9264 KD=2.9121 acc=0.000 state=0.4182 align=0.0000 latA=0.7735 latP=0.1200 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  270/445 | grad_norm=0.42 | sec/step~7.96 | keep=0.85 | K=8 | llama(L): tf=8.3594 first=7.9289 kCE=5.5959 KD=2.7659 acc=0.000 state=0.0223 align=0.0000 latA=0.8162 latP=0.1479 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  271/445 | (tail text) | align=0.0003 | text_tf=9.5827 | latent_scale=1.00
  step  280/445 | grad_norm=0.43 | sec/step~8.51 | keep=0.85 | K=8 | llama(L): tf=8.4372 first=7.3893 kCE=5.1893 KD=2.4713 acc=0.028 state=0.0457 align=0.0000 latA=0.7719 latP=0.1233 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  290/445 | grad_norm=0.28 | sec/step~7.83 | keep=0.85 | K=8 | llama(L): tf=8.3975 first=6.9185 kCE=5.5954 KD=3.2460 acc=0.111 state=0.0236 align=0.0000 latA=0.7649 latP=0.1249 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  300/445 | grad_norm=1.76 | sec/step~7.72 | keep=0.85 | K=8 | llama(L): tf=8.8795 first=7.8603 kCE=5.6473 KD=2.9522 acc=0.056 state=0.0223 align=0.0000 latA=0.7885 latP=0.1213 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  310/445 | grad_norm=1.62 | sec/step~8.88 | keep=0.85 | K=8 | llama(L): tf=8.4826 first=7.6054 kCE=5.3533 KD=3.2465 acc=0.028 state=0.0239 align=0.0000 latA=0.7939 latP=0.1249 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  320/445 | grad_norm=0.85 | sec/step~8.07 | keep=0.85 | K=8 | llama(L): tf=8.2262 first=7.3881 kCE=5.1935 KD=2.4271 acc=0.083 state=0.0248 align=0.0000 latA=0.7810 latP=0.1130 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  330/445 | grad_norm=0.93 | sec/step~8.61 | keep=0.85 | K=8 | llama(L): tf=8.5068 first=7.2049 kCE=5.8908 KD=3.3260 acc=0.056 state=0.0579 align=0.0000 latA=0.7679 latP=0.1440 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  333/445 | (tail text) | align=0.0003 | text_tf=9.6845 | latent_scale=1.00
  step  340/445 | grad_norm=0.61 | sec/step~8.16 | keep=0.85 | K=8 | llama(L): tf=8.5051 first=7.3416 kCE=5.0386 KD=2.5705 acc=0.056 state=0.0369 align=0.0000 latA=0.7745 latP=0.1149 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  341/445 | (tail text) | align=0.0003 | text_tf=9.2892 | latent_scale=1.00
  step  343/445 | (tail text) | align=0.0002 | text_tf=9.4670 | latent_scale=1.00
  step  347/445 | (tail text) | align=0.0003 | text_tf=8.8554 | latent_scale=1.00
  step  350/445 | grad_norm=0.56 | sec/step~7.77 | keep=0.85 | K=8 | llama(L): tf=8.1570 first=6.8060 kCE=5.7966 KD=2.9434 acc=0.111 state=0.0241 align=0.0000 latA=0.7532 latP=0.1317 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
  step  360/445 | grad_norm=3.44 | sec/step~9.18 | keep=0.85 | K=8 | llama(L): tf=8.3412 first=7.3008 kCE=4.8739 KD=2.5269 acc=0.000 state=0.0567 align=0.0000 latA=0.7760 latP=0.1083 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0019 rms_cal~0.0106 embed_rms~0.01058]
