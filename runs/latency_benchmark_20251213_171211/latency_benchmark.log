[Sat Dec 13 17:12:11 PST 2025] Starting latency benchmark...

==============================================
PHASE 1: Training SST-2 Bridge (~3.5 min)
==============================================

/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
usage: train_telepathy_sst2.py [-h] [--source_model SOURCE_MODEL]
                               [--target_model TARGET_MODEL]
                               [--source_layer SOURCE_LAYER]
                               [--soft_tokens SOFT_TOKENS] [--depth DEPTH]
                               [--heads HEADS] [--lr LR]
                               [--batch_size BATCH_SIZE]
                               [--grad_accum GRAD_ACCUM] [--steps STEPS]
                               [--warmup_steps WARMUP_STEPS]
                               [--save_path SAVE_PATH]
                               [--output_dir OUTPUT_DIR]
                               [--save_every SAVE_EVERY]
                               [--eval_every EVAL_EVERY]
                               [--diversity_weight DIVERSITY_WEIGHT] [--bf16]
                               [--use_fsq]
train_telepathy_sst2.py: error: unrecognized arguments: --gpu 0
