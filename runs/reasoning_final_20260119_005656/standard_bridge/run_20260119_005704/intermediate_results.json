{
  "timestamp": "2026-01-19T04:11:39.882249",
  "status": "in_progress",
  "zeroshot_llama": [
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "model_name": "llama",
      "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "seed": 42,
      "accuracy": 55.327545382794,
      "correct": 701,
      "total": 1267,
      "num_classes": 2
    },
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "model_name": "llama",
      "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "seed": 123,
      "accuracy": 55.327545382794,
      "correct": 701,
      "total": 1267,
      "num_classes": 2
    },
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "model_name": "llama",
      "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "seed": 456,
      "accuracy": 55.327545382794,
      "correct": 701,
      "total": 1267,
      "num_classes": 2
    }
  ],
  "zeroshot_mistral": [
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "model_name": "mistral",
      "model_id": "mistralai/Mistral-7B-Instruct-v0.3",
      "seed": 42,
      "accuracy": 54.064719810576165,
      "correct": 685,
      "total": 1267,
      "num_classes": 2
    },
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "model_name": "mistral",
      "model_id": "mistralai/Mistral-7B-Instruct-v0.3",
      "seed": 123,
      "accuracy": 54.064719810576165,
      "correct": 685,
      "total": 1267,
      "num_classes": 2
    },
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "model_name": "mistral",
      "model_id": "mistralai/Mistral-7B-Instruct-v0.3",
      "seed": 456,
      "accuracy": 54.064719810576165,
      "correct": 685,
      "total": 1267,
      "num_classes": 2
    }
  ],
  "text_relay": [
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "method": "text_relay_improved",
      "seed": 42,
      "accuracy": 54.14364640883978,
      "correct": 686,
      "total": 1267,
      "num_classes": 2,
      "latency_mean_ms": 926.6804488112631,
      "latency_std_ms": 8.500467113005138
    },
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "method": "text_relay_improved",
      "seed": 123,
      "accuracy": 54.14364640883978,
      "correct": 686,
      "total": 1267,
      "num_classes": 2,
      "latency_mean_ms": 927.3037495041573,
      "latency_std_ms": 11.512386189885053
    },
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "method": "text_relay_improved",
      "seed": 456,
      "accuracy": 54.14364640883978,
      "correct": 686,
      "total": 1267,
      "num_classes": 2,
      "latency_mean_ms": 924.8344082695497,
      "latency_std_ms": 9.245587491690598
    }
  ],
  "linear_probe": [],
  "prompt_tuning": [],
  "same_model_bridge": [],
  "bridge_8": [],
  "bridge_24": []
}