{"kind": "eval", "tag": "embedding-smoke", "config_path": "/projects/m000066/sujinesh/LatentWire/configs/baseline/embedding_baselines.json", "overrides": ["ckpt=runs/smoke/embedding_test/ckpt", "samples=30", "out_dir=runs/smoke/embedding_test/eval", "llama_id=meta-llama/Meta-Llama-3.1-8B-Instruct", "dataset=squad", "max_new_tokens=24", "embedding_replay=true", "embedding_baseline_modes=[\"raw\",\"anchor\",\"adapter\"]"], "argv": ["--ckpt", "runs/smoke/embedding_test/ckpt", "--models", "llama", "--llama_id", "meta-llama/Meta-Llama-3.1-8B-Instruct", "--dataset", "squad", "--samples", "30", "--max_new_tokens", "24", "--latent_anchor_mode", "auto", "--latent_anchor_text", "Answer: ", "--append_bos_after_prefix", "auto", "--use_chat_template", "yes", "--token_budget_mode", "content_only", "--token_budget_k", "32", "--chunk_size", "8", "--fresh_eval", "--embedding_replay", "--embedding_baseline_modes", "[\"raw\", \"anchor\", \"adapter\"]", "--out_dir", "runs/smoke/embedding_test/eval", "--first_token_top_p", "1.0", "--first_token_temperature", "0.0", "--min_new_tokens", "1", "--eos_ban_steps", "0", "--calibration", "embed_rms", "--prefix_gain", "1.0", "--hf_encoder_id", "sentence-transformers/all-MiniLM-L6-v2", "--max_enc_tokens", "1024", "--llama_device_map", "auto"], "timestamp": "2025-10-10T23:58:58.309237Z"}
