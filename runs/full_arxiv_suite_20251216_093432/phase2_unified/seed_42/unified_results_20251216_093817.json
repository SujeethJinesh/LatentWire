{
  "meta": {
    "timestamp": "20251216_093817",
    "sender": "meta-llama/Meta-Llama-3.1-8B-Instruct",
    "receiver": "mistralai/Mistral-7B-Instruct-v0.3",
    "soft_tokens": 8,
    "train_steps": 2000,
    "eval_samples": 200,
    "seeds": [
      42
    ]
  },
  "per_seed_results": {
    "sst2": {
      "42": {
        "random_chance": 50.0,
        "bridge": {
          "accuracy": 86.5,
          "correct": 173,
          "total": 200,
          "latency_ms": 43.43165159225464,
          "train_info": {
            "final_loss": 0.15444732666015626
          }
        },
        "prompt_tuning": {
          "accuracy": 88.0,
          "correct": 176,
          "total": 200,
          "train_info": {
            "final_loss": 0.2213671875
          }
        },
        "text_relay": {
          "accuracy": 70.5,
          "correct": 141,
          "total": 200,
          "latency_ms": 1170.658700466156
        },
        "llama_zeroshot": {
          "accuracy": 93.0,
          "correct": 186,
          "total": 200
        },
        "mistral_zeroshot": {
          "accuracy": 91.5,
          "correct": 183,
          "total": 200
        },
        "mistral_fewshot": {
          "accuracy": 96.5,
          "correct": 193,
          "total": 200
        }
      }
    },
    "agnews": {
      "42": {
        "random_chance": 25.0,
        "bridge": {
          "accuracy": 94.0,
          "correct": 188,
          "total": 200,
          "latency_ms": 43.90020132064819,
          "train_info": {
            "final_loss": 0.234384765625
          }
        },
        "prompt_tuning": {
          "accuracy": 79.0,
          "correct": 158,
          "total": 200,
          "train_info": {
            "final_loss": 0.6078448486328125
          }
        },
        "text_relay": {
          "accuracy": 70.0,
          "correct": 140,
          "total": 200,
          "latency_ms": 1163.482962846756
        },
        "llama_zeroshot": {
          "accuracy": 84.0,
          "correct": 168,
          "total": 200
        },
        "mistral_zeroshot": {
          "accuracy": 75.0,
          "correct": 150,
          "total": 200
        },
        "mistral_fewshot": {
          "accuracy": 81.0,
          "correct": 162,
          "total": 200
        }
      }
    },
    "trec": {
      "42": {
        "random_chance": 16.7,
        "bridge": {
          "accuracy": 97.5,
          "correct": 195,
          "total": 200,
          "latency_ms": 42.89666533470154,
          "train_info": {
            "final_loss": 0.21234188079833985
          }
        },
        "prompt_tuning": {
          "accuracy": 86.0,
          "correct": 172,
          "total": 200,
          "train_info": {
            "final_loss": 0.6971510314941406
          }
        },
        "text_relay": {
          "accuracy": 47.0,
          "correct": 94,
          "total": 200,
          "latency_ms": 1182.3018622398376
        },
        "llama_zeroshot": {
          "accuracy": 67.5,
          "correct": 135,
          "total": 200
        },
        "mistral_zeroshot": {
          "accuracy": 68.5,
          "correct": 137,
          "total": 200
        },
        "mistral_fewshot": {
          "accuracy": 68.5,
          "correct": 137,
          "total": 200
        }
      }
    }
  },
  "aggregated_results": {
    "sst2": {
      "random_chance": 50.0,
      "bridge": {
        "accuracy_mean": 86.5,
        "accuracy_std": 0.0,
        "accuracy_min": 86.5,
        "accuracy_max": 86.5,
        "num_seeds": 1,
        "latency_ms_mean": 43.43165159225464,
        "latency_ms_std": 0.0
      },
      "prompt_tuning": {
        "accuracy_mean": 88.0,
        "accuracy_std": 0.0,
        "accuracy_min": 88.0,
        "accuracy_max": 88.0,
        "num_seeds": 1
      },
      "text_relay": {
        "accuracy_mean": 70.5,
        "accuracy_std": 0.0,
        "accuracy_min": 70.5,
        "accuracy_max": 70.5,
        "num_seeds": 1,
        "latency_ms_mean": 1170.658700466156,
        "latency_ms_std": 0.0
      },
      "llama_zeroshot": {
        "accuracy_mean": 93.0,
        "accuracy_std": 0.0,
        "accuracy_min": 93.0,
        "accuracy_max": 93.0,
        "num_seeds": 1
      },
      "mistral_zeroshot": {
        "accuracy_mean": 91.5,
        "accuracy_std": 0.0,
        "accuracy_min": 91.5,
        "accuracy_max": 91.5,
        "num_seeds": 1
      },
      "mistral_fewshot": {
        "accuracy_mean": 96.5,
        "accuracy_std": 0.0,
        "accuracy_min": 96.5,
        "accuracy_max": 96.5,
        "num_seeds": 1
      }
    },
    "agnews": {
      "random_chance": 25.0,
      "bridge": {
        "accuracy_mean": 94.0,
        "accuracy_std": 0.0,
        "accuracy_min": 94.0,
        "accuracy_max": 94.0,
        "num_seeds": 1,
        "latency_ms_mean": 43.90020132064819,
        "latency_ms_std": 0.0
      },
      "prompt_tuning": {
        "accuracy_mean": 79.0,
        "accuracy_std": 0.0,
        "accuracy_min": 79.0,
        "accuracy_max": 79.0,
        "num_seeds": 1
      },
      "text_relay": {
        "accuracy_mean": 70.0,
        "accuracy_std": 0.0,
        "accuracy_min": 70.0,
        "accuracy_max": 70.0,
        "num_seeds": 1,
        "latency_ms_mean": 1163.482962846756,
        "latency_ms_std": 0.0
      },
      "llama_zeroshot": {
        "accuracy_mean": 84.0,
        "accuracy_std": 0.0,
        "accuracy_min": 84.0,
        "accuracy_max": 84.0,
        "num_seeds": 1
      },
      "mistral_zeroshot": {
        "accuracy_mean": 75.0,
        "accuracy_std": 0.0,
        "accuracy_min": 75.0,
        "accuracy_max": 75.0,
        "num_seeds": 1
      },
      "mistral_fewshot": {
        "accuracy_mean": 81.0,
        "accuracy_std": 0.0,
        "accuracy_min": 81.0,
        "accuracy_max": 81.0,
        "num_seeds": 1
      }
    },
    "trec": {
      "random_chance": 16.7,
      "bridge": {
        "accuracy_mean": 97.5,
        "accuracy_std": 0.0,
        "accuracy_min": 97.5,
        "accuracy_max": 97.5,
        "num_seeds": 1,
        "latency_ms_mean": 42.89666533470154,
        "latency_ms_std": 0.0
      },
      "prompt_tuning": {
        "accuracy_mean": 86.0,
        "accuracy_std": 0.0,
        "accuracy_min": 86.0,
        "accuracy_max": 86.0,
        "num_seeds": 1
      },
      "text_relay": {
        "accuracy_mean": 47.0,
        "accuracy_std": 0.0,
        "accuracy_min": 47.0,
        "accuracy_max": 47.0,
        "num_seeds": 1,
        "latency_ms_mean": 1182.3018622398376,
        "latency_ms_std": 0.0
      },
      "llama_zeroshot": {
        "accuracy_mean": 67.5,
        "accuracy_std": 0.0,
        "accuracy_min": 67.5,
        "accuracy_max": 67.5,
        "num_seeds": 1
      },
      "mistral_zeroshot": {
        "accuracy_mean": 68.5,
        "accuracy_std": 0.0,
        "accuracy_min": 68.5,
        "accuracy_max": 68.5,
        "num_seeds": 1
      },
      "mistral_fewshot": {
        "accuracy_mean": 68.5,
        "accuracy_std": 0.0,
        "accuracy_min": 68.5,
        "accuracy_max": 68.5,
        "num_seeds": 1
      }
    }
  },
  "comparison_table": {
    "sst2": {
      "Method": [
        "Random",
        "Prompt-Tuning",
        "Llama 0-shot",
        "Mistral 0-shot",
        "Mistral 5-shot",
        "Text-Relay",
        "Bridge (ours)"
      ],
      "Accuracy (Mean)": [
        50.0,
        88.0,
        93.0,
        91.5,
        96.5,
        70.5,
        86.5
      ],
      "Accuracy (Std)": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ]
    },
    "agnews": {
      "Method": [
        "Random",
        "Prompt-Tuning",
        "Llama 0-shot",
        "Mistral 0-shot",
        "Mistral 5-shot",
        "Text-Relay",
        "Bridge (ours)"
      ],
      "Accuracy (Mean)": [
        25.0,
        79.0,
        84.0,
        75.0,
        81.0,
        70.0,
        94.0
      ],
      "Accuracy (Std)": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ]
    },
    "trec": {
      "Method": [
        "Random",
        "Prompt-Tuning",
        "Llama 0-shot",
        "Mistral 0-shot",
        "Mistral 5-shot",
        "Text-Relay",
        "Bridge (ours)"
      ],
      "Accuracy (Mean)": [
        16.7,
        86.0,
        67.5,
        68.5,
        68.5,
        47.0,
        97.5
      ],
      "Accuracy (Std)": [
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ]
    }
  }
}