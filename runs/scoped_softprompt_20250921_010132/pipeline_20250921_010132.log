
=== Preflight: CUDA / SLURM / bitsandbytes ===

Sun Sep 21 01:01:38 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          Off |   00000000:1B:00.0 Off |                    0 |
| N/A   27C    P0             68W /  700W |       4MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          Off |   00000000:43:00.0 Off |                    0 |
| N/A   28C    P0             69W /  700W |       4MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          Off |   00000000:61:00.0 Off |                    0 |
| N/A   30C    P0             69W /  700W |       4MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          Off |   00000000:DF:00.0 Off |                    0 |
| N/A   41C    P0             76W /  700W |       4MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
torch: 2.4.0+cu121 cuda: 12.1 is_available: True count: 4
CUDA_VISIBLE_DEVICES: 0,1,2,3
bitsandbytes: 0.47.0

=== Stage A: LoRA (tiny) ===

/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading dataset subset...
Loading SQuAD subset...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 3426.02it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.53s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.48s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.25s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.00it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.14s/it]
[meta-llama/Meta-Llama-3.1-8B-Instruct] hf_device_map: {'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 1, 'model.layers.17': 1, 'model.layers.18': 1, 'model.layers.19': 1, 'model.layers.20': 1, 'model.layers.21': 1, 'model.layers.22': 1, 'model.layers.23': 1, 'model.layers.24': 1, 'model.layers.25': 1, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 3668.75it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.04it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.05s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.01s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.15it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.08it/s]
[Qwen/Qwen2.5-7B-Instruct] hf_device_map: {'model.embed_tokens': 2, 'model.layers.0': 2, 'model.layers.1': 2, 'model.layers.2': 2, 'model.layers.3': 2, 'model.layers.4': 2, 'model.layers.5': 2, 'model.layers.6': 2, 'model.layers.7': 2, 'model.layers.8': 2, 'model.layers.9': 2, 'model.layers.10': 2, 'model.layers.11': 2, 'model.layers.12': 2, 'model.layers.13': 2, 'model.layers.14': 2, 'model.layers.15': 3, 'model.layers.16': 3, 'model.layers.17': 3, 'model.layers.18': 3, 'model.layers.19': 3, 'model.layers.20': 3, 'model.layers.21': 3, 'model.layers.22': 3, 'model.layers.23': 3, 'model.layers.24': 3, 'model.layers.25': 3, 'model.layers.26': 3, 'model.layers.27': 3, 'model.norm': 3, 'model.rotary_emb': 3, 'lm_head': 3}
trainable params: 20,971,520 || all params: 8,051,232,768 || trainable%: 0.2605
trainable params: 20,185,088 || all params: 7,635,801,600 || trainable%: 0.2643
Llama hidden size: 4096, Qwen hidden size: 3584
[DeviceMap] Llama: {'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 1, 'model.layers.17': 1, 'model.layers.18': 1, 'model.layers.19': 1, 'model.layers.20': 1, 'model.layers.21': 1, 'model.layers.22': 1, 'model.layers.23': 1, 'model.layers.24': 1, 'model.layers.25': 1, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}
[DeviceMap] Qwen : {'model.embed_tokens': 2, 'model.layers.0': 2, 'model.layers.1': 2, 'model.layers.2': 2, 'model.layers.3': 2, 'model.layers.4': 2, 'model.layers.5': 2, 'model.layers.6': 2, 'model.layers.7': 2, 'model.layers.8': 2, 'model.layers.9': 2, 'model.layers.10': 2, 'model.layers.11': 2, 'model.layers.12': 2, 'model.layers.13': 2, 'model.layers.14': 2, 'model.layers.15': 3, 'model.layers.16': 3, 'model.layers.17': 3, 'model.layers.18': 3, 'model.layers.19': 3, 'model.layers.20': 3, 'model.layers.21': 3, 'model.layers.22': 3, 'model.layers.23': 3, 'model.layers.24': 3, 'model.layers.25': 3, 'model.layers.26': 3, 'model.layers.27': 3, 'model.norm': 3, 'model.rotary_emb': 3, 'lm_head': 3}
[WARN] t=0 alignment failed: t=0 mismatch: got 12366, expected 60704
[WARN] t=0 alignment failed: t=0 mismatch: got 12095, expected 59604
⚠️  No valid checkpoint found to resume; starting fresh.
Epoch 1/1
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
  step  10/250 | grad_norm=875.44 | sec/step~14.14 | keep=1.00 | K=4 | llama: tf=10.0975 first=9.1085 kCE=10.0385 KD=5.8627 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=11.0525 first=15.4205 kCE=9.3148 KD=6.7464 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~0.9999 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.9999 rms_cal~0.0136 embed_rms~0.01364]
  step  20/250 | grad_norm=220.29 | sec/step~13.98 | keep=1.00 | K=4 | llama: tf=10.8321 first=10.1174 kCE=10.2982 KD=5.9408 man=0.0001 | scale_pen(llama)=7.5730e-09 | qwen: tf=10.6525 first=14.1433 kCE=9.9573 KD=5.5435 man=0.0002 | scale_pen(qwen)=9.6020e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~0.9999 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.9999 rms_cal~0.0136 embed_rms~0.01364]
  step  30/250 | grad_norm=837.78 | sec/step~12.70 | keep=1.00 | K=4 | llama: tf=10.7176 first=9.9873 kCE=10.1546 KD=6.4734 man=0.0001 | scale_pen(llama)=7.5730e-09 | qwen: tf=11.2630 first=13.5814 kCE=9.7096 KD=5.8574 man=0.0002 | scale_pen(qwen)=9.6020e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  40/250 | grad_norm=86.41 | sec/step~11.45 | keep=1.00 | K=4 | llama: tf=10.4546 first=9.8707 kCE=10.8969 KD=6.1601 man=0.0001 | scale_pen(llama)=1.5076e-10 | qwen: tf=9.2908 first=10.9621 kCE=9.8623 KD=6.6863 man=0.0002 | scale_pen(qwen)=1.0669e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  50/250 | grad_norm=346.77 | sec/step~14.24 | keep=1.00 | K=4 | llama: tf=10.4614 first=9.3180 kCE=10.0603 KD=4.2381 man=0.0001 | scale_pen(llama)=2.9420e-09 | qwen: tf=10.5495 first=11.2923 kCE=8.5224 KD=6.0526 man=0.0002 | scale_pen(qwen)=1.5853e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  60/250 | grad_norm=1312.75 | sec/step~11.86 | keep=1.00 | K=4 | llama: tf=10.3427 first=8.9867 kCE=9.7736 KD=4.6283 man=0.0001 | scale_pen(llama)=2.9420e-09 | qwen: tf=9.1765 first=10.8870 kCE=8.0348 KD=6.1001 man=0.0002 | scale_pen(qwen)=1.5853e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  70/250 | grad_norm=62.89 | sec/step~11.66 | keep=1.00 | K=4 | llama: tf=9.9609 first=9.2641 kCE=9.1840 KD=4.2379 man=0.0001 | scale_pen(llama)=4.9636e-09 | qwen: tf=9.3027 first=10.3610 kCE=7.2838 KD=5.3043 man=0.0002 | scale_pen(qwen)=5.9488e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  80/250 | grad_norm=168.93 | sec/step~12.67 | keep=1.00 | K=4 | llama: tf=10.5302 first=9.0035 kCE=9.3424 KD=4.0261 man=0.0001 | scale_pen(llama)=2.6337e-09 | qwen: tf=10.1404 first=10.0612 kCE=7.8488 KD=5.3354 man=0.0002 | scale_pen(qwen)=4.1286e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~0.9999 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  90/250 | grad_norm=68.64 | sec/step~12.92 | keep=1.00 | K=4 | llama: tf=9.8792 first=8.7820 kCE=9.4386 KD=4.2457 man=0.0001 | scale_pen(llama)=2.6337e-09 | qwen: tf=9.9585 first=10.2439 kCE=7.8087 KD=5.6897 man=0.0002 | scale_pen(qwen)=4.1286e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~0.9999 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  100/250 | grad_norm=34.08 | sec/step~11.39 | keep=1.00 | K=4 | llama: tf=10.0317 first=8.7902 kCE=9.5985 KD=5.6667 man=0.0001 | scale_pen(llama)=2.7063e-10 | qwen: tf=10.4372 first=9.0581 kCE=7.5127 KD=6.1904 man=0.0002 | scale_pen(qwen)=8.5998e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  110/250 | grad_norm=129.49 | sec/step~12.69 | keep=1.00 | K=4 | llama: tf=9.9961 first=8.2199 kCE=9.4581 KD=4.5466 man=0.0001 | scale_pen(llama)=2.7063e-10 | qwen: tf=9.5135 first=9.3717 kCE=6.9983 KD=5.1468 man=0.0002 | scale_pen(qwen)=8.5998e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  120/250 | grad_norm=79.85 | sec/step~12.75 | keep=1.00 | K=4 | llama: tf=10.0304 first=8.2983 kCE=10.0672 KD=4.7755 man=0.0001 | scale_pen(llama)=3.8689e-10 | qwen: tf=9.1053 first=7.9883 kCE=7.6019 KD=5.9473 man=0.0002 | scale_pen(qwen)=1.3097e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  130/250 | grad_norm=6.08 | sec/step~13.84 | keep=1.00 | K=4 | llama: tf=10.0846 first=8.2132 kCE=9.2222 KD=3.8820 man=0.0001 | scale_pen(llama)=1.9350e-09 | qwen: tf=8.8349 first=8.1897 kCE=6.4649 KD=4.6096 man=0.0002 | scale_pen(qwen)=1.9140e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  140/250 | grad_norm=26.62 | sec/step~10.95 | keep=1.00 | K=4 | llama: tf=9.3746 first=8.2109 kCE=8.9567 KD=5.0185 man=0.0001 | scale_pen(llama)=1.9350e-09 | qwen: tf=9.3122 first=7.9234 kCE=7.1278 KD=5.7358 man=0.0002 | scale_pen(qwen)=1.9140e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  150/250 | grad_norm=37.85 | sec/step~13.83 | keep=1.00 | K=4 | llama: tf=9.5048 first=8.3029 kCE=9.7721 KD=4.0906 man=0.0001 | scale_pen(llama)=2.4475e-09 | qwen: tf=9.5898 first=7.4099 kCE=7.5332 KD=5.0642 man=0.0002 | scale_pen(qwen)=3.1125e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  160/250 | grad_norm=112.13 | sec/step~12.56 | keep=1.00 | K=4 | llama: tf=9.6907 first=8.8189 kCE=9.5918 KD=3.9271 man=0.0001 | scale_pen(llama)=1.4643e-09 | qwen: tf=9.2921 first=8.2112 kCE=7.6166 KD=5.0013 man=0.0002 | scale_pen(qwen)=2.3656e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  170/250 | grad_norm=163.32 | sec/step~11.55 | keep=1.00 | K=4 | llama: tf=10.1110 first=8.5782 kCE=9.4177 KD=4.1616 man=0.0001 | scale_pen(llama)=1.4643e-09 | qwen: tf=10.0903 first=7.8419 kCE=7.6145 KD=5.7748 man=0.0002 | scale_pen(qwen)=2.3656e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  180/250 | grad_norm=14.68 | sec/step~12.03 | keep=1.00 | K=4 | llama: tf=10.2702 first=9.3356 kCE=9.5789 KD=4.0583 man=0.0001 | scale_pen(llama)=2.7457e-10 | qwen: tf=10.8951 first=8.1229 kCE=7.7267 KD=5.6687 man=0.0002 | scale_pen(qwen)=7.7813e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  190/250 | grad_norm=43.14 | sec/step~13.16 | keep=1.00 | K=4 | llama: tf=9.6709 first=8.7881 kCE=9.5747 KD=3.6453 man=0.0001 | scale_pen(llama)=2.7457e-10 | qwen: tf=8.4706 first=7.4427 kCE=7.0996 KD=5.3165 man=0.0002 | scale_pen(qwen)=7.7813e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  200/250 | grad_norm=7.65 | sec/step~12.50 | keep=1.00 | K=4 | llama: tf=9.5640 first=9.0336 kCE=10.1361 KD=3.8941 man=0.0001 | scale_pen(llama)=6.3793e-11 | qwen: tf=10.1270 first=7.7974 kCE=8.8378 KD=5.1860 man=0.0002 | scale_pen(qwen)=9.0949e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  210/250 | grad_norm=4.92 | sec/step~13.61 | keep=1.00 | K=4 | llama: tf=9.2678 first=8.0476 kCE=9.2106 KD=3.8639 man=0.0001 | scale_pen(llama)=7.6819e-10 | qwen: tf=10.0603 first=7.3318 kCE=7.4252 KD=5.4866 man=0.0002 | scale_pen(qwen)=5.5994e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  220/250 | grad_norm=20.62 | sec/step~13.03 | keep=1.00 | K=4 | llama: tf=9.9072 first=7.8228 kCE=8.9946 KD=3.8638 man=0.0001 | scale_pen(llama)=7.6819e-10 | qwen: tf=9.7974 first=6.8574 kCE=6.7578 KD=5.2557 man=0.0002 | scale_pen(qwen)=5.5994e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  230/250 | grad_norm=15.67 | sec/step~10.62 | keep=1.00 | K=4 | llama: tf=9.9178 first=8.4903 kCE=9.4001 KD=4.5401 man=0.0001 | scale_pen(llama)=1.3701e-09 | qwen: tf=9.4032 first=7.3399 kCE=7.0733 KD=5.1816 man=0.0002 | scale_pen(qwen)=1.5056e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  240/250 | grad_norm=34.29 | sec/step~11.89 | keep=1.00 | K=4 | llama: tf=9.3155 first=8.2690 kCE=8.7358 KD=4.3820 man=0.0001 | scale_pen(llama)=1.1869e-09 | qwen: tf=9.6802 first=7.0756 kCE=6.0728 KD=5.3026 man=0.0002 | scale_pen(qwen)=1.6768e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  250/250 | grad_norm=42.82 | sec/step~13.06 | keep=1.00 | K=4 | llama: tf=9.5841 first=8.6973 kCE=9.3576 KD=3.8637 man=0.0001 | scale_pen(llama)=6.6917e-10 | qwen: tf=9.4405 first=7.3604 kCE=7.0536 KD=5.7257 man=0.0002 | scale_pen(qwen)=1.2620e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
[checkpoint] Freed 1.5KB before save.
[checkpoint] Saved latest: encoder.pt, adapter_llama.pt, adapter_qwen.pt, state.pt, config.json
[checkpoint] Freed 0.0B after save (non-canonical).
✅ Saved latest checkpoint to runs/scoped_softprompt_20250921_010132/ckpt
📝 Saved LoRA adapters for Llama
📝 Saved LoRA adapters for Qwen
📝 Saved training_stats.json: {'llama': {'rms_mean_raw': 1.0000335323810576, 'rms_mean_cal': 0.01057013490051031, 'embed_rms': 0.01057521253824234, 'count': 250}, 'qwen': {'rms_mean_raw': 1.000061657190323, 'rms_mean_cal': 0.013639273561537265, 'embed_rms': 0.013643525540828705, 'count': 250}}

=== Stage A -> merge LoRA ===


=== Stage B: Deep Prefix ===

/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading dataset subset...
Loading SQuAD subset...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 6861.85it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:05,  1.67s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.41s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.20s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.07it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.10s/it]
[runs/scoped_softprompt_20250921_010132/ckpt/merged_llama] hf_device_map: {'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 1, 'model.layers.17': 1, 'model.layers.18': 1, 'model.layers.19': 1, 'model.layers.20': 1, 'model.layers.21': 1, 'model.layers.22': 1, 'model.layers.23': 1, 'model.layers.24': 1, 'model.layers.25': 1, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 7970.17it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.35s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.02s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.01s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.05s/it]
[runs/scoped_softprompt_20250921_010132/ckpt/merged_qwen] hf_device_map: {'model.embed_tokens': 2, 'model.layers.0': 2, 'model.layers.1': 2, 'model.layers.2': 2, 'model.layers.3': 2, 'model.layers.4': 2, 'model.layers.5': 2, 'model.layers.6': 2, 'model.layers.7': 2, 'model.layers.8': 2, 'model.layers.9': 2, 'model.layers.10': 2, 'model.layers.11': 2, 'model.layers.12': 2, 'model.layers.13': 2, 'model.layers.14': 2, 'model.layers.15': 3, 'model.layers.16': 3, 'model.layers.17': 3, 'model.layers.18': 3, 'model.layers.19': 3, 'model.layers.20': 3, 'model.layers.21': 3, 'model.layers.22': 3, 'model.layers.23': 3, 'model.layers.24': 3, 'model.layers.25': 3, 'model.layers.26': 3, 'model.layers.27': 3, 'model.norm': 3, 'model.rotary_emb': 3, 'lm_head': 3}
/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.
  warnings.warn(
trainable params: 272,723,968 || all params: 8,323,956,736 || trainable%: 3.2764
trainable params: 104,640,000 || all params: 7,740,441,600 || trainable%: 1.3519
Llama hidden size: 4096, Qwen hidden size: 3584
[DeviceMap] Llama: {'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 1, 'model.layers.17': 1, 'model.layers.18': 1, 'model.layers.19': 1, 'model.layers.20': 1, 'model.layers.21': 1, 'model.layers.22': 1, 'model.layers.23': 1, 'model.layers.24': 1, 'model.layers.25': 1, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}
[DeviceMap] Qwen : {'model.embed_tokens': 2, 'model.layers.0': 2, 'model.layers.1': 2, 'model.layers.2': 2, 'model.layers.3': 2, 'model.layers.4': 2, 'model.layers.5': 2, 'model.layers.6': 2, 'model.layers.7': 2, 'model.layers.8': 2, 'model.layers.9': 2, 'model.layers.10': 2, 'model.layers.11': 2, 'model.layers.12': 2, 'model.layers.13': 2, 'model.layers.14': 2, 'model.layers.15': 3, 'model.layers.16': 3, 'model.layers.17': 3, 'model.layers.18': 3, 'model.layers.19': 3, 'model.layers.20': 3, 'model.layers.21': 3, 'model.layers.22': 3, 'model.layers.23': 3, 'model.layers.24': 3, 'model.layers.25': 3, 'model.layers.26': 3, 'model.layers.27': 3, 'model.norm': 3, 'model.rotary_emb': 3, 'lm_head': 3}
[WARN] t=0 alignment failed: t=0 mismatch: got 12366, expected 60704
[WARN] t=0 alignment failed: t=0 mismatch: got 12095, expected 59604
⚠️  No valid checkpoint found to resume; starting fresh.
Epoch 1/6
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
  step  10/500 | grad_norm=691.60 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=11.8870 first=10.5991 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=12.4865 first=15.3122 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~0.9999 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.9999 rms_cal~0.0136 embed_rms~0.01364]
  step  20/500 | grad_norm=70.36 | sec/step~0.58 | keep=1.00 | K=4 | llama: tf=9.6500 first=10.5755 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.0747e-09 | qwen: tf=9.8807 first=9.7788 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=9.5321e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~0.9999 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.9999 rms_cal~0.0136 embed_rms~0.01364]
  step  30/500 | grad_norm=220.77 | sec/step~0.67 | keep=1.00 | K=4 | llama: tf=10.8729 first=11.7037 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.0747e-09 | qwen: tf=11.9063 first=11.7568 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=9.5321e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~0.9999 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  40/500 | grad_norm=931.12 | sec/step~0.76 | keep=1.00 | K=4 | llama: tf=10.0388 first=9.8106 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.6139e-09 | qwen: tf=10.4135 first=11.8995 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=7.5831e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~0.9999 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  50/500 | grad_norm=4.63 | sec/step~0.64 | keep=1.00 | K=4 | llama: tf=9.5427 first=9.4176 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=6.9407e-10 | qwen: tf=10.6516 first=12.8356 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.0904e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~0.9999 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  60/500 | grad_norm=26.92 | sec/step~0.64 | keep=1.00 | K=4 | llama: tf=9.4757 first=8.5354 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=6.9407e-10 | qwen: tf=10.6982 first=13.1083 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.0904e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  70/500 | grad_norm=25.32 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=10.2650 first=7.9871 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.0756e-10 | qwen: tf=10.6591 first=11.7360 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.8722e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.9999 rms_cal~0.0136 embed_rms~0.01364]
  step  80/500 | grad_norm=64.06 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=10.1177 first=8.9153 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=9.8669e-10 | qwen: tf=10.6582 first=12.4144 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1861e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.9999 rms_cal~0.0136 embed_rms~0.01364]
  step  90/500 | grad_norm=9.24 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=10.1285 first=8.2983 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=9.8669e-10 | qwen: tf=10.4575 first=11.1034 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1861e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.9999 rms_cal~0.0136 embed_rms~0.01364]
  step  100/500 | grad_norm=31.50 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=11.0176 first=8.7374 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.3760e-10 | qwen: tf=10.2374 first=12.4799 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=9.1683e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  110/500 | grad_norm=125.35 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=10.5239 first=7.5594 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.3760e-10 | qwen: tf=10.5473 first=11.2612 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=9.1683e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  120/500 | grad_norm=50.03 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=9.9333 first=8.0427 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=9.6187 first=10.1257 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=8.8818e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  130/500 | grad_norm=19.86 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=9.1473 first=7.2148 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=4.1554e-10 | qwen: tf=10.6957 first=9.9405 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=9.6065e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  140/500 | grad_norm=55.80 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=9.0648 first=7.7696 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=4.1554e-10 | qwen: tf=8.7772 first=9.6998 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=9.6065e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  150/500 | grad_norm=20.18 | sec/step~0.64 | keep=1.00 | K=4 | llama: tf=9.4844 first=7.1207 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.7413e-10 | qwen: tf=9.8254 first=9.9061 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.9666e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  160/500 | grad_norm=85.78 | sec/step~0.64 | keep=1.00 | K=4 | llama: tf=9.3659 first=6.9737 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.3928e-10 | qwen: tf=9.8862 first=10.3441 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.6719e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  170/500 | grad_norm=151.33 | sec/step~0.62 | keep=1.00 | K=4 | llama: tf=9.1193 first=6.5842 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.3928e-10 | qwen: tf=9.1103 first=8.7703 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.6719e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  180/500 | grad_norm=38.39 | sec/step~0.77 | keep=1.00 | K=4 | llama: tf=9.3578 first=7.5290 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.9918e-11 | qwen: tf=9.8955 first=11.0403 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=6.6302e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  190/500 | grad_norm=140.44 | sec/step~0.95 | keep=1.00 | K=4 | llama: tf=9.7281 first=7.0662 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.9918e-11 | qwen: tf=9.4781 first=9.5899 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=6.6302e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  200/500 | grad_norm=99.97 | sec/step~0.91 | keep=1.00 | K=4 | llama: tf=10.0870 first=8.1125 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5028e-10 | qwen: tf=9.8993 first=10.0368 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.6428e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0000 rms_cal~0.0136 embed_rms~0.01364]
  step  210/500 | grad_norm=1.96 | sec/step~0.85 | keep=1.00 | K=4 | llama: tf=10.2327 first=7.8839 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.4362e-10 | qwen: tf=11.1502 first=8.4512 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.8655e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  220/500 | grad_norm=16.40 | sec/step~0.69 | keep=1.00 | K=4 | llama: tf=9.6233 first=8.5165 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.4362e-10 | qwen: tf=9.4901 first=8.0096 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.8655e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  230/500 | grad_norm=11.19 | sec/step~0.56 | keep=1.00 | K=4 | llama: tf=9.3918 first=7.6561 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.9121e-11 | qwen: tf=9.8707 first=7.8315 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=9.3132e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  240/500 | grad_norm=29.01 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=9.2240 first=7.5092 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=4.1439e-11 | qwen: tf=9.1035 first=7.3094 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.1102e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  250/500 | grad_norm=29.81 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=9.0010 first=7.2643 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=4.1439e-11 | qwen: tf=10.3120 first=7.4734 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.1102e-09 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  260/500 | grad_norm=4.95 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.9082 first=7.0951 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.3283e-10 | qwen: tf=9.6178 first=7.0183 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=6.7226e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  270/500 | grad_norm=11.65 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=9.1801 first=7.9906 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.3283e-10 | qwen: tf=9.7215 first=6.8048 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=6.7226e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  280/500 | grad_norm=7.63 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.7908 first=7.5263 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.0124e-10 | qwen: tf=9.1177 first=7.4336 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.3509e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  290/500 | grad_norm=2.41 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=9.4720 first=7.5126 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.3888e-11 | qwen: tf=10.0881 first=7.5511 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.2737e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  300/500 | grad_norm=46.43 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=9.1665 first=6.9445 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.3888e-11 | qwen: tf=9.2304 first=6.4952 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.2737e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  310/500 | grad_norm=2.44 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=9.2888 first=7.8371 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=4.2210e-11 | qwen: tf=9.5660 first=7.9526 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.2402e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  320/500 | grad_norm=10.02 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=9.5837 first=7.7719 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.7039e-10 | qwen: tf=10.3456 first=7.9532 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.9721e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  330/500 | grad_norm=6.79 | sec/step~0.64 | keep=1.00 | K=4 | llama: tf=9.1625 first=8.1499 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.7039e-10 | qwen: tf=9.7272 first=7.7385 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.9721e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  340/500 | grad_norm=3.29 | sec/step~0.80 | keep=1.00 | K=4 | llama: tf=9.3478 first=7.5193 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.2961e-10 | qwen: tf=9.7055 first=6.9947 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.0763e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  350/500 | grad_norm=6.95 | sec/step~0.82 | keep=1.00 | K=4 | llama: tf=9.3633 first=8.1916 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.2961e-10 | qwen: tf=9.7216 first=7.8593 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.0763e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  360/500 | grad_norm=4.67 | sec/step~0.84 | keep=1.00 | K=4 | llama: tf=10.0459 first=8.2409 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.0747e-11 | qwen: tf=10.1309 first=8.0928 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.9122e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  370/500 | grad_norm=42.02 | sec/step~0.83 | keep=1.00 | K=4 | llama: tf=9.6113 first=6.9911 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-11 | qwen: tf=10.2708 first=6.7561 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.4016e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  380/500 | grad_norm=42.80 | sec/step~0.68 | keep=1.00 | K=4 | llama: tf=8.6902 first=7.3391 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-11 | qwen: tf=8.4745 first=7.2026 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.4016e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  390/500 | grad_norm=2.36 | sec/step~0.57 | keep=1.00 | K=4 | llama: tf=9.5280 first=8.4576 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.1256e-10 | qwen: tf=9.8236 first=7.6719 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.0388e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0001 rms_cal~0.0136 embed_rms~0.01364]
  step  400/500 | grad_norm=22.47 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=9.4555 first=8.0037 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=6.9633e-11 | qwen: tf=11.0644 first=7.9174 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1127e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  410/500 | grad_norm=2.41 | sec/step~0.54 | keep=1.00 | K=4 | llama: tf=8.5573 first=7.4025 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=6.9633e-11 | qwen: tf=8.3527 first=6.7389 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1127e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  420/500 | grad_norm=23.50 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.9584 first=7.4488 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.1511e-12 | qwen: tf=10.2112 first=7.7787 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5701e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  430/500 | grad_norm=25.09 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=9.2081 first=7.5911 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.1511e-12 | qwen: tf=10.4824 first=7.9003 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5701e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  440/500 | grad_norm=4.82 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=9.4966 first=7.6306 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.9169e-11 | qwen: tf=10.2440 first=6.7715 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.9620e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  450/500 | grad_norm=2.34 | sec/step~0.53 | keep=1.00 | K=4 | llama: tf=9.1059 first=7.3176 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=8.3165e-11 | qwen: tf=11.0199 first=7.0414 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.6276e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  460/500 | grad_norm=2.18 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=9.0945 first=7.0045 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=8.3165e-11 | qwen: tf=10.2270 first=6.3045 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.6276e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  470/500 | grad_norm=1.09 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=9.0352 first=7.9652 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.6962e-11 | qwen: tf=9.2966 first=7.4273 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.0520e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  480/500 | grad_norm=3.99 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=9.2815 first=7.1800 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.2737e-13 | qwen: tf=10.9106 first=6.9287 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.3648e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  490/500 | grad_norm=1.70 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.6751 first=7.5040 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.2737e-13 | qwen: tf=8.5564 first=6.9079 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.3648e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  500/500 | grad_norm=0.42 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.9871 first=7.8422 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.0027e-10 | qwen: tf=9.6007 first=7.3689 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.2921e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
Epoch 2/6
  step  10/500 | grad_norm=1.33 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=9.1350 first=7.8046 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.0027e-10 | qwen: tf=10.5194 first=7.5553 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.2921e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  20/500 | grad_norm=0.71 | sec/step~0.65 | keep=1.00 | K=4 | llama: tf=9.3682 first=7.2132 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=4.7805e-11 | qwen: tf=10.0496 first=7.1335 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.1511e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  30/500 | grad_norm=2.25 | sec/step~0.63 | keep=1.00 | K=4 | llama: tf=8.8927 first=7.2048 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=4.7805e-11 | qwen: tf=9.9820 first=6.8410 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.1511e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  40/500 | grad_norm=2.07 | sec/step~0.70 | keep=1.00 | K=4 | llama: tf=8.9345 first=7.6938 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.8777e-13 | qwen: tf=8.9986 first=6.9502 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=8.8818e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  50/500 | grad_norm=2.19 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.8058 first=6.9702 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=4.8633e-11 | qwen: tf=9.9497 first=7.0274 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.7512e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  60/500 | grad_norm=3.86 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.9160 first=7.1468 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=4.8633e-11 | qwen: tf=10.2753 first=6.9851 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.7512e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  70/500 | grad_norm=1.73 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.4611 first=7.1489 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=6.7658e-11 | qwen: tf=8.7902 first=6.6976 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2028e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  80/500 | grad_norm=2.68 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.2376 first=8.4399 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.5476e-11 | qwen: tf=8.1635 first=7.2918 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.5076e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  90/500 | grad_norm=1.80 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.6093 first=7.0603 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.5476e-11 | qwen: tf=8.3014 first=6.4793 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.5076e-10 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  100/500 | grad_norm=8.59 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=9.2955 first=7.7602 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=6.8781e-12 | qwen: tf=10.8593 first=7.9719 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=8.4256e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  110/500 | grad_norm=27.56 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.5462 first=7.2061 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=6.8781e-12 | qwen: tf=8.8409 first=6.4417 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=8.4256e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  120/500 | grad_norm=2.62 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.9176 first=7.0146 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=4.2988e-11 | qwen: tf=10.0346 first=6.6096 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=9.6065e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  130/500 | grad_norm=0.69 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.9772 first=7.5575 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.0070e-11 | qwen: tf=9.5441 first=7.5890 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.1951e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  140/500 | grad_norm=2.87 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=9.3233 first=7.8273 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.0070e-11 | qwen: tf=8.6521 first=6.3885 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.1951e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  150/500 | grad_norm=1.41 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.9419 first=7.1859 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-13 | qwen: tf=9.8204 first=6.9960 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=6.3793e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  160/500 | grad_norm=2.73 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=9.4235 first=7.9458 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.8932e-11 | qwen: tf=10.2302 first=7.5933 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=8.2082e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  170/500 | grad_norm=3.61 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=9.0323 first=6.7609 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.8932e-11 | qwen: tf=9.6485 first=6.4229 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=8.2082e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  180/500 | grad_norm=0.47 | sec/step~0.56 | keep=1.00 | K=4 | llama: tf=9.3575 first=8.0628 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.3427e-11 | qwen: tf=10.0821 first=7.8307 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=4.1439e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  190/500 | grad_norm=1.13 | sec/step~0.77 | keep=1.00 | K=4 | llama: tf=8.9925 first=6.3107 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.3427e-11 | qwen: tf=9.6041 first=6.1319 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=4.1439e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  200/500 | grad_norm=10.72 | sec/step~0.79 | keep=1.00 | K=4 | llama: tf=8.2542 first=7.7332 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=9.2406e-12 | qwen: tf=7.7598 first=7.0605 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.4016e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  210/500 | grad_norm=0.38 | sec/step~1.02 | keep=1.00 | K=4 | llama: tf=8.5572 first=8.3276 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.4016e-12 | qwen: tf=8.1505 first=7.9911 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2790e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  220/500 | grad_norm=1.31 | sec/step~0.66 | keep=1.00 | K=4 | llama: tf=8.8048 first=7.7405 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.4016e-12 | qwen: tf=9.6446 first=7.2689 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2790e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  230/500 | grad_norm=1.78 | sec/step~0.63 | keep=1.00 | K=4 | llama: tf=7.9892 first=8.0668 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.0520e-11 | qwen: tf=8.3322 first=7.4976 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=4.7805e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  240/500 | grad_norm=4.29 | sec/step~0.58 | keep=1.00 | K=4 | llama: tf=8.7112 first=6.7776 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.3657e-11 | qwen: tf=8.9454 first=6.4291 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.3749e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  250/500 | grad_norm=0.68 | sec/step~0.53 | keep=1.00 | K=4 | llama: tf=8.9871 first=7.8185 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.3657e-11 | qwen: tf=9.6511 first=7.6799 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.3749e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  260/500 | grad_norm=1.97 | sec/step~0.67 | keep=1.00 | K=4 | llama: tf=9.0237 first=7.6045 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=9.2859 first=7.6751 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.3888e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  270/500 | grad_norm=2.04 | sec/step~0.55 | keep=1.00 | K=4 | llama: tf=8.7714 first=7.1584 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=9.3528 first=7.3636 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.3888e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  280/500 | grad_norm=2.66 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.4043 first=6.4728 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.0747e-11 | qwen: tf=8.4242 first=4.5775 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=6.0041e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  290/500 | grad_norm=0.74 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=9.1868 first=7.0245 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.5476e-11 | qwen: tf=10.0645 first=6.8191 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.0360e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0002 rms_cal~0.0136 embed_rms~0.01364]
  step  300/500 | grad_norm=13.35 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=9.0256 first=7.7462 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.5476e-11 | qwen: tf=8.1605 first=7.1311 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.0360e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  310/500 | grad_norm=1.87 | sec/step~0.54 | keep=1.00 | K=4 | llama: tf=9.1652 first=7.5309 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.5899e-12 | qwen: tf=8.5191 first=6.5972 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.8777e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  320/500 | grad_norm=4.26 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=9.0719 first=6.9466 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.7853e-12 | qwen: tf=7.8294 first=5.4358 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.5068e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  330/500 | grad_norm=2.90 | sec/step~0.53 | keep=1.00 | K=4 | llama: tf=9.1648 first=7.6612 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.7853e-12 | qwen: tf=9.2348 first=7.1450 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.5068e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  340/500 | grad_norm=1.01 | sec/step~0.55 | keep=1.00 | K=4 | llama: tf=8.5921 first=8.0524 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.0360e-11 | qwen: tf=8.7855 first=8.2356 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=6.2670e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  350/500 | grad_norm=1.80 | sec/step~0.64 | keep=1.00 | K=4 | llama: tf=9.0130 first=6.9750 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.0360e-11 | qwen: tf=9.9687 first=6.7644 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=6.2670e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  360/500 | grad_norm=1.67 | sec/step~0.76 | keep=1.00 | K=4 | llama: tf=8.1479 first=7.6822 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.6380e-12 | qwen: tf=7.6826 first=7.2811 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=7.9936e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  370/500 | grad_norm=5.43 | sec/step~0.61 | keep=1.00 | K=4 | llama: tf=9.3317 first=7.1863 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=7.9936e-13 | qwen: tf=10.5963 first=7.0652 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.3220e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  380/500 | grad_norm=6.01 | sec/step~0.58 | keep=1.00 | K=4 | llama: tf=8.8398 first=8.1658 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=7.9936e-13 | qwen: tf=9.2622 first=7.5938 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.3220e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  390/500 | grad_norm=32.21 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.7169 first=7.8830 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=7.5175e-12 | qwen: tf=8.7503 first=7.3821 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.2172e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  400/500 | grad_norm=34.81 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.0650 first=6.6052 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.1301e-12 | qwen: tf=7.8267 first=5.9495 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2790e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  410/500 | grad_norm=14.90 | sec/step~0.59 | keep=1.00 | K=4 | llama: tf=8.5158 first=7.6787 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.1301e-12 | qwen: tf=9.0010 first=7.3706 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2790e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  420/500 | grad_norm=3.58 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.9032 first=6.9416 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.6631 first=6.1663 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.1511e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  430/500 | grad_norm=6.13 | sec/step~0.59 | keep=1.00 | K=4 | llama: tf=8.7837 first=7.6911 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=9.1652 first=6.9769 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.1511e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  440/500 | grad_norm=13.36 | sec/step~0.66 | keep=1.00 | K=4 | llama: tf=9.2811 first=8.7073 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.6380e-12 | qwen: tf=9.0593 first=7.7629 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.4016e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  450/500 | grad_norm=0.41 | sec/step~0.82 | keep=1.00 | K=4 | llama: tf=8.4062 first=6.7868 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.6380e-12 | qwen: tf=9.1970 first=6.3322 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=9.6065e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  460/500 | grad_norm=3.64 | sec/step~0.94 | keep=1.00 | K=4 | llama: tf=9.0541 first=7.6626 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.6380e-12 | qwen: tf=9.8551 first=7.6024 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=9.6065e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  470/500 | grad_norm=2.11 | sec/step~0.70 | keep=1.00 | K=4 | llama: tf=8.5274 first=7.0598 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.6843e-14 | qwen: tf=8.4555 first=6.3097 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=9.6065e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  480/500 | grad_norm=4.37 | sec/step~0.57 | keep=1.00 | K=4 | llama: tf=8.6688 first=7.9233 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.4016e-12 | qwen: tf=9.1228 first=7.5819 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.4016e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  490/500 | grad_norm=2.88 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.5999 first=7.5994 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.4016e-12 | qwen: tf=8.1160 first=6.6121 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.4016e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  500/500 | grad_norm=2.94 | sec/step~0.53 | keep=1.00 | K=4 | llama: tf=8.2555 first=7.4913 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.6380e-12 | qwen: tf=9.0321 first=7.0663 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=6.8781e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
Epoch 3/6
  step  10/500 | grad_norm=2.51 | sec/step~0.60 | keep=1.00 | K=4 | llama: tf=8.3064 first=6.2838 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.6380e-12 | qwen: tf=8.6271 first=5.5823 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=6.8781e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  20/500 | grad_norm=0.44 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.7774 first=7.3466 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.2790e-13 | qwen: tf=9.1823 first=6.4513 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.0747e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  30/500 | grad_norm=2.47 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.4001 first=6.6817 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.2790e-13 | qwen: tf=9.2583 first=6.7329 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.0747e-11 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  40/500 | grad_norm=14.65 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=9.4417 first=8.1335 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.7195e-12 | qwen: tf=9.6391 first=7.6100 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.9721e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  50/500 | grad_norm=1.23 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.4196 first=6.9519 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.0464e-12 | qwen: tf=9.1271 first=6.6494 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=4.2988e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  60/500 | grad_norm=7.14 | sec/step~0.59 | keep=1.00 | K=4 | llama: tf=9.3643 first=6.9949 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.0464e-12 | qwen: tf=9.6215 first=6.3364 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=4.2988e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  70/500 | grad_norm=3.19 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.6458 first=7.7040 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.6843e-14 | qwen: tf=9.0510 first=7.9232 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  80/500 | grad_norm=9.13 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.8623 first=7.6359 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.2825e-12 | qwen: tf=9.5121 first=8.0464 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=4.6043e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  90/500 | grad_norm=15.52 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.6296 first=7.5463 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.2825e-12 | qwen: tf=8.8606 first=7.0338 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=4.6043e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  100/500 | grad_norm=0.97 | sec/step~0.53 | keep=1.00 | K=4 | llama: tf=8.9187 first=7.6385 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.0464e-12 | qwen: tf=9.2693 first=7.1341 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.6380e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  110/500 | grad_norm=3.27 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.3088 first=6.9553 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.0464e-12 | qwen: tf=8.3710 first=6.6015 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.6380e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  120/500 | grad_norm=36.70 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.9734 first=8.3184 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.8777e-13 | qwen: tf=8.1855 first=7.7155 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  130/500 | grad_norm=0.69 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.5606 first=8.2515 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.1159e-13 | qwen: tf=7.7710 first=7.3947 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.1159e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  140/500 | grad_norm=1.93 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.6352 first=6.8217 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.1159e-13 | qwen: tf=9.4614 first=6.4074 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.1159e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  150/500 | grad_norm=5.79 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.7035 first=7.1545 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.1511e-12 | qwen: tf=8.3374 first=6.6640 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.7853e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  160/500 | grad_norm=6.78 | sec/step~0.53 | keep=1.00 | K=4 | llama: tf=8.6186 first=7.4603 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.6843e-14 | qwen: tf=8.2278 first=7.2427 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1974e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  170/500 | grad_norm=11.88 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.5575 first=7.4862 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.6843e-14 | qwen: tf=8.6965 first=7.2651 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1974e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  180/500 | grad_norm=0.88 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.6779 first=7.6723 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=6.0041e-13 | qwen: tf=7.9003 first=7.2431 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2825e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  190/500 | grad_norm=3.88 | sec/step~0.60 | keep=1.00 | K=4 | llama: tf=9.2522 first=7.2210 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=6.0041e-13 | qwen: tf=9.8372 first=6.9993 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2825e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  200/500 | grad_norm=2.02 | sec/step~0.62 | keep=1.00 | K=4 | llama: tf=8.0509 first=6.9914 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.1511e-12 | qwen: tf=7.3485 first=6.6844 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  210/500 | grad_norm=3.38 | sec/step~0.68 | keep=1.00 | K=4 | llama: tf=8.4435 first=7.5770 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.7408e-13 | qwen: tf=8.3794 first=7.5549 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=6.9633e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  220/500 | grad_norm=3.99 | sec/step~0.72 | keep=1.00 | K=4 | llama: tf=8.3348 first=5.9733 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.7408e-13 | qwen: tf=7.8145 first=5.3020 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=6.9633e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  230/500 | grad_norm=1.48 | sec/step~0.76 | keep=1.00 | K=4 | llama: tf=9.0176 first=7.5075 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.2737e-13 | qwen: tf=9.5821 first=7.5413 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.1511e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  240/500 | grad_norm=3.27 | sec/step~0.88 | keep=1.00 | K=4 | llama: tf=8.9270 first=7.3172 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.1159e-13 | qwen: tf=9.4762 first=6.6661 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  250/500 | grad_norm=4.50 | sec/step~0.83 | keep=1.00 | K=4 | llama: tf=9.8021 first=6.5744 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.1159e-13 | qwen: tf=10.2185 first=6.1699 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  260/500 | grad_norm=0.58 | sec/step~0.77 | keep=1.00 | K=4 | llama: tf=8.6644 first=6.9644 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.5373 first=6.1446 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1974e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  270/500 | grad_norm=3.23 | sec/step~0.69 | keep=1.00 | K=4 | llama: tf=9.0808 first=6.8575 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=9.0854 first=6.6470 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1974e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  280/500 | grad_norm=5.17 | sec/step~0.82 | keep=1.00 | K=4 | llama: tf=9.3283 first=7.3386 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-13 | qwen: tf=10.0282 first=7.2382 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=7.9936e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  290/500 | grad_norm=3.46 | sec/step~0.82 | keep=1.00 | K=4 | llama: tf=8.3706 first=7.3539 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=6.0041e-13 | qwen: tf=8.5261 first=7.4690 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  300/500 | grad_norm=3.23 | sec/step~0.68 | keep=1.00 | K=4 | llama: tf=8.2756 first=6.5326 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=6.0041e-13 | qwen: tf=7.8664 first=6.3339 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  310/500 | grad_norm=1.04 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.9170 first=7.4171 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.6843e-14 | qwen: tf=9.0280 first=7.8410 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=7.9936e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  320/500 | grad_norm=3.30 | sec/step~0.54 | keep=1.00 | K=4 | llama: tf=9.1142 first=7.1621 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.2790e-13 | qwen: tf=9.7038 first=6.9270 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=8.8818e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  330/500 | grad_norm=5.32 | sec/step~0.65 | keep=1.00 | K=4 | llama: tf=9.3619 first=8.2899 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.2790e-13 | qwen: tf=9.5732 first=8.0999 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=8.8818e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  340/500 | grad_norm=1.39 | sec/step~0.61 | keep=1.00 | K=4 | llama: tf=9.3061 first=7.4643 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.2737e-13 | qwen: tf=9.5333 first=7.0789 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2790e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  350/500 | grad_norm=2.71 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.3807 first=7.6804 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.2737e-13 | qwen: tf=7.9667 first=6.7092 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2790e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  360/500 | grad_norm=6.02 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.5429 first=7.2023 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=7.9791 first=7.1203 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  370/500 | grad_norm=0.68 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=9.4441 first=7.5996 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.8777e-13 | qwen: tf=10.1525 first=7.2970 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.2737e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  380/500 | grad_norm=1.20 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=9.1414 first=7.9695 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.8777e-13 | qwen: tf=8.3534 first=7.6152 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.2737e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  390/500 | grad_norm=1.15 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.8272 first=7.6814 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=2.8777e-13 | qwen: tf=9.2124 first=7.8183 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  400/500 | grad_norm=1.89 | sec/step~0.53 | keep=1.00 | K=4 | llama: tf=9.1842 first=7.3906 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=9.5641 first=7.0282 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.8777e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  410/500 | grad_norm=13.61 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.4988 first=6.6824 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=7.9088 first=6.1167 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.8777e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  420/500 | grad_norm=0.37 | sec/step~0.67 | keep=1.00 | K=4 | llama: tf=9.2578 first=7.5344 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.6843e-14 | qwen: tf=9.2150 first=7.4716 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=7.9936e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  430/500 | grad_norm=21.11 | sec/step~0.62 | keep=1.00 | K=4 | llama: tf=8.4414 first=7.3555 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.6843e-14 | qwen: tf=8.1313 first=6.3721 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=7.9936e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  440/500 | grad_norm=1.21 | sec/step~0.54 | keep=1.00 | K=4 | llama: tf=9.0406 first=8.2620 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.6843e-14 | qwen: tf=8.5830 first=7.1570 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=9.0949e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  450/500 | grad_norm=0.31 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.2462 first=8.0523 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.1344 first=7.6436 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  460/500 | grad_norm=2.88 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.9399 first=7.1030 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=9.2671 first=6.8510 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  470/500 | grad_norm=2.11 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.5515 first=8.9187 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.2790e-13 | qwen: tf=7.9859 first=8.4182 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  480/500 | grad_norm=3.70 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.4116 first=6.4711 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.2790e-13 | qwen: tf=8.3500 first=6.0236 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2790e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  490/500 | grad_norm=1.51 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=9.1057 first=7.5985 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.2790e-13 | qwen: tf=8.9874 first=7.0394 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2790e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  500/500 | grad_norm=4.76 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.7557 first=8.3929 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.3003 first=7.4537 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2790e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
Epoch 4/6
  step  10/500 | grad_norm=1.18 | sec/step~0.54 | keep=1.00 | K=4 | llama: tf=8.9902 first=6.4678 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=9.7558 first=6.1432 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2790e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  20/500 | grad_norm=1.03 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.3182 first=7.3483 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=7.9820 first=6.7518 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  30/500 | grad_norm=9.83 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.7136 first=7.0169 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=7.9837 first=5.6726 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  40/500 | grad_norm=0.97 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.7017 first=7.3901 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.1974e-14 | qwen: tf=8.8787 first=6.9393 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.2737e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  50/500 | grad_norm=0.20 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.8760 first=6.9699 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.6843e-14 | qwen: tf=9.0134 first=6.4413 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.1159e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  60/500 | grad_norm=1.53 | sec/step~0.59 | keep=1.00 | K=4 | llama: tf=9.0674 first=7.1913 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.6843e-14 | qwen: tf=9.2198 first=7.1911 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.1159e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  70/500 | grad_norm=0.95 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.8616 first=7.7067 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=9.1296 first=7.6748 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  80/500 | grad_norm=1.65 | sec/step~0.54 | keep=1.00 | K=4 | llama: tf=8.6024 first=7.5408 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=7.8984 first=6.9646 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  90/500 | grad_norm=1.13 | sec/step~0.65 | keep=1.00 | K=4 | llama: tf=9.1293 first=6.9288 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=10.0619 first=6.7154 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  100/500 | grad_norm=0.61 | sec/step~0.72 | keep=1.00 | K=4 | llama: tf=8.5591 first=7.8014 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=8.2190 first=7.3478 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  110/500 | grad_norm=1.22 | sec/step~0.96 | keep=1.00 | K=4 | llama: tf=8.4097 first=7.2558 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=8.0301 first=6.3893 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  120/500 | grad_norm=1.31 | sec/step~0.74 | keep=1.00 | K=4 | llama: tf=8.1481 first=8.0948 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=7.9137 first=7.5502 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  130/500 | grad_norm=0.26 | sec/step~0.66 | keep=1.00 | K=4 | llama: tf=8.4917 first=7.3216 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.1974e-14 | qwen: tf=8.4577 first=6.4967 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  140/500 | grad_norm=0.96 | sec/step~0.56 | keep=1.00 | K=4 | llama: tf=9.2655 first=7.8435 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.1974e-14 | qwen: tf=9.8889 first=7.5971 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  150/500 | grad_norm=73.55 | sec/step~0.54 | keep=1.00 | K=4 | llama: tf=9.1623 first=7.7460 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.1974e-14 | qwen: tf=9.3886 first=7.2963 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  160/500 | grad_norm=74.33 | sec/step~0.64 | keep=1.00 | K=4 | llama: tf=8.1193 first=7.1543 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=7.7429 first=7.3949 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2790e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  170/500 | grad_norm=1.30 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.3742 first=7.1214 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=7.8985 first=6.4513 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2790e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  180/500 | grad_norm=0.78 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=9.0847 first=7.9919 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=8.4650 first=7.6461 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.2737e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  190/500 | grad_norm=2.96 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.2294 first=7.5172 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=7.7614 first=7.0299 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.2737e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  200/500 | grad_norm=1.10 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.4982 first=7.0153 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.4829 first=6.3221 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2790e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  210/500 | grad_norm=0.24 | sec/step~0.60 | keep=1.00 | K=4 | llama: tf=8.9233 first=7.9526 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.1872 first=7.2251 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  220/500 | grad_norm=0.79 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.2401 first=6.5899 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.2927 first=6.3582 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  230/500 | grad_norm=0.63 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=9.0168 first=7.7327 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.3513 first=6.4313 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  240/500 | grad_norm=2.06 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.2660 first=7.2539 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=7.6575 first=6.4077 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  250/500 | grad_norm=5.00 | sec/step~0.53 | keep=1.00 | K=4 | llama: tf=8.9980 first=7.1834 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=9.0015 first=6.7717 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  260/500 | grad_norm=0.74 | sec/step~0.99 | keep=1.00 | K=4 | llama: tf=8.1081 first=7.9049 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=7.3237 first=7.1627 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  270/500 | grad_norm=1.40 | sec/step~0.57 | keep=1.00 | K=4 | llama: tf=8.0712 first=6.4762 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=7.4897 first=5.8978 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  280/500 | grad_norm=0.68 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.5053 first=7.6909 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=7.9702 first=7.0941 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1974e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  290/500 | grad_norm=0.44 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=9.0730 first=7.9650 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.7660 first=7.8778 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2825e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  300/500 | grad_norm=15.83 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.6749 first=7.4552 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.0249 first=6.8823 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2825e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  310/500 | grad_norm=2.05 | sec/step~0.58 | keep=1.00 | K=4 | llama: tf=8.4653 first=6.9834 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.0066 first=6.1473 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.0464e-12 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  320/500 | grad_norm=2.15 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.5631 first=6.7970 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.4297 first=6.0723 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=7.9936e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  330/500 | grad_norm=0.74 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.5510 first=6.8896 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.8046 first=6.3292 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=7.9936e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  340/500 | grad_norm=3.84 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=9.2968 first=7.9645 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=9.0331 first=7.3739 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  350/500 | grad_norm=3.81 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.9316 first=7.1180 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=9.1539 first=7.0065 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  360/500 | grad_norm=7.07 | sec/step~0.75 | keep=1.00 | K=4 | llama: tf=8.7287 first=7.3645 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.2496 first=6.5524 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.1159e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  370/500 | grad_norm=0.34 | sec/step~0.57 | keep=1.00 | K=4 | llama: tf=8.7382 first=6.8414 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=7.6722 first=6.4613 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=6.9633e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  380/500 | grad_norm=1.31 | sec/step~0.71 | keep=1.00 | K=4 | llama: tf=8.3225 first=7.0232 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.3397 first=6.3865 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=6.9633e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  390/500 | grad_norm=10.95 | sec/step~0.79 | keep=1.00 | K=4 | llama: tf=8.8311 first=7.6409 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.6369 first=7.1781 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2790e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  400/500 | grad_norm=13.15 | sec/step~0.83 | keep=1.00 | K=4 | llama: tf=8.6092 first=7.7936 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.7416 first=7.4076 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=8.8818e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  410/500 | grad_norm=0.82 | sec/step~0.88 | keep=1.00 | K=4 | llama: tf=8.7870 first=7.4648 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=7.8223 first=6.2946 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=8.8818e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  420/500 | grad_norm=0.40 | sec/step~0.59 | keep=1.00 | K=4 | llama: tf=8.4585 first=7.4641 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=7.1993 first=6.2645 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=6.9633e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  430/500 | grad_norm=2.38 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.4807 first=6.9092 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=7.3681 first=6.5020 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=6.9633e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  440/500 | grad_norm=0.69 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.4246 first=7.0933 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=8.5800 first=6.8395 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=7.9936e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  450/500 | grad_norm=1.80 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.5638 first=6.9424 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.4175 first=6.1503 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.2737e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  460/500 | grad_norm=1.80 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.1416 first=7.6895 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.2554 first=7.6573 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.2737e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  470/500 | grad_norm=0.51 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.8598 first=7.5580 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.2190 first=6.9258 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  480/500 | grad_norm=1.76 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.7857 first=6.5809 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.1974e-14 | qwen: tf=8.7302 first=6.2120 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.2737e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  490/500 | grad_norm=0.73 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.4059 first=7.3290 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.1974e-14 | qwen: tf=6.7558 first=6.9549 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.2737e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  500/500 | grad_norm=0.50 | sec/step~0.53 | keep=1.00 | K=4 | llama: tf=9.3817 first=7.9729 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=10.1975 first=7.9014 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
Epoch 5/6
  step  10/500 | grad_norm=0.47 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.8010 first=7.3228 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.8890 first=7.1794 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  20/500 | grad_norm=0.54 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.8641 first=7.1660 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.7559 first=6.9202 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  30/500 | grad_norm=1.27 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.8212 first=7.0345 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.0568 first=6.1262 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  40/500 | grad_norm=0.63 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.0623 first=7.0356 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=6.8638 first=6.7604 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.8777e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  50/500 | grad_norm=0.23 | sec/step~0.62 | keep=1.00 | K=4 | llama: tf=8.6953 first=8.0960 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.0450 first=8.1091 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.8777e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  60/500 | grad_norm=1.08 | sec/step~0.80 | keep=1.00 | K=4 | llama: tf=9.2537 first=8.1736 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.1259 first=7.7674 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.8777e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  70/500 | grad_norm=0.32 | sec/step~0.80 | keep=1.00 | K=4 | llama: tf=8.9133 first=7.4431 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=9.0155 first=7.0399 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=8.8818e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  80/500 | grad_norm=0.89 | sec/step~0.85 | keep=1.00 | K=4 | llama: tf=8.1923 first=7.5402 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=6.8006 first=6.2955 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  90/500 | grad_norm=5.88 | sec/step~0.85 | keep=1.00 | K=4 | llama: tf=9.0834 first=9.0281 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=9.0923 first=9.1330 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  100/500 | grad_norm=0.28 | sec/step~0.84 | keep=1.00 | K=4 | llama: tf=8.5055 first=7.0470 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.9498 first=6.5853 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  110/500 | grad_norm=0.66 | sec/step~0.76 | keep=1.00 | K=4 | llama: tf=9.4284 first=7.5609 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=9.2497 first=6.9765 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  120/500 | grad_norm=1.16 | sec/step~0.77 | keep=1.00 | K=4 | llama: tf=8.3450 first=6.4069 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=7.9403 first=5.0730 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  130/500 | grad_norm=0.17 | sec/step~0.71 | keep=1.00 | K=4 | llama: tf=8.5578 first=6.1926 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.0566 first=5.3827 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  140/500 | grad_norm=0.51 | sec/step~0.65 | keep=1.00 | K=4 | llama: tf=9.1041 first=7.6451 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.2179 first=7.4408 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  150/500 | grad_norm=0.36 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.4106 first=8.0483 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=7.9174 first=7.5543 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.7408e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  160/500 | grad_norm=0.70 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.8334 first=7.6237 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.4592 first=7.2004 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.8777e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  170/500 | grad_norm=0.61 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=9.4381 first=7.4283 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=9.4090 first=7.4451 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=2.8777e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  180/500 | grad_norm=0.17 | sec/step~0.61 | keep=1.00 | K=4 | llama: tf=9.3890 first=7.1061 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=9.0835 first=6.8079 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2790e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  190/500 | grad_norm=0.31 | sec/step~0.62 | keep=1.00 | K=4 | llama: tf=8.5068 first=6.0294 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.6282 first=5.7725 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2790e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  200/500 | grad_norm=0.44 | sec/step~0.58 | keep=1.00 | K=4 | llama: tf=9.5755 first=7.4674 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=9.7086 first=7.0100 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  210/500 | grad_norm=0.13 | sec/step~0.60 | keep=1.00 | K=4 | llama: tf=9.5562 first=8.2892 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=9.4681 first=7.9137 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  220/500 | grad_norm=0.44 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.8308 first=7.6408 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=7.8846 first=7.3379 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  230/500 | grad_norm=0.22 | sec/step~0.77 | keep=1.00 | K=4 | llama: tf=8.0308 first=7.0998 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=7.5496 first=5.8011 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  240/500 | grad_norm=0.35 | sec/step~0.82 | keep=1.00 | K=4 | llama: tf=8.8212 first=7.6383 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=8.4292 first=7.1844 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  250/500 | grad_norm=0.62 | sec/step~0.85 | keep=1.00 | K=4 | llama: tf=8.7331 first=7.1226 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=8.6372 first=6.5801 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  260/500 | grad_norm=0.27 | sec/step~0.80 | keep=1.00 | K=4 | llama: tf=7.9762 first=6.7331 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=6.8619 first=5.6806 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  270/500 | grad_norm=0.53 | sec/step~0.81 | keep=1.00 | K=4 | llama: tf=8.5312 first=7.8263 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=7.6986 first=7.3524 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  280/500 | grad_norm=0.42 | sec/step~0.80 | keep=1.00 | K=4 | llama: tf=9.1123 first=7.6839 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=9.4660 first=8.1192 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.2790e-13 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  290/500 | grad_norm=0.16 | sec/step~0.76 | keep=1.00 | K=4 | llama: tf=9.2316 first=8.1654 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=9.1777 first=7.5866 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=8.8818e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  300/500 | grad_norm=0.79 | sec/step~0.62 | keep=1.00 | K=4 | llama: tf=8.4744 first=7.4089 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=7.8421 first=7.0181 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=8.8818e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  310/500 | grad_norm=0.37 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.8925 first=7.2644 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.9270 first=7.1000 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  320/500 | grad_norm=0.52 | sec/step~0.54 | keep=1.00 | K=4 | llama: tf=8.2374 first=7.1426 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=7.3678 first=6.3565 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  330/500 | grad_norm=0.56 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=9.3588 first=7.5897 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=9.2877 first=7.1461 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  340/500 | grad_norm=0.22 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.2778 first=6.6762 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=7.1587 first=6.4974 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  350/500 | grad_norm=0.40 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.6383 first=6.9958 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.7544 first=7.2134 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  360/500 | grad_norm=0.61 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=9.6724 first=7.7728 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=9.5437 first=7.1525 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  370/500 | grad_norm=0.14 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.4245 first=6.6760 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.1021 first=6.2917 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  380/500 | grad_norm=0.32 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.4180 first=6.8680 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.6018 first=6.6626 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  390/500 | grad_norm=0.58 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.6234 first=6.7618 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.0966 first=5.6652 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  400/500 | grad_norm=1.11 | sec/step~0.53 | keep=1.00 | K=4 | llama: tf=8.7786 first=6.8796 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=9.1639 first=6.6154 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1974e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  410/500 | grad_norm=0.54 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=9.2690 first=7.2302 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=9.3833 first=7.0457 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1974e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  420/500 | grad_norm=0.41 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.6386 first=6.9352 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=7.8734 first=6.4517 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  430/500 | grad_norm=0.79 | sec/step~0.53 | keep=1.00 | K=4 | llama: tf=8.7242 first=6.4967 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=9.3436 first=6.1831 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  440/500 | grad_norm=0.41 | sec/step~0.65 | keep=1.00 | K=4 | llama: tf=8.9674 first=8.4102 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.1859 first=8.0326 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  450/500 | grad_norm=0.14 | sec/step~0.78 | keep=1.00 | K=4 | llama: tf=9.4111 first=7.4577 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=9.9053 first=6.9229 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  460/500 | grad_norm=0.48 | sec/step~0.75 | keep=1.00 | K=4 | llama: tf=8.4658 first=7.5126 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.3006 first=6.7383 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  470/500 | grad_norm=0.38 | sec/step~0.81 | keep=1.00 | K=4 | llama: tf=8.6542 first=7.5306 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.5282 first=6.8535 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  480/500 | grad_norm=0.82 | sec/step~0.79 | keep=1.00 | K=4 | llama: tf=9.3705 first=7.2101 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=9.8519 first=6.6990 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1974e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  490/500 | grad_norm=0.44 | sec/step~0.71 | keep=1.00 | K=4 | llama: tf=8.5890 first=7.6636 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=8.0724 first=7.1864 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1974e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  500/500 | grad_norm=0.19 | sec/step~0.66 | keep=1.00 | K=4 | llama: tf=8.4556 first=6.8897 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.1974e-14 | qwen: tf=8.3432 first=6.5101 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
Epoch 6/6
  step  10/500 | grad_norm=0.99 | sec/step~0.57 | keep=1.00 | K=4 | llama: tf=9.0661 first=7.1577 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.1974e-14 | qwen: tf=9.0044 first=6.4415 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  20/500 | grad_norm=0.26 | sec/step~0.58 | keep=1.00 | K=4 | llama: tf=9.0479 first=7.2108 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.1974e-14 | qwen: tf=8.7879 first=6.9312 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  30/500 | grad_norm=0.52 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.5874 first=7.4709 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.1974e-14 | qwen: tf=7.8225 first=7.3371 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  40/500 | grad_norm=0.49 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.5196 first=6.8263 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=8.4333 first=6.2125 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1974e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  50/500 | grad_norm=0.23 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.4847 first=7.4696 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.1462 first=7.6249 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  60/500 | grad_norm=0.80 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.6760 first=7.2151 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.4728 first=6.5118 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  70/500 | grad_norm=0.27 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.8314 first=7.3579 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.8297 first=7.1011 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  80/500 | grad_norm=1.02 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.5070 first=6.7182 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.6843e-14 | qwen: tf=8.3356 first=6.5541 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  90/500 | grad_norm=0.52 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.4649 first=6.8468 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.6843e-14 | qwen: tf=8.0676 first=6.5123 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  100/500 | grad_norm=0.30 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=9.1373 first=6.8843 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.1974e-14 | qwen: tf=9.1186 first=6.5001 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1974e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  110/500 | grad_norm=0.67 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=7.9322 first=6.9826 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.1974e-14 | qwen: tf=7.6613 first=7.2095 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1974e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  120/500 | grad_norm=0.58 | sec/step~0.61 | keep=1.00 | K=4 | llama: tf=8.5512 first=6.6858 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=8.2212 first=5.7981 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  130/500 | grad_norm=0.29 | sec/step~0.81 | keep=1.00 | K=4 | llama: tf=8.2002 first=8.3976 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=6.4196 first=7.3730 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  140/500 | grad_norm=0.66 | sec/step~0.80 | keep=1.00 | K=4 | llama: tf=9.1556 first=7.8966 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.1866 first=7.2418 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  150/500 | grad_norm=0.57 | sec/step~0.76 | keep=1.00 | K=4 | llama: tf=8.4464 first=7.2588 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.5251 first=7.3374 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  160/500 | grad_norm=0.71 | sec/step~0.71 | keep=1.00 | K=4 | llama: tf=8.4045 first=7.0216 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.6843e-14 | qwen: tf=7.7075 first=6.9888 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  170/500 | grad_norm=0.60 | sec/step~0.63 | keep=1.00 | K=4 | llama: tf=9.2187 first=7.1529 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.6843e-14 | qwen: tf=8.9397 first=7.1624 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  180/500 | grad_norm=0.42 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=9.4080 first=7.5096 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.1974e-14 | qwen: tf=9.5032 first=7.4207 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  190/500 | grad_norm=0.74 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.6049 first=7.4024 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.1974e-14 | qwen: tf=8.0394 first=6.7533 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  200/500 | grad_norm=0.44 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.3418 first=6.7365 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=8.6585 first=6.6529 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  210/500 | grad_norm=0.19 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.5351 first=7.0157 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.5011 first=6.2776 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1974e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  220/500 | grad_norm=0.73 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.7825 first=7.9929 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.3087 first=7.6841 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1974e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  230/500 | grad_norm=0.48 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=9.3392 first=7.1380 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.7043 first=6.7225 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  240/500 | grad_norm=0.62 | sec/step~0.53 | keep=1.00 | K=4 | llama: tf=8.6308 first=7.3263 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.6843e-14 | qwen: tf=8.5579 first=7.2010 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  250/500 | grad_norm=0.63 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=9.0169 first=8.2974 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.6843e-14 | qwen: tf=7.7526 first=7.6913 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  260/500 | grad_norm=0.41 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=7.8201 first=7.3977 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=6.6062 first=6.2036 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  270/500 | grad_norm=0.79 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=7.9927 first=7.6357 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=7.4111 first=7.1979 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  280/500 | grad_norm=0.31 | sec/step~0.59 | keep=1.00 | K=4 | llama: tf=9.2635 first=7.7283 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=9.3480 first=7.5807 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  290/500 | grad_norm=0.16 | sec/step~0.64 | keep=1.00 | K=4 | llama: tf=9.6410 first=7.7888 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=9.1954 first=7.3820 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  300/500 | grad_norm=0.66 | sec/step~0.64 | keep=1.00 | K=4 | llama: tf=8.7584 first=8.2337 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=7.9750 first=8.4182 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  310/500 | grad_norm=0.34 | sec/step~0.67 | keep=1.00 | K=4 | llama: tf=8.5826 first=7.4397 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.1974e-14 | qwen: tf=8.9755 first=7.5773 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  320/500 | grad_norm=1.07 | sec/step~0.63 | keep=1.00 | K=4 | llama: tf=9.0718 first=7.0426 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.1974e-14 | qwen: tf=8.7713 first=6.5836 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  330/500 | grad_norm=0.99 | sec/step~0.60 | keep=1.00 | K=4 | llama: tf=8.7210 first=7.6548 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.1974e-14 | qwen: tf=7.7470 first=6.5206 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  340/500 | grad_norm=0.29 | sec/step~0.60 | keep=1.00 | K=4 | llama: tf=8.2024 first=7.7047 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=7.7642 first=7.2392 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  350/500 | grad_norm=0.51 | sec/step~0.59 | keep=1.00 | K=4 | llama: tf=8.5850 first=6.0423 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.3699 first=5.6045 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=5.6843e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  360/500 | grad_norm=0.60 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.1431 first=6.6181 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=6.6565 first=5.6206 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1974e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  370/500 | grad_norm=0.17 | sec/step~0.58 | keep=1.00 | K=4 | llama: tf=8.2268 first=6.9853 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=7.4272 first=6.3068 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  380/500 | grad_norm=1.16 | sec/step~0.71 | keep=1.00 | K=4 | llama: tf=9.1504 first=7.1527 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=9.6896 first=7.0391 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  390/500 | grad_norm=0.28 | sec/step~0.85 | keep=1.00 | K=4 | llama: tf=9.5319 first=8.1104 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=5.6843e-14 | qwen: tf=9.6557 first=7.1587 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  400/500 | grad_norm=1.66 | sec/step~0.85 | keep=1.00 | K=4 | llama: tf=8.7681 first=7.6805 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.8674 first=7.5826 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  410/500 | grad_norm=1.20 | sec/step~0.85 | keep=1.00 | K=4 | llama: tf=8.2673 first=7.5411 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=7.1087 first=6.3860 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  420/500 | grad_norm=0.47 | sec/step~0.64 | keep=1.00 | K=4 | llama: tf=8.4153 first=7.8843 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=7.8192 first=7.5658 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  430/500 | grad_norm=1.25 | sec/step~0.56 | keep=1.00 | K=4 | llama: tf=9.2047 first=7.9829 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=9.7402 first=7.7544 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  440/500 | grad_norm=0.69 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.8731 first=6.7407 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=9.2659 first=6.8295 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1974e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  450/500 | grad_norm=0.43 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.6248 first=7.8763 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=7.6720 first=6.6250 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1974e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  460/500 | grad_norm=0.69 | sec/step~0.51 | keep=1.00 | K=4 | llama: tf=8.0126 first=7.2282 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=7.6589 first=6.4112 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1974e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  470/500 | grad_norm=0.29 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.2316 first=7.0770 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=1.4211e-14 | qwen: tf=8.0256 first=6.3902 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.1974e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  480/500 | grad_norm=1.24 | sec/step~0.54 | keep=1.00 | K=4 | llama: tf=8.6135 first=7.7377 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.0733 first=7.3491 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  490/500 | grad_norm=1.05 | sec/step~0.50 | keep=1.00 | K=4 | llama: tf=8.9014 first=7.4148 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=3.5527e-15 | qwen: tf=8.7687 first=6.7692 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=1.4211e-14 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
  step  500/500 | grad_norm=0.92 | sec/step~0.52 | keep=1.00 | K=4 | llama: tf=8.0525 first=7.2242 kCE=0.0000 KD=0.0000 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=7.4124 first=7.2458 kCE=0.0000 KD=0.0000 man=0.0002 | scale_pen(qwen)=3.5527e-15 | K=4 tau=1.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~1.0003 rms_cal~0.0136 embed_rms~0.01364]
[checkpoint] Freed 1.6KB before save.
[checkpoint] Saved latest: encoder.pt, adapter_llama.pt, adapter_qwen.pt, state.pt, config.json
[checkpoint] Freed 0.0B after save (non-canonical).
✅ Saved latest checkpoint to runs/scoped_softprompt_20250921_010132/ckpt/stageB
📝 Saved Prefix-Tuning adapters for Llama
📝 Saved Prefix-Tuning adapters for Qwen
📝 Saved training_stats.json: {'llama': {'rms_mean_raw': 1.0002167213360469, 'rms_mean_cal': 0.010569901755700509, 'embed_rms': 0.01057521253824234, 'count': 3000}, 'qwen': {'rms_mean_raw': 1.0002968802452088, 'rms_mean_cal': 0.013638631736238797, 'embed_rms': 0.013643525540828705, 'count': 3000}}

=== Stage B -> refresh merged weights ===


=== Stage B -> restore LoRA adapters ===


=== Stage C: Eval ===

/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Auto-detected device: cuda
Loaded training_stats.json: runs/scoped_softprompt_20250921_010132/ckpt/stageB/training_stats.json
Building encoder and computing Z...

[Standard Evaluation Mode - both models loaded]
(Use --sequential_eval to enable per-model encoder text auto-alignment.)
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2007.32it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:08,  2.73s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:04<00:04,  2.12s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.82s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.76s/it]
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[runs/scoped_softprompt_20250921_010132/ckpt/merged_llama] hf_device_map: {'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 1, 'model.layers.17': 1, 'model.layers.18': 1, 'model.layers.19': 1, 'model.layers.20': 1, 'model.layers.21': 1, 'model.layers.22': 1, 'model.layers.23': 1, 'model.layers.24': 1, 'model.layers.25': 1, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 3584.11it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:07,  2.47s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:02,  1.44s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.82s/it]
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[runs/scoped_softprompt_20250921_010132/ckpt/merged_qwen] hf_device_map: {'model.embed_tokens': 2, 'model.layers.0': 2, 'model.layers.1': 2, 'model.layers.2': 2, 'model.layers.3': 2, 'model.layers.4': 2, 'model.layers.5': 2, 'model.layers.6': 2, 'model.layers.7': 2, 'model.layers.8': 2, 'model.layers.9': 2, 'model.layers.10': 2, 'model.layers.11': 2, 'model.layers.12': 2, 'model.layers.13': 2, 'model.layers.14': 2, 'model.layers.15': 3, 'model.layers.16': 3, 'model.layers.17': 3, 'model.layers.18': 3, 'model.layers.19': 3, 'model.layers.20': 3, 'model.layers.21': 3, 'model.layers.22': 3, 'model.layers.23': 3, 'model.layers.24': 3, 'model.layers.25': 3, 'model.layers.26': 3, 'model.layers.27': 3, 'model.norm': 3, 'model.rotary_emb': 3, 'lm_head': 3}
✓ Loaded Prefix-Tuning adapters for llama
✓ Loaded Prefix-Tuning adapters for qwen
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)

==== LatentWire Evaluation ====
Dataset: squad
Samples: 1000  |  Max new tokens: 16
Device: cuda  |  Dtype: bfloat16
Avg prompt tokens (Llama): 244.6 | (Qwen): 231.0 | Latent length M: 64
Compression ratio (Llama): 3.8x | (Qwen): 3.6x
Approx interlingua payload per example: 13312000 bytes (6-bit selected); fp16 reference: 32768000 bytes; fp32 reference: 65536000 bytes
latent/text bytes (one-copy, fp16): n/a

— Baseline: Text prompting
Llama  EM: 0.000  F1: 0.006  |  NLL/token (gold): 9.03055443287953
Qwen   EM: 0.000   F1: 0.000   |  NLL/token (gold): 8.133645405302298
Wall clock: 181.33s

— Latent prompting (shared interlingua)
Llama  EM: 0.000  F1: 0.000  |  NLL/token (gold): 8.878243170186316
       First-token acc: top1=0.039  top5=0.045
Qwen   EM: 0.000   F1: 0.015  |  NLL/token (gold): 8.066115317576333
       First-token acc: top1=0.000  top5=0.000
Wall clock: 156.13s

— Token-budget baseline (mode: content_only)
Llama  EM: 0.000  F1: 0.000
Qwen   EM: 0.000   F1: 0.000
Wall clock: 158.86s

— 2-LLM joint (rescored pick on latent runs)
Joint  EM: 0.000  F1: 0.015
Inter-model agreement (normalized): 0.000
Oracle upper bound:  EM 0.000  F1 0.015

==== METRICS_JSON ====
{
  "samples": 1000,
  "max_new_tokens": 16,
  "latent_len": 64,
  "device": "cuda",
  "dtype": "torch.bfloat16",
  "avg_prompt_tokens": {
    "llama": 244.558,
    "qwen": 231.026
  },
  "compression": {
    "llama": 3.82121875,
    "qwen": 3.60978125
  },
  "payload_bytes": 13312000,
  "payload_bytes_detail": {
    "fp32": 65536000,
    "fp16": 32768000,
    "selected": 13312000
  },
  "wire": {
    "prompt_chars": {
      "llama": 1243778,
      "qwen": 1091778
    },
    "prompt_count": 1000,
    "latent_shape": [
      1000,
      64,
      256
    ],
    "latent_bytes": {
      "fp32": 65536000,
      "fp16": 32768000,
      "quantized": 12288000,
      "quantized_with_scales": 13312000
    },
    "group_size": 32,
    "scale_bits": 16,
    "selected_bits": 6,
    "selected_latent_bytes": 13312000,
    "base_latent_bytes": 65536,
    "wire_ratio": {}
  },
  "text": {
    "llama": {
      "em": 0.0,
      "f1": 0.005623160127337889,
      "nll_token": 9.03055443287953
    },
    "qwen": {
      "em": 0.0,
      "f1": 0.00039999999520000005,
      "nll_token": 8.133645405302298
    },
    "wall_clock_sec": 181.3305103778839
  },
  "latent": {
    "llama": {
      "em": 0.0,
      "f1": 0.0,
      "nll": 8.878243170186316,
      "first_token_top1": 0.039,
      "first_token_top5": 0.045,
      "nll_token": 8.878243170186316
    },
    "qwen": {
      "em": 0.0,
      "f1": 0.014650534351621216,
      "nll": 8.066115317576333,
      "first_token_top1": 0.0,
      "first_token_top5": 0.0,
      "nll_token": 8.066115317576333
    },
    "wall_clock_sec": 156.12888741493225
  },
  "token_budget": {
    "mode": "content_only",
    "k": 64,
    "llama": {
      "em": 0.0,
      "f1": 0.0
    },
    "qwen": {
      "em": 0.0,
      "f1": 0.0
    },
    "wall_clock_sec": 158.86180591583252
  },
  "joint": {
    "em": 0.0,
    "f1": 0.014650534351621216,
    "agreement": 0.0,
    "oracle": {
      "em": 0.0,
      "f1": 0.014650534351621216
    }
  },
  "debug": {
    "llama": {},
    "qwen": {},
    "settings": {
      "latent_anchor_mode": "chat",
      "latent_anchor_text": "Answer: ",
      "prefix_gain": 1.0,
      "calibration_mode": "embed_rms",
      "append_bos_after_prefix": "yes",
      "decode": {
        "min_new_tokens": 3,
        "eos_ban_steps": 6,
        "first_token_top_p": 1.0,
        "first_token_temperature": 0.0
      }
    }
  },
  "oracle": {
    "em": 0.0,
    "f1": 0.014650534351621216
  },
  "dataset": "squad"
}
