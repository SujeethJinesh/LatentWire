{
  "timestamp": "2026-01-20T21:05:21.175132",
  "status": "in_progress",
  "zeroshot_llama": [
    {
      "dataset": "arc_easy",
      "dataset_name": "ARC-Easy",
      "model_name": "llama",
      "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "seed": 42,
      "accuracy": 87.87878787878788,
      "correct": 2088,
      "total": 2376,
      "num_classes": 4,
      "predictions_sample": [
        "A",
        "B",
        "D",
        "D",
        "C",
        "C",
        "B",
        "C",
        "C",
        "A",
        "A",
        "B",
        "B",
        "B",
        "B",
        "B",
        "B",
        "D",
        "B",
        "D",
        "D",
        "D",
        "A",
        "C",
        "B",
        "C",
        "B",
        "B",
        "A",
        "B",
        "A",
        "C",
        "A",
        "A",
        "C",
        "A",
        "D",
        "C",
        "C",
        "B",
        "A",
        "B",
        "A",
        "D",
        "B",
        "D",
        "D",
        "C",
        "D",
        "D"
      ]
    },
    {
      "dataset": "arc_easy",
      "dataset_name": "ARC-Easy",
      "model_name": "llama",
      "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "seed": 123,
      "accuracy": 87.87878787878788,
      "correct": 2088,
      "total": 2376,
      "num_classes": 4,
      "predictions_sample": [
        "A",
        "B",
        "D",
        "D",
        "C",
        "C",
        "B",
        "C",
        "C",
        "A",
        "A",
        "B",
        "B",
        "B",
        "B",
        "B",
        "B",
        "D",
        "B",
        "D",
        "D",
        "D",
        "A",
        "C",
        "B",
        "C",
        "B",
        "B",
        "A",
        "B",
        "A",
        "C",
        "A",
        "A",
        "C",
        "A",
        "D",
        "C",
        "C",
        "B",
        "A",
        "B",
        "A",
        "D",
        "B",
        "D",
        "D",
        "C",
        "D",
        "D"
      ]
    },
    {
      "dataset": "arc_easy",
      "dataset_name": "ARC-Easy",
      "model_name": "llama",
      "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "seed": 456,
      "accuracy": 87.87878787878788,
      "correct": 2088,
      "total": 2376,
      "num_classes": 4,
      "predictions_sample": [
        "A",
        "B",
        "D",
        "D",
        "C",
        "C",
        "B",
        "C",
        "C",
        "A",
        "A",
        "B",
        "B",
        "B",
        "B",
        "B",
        "B",
        "D",
        "B",
        "D",
        "D",
        "D",
        "A",
        "C",
        "B",
        "C",
        "B",
        "B",
        "A",
        "B",
        "A",
        "C",
        "A",
        "A",
        "C",
        "A",
        "D",
        "C",
        "C",
        "B",
        "A",
        "B",
        "A",
        "D",
        "B",
        "D",
        "D",
        "C",
        "D",
        "D"
      ]
    },
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "model_name": "llama",
      "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "seed": 42,
      "accuracy": 55.248618784530386,
      "correct": 700,
      "total": 1267,
      "num_classes": 2
    },
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "model_name": "llama",
      "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "seed": 123,
      "accuracy": 55.248618784530386,
      "correct": 700,
      "total": 1267,
      "num_classes": 2
    },
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "model_name": "llama",
      "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "seed": 456,
      "accuracy": 55.248618784530386,
      "correct": 700,
      "total": 1267,
      "num_classes": 2
    },
    {
      "dataset": "hellaswag",
      "dataset_name": "HellaSwag",
      "model_name": "llama",
      "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "seed": 42,
      "accuracy": 59.62955586536547,
      "correct": 5988,
      "total": 10042,
      "num_classes": 4
    },
    {
      "dataset": "hellaswag",
      "dataset_name": "HellaSwag",
      "model_name": "llama",
      "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "seed": 123,
      "accuracy": 59.62955586536547,
      "correct": 5988,
      "total": 10042,
      "num_classes": 4
    }
  ],
  "zeroshot_mistral": [
    {
      "dataset": "arc_easy",
      "dataset_name": "ARC-Easy",
      "model_name": "mistral",
      "model_id": "mistralai/Mistral-7B-Instruct-v0.3",
      "seed": 42,
      "accuracy": 84.04882154882155,
      "correct": 1997,
      "total": 2376,
      "num_classes": 4,
      "predictions_sample": [
        "A",
        "B",
        "D",
        "D",
        "A",
        "C",
        "B",
        "C",
        "C",
        "A",
        "B",
        "B",
        "D",
        "B",
        "B",
        "B",
        "A",
        "D",
        "B",
        "D",
        "A",
        "D",
        "D",
        "D",
        "B",
        "C",
        "D",
        "B",
        "A",
        "B",
        "A",
        "C",
        "A",
        "A",
        "A",
        "A",
        "D",
        "C",
        "C",
        "B",
        "A",
        "B",
        "A",
        "D",
        "A",
        "D",
        "D",
        "C",
        "D",
        "D"
      ]
    },
    {
      "dataset": "arc_easy",
      "dataset_name": "ARC-Easy",
      "model_name": "mistral",
      "model_id": "mistralai/Mistral-7B-Instruct-v0.3",
      "seed": 123,
      "accuracy": 84.04882154882155,
      "correct": 1997,
      "total": 2376,
      "num_classes": 4,
      "predictions_sample": [
        "A",
        "B",
        "D",
        "D",
        "A",
        "C",
        "B",
        "C",
        "C",
        "A",
        "B",
        "B",
        "D",
        "B",
        "B",
        "B",
        "A",
        "D",
        "B",
        "D",
        "A",
        "D",
        "D",
        "D",
        "B",
        "C",
        "D",
        "B",
        "A",
        "B",
        "A",
        "C",
        "A",
        "A",
        "A",
        "A",
        "D",
        "C",
        "C",
        "B",
        "A",
        "B",
        "A",
        "D",
        "A",
        "D",
        "D",
        "C",
        "D",
        "D"
      ]
    },
    {
      "dataset": "arc_easy",
      "dataset_name": "ARC-Easy",
      "model_name": "mistral",
      "model_id": "mistralai/Mistral-7B-Instruct-v0.3",
      "seed": 456,
      "accuracy": 84.04882154882155,
      "correct": 1997,
      "total": 2376,
      "num_classes": 4
    },
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "model_name": "mistral",
      "model_id": "mistralai/Mistral-7B-Instruct-v0.3",
      "seed": 42,
      "accuracy": 54.064719810576165,
      "correct": 685,
      "total": 1267,
      "num_classes": 2
    },
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "model_name": "mistral",
      "model_id": "mistralai/Mistral-7B-Instruct-v0.3",
      "seed": 123,
      "accuracy": 54.064719810576165,
      "correct": 685,
      "total": 1267,
      "num_classes": 2
    },
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "model_name": "mistral",
      "model_id": "mistralai/Mistral-7B-Instruct-v0.3",
      "seed": 456,
      "accuracy": 54.064719810576165,
      "correct": 685,
      "total": 1267,
      "num_classes": 2
    },
    {
      "dataset": "hellaswag",
      "dataset_name": "HellaSwag",
      "model_name": "mistral",
      "model_id": "mistralai/Mistral-7B-Instruct-v0.3",
      "seed": 42,
      "accuracy": 57.070304720175265,
      "correct": 5731,
      "total": 10042,
      "num_classes": 4
    }
  ],
  "text_relay": [],
  "linear_probe": [],
  "prompt_tuning": [],
  "same_model_bridge": [],
  "bridge_8": [],
  "bridge_24": []
}