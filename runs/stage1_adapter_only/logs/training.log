Starting training at Sat Oct 11 16:27:27 PDT 2025

/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(

Configuration:
  model_id: meta-llama/Meta-Llama-3.1-8B-Instruct
  compress_dim: 1024
  compress_method: pca
  input_dim: 4096
  pca_samples: 10000
  adapter_hidden_mult: 4
  adapter_dropout: 0.1
  adapter_lr: 0.0005
  samples: 10000
  epochs: 3
  batch_size: 64
  eval_every: 1
  eval_samples: 500
  save_dir: runs/stage1_adapter_only
  diagnostic_log: runs/stage1_adapter_only/logs/diagnostics.jsonl
============================================================
STAGE 1 PHASE 1: PURE RECONSTRUCTION TRAINING
Model: meta-llama/Meta-Llama-3.1-8B-Instruct
Compression: 4096 → 1024 (4.0× compression)
Training samples: 10000
PCA samples: 10000
============================================================

GPU Information:
  CUDA available: Yes
  GPU count: 4
  GPU 0: NVIDIA H100 80GB HBM3 (85.0 GB)
  GPU 1: NVIDIA H100 80GB HBM3 (85.0 GB)
  GPU 2: NVIDIA H100 80GB HBM3 (85.0 GB)
  GPU 3: NVIDIA H100 80GB HBM3 (85.0 GB)

Logging diagnostics to: runs/stage1_adapter_only/logs/diagnostics.jsonl

Loading model...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 3308.46it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.42s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.37s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.18s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.08it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.06s/it]

Creating adapter...
Adapter parameters: 50,366,465

Loading dataset...
Training samples: 10000
Validation samples: 500

Fitting PCA compressor on 10,000 samples...

GPU memory status:
  GPU 0: 80.9 GB free / 85.0 GB total (allocated: 3.3 GB)
  GPU 1: 80.1 GB free / 85.0 GB total (allocated: 4.4 GB)
  GPU 2: 80.1 GB free / 85.0 GB total (allocated: 4.4 GB)
  GPU 3: 80.3 GB free / 85.0 GB total (allocated: 4.1 GB)

Using GPU 0 for PCA (80.9 GB free)
Collecting embeddings...
Collecting embeddings:   0%|          | 0/157 [00:00<?, ?it/s]Collecting embeddings:   1%|          | 1/157 [00:00<00:17,  8.84it/s]Collecting embeddings:   3%|▎         | 4/157 [00:00<00:08, 18.04it/s]Collecting embeddings:   4%|▍         | 6/157 [00:00<00:08, 17.81it/s]Collecting embeddings:   6%|▋         | 10/157 [00:00<00:06, 22.09it/s]Collecting embeddings:   8%|▊         | 13/157 [00:00<00:07, 18.74it/s]Collecting embeddings:  10%|▉         | 15/157 [00:00<00:07, 18.59it/s]Collecting embeddings:  11%|█         | 17/157 [00:00<00:08, 16.31it/s]Collecting embeddings:  14%|█▍        | 22/157 [00:01<00:05, 24.34it/s]Collecting embeddings:  18%|█▊        | 28/157 [00:01<00:03, 32.44it/s]Collecting embeddings:  22%|██▏       | 34/157 [00:01<00:03, 38.27it/s]Collecting embeddings:  25%|██▌       | 40/157 [00:01<00:02, 42.31it/s]Collecting embeddings:  29%|██▉       | 46/157 [00:01<00:02, 44.85it/s]Collecting embeddings:  32%|███▏      | 51/157 [00:01<00:02, 40.48it/s]Collecting embeddings:  36%|███▌      | 56/157 [00:01<00:02, 42.30it/s]Collecting embeddings:  39%|███▉      | 61/157 [00:02<00:02, 33.25it/s]Collecting embeddings:  42%|████▏     | 66/157 [00:02<00:03, 28.80it/s]Collecting embeddings:  45%|████▍     | 70/157 [00:02<00:03, 24.79it/s]Collecting embeddings:  48%|████▊     | 76/157 [00:02<00:02, 30.36it/s]Collecting embeddings:  52%|█████▏    | 82/157 [00:02<00:02, 35.17it/s]Collecting embeddings:  56%|█████▌    | 88/157 [00:02<00:01, 39.22it/s]Collecting embeddings:  60%|█████▉    | 94/157 [00:02<00:01, 42.51it/s]Collecting embeddings:  63%|██████▎   | 99/157 [00:03<00:01, 44.12it/s]Collecting embeddings:  67%|██████▋   | 105/157 [00:03<00:01, 46.00it/s]Collecting embeddings:  71%|███████   | 111/157 [00:03<00:00, 47.75it/s]Collecting embeddings:  75%|███████▍  | 117/157 [00:03<00:00, 48.83it/s]Collecting embeddings:  78%|███████▊  | 122/157 [00:03<00:00, 49.08it/s]Collecting embeddings:  81%|████████  | 127/157 [00:03<00:00, 45.44it/s]Collecting embeddings:  84%|████████▍ | 132/157 [00:03<00:00, 29.48it/s]Collecting embeddings:  87%|████████▋ | 136/157 [00:04<00:00, 21.12it/s]Collecting embeddings:  90%|█████████ | 142/157 [00:04<00:00, 26.46it/s]Collecting embeddings:  94%|█████████▍| 148/157 [00:04<00:00, 31.63it/s]Collecting embeddings:  98%|█████████▊| 154/157 [00:04<00:00, 36.09it/s]Collecting embeddings: 100%|██████████| 157/157 [00:04<00:00, 33.46it/s]
Traceback (most recent call last):
  File "/projects/m000066/sujinesh/LatentWire/train_adapter_only_phase1.py", line 627, in main
    best_f1 = train_adapter_phase1(args)
  File "/projects/m000066/sujinesh/LatentWire/train_adapter_only_phase1.py", line 298, in train_adapter_phase1
    compressor.fit(all_embeddings, device=pca_device)
  File "/projects/m000066/sujinesh/LatentWire/train_adapter_only_phase1.py", line 67, in fit
    U, S, V = torch.svd_lowrank(centered, q=self.output_dim, niter=4)
  File "/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/torch/_lowrank.py", line 146, in svd_lowrank
    return _svd_lowrank(A, q=q, niter=niter, M=M)
  File "/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/torch/_lowrank.py", line 169, in _svd_lowrank
    Q = get_approximate_basis(A, q, niter=niter, M=M)
  File "/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/torch/_lowrank.py", line 72, in get_approximate_basis
    Q = torch.linalg.qr(X).Q
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.59 GiB. GPU 0 has a total capacity of 79.19 GiB of which 2.72 GiB is free. Including non-PyTorch memory, this process has 76.46 GiB memory in use. Of the allocated memory 75.71 GiB is allocated by PyTorch, and 87.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Concatenating 1,727,893 embedding vectors...
  Fitting PCA on GPU with 1,727,893 embedding vectors...
  Computing top 1024 components via randomized SVD...

============================================================
ERROR: Training failed!
============================================================
Error: CUDA out of memory. Tried to allocate 6.59 GiB. GPU 0 has a total capacity of 79.19 GiB of which 2.72 GiB is free. Including non-PyTorch memory, this process has 76.46 GiB memory in use. Of the allocated memory 75.71 GiB is allocated by PyTorch, and 87.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
