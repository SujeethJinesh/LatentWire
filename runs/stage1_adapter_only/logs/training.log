Starting training at Sat Oct 11 11:22:16 PDT 2025

/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(

Configuration:
  model_id: meta-llama/Meta-Llama-3.1-8B-Instruct
  compress_dim: 512
  compress_method: pca
  input_dim: 4096
  adapter_hidden_mult: 4
  adapter_dropout: 0.1
  adapter_lr: 0.0005
  samples: 10000
  epochs: 3
  batch_size: 96
  recon_weight: 1.0
  ce_weight: 1.0
  eval_every: 1
  eval_samples: 500
  save_dir: runs/stage1_adapter_only
  diagnostic_log: runs/stage1_adapter_only/logs/diagnostics.jsonl
============================================================
ADAPTER-ONLY TRAINING
Model: meta-llama/Meta-Llama-3.1-8B-Instruct
Compression: 4096 → 512
Samples: 10000
============================================================

GPU Information:
  CUDA available: Yes
  Number of GPUs: 4
  GPU 0: NVIDIA H100 80GB HBM3 (85.0 GB)
  GPU 1: NVIDIA H100 80GB HBM3 (85.0 GB)
  GPU 2: NVIDIA H100 80GB HBM3 (85.0 GB)
  GPU 3: NVIDIA H100 80GB HBM3 (85.0 GB)
Logging diagnostics to: runs/stage1_adapter_only/logs/diagnostics.jsonl
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 4089.01it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.03s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.20s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.08s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.33it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.13it/s]

Adapter params: 19,952,641

Fitting compressor...
Collecting embeddings:   0%|          | 0/100 [00:00<?, ?it/s]Collecting embeddings: 100%|██████████| 100/100 [00:00<00:00, 1107.80it/s]
Compressor fitted on 17408 embedding vectors

Training adapter...
Epoch 1/3:   0%|          | 0/104 [00:00<?, ?it/s]Epoch 1/3:   0%|          | 0/104 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/projects/m000066/sujinesh/LatentWire/train_adapter_only.py", line 522, in main
    train_adapter_only(args)
  File "/projects/m000066/sujinesh/LatentWire/train_adapter_only.py", line 274, in train_adapter_only
    outputs = model(
  File "/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/accelerate/hooks.py", line 175, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 1229, in forward
    loss = loss_fct(shift_logits, shift_labels)
  File "/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 1188, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/torch/nn/functional.py", line 3104, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: CUDA error: unspecified launch failure
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


============================================================
ERROR: Training failed!
============================================================
Error: CUDA error: unspecified launch failure
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

