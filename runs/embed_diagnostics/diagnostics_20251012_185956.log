Training quick checkpoint with real data...
  Epochs: 1
  Samples: 1000
  Batch size: 8
  Latent: M=32, d_z=256

/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[Optimization] Enabled FlashAttention-2 and memory-efficient kernels
[Optimization] Enabled TF32 for matmul and cuDNN
Loading dataset subset...
Loading SQuAD subset...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 3348.75it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.27s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.05s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.06s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.20it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.07it/s]
[meta-llama/Meta-Llama-3.1-8B-Instruct] hf_device_map: {'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 1, 'model.layers.6': 1, 'model.layers.7': 1, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 1, 'model.layers.15': 2, 'model.layers.16': 2, 'model.layers.17': 2, 'model.layers.18': 2, 'model.layers.19': 2, 'model.layers.20': 2, 'model.layers.21': 2, 'model.layers.22': 2, 'model.layers.23': 2, 'model.layers.24': 2, 'model.layers.25': 3, 'model.layers.26': 3, 'model.layers.27': 3, 'model.layers.28': 3, 'model.layers.29': 3, 'model.layers.30': 3, 'model.layers.31': 3, 'model.norm': 3, 'model.rotary_emb': 3, 'lm_head': 3}
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2001.58it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:20,  6.84s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:14<00:14,  7.17s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:21<00:07,  7.13s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:27<00:00,  6.67s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:27<00:00,  6.82s/it]
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
[Qwen/Qwen2.5-7B-Instruct] hf_device_map: {'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 1, 'model.layers.5': 1, 'model.layers.6': 1, 'model.layers.7': 1, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 2, 'model.layers.14': 2, 'model.layers.15': 2, 'model.layers.16': 2, 'model.layers.17': 2, 'model.layers.18': 2, 'model.layers.19': 2, 'model.layers.20': 2, 'model.layers.21': 2, 'model.layers.22': 3, 'model.layers.23': 3, 'model.layers.24': 3, 'model.layers.25': 3, 'model.layers.26': 3, 'model.layers.27': 3, 'model.norm': 3, 'model.rotary_emb': 3, 'lm_head': 3}
Llama hidden size: 4096, Qwen hidden size: 3584
[DeviceMap] Llama: {'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 1, 'model.layers.6': 1, 'model.layers.7': 1, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 1, 'model.layers.15': 2, 'model.layers.16': 2, 'model.layers.17': 2, 'model.layers.18': 2, 'model.layers.19': 2, 'model.layers.20': 2, 'model.layers.21': 2, 'model.layers.22': 2, 'model.layers.23': 2, 'model.layers.24': 2, 'model.layers.25': 3, 'model.layers.26': 3, 'model.layers.27': 3, 'model.layers.28': 3, 'model.layers.29': 3, 'model.layers.30': 3, 'model.layers.31': 3, 'model.norm': 3, 'model.rotary_emb': 3, 'lm_head': 3}
[DeviceMap] Qwen : {'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 1, 'model.layers.5': 1, 'model.layers.6': 1, 'model.layers.7': 1, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 2, 'model.layers.14': 2, 'model.layers.15': 2, 'model.layers.16': 2, 'model.layers.17': 2, 'model.layers.18': 2, 'model.layers.19': 2, 'model.layers.20': 2, 'model.layers.21': 2, 'model.layers.22': 3, 'model.layers.23': 3, 'model.layers.24': 3, 'model.layers.25': 3, 'model.layers.26': 3, 'model.layers.27': 3, 'model.norm': 3, 'model.rotary_emb': 3, 'lm_head': 3}
[After Model Loading] [GPU Memory] GPU0:6.2GB(7%), GPU1:8.6GB(10%), GPU2:8.6GB(10%), GPU3:8.0GB(9%) | Total: 31.4GB allocated, 31.5GB reserved, 308.6GB free, Peak: 31.4GB
[WARN] t=0 alignment failed: t=0 mismatch: got 12366, expected 60704
[INFO] llama anchor tokens: 3
[WARN] t=0 alignment failed: t=0 mismatch: got 12095, expected 59604
[INFO] qwen anchor tokens: 3
[Optimizer] Gathering latent adapter parameters (direct wrappers fallback)...
[Optimizer]   Meta-Llama-3.1-8B-Instruct: skipped (use_latent_adapters=False)
[Optimizer]   Qwen2.5-7B-Instruct: skipped (use_latent_adapters=False)
[Optimizer] Latent adapter summary: 0 params in 0 tensors
[Optimizer] No latent adapters enabled (expected)
[Optimization] Using fused AdamW optimizer
[Optimizer] Created 3 parameter groups:
  [1] encoder(90 tensors)
  [2] llama_adapter(20 tensors)
  [3] qwen_adapter(20 tensors)
[INFO] LR scheduler: CosineAnnealingLR (T_max=125, eta_min=2.00e-06)
⚠️  No valid checkpoint found to resume; starting fresh.
Epoch 1/1
[Epoch 1 Start] [GPU Memory] GPU0:6.3GB(14%), GPU1:8.6GB(10%), GPU2:8.6GB(10%), GPU3:8.0GB(9%) | Total: 31.4GB allocated, 37.1GB reserved, 303.0GB free, Peak: 34.5GB
    [Memory after encoder] 31.9GB allocated
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] KD teacher: adapters NOT disabled - KD may be contaminated
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
    [Memory after backward] 31.9GB allocated, peak 68.9GB
    [Memory after optimizer] 32.0GB allocated
  [Step 1] [GPU Memory] GPU0:6.6GB(18%), GPU1:8.6GB(22%), GPU2:8.6GB(22%), GPU3:8.1GB(22%) | Total: 32.0GB allocated, 71.3GB reserved, 268.8GB free, Peak: 68.9GB
    [Memory after encoder] 32.5GB allocated
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
    [Memory after backward] 32.2GB allocated, peak 70.2GB
    [Memory after optimizer] 32.2GB allocated
  [Step 2] [GPU Memory] GPU0:6.6GB(18%), GPU1:8.6GB(23%), GPU2:8.6GB(23%), GPU3:8.1GB(23%) | Total: 32.0GB allocated, 73.8GB reserved, 266.3GB free, Peak: 70.2GB
    [Memory after encoder] 32.5GB allocated
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
    [Memory after backward] 32.2GB allocated, peak 70.9GB
    [Memory after optimizer] 32.2GB allocated
  [Step 3] [GPU Memory] GPU0:6.6GB(20%), GPU1:8.6GB(23%), GPU2:8.6GB(23%), GPU3:8.1GB(25%) | Total: 32.0GB allocated, 77.3GB reserved, 262.8GB free, Peak: 70.9GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 4] [GPU Memory] GPU0:6.6GB(20%), GPU1:8.6GB(23%), GPU2:8.6GB(23%), GPU3:8.1GB(25%) | Total: 32.0GB allocated, 77.4GB reserved, 262.7GB free, Peak: 70.9GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 5] [GPU Memory] GPU0:6.6GB(20%), GPU1:8.6GB(23%), GPU2:8.6GB(23%), GPU3:8.1GB(25%) | Total: 32.0GB allocated, 77.4GB reserved, 262.7GB free, Peak: 70.9GB
  [Batch Size Suggestion after 5 steps] Low peak memory (20.9%), can cautiously increase batch size
    Current: 8, Suggested: 9
    To apply: set BATCH_SIZE_STAGEA/B=9 in run script
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 6] [GPU Memory] GPU0:6.6GB(20%), GPU1:8.6GB(23%), GPU2:8.6GB(23%), GPU3:8.1GB(25%) | Total: 32.0GB allocated, 77.4GB reserved, 262.7GB free, Peak: 70.9GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 7] [GPU Memory] GPU0:6.6GB(20%), GPU1:8.6GB(23%), GPU2:8.6GB(23%), GPU3:8.1GB(25%) | Total: 32.0GB allocated, 77.4GB reserved, 262.7GB free, Peak: 70.9GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 8] [GPU Memory] GPU0:6.6GB(20%), GPU1:8.6GB(23%), GPU2:8.6GB(23%), GPU3:8.1GB(25%) | Total: 32.0GB allocated, 77.4GB reserved, 262.7GB free, Peak: 70.9GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 9] [GPU Memory] GPU0:6.6GB(20%), GPU1:8.6GB(23%), GPU2:8.6GB(23%), GPU3:8.1GB(25%) | Total: 32.0GB allocated, 77.4GB reserved, 262.7GB free, Peak: 70.9GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  step  10/125 | grad_norm=70.83 | sec/step~1.47 | lr=9.85e-05 | keep=1.00 | K=4 | llama(L): tf=10.3660 first=8.9202 kCE=8.6971 KD=6.3909 acc=0.000 align=0.0000 | scale_pen(llama)=9.6065e-12 | qwen(L): tf=13.8518 first=11.5100 kCE=12.9513 KD=19.7849 acc=0.000 align=0.0000 | scale_pen(qwen)=1.2283e-09 | feature_grads[encoder=3.433e+01, adapter_llama=2.008e+01, adapter_qwen=5.861e+01] | K=4 tau=2.00
  [Step 10] [GPU Memory] GPU0:6.6GB(20%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(26%) | Total: 32.0GB allocated, 78.7GB reserved, 261.4GB free, Peak: 71.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 11] [GPU Memory] GPU0:6.6GB(20%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(26%) | Total: 32.0GB allocated, 78.7GB reserved, 261.4GB free, Peak: 71.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 12] [GPU Memory] GPU0:6.6GB(20%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(26%) | Total: 32.0GB allocated, 78.7GB reserved, 261.4GB free, Peak: 71.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 13] [GPU Memory] GPU0:6.6GB(20%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(26%) | Total: 32.0GB allocated, 78.7GB reserved, 261.4GB free, Peak: 71.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 14] [GPU Memory] GPU0:6.6GB(20%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(26%) | Total: 32.0GB allocated, 78.7GB reserved, 261.4GB free, Peak: 71.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 15] [GPU Memory] GPU0:6.6GB(20%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(26%) | Total: 32.0GB allocated, 78.7GB reserved, 261.4GB free, Peak: 71.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 16] [GPU Memory] GPU0:6.6GB(20%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(26%) | Total: 32.0GB allocated, 78.7GB reserved, 261.4GB free, Peak: 71.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 17] [GPU Memory] GPU0:6.6GB(20%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(26%) | Total: 32.0GB allocated, 78.7GB reserved, 261.4GB free, Peak: 71.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 18] [GPU Memory] GPU0:6.6GB(20%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(26%) | Total: 32.0GB allocated, 78.7GB reserved, 261.4GB free, Peak: 71.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 19] [GPU Memory] GPU0:6.6GB(20%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(26%) | Total: 32.0GB allocated, 78.7GB reserved, 261.4GB free, Peak: 71.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  step  20/125 | grad_norm=68.64 | sec/step~1.46 | lr=9.39e-05 | keep=1.00 | K=4 | llama(L): tf=8.8647 first=7.9243 kCE=7.9528 KD=3.7989 acc=0.000 align=0.0000 | scale_pen(llama)=4.9429e-10 | qwen(L): tf=10.9318 first=10.9027 kCE=6.7830 KD=9.0210 acc=0.125 [✓'1'] align=0.0000 | scale_pen(qwen)=1.5289e-09 | feature_grads[encoder=3.182e+01, adapter_llama=7.620e+00, adapter_qwen=6.034e+01] | K=4 tau=2.00
  [Step 20] [GPU Memory] GPU0:6.6GB(20%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(26%) | Total: 32.0GB allocated, 78.7GB reserved, 261.4GB free, Peak: 71.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 21] [GPU Memory] GPU0:6.6GB(20%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(26%) | Total: 32.0GB allocated, 78.7GB reserved, 261.4GB free, Peak: 71.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 22] [GPU Memory] GPU0:6.6GB(20%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(26%) | Total: 32.0GB allocated, 78.7GB reserved, 261.4GB free, Peak: 71.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 23] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 24] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 25] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 26] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 27] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 28] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 29] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  step  30/125 | grad_norm=34.98 | sec/step~1.62 | lr=8.67e-05 | keep=1.00 | K=4 | llama(L): tf=9.2071 first=8.1105 kCE=8.0868 KD=4.1996 acc=0.000 align=0.0000 | scale_pen(llama)=6.0041e-11 | qwen(L): tf=9.3107 first=11.7598 kCE=6.6048 KD=9.9505 acc=0.000 align=0.0000 | scale_pen(qwen)=2.2204e-10 | feature_grads[encoder=1.601e+01, adapter_llama=6.156e+00, adapter_qwen=3.048e+01] | K=4 tau=2.00
  [Step 30] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 31] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 32] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 33] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 34] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 35] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
  🌟 NEW PEAK: first_acc_ema=1.2% (raw_batch=12.5%) at step 35 → saved to runs/embed_diagnostics/checkpoint_best
      Sample predictions (first 5):
        ✗ pred=' ' | gold='199'
        ✗ pred=' ' | gold='3'
        ✓ pred='the' | gold='the'
        ✗ pred=' ' | gold='to'
        ✗ pred=' ' | gold='am'
      Prediction diversity: 2/8 unique tokens
      Top-3 predictions: ' '(7) 'the'(1) 
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 36] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 37] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 38] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 39] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  step  40/125 | grad_norm=166.37 | sec/step~1.40 | lr=7.73e-05 | keep=1.00 | K=4 | llama(L): tf=9.2096 first=8.3603 kCE=7.8085 KD=2.9763 acc=0.000 align=0.0000 | scale_pen(llama)=1.8794e-12 | qwen(L): tf=12.8186 first=13.1205 kCE=6.5505 KD=8.4650 acc=0.000 align=0.0000 | scale_pen(qwen)=1.2028e-10 | feature_grads[encoder=7.619e+01, adapter_llama=7.020e+00, adapter_qwen=1.477e+02] | K=4 tau=2.00
  [Step 40] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 41] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 42] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 43] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 44] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 45] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 46] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
  🌟 NEW PEAK: first_acc_ema=1.6% (raw_batch=12.5%) at step 46 → saved to runs/embed_diagnostics/checkpoint_best
      Sample predictions (first 5):
        ✗ pred=' ' | gold='B'
        ✗ pred=' ' | gold='$'
        ✗ pred=' ' | gold='Black'
        ✗ pred=' ' | gold='154'
        ✓ pred='the' | gold='the'
      Prediction diversity: 2/8 unique tokens
      Top-3 predictions: ' '(7) 'the'(1) 
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 47] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 48] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 49] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  step  50/125 | grad_norm=9.17 | sec/step~1.47 | lr=6.61e-05 | keep=1.00 | K=4 | llama(L): tf=10.4851 first=10.0238 kCE=7.7409 KD=5.0037 acc=0.000 align=0.0000 | scale_pen(llama)=9.0949e-11 | qwen(L): tf=12.7652 first=15.0550 kCE=7.8362 KD=8.6769 acc=0.125 [✓'1'] align=0.0000 | scale_pen(qwen)=1.8794e-12 | feature_grads[encoder=3.858e+00, adapter_llama=6.432e+00, adapter_qwen=5.282e+00] | K=4 tau=2.00
  [Step 50] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 51] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 52] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 53] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 54] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 55] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 56] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 57] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 58] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 59] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  step  60/125 | grad_norm=9.93 | sec/step~1.51 | lr=5.41e-05 | keep=1.00 | K=4 | llama(L): tf=9.1968 first=8.3050 kCE=6.8994 KD=4.1398 acc=0.000 align=0.0000 | scale_pen(llama)=1.3657e-11 | qwen(L): tf=9.1829 first=13.1545 kCE=5.9150 KD=7.3907 acc=0.125 [✓'1'] align=0.0000 | scale_pen(qwen)=1.7408e-11 | feature_grads[encoder=3.888e+00, adapter_llama=6.839e+00, adapter_qwen=6.067e+00] | K=4 tau=2.00
  [Step 60] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 61] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 62] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 63] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 64] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 65] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 66] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 67] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 68] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 69] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  step  70/125 | grad_norm=7.12 | sec/step~1.52 | lr=4.18e-05 | keep=1.00 | K=4 | llama(L): tf=8.6020 first=7.5130 kCE=7.1254 KD=3.2713 acc=0.125 [✓'the'] align=0.0000 | scale_pen(llama)=6.9633e-13 | qwen(L): tf=10.7678 first=11.1126 kCE=5.8704 KD=6.1417 acc=0.000 align=0.0000 | scale_pen(qwen)=1.0360e-11 | feature_grads[encoder=2.658e+00, adapter_llama=4.126e+00, adapter_qwen=5.164e+00] | K=4 tau=2.00
  [Step 70] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
  🌟 NEW PEAK: first_acc_ema=1.6% (raw_batch=12.5%) at step 70 → saved to runs/embed_diagnostics/checkpoint_best
      Sample predictions (first 5):
        ✗ pred='the' | gold='United'
        ✓ pred='the' | gold='the'
        ✗ pred='the' | gold='Spanish'
        ✗ pred='the' | gold='his'
        ✗ pred='the' | gold='Sl'
      Prediction diversity: 1/8 unique tokens
      Top-3 predictions: 'the'(8) 
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 71] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 72] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
  🌟 NEW PEAK: first_acc_ema=3.6% (raw_batch=25.0%) at step 72 → saved to runs/embed_diagnostics/checkpoint_best
      Sample predictions (first 5):
        ✗ pred='the' | gold='civil'
        ✓ pred='the' | gold='the'
        ✗ pred='the' | gold='1'
        ✗ pred='the' | gold='uns'
        ✗ pred='the' | gold='These'
      Prediction diversity: 1/8 unique tokens
      Top-3 predictions: 'the'(8) 
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 73] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 74] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 75] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 76] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 77] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
  🌟 NEW PEAK: first_acc_ema=3.6% (raw_batch=12.5%) at step 77 → saved to runs/embed_diagnostics/checkpoint_best
      Sample predictions (first 5):
        ✗ pred='the' | gold='May'
        ✗ pred='the' | gold='The'
        ✗ pred='the' | gold='James'
        ✗ pred='the' | gold='contact'
        ✗ pred='the' | gold='a'
      Prediction diversity: 1/8 unique tokens
      Top-3 predictions: 'the'(8) 
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 78] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 79] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  step  80/125 | grad_norm=10.81 | sec/step~1.24 | lr=3.01e-05 | keep=1.00 | K=4 | llama(L): tf=9.4488 first=8.9292 kCE=7.0410 KD=4.8972 acc=0.000 align=0.0000 | scale_pen(llama)=1.2825e-12 | qwen(L): tf=11.0960 first=11.2250 kCE=6.2687 KD=10.4796 acc=0.000 align=0.0000 | scale_pen(qwen)=2.8777e-13 | feature_grads[encoder=4.216e+00, adapter_llama=5.423e+00, adapter_qwen=8.347e+00] | K=4 tau=2.00
  [Step 80] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 81] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 82] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 83] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 84] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 85] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 86] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 87] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 88] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 89] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  step  90/125 | grad_norm=7.28 | sec/step~2.15 | lr=1.98e-05 | keep=1.00 | K=4 | llama(L): tf=8.2177 first=7.6426 kCE=8.5420 KD=6.1701 acc=0.000 align=0.0000 | scale_pen(llama)=5.6843e-14 | qwen(L): tf=9.5502 first=7.6005 kCE=6.3629 KD=14.1025 acc=0.000 align=0.0000 | scale_pen(qwen)=1.2790e-13 | feature_grads[encoder=2.923e+00, adapter_llama=5.459e+00, adapter_qwen=3.836e+00] | K=4 tau=2.00
  [Step 90] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 91] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 92] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 93] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
  🌟 NEW PEAK: first_acc_ema=3.6% (raw_batch=12.5%) at step 93 → saved to runs/embed_diagnostics/checkpoint_best
      Sample predictions (first 5):
        ✗ pred='the' | gold='rem'
        ✗ pred='the' | gold='196'
        ✗ pred='the' | gold='184'
        ✗ pred='the' | gold='never'
        ✗ pred='the' | gold='Royal'
      Prediction diversity: 1/8 unique tokens
      Top-3 predictions: 'the'(8) 
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 94] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
  🌟 NEW PEAK: first_acc_ema=3.6% (raw_batch=12.5%) at step 94 → saved to runs/embed_diagnostics/checkpoint_best
      Sample predictions (first 5):
        ✗ pred='the' | gold='pri'
        ✗ pred='the' | gold='multiple'
        ✗ pred='the' | gold='25'
        ✗ pred='the' | gold='East'
        ✗ pred='the' | gold='manual'
      Prediction diversity: 1/8 unique tokens
      Top-3 predictions: 'the'(8) 
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 95] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 96] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 97] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
  🌟 NEW PEAK: first_acc_ema=3.6% (raw_batch=12.5%) at step 97 → saved to runs/embed_diagnostics/checkpoint_best
      Sample predictions (first 5):
        ✗ pred='the' | gold='I'
        ✗ pred='the' | gold='M'
        ✓ pred='the' | gold='the'
        ✗ pred='the' | gold='Ben'
        ✗ pred='the' | gold='3'
      Prediction diversity: 1/8 unique tokens
      Top-3 predictions: 'the'(8) 
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 98] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 99] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  step  100/125 | grad_norm=7.90 | sec/step~1.83 | lr=1.14e-05 | keep=1.00 | K=4 | llama(L): tf=9.5660 first=8.2222 kCE=6.9035 KD=6.0092 acc=0.125 [✓'the'] align=0.0000 | scale_pen(llama)=3.1974e-14 | qwen(L): tf=10.8788 first=8.7520 kCE=5.8018 KD=13.9729 acc=0.125 [✓'1'] align=0.0000 | scale_pen(qwen)=3.1974e-14 | feature_grads[encoder=3.228e+00, adapter_llama=6.011e+00, adapter_qwen=3.973e+00] | K=4 tau=2.00
  [Step 100] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
  🌟 NEW PEAK: first_acc_ema=3.7% (raw_batch=12.5%) at step 100 → saved to runs/embed_diagnostics/checkpoint_best
      Sample predictions (first 5):
        ✗ pred='the' | gold='Eu'
        ✗ pred='the' | gold='Com'
        ✗ pred='the' | gold='15'
        ✓ pred='the' | gold='the'
        ✗ pred='the' | gold='Gl'
      Prediction diversity: 1/8 unique tokens
      Top-3 predictions: 'the'(8) 
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 101] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 102] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 103] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
  🌟 NEW PEAK: first_acc_ema=4.0% (raw_batch=12.5%) at step 103 → saved to runs/embed_diagnostics/checkpoint_best
      Sample predictions (first 5):
        ✗ pred='the' | gold='L'
        ✗ pred='the' | gold='Earth'
        ✗ pred='the' | gold='community'
        ✗ pred='the' | gold='M'
        ✗ pred='the' | gold='their'
      Prediction diversity: 1/8 unique tokens
      Top-3 predictions: 'the'(8) 
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 104] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
  🌟 NEW PEAK: first_acc_ema=4.8% (raw_batch=12.5%) at step 104 → saved to runs/embed_diagnostics/checkpoint_best
      Sample predictions (first 5):
        ✓ pred='the' | gold='the'
        ✗ pred='the' | gold='171'
        ✗ pred='the' | gold='184'
        ✗ pred='the' | gold='£'
        ✗ pred='the' | gold='Ad'
      Prediction diversity: 1/8 unique tokens
      Top-3 predictions: 'the'(8) 
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 105] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 106] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 107] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 108] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 109] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
  🌟 NEW PEAK: first_acc_ema=4.8% (raw_batch=12.5%) at step 109 → saved to runs/embed_diagnostics/checkpoint_best
      Sample predictions (first 5):
        ✗ pred='the' | gold='ann'
        ✗ pred='the' | gold='83'
        ✓ pred='the' | gold='the'
        ✗ pred='the' | gold='ev'
        ✗ pred='the' | gold='as'
      Prediction diversity: 1/8 unique tokens
      Top-3 predictions: 'the'(8) 
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  step  110/125 | grad_norm=6.98 | sec/step~1.72 | lr=5.44e-06 | keep=1.00 | K=4 | llama(L): tf=8.6770 first=8.1460 kCE=7.3809 KD=4.6112 acc=0.000 align=0.0000 | scale_pen(llama)=3.5527e-15 | qwen(L): tf=9.3299 first=8.1112 kCE=5.3879 KD=12.6474 acc=0.125 [✓'1'] align=0.0000 | scale_pen(qwen)=1.7408e-13 | feature_grads[encoder=2.830e+00, adapter_llama=5.209e+00, adapter_qwen=3.681e+00] | K=4 tau=2.00
  [Step 110] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 111] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 112] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 113] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
  🌟 NEW PEAK: first_acc_ema=4.8% (raw_batch=12.5%) at step 113 → saved to runs/embed_diagnostics/checkpoint_best
      Sample predictions (first 5):
        ✗ pred='the' | gold='Al'
        ✗ pred='the' | gold='Gu'
        ✗ pred='the' | gold='April'
        ✗ pred='the' | gold='they'
        ✗ pred='the' | gold='Nor'
      Prediction diversity: 1/8 unique tokens
      Top-3 predictions: 'the'(8) 
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 114] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 115] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 116] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 117] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
  🌟 NEW PEAK: first_acc_ema=4.8% (raw_batch=12.5%) at step 117 → saved to runs/embed_diagnostics/checkpoint_best
      Sample predictions (first 5):
        ✗ pred='the' | gold='North'
        ✗ pred='the' | gold='m'
        ✗ pred='the' | gold='Red'
        ✗ pred='the' | gold='early'
        ✗ pred='the' | gold='D'
      Prediction diversity: 1/8 unique tokens
      Top-3 predictions: 'the'(8) 
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 118] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
  🌟 NEW PEAK: first_acc_ema=5.9% (raw_batch=25.0%) at step 118 → saved to runs/embed_diagnostics/checkpoint_best
      Sample predictions (first 5):
        ✗ pred='the' | gold='D'
        ✓ pred='the' | gold='the'
        ✗ pred='the' | gold='city'
        ✗ pred='the' | gold='104'
        ✗ pred='the' | gold='7'
      Prediction diversity: 1/8 unique tokens
      Top-3 predictions: 'the'(8) 
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 119] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  step  120/125 | grad_norm=9.28 | sec/step~1.60 | lr=2.39e-06 | keep=1.00 | K=4 | llama(L): tf=9.3118 first=9.6264 kCE=6.4360 KD=4.8752 acc=0.000 align=0.0000 | scale_pen(llama)=0.0000e+00 | qwen(L): tf=8.2303 first=8.4961 kCE=5.3663 KD=14.0346 acc=0.125 [✓'1'] align=0.0000 | scale_pen(qwen)=3.5527e-15 | feature_grads[encoder=3.753e+00, adapter_llama=5.424e+00, adapter_qwen=6.528e+00] | K=4 tau=2.00
  [Step 120] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 121] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
  🌟 NEW PEAK: first_acc_ema=5.9% (raw_batch=12.5%) at step 121 → saved to runs/embed_diagnostics/checkpoint_best
      Sample predictions (first 5):
        ✗ pred='the' | gold='Her'
        ✗ pred='the' | gold='sim'
        ✗ pred='the' | gold='Ze'
        ✗ pred='the' | gold='minor'
        ✗ pred='the' | gold='in'
      Prediction diversity: 1/8 unique tokens
      Top-3 predictions: 'the'(8) 
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 122] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 123] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  [Step 124] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
[WARN] Failed to disable KD teacher adapters: No adapter loaded. Please load an adapter first.
  step  125/125 | grad_norm=6.89 | sec/step~1.75 | lr=2.00e-06 | keep=1.00 | K=4 | llama(L): tf=8.5406 first=7.8884 kCE=6.9012 KD=5.8884 acc=0.000 align=0.0000 | scale_pen(llama)=0.0000e+00 | qwen(L): tf=9.4222 first=8.9910 kCE=5.1664 KD=14.8514 acc=0.125 [✓'1'] align=0.0000 | scale_pen(qwen)=5.6843e-14 | feature_grads[encoder=2.488e+00, adapter_llama=5.261e+00, adapter_qwen=3.698e+00] | K=4 tau=2.00
  [Step 125] [GPU Memory] GPU0:6.6GB(26%), GPU1:8.6GB(24%), GPU2:8.6GB(24%), GPU3:8.1GB(29%) | Total: 32.0GB allocated, 87.4GB reserved, 252.7GB free, Peak: 73.3GB
[checkpoint] Freed 936.0B before save.
[checkpoint] Saved latest: encoder.pt, state.pt, config.json, adapter_llama.pt, adapter_qwen.pt
[checkpoint] Freed 0.0B after save (non-canonical).
✅ Saved latest checkpoint to runs/embed_diagnostics/checkpoint

Training complete!

/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Using device: cuda
Number of GPUs: 4
Samples: 1000
Batch size: 8
Output: runs/embed_diagnostics

Loading model: meta-llama/Meta-Llama-3.1-8B-Instruct...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2844.08it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:18,  6.15s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:12<00:12,  6.47s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:18<00:06,  6.16s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:19<00:00,  4.17s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:19<00:00,  4.94s/it]
Model loaded! (23.08s)

Caching vocabulary statistics...
  Vocab RMS: 0.0105
  Vocab mean: 0.000023
  Vocab std: 0.0106
  Time: 0.05s
Traceback (most recent call last):
  File "/projects/m000066/sujinesh/LatentWire/scripts/run_embedding_diagnostics.py", line 692, in <module>
    main()
  File "/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/projects/m000066/sujinesh/LatentWire/scripts/run_embedding_diagnostics.py", line 308, in main
    json.dump(vocab_stats_save, f, indent=2)
UnboundLocalError: local variable 'json' referenced before assignment
