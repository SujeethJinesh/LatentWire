{
  "timestamp": "2026-01-18T19:46:59.311745",
  "status": "in_progress",
  "zeroshot_llama": [
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "model_name": "llama",
      "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "seed": 42,
      "accuracy": 55.327545382794,
      "correct": 701,
      "total": 1267,
      "num_classes": 2
    },
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "model_name": "llama",
      "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "seed": 123,
      "accuracy": 55.327545382794,
      "correct": 701,
      "total": 1267,
      "num_classes": 2
    },
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "model_name": "llama",
      "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "seed": 456,
      "accuracy": 55.327545382794,
      "correct": 701,
      "total": 1267,
      "num_classes": 2
    }
  ],
  "zeroshot_mistral": [
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "model_name": "mistral",
      "model_id": "mistralai/Mistral-7B-Instruct-v0.3",
      "seed": 42,
      "accuracy": 54.064719810576165,
      "correct": 685,
      "total": 1267,
      "num_classes": 2
    },
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "model_name": "mistral",
      "model_id": "mistralai/Mistral-7B-Instruct-v0.3",
      "seed": 123,
      "accuracy": 54.064719810576165,
      "correct": 685,
      "total": 1267,
      "num_classes": 2
    },
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "model_name": "mistral",
      "model_id": "mistralai/Mistral-7B-Instruct-v0.3",
      "seed": 456,
      "accuracy": 54.064719810576165,
      "correct": 685,
      "total": 1267,
      "num_classes": 2
    }
  ],
  "text_relay": [
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "method": "text_relay_improved",
      "seed": 42,
      "accuracy": 54.14364640883978,
      "correct": 686,
      "total": 1267,
      "num_classes": 2,
      "latency_mean_ms": 940.3778546395687,
      "latency_std_ms": 23.92090565500458
    },
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "method": "text_relay_improved",
      "seed": 123,
      "accuracy": 54.14364640883978,
      "correct": 686,
      "total": 1267,
      "num_classes": 2,
      "latency_mean_ms": 960.693168230046,
      "latency_std_ms": 42.07419260405324
    },
    {
      "dataset": "winogrande",
      "dataset_name": "WinoGrande",
      "method": "text_relay_improved",
      "seed": 456,
      "accuracy": 54.14364640883978,
      "correct": 686,
      "total": 1267,
      "num_classes": 2,
      "latency_mean_ms": 955.8164480549519,
      "latency_std_ms": 34.85068459654812
    }
  ],
  "linear_probe": [],
  "prompt_tuning": [],
  "same_model_bridge": [],
  "bridge_8": [],
  "bridge_24": []
}