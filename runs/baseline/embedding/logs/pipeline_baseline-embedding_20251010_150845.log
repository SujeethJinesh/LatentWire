=== Starting python -m latentwire.cli.eval --config configs/baseline/embedding_baselines.json --override ckpt=runs/smoke/base/ckpt --override out_dir=runs/baseline/embedding/eval --tag baseline-embedding ===
/Users/sujeethjinesh/opt/anaconda3/lib/python3.9/runpy.py:127: RuntimeWarning: 'latentwire.cli.eval' found in sys.modules after import of package 'latentwire.cli', but prior to execution of 'latentwire.cli.eval'; this may result in unpredictable behaviour
  warn(RuntimeWarning(msg))
Traceback (most recent call last):
  File "/Users/sujeethjinesh/opt/anaconda3/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/Users/sujeethjinesh/opt/anaconda3/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/Users/sujeethjinesh/Desktop/LatentWire/latentwire/cli/eval.py", line 139, in <module>
    main()
  File "/Users/sujeethjinesh/Desktop/LatentWire/latentwire/cli/eval.py", line 120, in main
    run_eval(argv)
  File "/Users/sujeethjinesh/Desktop/LatentWire/latentwire/cli/eval.py", line 89, in run_eval
    from latentwire import eval as eval_module
  File "/Users/sujeethjinesh/Desktop/LatentWire/latentwire/eval.py", line 13, in <module>
    import torch
  File "/Users/sujeethjinesh/opt/anaconda3/lib/python3.9/site-packages/torch/__init__.py", line 229, in <module>
    from torch._C import *  # noqa: F403
ImportError: dlopen(/Users/sujeethjinesh/opt/anaconda3/lib/python3.9/site-packages/torch/_C.cpython-39-darwin.so, 0x0002): Library not loaded: @loader_path/libtorch_cpu.dylib
  Referenced from: <9F28170E-1091-3C0E-B17E-71871B0E6A44> /Users/sujeethjinesh/opt/anaconda3/lib/python3.9/site-packages/torch/lib/libtorch_python.dylib
  Reason: tried: '/Users/sujeethjinesh/opt/anaconda3/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib' (no such file), '/usr/local/lib/libtorch_cpu.dylib' (no such file), '/usr/lib/libtorch_cpu.dylib' (no such file, not in dyld cache)
=== LatentWire Eval CLI ===
Config: /Users/sujeethjinesh/Desktop/LatentWire/configs/baseline/embedding_baselines.json
Overrides:
  - ckpt=runs/smoke/base/ckpt
  - out_dir=runs/baseline/embedding/eval
Derived argv: --ckpt runs/smoke/base/ckpt --models llama --llama_id meta-llama/Meta-Llama-3.1-8B-Instruct --dataset squad --samples 5 --max_new_tokens 24 --latent_anchor_mode auto --latent_anchor_text Answer:  --append_bos_after_prefix auto --use_chat_template yes --token_budget_mode content_only --token_budget_k 32 --chunk_size 8 --fresh_eval --embedding_replay --embedding_baseline_modes ["raw", "anchor", "adapter"] --out_dir runs/baseline/embedding/eval --first_token_top_p 1.0 --first_token_temperature 0.0 --min_new_tokens 1 --eos_ban_steps 0 --calibration embed_rms --prefix_gain 1.0 --hf_encoder_id sentence-transformers/all-MiniLM-L6-v2 --max_enc_tokens 1024 --llama_device_map auto
--- baseline-embedding failed with exit code 1 ---

