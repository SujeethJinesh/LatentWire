{
  "samples": 200,
  "max_new_tokens": 12,
  "latent_len": 32,
  "device": "cuda",
  "dtype": "torch.bfloat16",
  "avg_prompt_tokens": {
    "llama": 245.065,
    "qwen": 231.69
  },
  "compression": {
    "llama": 7.65828125,
    "qwen": 7.2403125
  },
  "payload_bytes": 32768,
  "wire": {
    "text_bytes_onecopy": {
      "llama_avg": 1259,
      "qwen_avg": 1107,
      "max_avg": 1259
    },
    "text_bytes_twocopies": {
      "sum_avg": 2366
    },
    "latent_bytes": {
      "fp32": 32768,
      "fp16": 16384
    },
    "wire_compression": {
      "vs_onecopy_fp16": 13.013502779984114,
      "vs_onecopy_fp32": 26.027005559968227
    },
    "wire_ratio": {
      "latent_over_onecopy_fp16": 13.013502779984114,
      "latent_over_onecopy_fp32": 26.027005559968227,
      "onecopy_over_latent_fp16": 0.07684326171875,
      "onecopy_over_latent_fp32": 0.038421630859375
    }
  },
  "text": {
    "wall_clock_sec": 19.187469244003296,
    "llama": {
      "em": 0.58,
      "f1": 0.7994106570072514,
      "nll_token": 12.72173482274305
    },
    "qwen": {
      "em": 0.68,
      "f1": 0.8528460272957177,
      "nll_token": 25.81069942126198
    }
  },
  "latent": {
    "wall_clock_sec": 16.800423860549927,
    "llama": {
      "em": 0.0,
      "f1": 0.024617243867243864,
      "nll_token": 7.23870018604391,
      "first_token_top1": 0.03999999910593033,
      "first_token_top5": 0.08999999612569809
    },
    "qwen": {
      "em": 0.0,
      "f1": 0.012846495008259714,
      "nll_token": 7.365889173020761,
      "first_token_top1": 0.05999999865889549,
      "first_token_top5": 0.1550000011920929
    }
  },
  "token_budget": {
    "mode": "content_only",
    "k": 32,
    "llama": {
      "em": 0.005,
      "f1": 0.04086507936507937
    },
    "wall_clock_sec": 14.154929637908936,
    "qwen": {
      "em": 0.04,
      "f1": 0.07479711954711955
    }
  },
  "joint": {
    "em": 0.0,
    "f1": 0.012017740429505137,
    "agreement": 0.0,
    "oracle": {
      "em": null,
      "f1": null
    }
  },
  "debug": {
    "llama": {
      "adapter_scale": 0.9916385412216187,
      "Z_std": 0.7462534308433533,
      "Z_mean_norm": 11.881779670715332,
      "prefix_std": 0.012158986181020737,
      "prefix_mean_norm": 0.7774772644042969,
      "embed_rms": 0.010569815523922443,
      "encoder_text_mode": "raw",
      "calibration_mode": "embed_rms",
      "append_bos_after_prefix": "no",
      "latent_anchor_mode": "text",
      "latent_anchor_text": "Answer: ",
      "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct"
    },
    "qwen": {
      "adapter_scale": 0.9966626167297363,
      "Z_std": 0.7462534308433533,
      "Z_mean_norm": 11.881779670715332,
      "prefix_std": 0.015683025121688843,
      "prefix_mean_norm": 0.937647819519043,
      "embed_rms": 0.01364860124886036,
      "encoder_text_mode": "raw",
      "calibration_mode": "embed_rms",
      "append_bos_after_prefix": "no",
      "latent_anchor_mode": "text",
      "latent_anchor_text": "Answer: ",
      "model_id": "Qwen/Qwen2.5-7B-Instruct"
    },
    "latent_anchor_mode": "text",
    "latent_anchor_text": "Answer: ",
    "prefix_gain": 1.15,
    "calibration_mode": "embed_rms",
    "append_bos_after_prefix": "no",
    "decode": {
      "min_new_tokens": 3,
      "eos_ban_steps": 6,
      "first_token_top_p": 1.0,
      "first_token_temperature": 0.0
    }
  },
  "oracle": {
    "em": 0.0,
    "f1": 0.028265936677701383
  },
  "dataset": "squad"
}