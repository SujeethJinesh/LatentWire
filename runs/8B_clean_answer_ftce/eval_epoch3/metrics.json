{
  "samples": 200,
  "max_new_tokens": 12,
  "latent_len": 32,
  "device": "cuda",
  "dtype": "torch.bfloat16",
  "avg_prompt_tokens": {
    "llama": 245.065,
    "qwen": 231.69
  },
  "compression": {
    "llama": 7.65828125,
    "qwen": 7.2403125
  },
  "payload_bytes": 32768,
  "wire": {
    "text_bytes_onecopy": {
      "llama_avg": 1259,
      "qwen_avg": 1107,
      "max_avg": 1259
    },
    "text_bytes_twocopies": {
      "sum_avg": 2366
    },
    "latent_bytes": {
      "fp32": 32768,
      "fp16": 16384
    },
    "wire_compression": {
      "vs_onecopy_fp16": 13.013502779984114,
      "vs_onecopy_fp32": 26.027005559968227
    },
    "wire_ratio": {
      "latent_over_onecopy_fp16": 13.013502779984114,
      "latent_over_onecopy_fp32": 26.027005559968227,
      "onecopy_over_latent_fp16": 0.07684326171875,
      "onecopy_over_latent_fp32": 0.038421630859375
    }
  },
  "text": {
    "wall_clock_sec": 16.47888159751892,
    "llama": {
      "em": 0.58,
      "f1": 0.7994106570072514,
      "nll_token": 12.72173482274305
    },
    "qwen": {
      "em": 0.68,
      "f1": 0.8528460272957177,
      "nll_token": 25.81069942126198
    }
  },
  "latent": {
    "wall_clock_sec": 13.32939076423645,
    "llama": {
      "em": 0.0,
      "f1": 0.027049825174825175,
      "nll_token": 7.621333787230407,
      "first_token_top1": 0.02499999850988388,
      "first_token_top5": 0.07499999552965164
    },
    "qwen": {
      "em": 0.0,
      "f1": 0.012774891774891774,
      "nll_token": 7.299324211147097,
      "first_token_top1": 0.05999999865889549,
      "first_token_top5": 0.125
    }
  },
  "token_budget": {
    "mode": "content_only",
    "k": 32,
    "llama": {
      "em": 0.005,
      "f1": 0.04086507936507937
    },
    "wall_clock_sec": 11.502137184143066,
    "qwen": {
      "em": 0.04,
      "f1": 0.07479711954711955
    }
  },
  "joint": {
    "em": 0.0,
    "f1": 0.010799714174714174,
    "agreement": 0.0,
    "oracle": {
      "em": null,
      "f1": null
    }
  },
  "debug": {
    "llama": {
      "adapter_scale": 0.9931514263153076,
      "Z_std": 0.7253382205963135,
      "Z_mean_norm": 11.568334579467773,
      "prefix_std": 0.010572593659162521,
      "prefix_mean_norm": 0.6765959858894348,
      "embed_rms": 0.010569815523922443,
      "encoder_text_mode": "raw",
      "calibration_mode": "embed_rms",
      "append_bos_after_prefix": "yes",
      "latent_anchor_mode": "text",
      "latent_anchor_text": "Answer: ",
      "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct"
    },
    "qwen": {
      "adapter_scale": 0.9994001984596252,
      "Z_std": 0.7253382205963135,
      "Z_mean_norm": 11.568334579467773,
      "prefix_std": 0.013636560179293156,
      "prefix_mean_norm": 0.8161417841911316,
      "embed_rms": 0.01364860124886036,
      "encoder_text_mode": "raw",
      "calibration_mode": "embed_rms",
      "append_bos_after_prefix": "yes",
      "latent_anchor_mode": "text",
      "latent_anchor_text": "Answer: ",
      "model_id": "Qwen/Qwen2.5-7B-Instruct"
    },
    "latent_anchor_mode": "text",
    "latent_anchor_text": "Answer: ",
    "prefix_gain": 1.0,
    "calibration_mode": "embed_rms",
    "append_bos_after_prefix": "yes",
    "decode": {
      "min_new_tokens": 3,
      "eos_ban_steps": 6,
      "first_token_top_p": 1.0,
      "first_token_temperature": 0.0
    }
  },
  "oracle": {
    "em": 0.0,
    "f1": 0.030848415473415478
  },
  "dataset": "squad"
}