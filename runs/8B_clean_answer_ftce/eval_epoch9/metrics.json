{
  "samples": 200,
  "max_new_tokens": 12,
  "latent_len": 32,
  "device": "cuda",
  "dtype": "torch.bfloat16",
  "avg_prompt_tokens": {
    "llama": 245.065,
    "qwen": 231.69
  },
  "compression": {
    "llama": 7.65828125,
    "qwen": 7.2403125
  },
  "payload_bytes": 32768,
  "wire": {
    "text_bytes_onecopy": {
      "llama_avg": 1259,
      "qwen_avg": 1107,
      "max_avg": 1259
    },
    "text_bytes_twocopies": {
      "sum_avg": 2366
    },
    "latent_bytes": {
      "fp32": 32768,
      "fp16": 16384
    },
    "wire_compression": {
      "vs_onecopy_fp16": 13.013502779984114,
      "vs_onecopy_fp32": 26.027005559968227
    },
    "wire_ratio": {
      "latent_over_onecopy_fp16": 13.013502779984114,
      "latent_over_onecopy_fp32": 26.027005559968227,
      "onecopy_over_latent_fp16": 0.07684326171875,
      "onecopy_over_latent_fp32": 0.038421630859375
    }
  },
  "text": {
    "wall_clock_sec": 16.692883253097534,
    "llama": {
      "em": 0.58,
      "f1": 0.7994106570072514,
      "nll_token": 12.72173482274305
    },
    "qwen": {
      "em": 0.68,
      "f1": 0.8528460272957177,
      "nll_token": 25.81069942126198
    }
  },
  "latent": {
    "wall_clock_sec": 15.478205680847168,
    "llama": {
      "em": 0.0,
      "f1": 0.02957262852386692,
      "nll_token": 7.050568657126827,
      "first_token_top1": 0.03999999910593033,
      "first_token_top5": 0.125
    },
    "qwen": {
      "em": 0.0,
      "f1": 0.019997076452958805,
      "nll_token": 7.118333921703712,
      "first_token_top1": 0.05999999865889549,
      "first_token_top5": 0.1599999964237213
    }
  },
  "token_budget": {
    "mode": "content_only",
    "k": 32,
    "llama": {
      "em": 0.005,
      "f1": 0.04086507936507937
    },
    "wall_clock_sec": 13.07660436630249,
    "qwen": {
      "em": 0.04,
      "f1": 0.07479711954711955
    }
  },
  "joint": {
    "em": 0.0,
    "f1": 0.021055923007161397,
    "agreement": 0.005,
    "oracle": {
      "em": null,
      "f1": null
    }
  },
  "debug": {
    "llama": {
      "adapter_scale": 0.9973437786102295,
      "Z_std": 0.6603639125823975,
      "Z_mean_norm": 10.403753280639648,
      "prefix_std": 0.012159290723502636,
      "prefix_mean_norm": 0.7773622870445251,
      "embed_rms": 0.010569815523922443,
      "encoder_text_mode": "raw",
      "calibration_mode": "embed_rms",
      "append_bos_after_prefix": "no",
      "latent_anchor_mode": "text",
      "latent_anchor_text": "Answer: ",
      "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct"
    },
    "qwen": {
      "adapter_scale": 0.9999295473098755,
      "Z_std": 0.6603639125823975,
      "Z_mean_norm": 10.403753280639648,
      "prefix_std": 0.01568557322025299,
      "prefix_mean_norm": 0.93660968542099,
      "embed_rms": 0.01364860124886036,
      "encoder_text_mode": "raw",
      "calibration_mode": "embed_rms",
      "append_bos_after_prefix": "no",
      "latent_anchor_mode": "text",
      "latent_anchor_text": "Answer: ",
      "model_id": "Qwen/Qwen2.5-7B-Instruct"
    },
    "latent_anchor_mode": "text",
    "latent_anchor_text": "Answer: ",
    "prefix_gain": 1.15,
    "calibration_mode": "embed_rms",
    "append_bos_after_prefix": "no",
    "decode": {
      "min_new_tokens": 3,
      "eos_ban_steps": 6,
      "first_token_top_p": 1.0,
      "first_token_temperature": 0.0
    }
  },
  "oracle": {
    "em": 0.0,
    "f1": 0.03517113235921287
  },
  "dataset": "squad"
}