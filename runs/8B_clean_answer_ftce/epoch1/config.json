{
  "d_z": 256,
  "latent_len": 32,
  "byte_max": 2048,
  "llama_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
  "qwen_id": "Qwen/Qwen2.5-7B-Instruct",
  "encoder_type": "byte",
  "encoder_use_chat_template": false,
  "encoder_backbone": "",
  "warm_anchor_text": "Answer: ",
  "train_append_bos_after_prefix": "yes",
  "first_token_ce_weight": 0.5,
  "seed": 42,
  "data_seed": 42
}