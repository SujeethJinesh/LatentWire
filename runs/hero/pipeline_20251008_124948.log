Starting GPU monitoring â†’ runs/hero/gpu_monitor.log

>>> Combination 1: m64_dz256_rl2_rh4
    RUN_TAG=hero
    EPOCHS_STAGEA=6 | EPOCHS_STAGEB=10
    WARMUP_TEXT_LATENT_EPOCHS_STAGEA=1.0 | WARMUP_TEXT_LATENT_EPOCHS_STAGEB=2.0

=== CUDA preflight ===
torch: 2.4.0+cu121 cuda: 12.1 available: True
CUDA_VISIBLE_DEVICES: 0,1,2,3
PYTORCH_CUDA_ALLOC_CONF: expandable_segments:True

=== Stage A: Llama latent fit ===

/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading dataset subset...
Loading SQuAD subset...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 3753.29it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:05,  1.87s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.81s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.58s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.11s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.33s/it]
[meta-llama/Meta-Llama-3.1-8B-Instruct] hf_device_map: {'model.embed_tokens': 0, 'model.rotary_emb': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 2, 'model.layers.17': 2, 'model.layers.18': 2, 'model.layers.19': 2, 'model.layers.20': 2, 'model.layers.21': 2, 'model.layers.22': 2, 'model.layers.23': 2, 'model.layers.24': 3, 'model.layers.25': 3, 'model.layers.26': 3, 'model.layers.27': 3, 'model.layers.28': 3, 'model.layers.29': 3, 'model.layers.30': 3, 'model.layers.31': 3, 'model.norm': 3, 'lm_head': 3}

ðŸ”§ Applying LoRA (r=8, alpha=8)...
   Llama BEFORE LoRA: 0 trainable / 8,030,261,248 total
trainable params: 6,815,744 || all params: 8,037,076,992 || trainable%: 0.0848
   Llama AFTER LoRA:  6,815,744 trainable / 8,037,076,992 total
   âœ“ Added 6,815,744 LoRA parameters to Llama
Llama hidden size: 4096
[DeviceMap] Llama: {'model.embed_tokens': 0, 'model.rotary_emb': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 2, 'model.layers.17': 2, 'model.layers.18': 2, 'model.layers.19': 2, 'model.layers.20': 2, 'model.layers.21': 2, 'model.layers.22': 2, 'model.layers.23': 2, 'model.layers.24': 3, 'model.layers.25': 3, 'model.layers.26': 3, 'model.layers.27': 3, 'model.layers.28': 3, 'model.layers.29': 3, 'model.layers.30': 3, 'model.layers.31': 3, 'model.norm': 3, 'lm_head': 3}
[INFO] llama anchor tokens: 3
[INFO] LR scheduler: CosineAnnealingLR (T_max=1998, eta_min=1.00e-06)
âš ï¸  No valid checkpoint found to resume; starting fresh.
[warmup] alternating text/latent for first 334 steps
Epoch 1/6
[warmup] step=0 mode=text (warm-up)
We detected that you are passing `past_key_values` as a tuple of tuples. This is deprecated and will be removed in v4.47. Please convert your cache or use an appropriate `Cache` class (https://huggingface.co/docs/transformers/kv_cache#legacy-cache-format)
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
  step  1/334 | (warm-up text) | align=0.0002 | text_tf=14.1440 | latent_scale=0.00
[warmup] step=1 mode=latent (warm-up)
[warmup] step=2 mode=text (warm-up)
  step  3/334 | (warm-up text) | align=0.0002 | text_tf=16.1955 | latent_scale=0.00
[warmup] step=3 mode=latent (warm-up)
[warmup] step=4 mode=text (warm-up)
  step  5/334 | (warm-up text) | align=0.0002 | text_tf=16.4431 | latent_scale=0.01
[warmup] step=5 mode=latent (warm-up)
[warmup] step=6 mode=text (warm-up)
  step  7/334 | (warm-up text) | align=0.0002 | text_tf=13.0606 | latent_scale=0.01
[warmup] step=7 mode=latent (warm-up)
[warmup] step=8 mode=text (warm-up)
  step  9/334 | (warm-up text) | align=0.0002 | text_tf=14.7693 | latent_scale=0.01
[warmup] step=9 mode=latent (warm-up)
  step  10/334 | grad_norm=58.21 | sec/step~5.74 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=0.27 | llama(L): tf=14.7550 first=14.6710 kCE=14.5390 KD=5.9016 acc=0.000 state=12.9515 ent=9.372 align=0.0000 latA=0.5019 latP=0.2476 | scale_pen(llama)=0.0000e+00 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  11/334 | (warm-up text) | align=0.0002 | text_tf=16.6695 | latent_scale=0.01
  step  13/334 | (warm-up text) | align=0.0002 | text_tf=17.3862 | latent_scale=0.02
  step  15/334 | (warm-up text) | align=0.0002 | text_tf=13.3126 | latent_scale=0.02
  step  17/334 | (warm-up text) | align=0.0002 | text_tf=16.0307 | latent_scale=0.02
  step  19/334 | (warm-up text) | align=0.0002 | text_tf=14.2669 | latent_scale=0.03
  step  20/334 | grad_norm=315.92 | sec/step~5.28 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=0.57 | llama(L): tf=39.3580 first=42.5766 kCE=40.9961 KD=57.6761 acc=0.000 state=13.7978 ent=0.009 align=0.0000 latA=0.5033 latP=0.2477 | scale_pen(llama)=5.1159e-13 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  21/334 | (warm-up text) | align=0.0002 | text_tf=12.5981 | latent_scale=0.03
  step  23/334 | (warm-up text) | align=0.0002 | text_tf=15.3053 | latent_scale=0.03
  step  25/334 | (warm-up text) | align=0.0002 | text_tf=13.9842 | latent_scale=0.04
  step  27/334 | (warm-up text) | align=0.0002 | text_tf=16.4100 | latent_scale=0.04
  step  29/334 | (warm-up text) | align=0.0002 | text_tf=14.7198 | latent_scale=0.04
  step  30/334 | grad_norm=16.67 | sec/step~4.95 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=0.87 | llama(L): tf=16.7226 first=17.4336 kCE=17.2652 KD=10.8049 acc=0.000 state=13.2132 ent=2.499 align=0.0000 latA=0.5025 latP=0.2481 | scale_pen(llama)=6.0041e-13 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  31/334 | (warm-up text) | align=0.0002 | text_tf=13.2578 | latent_scale=0.04
  step  33/334 | (warm-up text) | align=0.0002 | text_tf=14.4329 | latent_scale=0.05
  step  35/334 | (warm-up text) | align=0.0002 | text_tf=12.5110 | latent_scale=0.05
  step  37/334 | (warm-up text) | align=0.0002 | text_tf=12.6971 | latent_scale=0.05
  step  39/334 | (warm-up text) | align=0.0002 | text_tf=12.3652 | latent_scale=0.06
  step  40/334 | grad_norm=109.92 | sec/step~5.30 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=1.17 | llama(L): tf=16.2560 first=18.6370 kCE=17.1416 KD=10.5111 acc=0.000 state=14.3079 ent=2.465 align=0.0000 latA=0.5026 latP=0.2483 | scale_pen(llama)=6.0041e-13 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  41/334 | (warm-up text) | align=0.0002 | text_tf=14.3621 | latent_scale=0.06
  step  43/334 | (warm-up text) | align=0.0002 | text_tf=14.2176 | latent_scale=0.06
  step  45/334 | (warm-up text) | align=0.0002 | text_tf=13.0832 | latent_scale=0.07
  step  47/334 | (warm-up text) | align=0.0002 | text_tf=12.3347 | latent_scale=0.07
  step  49/334 | (warm-up text) | align=0.0002 | text_tf=14.8391 | latent_scale=0.07
  step  50/334 | grad_norm=55.39 | sec/step~5.67 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=1.47 | llama(L): tf=13.2119 first=11.7027 kCE=13.6830 KD=5.8920 acc=0.000 state=14.8750 ent=3.573 align=0.0000 latA=0.5025 latP=0.2488 | scale_pen(llama)=1.4211e-14 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  51/334 | (warm-up text) | align=0.0002 | text_tf=10.1441 | latent_scale=0.07
  step  53/334 | (warm-up text) | align=0.0002 | text_tf=11.4142 | latent_scale=0.08
  step  55/334 | (warm-up text) | align=0.0002 | text_tf=10.9489 | latent_scale=0.08
  step  57/334 | (warm-up text) | align=0.0002 | text_tf=10.9934 | latent_scale=0.08
  step  59/334 | (warm-up text) | align=0.0002 | text_tf=11.2936 | latent_scale=0.09
  step  60/334 | grad_norm=15.81 | sec/step~5.17 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=1.77 | llama(L): tf=13.8012 first=12.5511 kCE=13.5091 KD=5.4791 acc=0.000 state=14.1858 ent=9.526 align=0.0000 latA=0.5020 latP=0.2491 | scale_pen(llama)=3.5527e-13 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  61/334 | (warm-up text) | align=0.0002 | text_tf=11.7691 | latent_scale=0.09
  step  63/334 | (warm-up text) | align=0.0002 | text_tf=10.9956 | latent_scale=0.09
  step  65/334 | (warm-up text) | align=0.0002 | text_tf=11.2267 | latent_scale=0.10
  step  67/334 | (warm-up text) | align=0.0002 | text_tf=12.4069 | latent_scale=0.10
  step  69/334 | (warm-up text) | align=0.0002 | text_tf=9.8055 | latent_scale=0.10
  step  70/334 | grad_norm=56.97 | sec/step~4.69 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=2.07 | llama(L): tf=13.6879 first=12.1001 kCE=13.5664 KD=5.3911 acc=0.000 state=13.7397 ent=9.517 align=0.0000 latA=0.5013 latP=0.2491 | scale_pen(llama)=1.4211e-14 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  71/334 | (warm-up text) | align=0.0002 | text_tf=9.7895 | latent_scale=0.10
  step  73/334 | (warm-up text) | align=0.0002 | text_tf=10.1104 | latent_scale=0.11
  step  75/334 | (warm-up text) | align=0.0002 | text_tf=11.1645 | latent_scale=0.11
  step  77/334 | (warm-up text) | align=0.0002 | text_tf=11.0491 | latent_scale=0.11
  step  79/334 | (warm-up text) | align=0.0002 | text_tf=11.7012 | latent_scale=0.12
  step  80/334 | grad_norm=51.45 | sec/step~5.73 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=2.37 | llama(L): tf=15.2427 first=12.9239 kCE=15.1828 KD=5.6429 acc=0.000 state=15.3733 ent=9.326 align=0.0000 latA=0.5012 latP=0.2496 | scale_pen(llama)=1.4211e-14 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  81/334 | (warm-up text) | align=0.0002 | text_tf=9.8806 | latent_scale=0.12
  step  83/334 | (warm-up text) | align=0.0002 | text_tf=10.7353 | latent_scale=0.12
  step  85/334 | (warm-up text) | align=0.0002 | text_tf=8.8470 | latent_scale=0.13
  step  87/334 | (warm-up text) | align=0.0002 | text_tf=10.0226 | latent_scale=0.13
  step  89/334 | (warm-up text) | align=0.0002 | text_tf=9.8489 | latent_scale=0.13
  step  90/334 | grad_norm=23.99 | sec/step~5.38 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=2.67 | llama(L): tf=13.4098 first=11.2831 kCE=13.4400 KD=5.2979 acc=0.000 state=14.4169 ent=9.628 align=0.0000 latA=0.5010 latP=0.2499 | scale_pen(llama)=3.1974e-14 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  91/334 | (warm-up text) | align=0.0002 | text_tf=10.6749 | latent_scale=0.13
  step  93/334 | (warm-up text) | align=0.0002 | text_tf=10.0250 | latent_scale=0.14
  step  95/334 | (warm-up text) | align=0.0002 | text_tf=9.3584 | latent_scale=0.14
  step  97/334 | (warm-up text) | align=0.0002 | text_tf=10.0990 | latent_scale=0.14
  step  99/334 | (warm-up text) | align=0.0002 | text_tf=10.4194 | latent_scale=0.15
  step  100/334 | grad_norm=6.38 | sec/step~5.65 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=2.97 | llama(L): tf=12.1321 first=9.1072 kCE=12.2106 KD=5.0575 acc=0.042 [âœ“'C'] state=15.1906 ent=7.711 align=0.0000 latA=0.4983 latP=0.2498 | scale_pen(llama)=5.6843e-14 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  101/334 | (warm-up text) | align=0.0002 | text_tf=8.9241 | latent_scale=0.15
  step  103/334 | (warm-up text) | align=0.0002 | text_tf=10.1175 | latent_scale=0.15
  step  105/334 | (warm-up text) | align=0.0002 | text_tf=9.7311 | latent_scale=0.16
  step  107/334 | (warm-up text) | align=0.0002 | text_tf=9.0263 | latent_scale=0.16
  step  109/334 | (warm-up text) | align=0.0002 | text_tf=9.5194 | latent_scale=0.16
  step  110/334 | grad_norm=36.62 | sec/step~5.84 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=3.27 | llama(L): tf=11.7217 first=9.9396 kCE=12.1899 KD=5.0880 acc=0.000 state=14.5698 ent=7.572 align=0.0000 latA=0.5012 latP=0.2500 | scale_pen(llama)=5.6843e-14 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  111/334 | (warm-up text) | align=0.0002 | text_tf=9.9533 | latent_scale=0.16
  step  113/334 | (warm-up text) | align=0.0002 | text_tf=10.4868 | latent_scale=0.17
  ðŸŒŸ NEW PEAK: first_acc_ema=2.3% (raw_batch=20.8%) at step 114 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='Ex'
        âœ— pred='the' | gold='*'
        âœ— pred='the' | gold='Jeff'
        âœ— pred='the' | gold='early'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  115/334 | (warm-up text) | align=0.0002 | text_tf=9.4132 | latent_scale=0.17
  ðŸŒŸ NEW PEAK: first_acc_ema=2.9% (raw_batch=8.3%) at step 116 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='S'
        âœ— pred='the' | gold='Å¡'
        âœ— pred='the' | gold='legal'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='BBC'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  117/334 | (warm-up text) | align=0.0002 | text_tf=9.1515 | latent_scale=0.17
  ðŸŒŸ NEW PEAK: first_acc_ema=3.8% (raw_batch=12.5%) at step 118 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='200'
        âœ— pred='the' | gold='January'
        âœ— pred='the' | gold='re'
        âœ— pred='the' | gold='until'
        âœ— pred='the' | gold='.'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  119/334 | (warm-up text) | align=0.0002 | text_tf=8.6623 | latent_scale=0.18
  step  120/334 | grad_norm=21.93 | sec/step~4.81 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=3.57 | llama(L): tf=11.7147 first=9.7721 kCE=12.1373 KD=5.1862 acc=0.083 [âœ“'the'] state=15.1961 ent=6.774 align=0.0000 latA=0.5021 latP=0.2498 | scale_pen(llama)=3.5527e-15 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  ðŸŒŸ NEW PEAK: first_acc_ema=4.3% (raw_batch=8.3%) at step 120 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='Ar'
        âœ— pred='the' | gold='skin'
        âœ— pred='the' | gold='South'
        âœ— pred='the' | gold='Wars'
        âœ— pred='the' | gold='From'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  121/334 | (warm-up text) | align=0.0002 | text_tf=8.8903 | latent_scale=0.18
  ðŸŒŸ NEW PEAK: first_acc_ema=4.7% (raw_batch=8.3%) at step 122 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='Hay'
        âœ— pred='the' | gold='firm'
        âœ— pred='the' | gold='Q'
        âœ— pred='the' | gold='Florida'
        âœ— pred='the' | gold='a'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  123/334 | (warm-up text) | align=0.0002 | text_tf=8.2346 | latent_scale=0.18
  step  125/334 | (warm-up text) | align=0.0002 | text_tf=10.3961 | latent_scale=0.19
  ðŸŒŸ NEW PEAK: first_acc_ema=5.4% (raw_batch=12.5%) at step 126 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='Grand'
        âœ— pred='the' | gold='every'
        âœ— pred='the' | gold='199'
        âœ— pred='the' | gold='Z'
        âœ“ pred='the' | gold='the'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  127/334 | (warm-up text) | align=0.0002 | text_tf=8.9472 | latent_scale=0.19
  ðŸŒŸ NEW PEAK: first_acc_ema=5.7% (raw_batch=8.3%) at step 128 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='164'
        âœ— pred='the' | gold='201'
        âœ— pred='the' | gold='Anthony'
        âœ— pred='the' | gold='197'
        âœ— pred='the' | gold='discord'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  129/334 | (warm-up text) | align=0.0002 | text_tf=10.0281 | latent_scale=0.19
  step  130/334 | grad_norm=12.86 | sec/step~5.52 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=3.87 | llama(L): tf=11.4907 first=7.9713 kCE=11.8802 KD=5.2220 acc=0.125 [âœ“'the'] state=15.0622 ent=6.159 align=0.0000 latA=0.5000 latP=0.2503 | scale_pen(llama)=8.8818e-14 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  ðŸŒŸ NEW PEAK: first_acc_ema=6.4% (raw_batch=12.5%) at step 130 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='B'
        âœ— pred='the' | gold='as'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='internet'
        âœ— pred='the' | gold='AB'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  131/334 | (warm-up text) | align=0.0002 | text_tf=8.7529 | latent_scale=0.19
  step  133/334 | (warm-up text) | align=0.0002 | text_tf=10.3141 | latent_scale=0.20
  step  135/334 | (warm-up text) | align=0.0002 | text_tf=9.7072 | latent_scale=0.20
  ðŸŒŸ NEW PEAK: first_acc_ema=6.6% (raw_batch=12.5%) at step 136 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='z'
        âœ— pred='the' | gold='The'
        âœ— pred='the' | gold='The'
        âœ— pred='the' | gold='R'
        âœ— pred='the' | gold='jh'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  137/334 | (warm-up text) | align=0.0002 | text_tf=9.1771 | latent_scale=0.20
  step  139/334 | (warm-up text) | align=0.0002 | text_tf=8.6460 | latent_scale=0.21
  step  140/334 | grad_norm=50.42 | sec/step~4.69 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=4.17 | llama(L): tf=11.2687 first=9.4867 kCE=12.0178 KD=5.2506 acc=0.042 [âœ“'the'] state=14.5625 ent=6.122 align=0.0000 latA=0.5034 latP=0.2504 | scale_pen(llama)=3.5527e-15 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  141/334 | (warm-up text) | align=0.0002 | text_tf=10.0364 | latent_scale=0.21
  step  143/334 | (warm-up text) | align=0.0002 | text_tf=9.9847 | latent_scale=0.21
  step  145/334 | (warm-up text) | align=0.0002 | text_tf=10.2157 | latent_scale=0.22
  step  147/334 | (warm-up text) | align=0.0002 | text_tf=9.6757 | latent_scale=0.22
  step  149/334 | (warm-up text) | align=0.0002 | text_tf=9.1521 | latent_scale=0.22
  step  150/334 | grad_norm=21.22 | sec/step~4.83 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=4.47 | llama(L): tf=11.4809 first=8.8250 kCE=11.0810 KD=4.7581 acc=0.042 [âœ“'the'] state=14.5592 ent=8.050 align=0.0000 latA=0.5025 latP=0.2505 | scale_pen(llama)=3.5527e-15 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  151/334 | (warm-up text) | align=0.0002 | text_tf=9.6979 | latent_scale=0.22
  step  153/334 | (warm-up text) | align=0.0002 | text_tf=9.4003 | latent_scale=0.23
NaN/Inf loss; skipping step
  step  155/334 | (warm-up text) | align=0.0002 | text_tf=10.5490 | latent_scale=0.23
  ðŸŒŸ NEW PEAK: first_acc_ema=6.6% (raw_batch=12.5%) at step 155 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='$'
        âœ— pred='the' | gold='Am'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='a'
        âœ— pred='the' | gold='which'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  157/334 | (warm-up text) | align=0.0002 | text_tf=8.3496 | latent_scale=0.23
  step  159/334 | (warm-up text) | align=0.0002 | text_tf=10.2153 | latent_scale=0.24
  step  160/334 | grad_norm=36.70 | sec/step~4.96 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=4.74 | llama(L): tf=10.9355 first=9.4801 kCE=10.5182 KD=4.8995 acc=0.000 state=15.0188 ent=8.023 align=0.0000 latA=0.5016 latP=0.2506 | scale_pen(llama)=3.5527e-15 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  161/334 | (warm-up text) | align=0.0002 | text_tf=10.2635 | latent_scale=0.24
NaN/Inf loss; skipping step
  step  163/334 | (warm-up text) | align=0.0002 | text_tf=8.5294 | latent_scale=0.24
  ðŸŒŸ NEW PEAK: first_acc_ema=6.6% (raw_batch=16.7%) at step 162 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='C'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='it'
        âœ— pred='the' | gold='Inside'
        âœ— pred='the' | gold='etch'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  165/334 | (warm-up text) | align=0.0002 | text_tf=10.4161 | latent_scale=0.25
  ðŸŒŸ NEW PEAK: first_acc_ema=6.6% (raw_batch=8.3%) at step 164 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='six'
        âœ— pred='the' | gold='178'
        âœ— pred='the' | gold='De'
        âœ— pred='the' | gold='two'
        âœ— pred='the' | gold='Peter'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  167/334 | (warm-up text) | align=0.0002 | text_tf=8.4091 | latent_scale=0.25
  step  169/334 | (warm-up text) | align=0.0002 | text_tf=9.4948 | latent_scale=0.25
  step  170/334 | grad_norm=6.10 | sec/step~4.44 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=5.01 | llama(L): tf=10.9159 first=9.1299 kCE=11.0810 KD=4.7709 acc=0.000 state=13.7710 ent=9.128 align=0.0000 latA=0.5015 latP=0.2505 | scale_pen(llama)=5.6843e-14 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  171/334 | (warm-up text) | align=0.0002 | text_tf=10.0413 | latent_scale=0.25
  step  173/334 | (warm-up text) | align=0.0002 | text_tf=10.1885 | latent_scale=0.26
  step  175/334 | (warm-up text) | align=0.0002 | text_tf=8.3522 | latent_scale=0.26
  step  177/334 | (warm-up text) | align=0.0002 | text_tf=10.0079 | latent_scale=0.26
  step  179/334 | (warm-up text) | align=0.0002 | text_tf=8.2875 | latent_scale=0.27
  step  180/334 | grad_norm=26.28 | sec/step~5.34 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=5.31 | llama(L): tf=10.0433 first=8.7220 kCE=10.4100 KD=4.8365 acc=0.000 state=14.6157 ent=9.122 align=0.0000 latA=0.4994 latP=0.2506 | scale_pen(llama)=5.6843e-14 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  181/334 | (warm-up text) | align=0.0002 | text_tf=9.4683 | latent_scale=0.27
  step  183/334 | (warm-up text) | align=0.0002 | text_tf=8.0134 | latent_scale=0.27
  step  185/334 | (warm-up text) | align=0.0002 | text_tf=9.7248 | latent_scale=0.28
  step  187/334 | (warm-up text) | align=0.0002 | text_tf=9.2445 | latent_scale=0.28
  step  189/334 | (warm-up text) | align=0.0002 | text_tf=9.2142 | latent_scale=0.28
NaN/Inf loss; skipping step
  step  191/334 | (warm-up text) | align=0.0002 | text_tf=8.3039 | latent_scale=0.28
  step  193/334 | (warm-up text) | align=0.0002 | text_tf=9.0641 | latent_scale=0.29
  step  195/334 | (warm-up text) | align=0.0002 | text_tf=7.7757 | latent_scale=0.29
  step  197/334 | (warm-up text) | align=0.0002 | text_tf=8.4694 | latent_scale=0.29
  step  199/334 | (warm-up text) | align=0.0002 | text_tf=9.5218 | latent_scale=0.30
  step  200/334 | grad_norm=11.23 | sec/step~5.54 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=5.88 | llama(L): tf=10.5034 first=7.9957 kCE=10.9254 KD=4.3040 acc=0.000 state=15.0637 ent=8.917 align=0.0000 latA=0.5038 latP=0.2506 | scale_pen(llama)=1.2790e-13 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  201/334 | (warm-up text) | align=0.0002 | text_tf=7.3868 | latent_scale=0.30
  step  203/334 | (warm-up text) | align=0.0002 | text_tf=9.1105 | latent_scale=0.30
  step  205/334 | (warm-up text) | align=0.0002 | text_tf=8.8825 | latent_scale=0.31
  step  207/334 | (warm-up text) | align=0.0002 | text_tf=9.8095 | latent_scale=0.31
  step  209/334 | (warm-up text) | align=0.0002 | text_tf=10.5313 | latent_scale=0.31
  step  210/334 | grad_norm=32.81 | sec/step~5.05 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=6.00 | llama(L): tf=10.7982 first=8.9763 kCE=11.0651 KD=4.5524 acc=0.000 state=14.6703 ent=8.973 align=0.0000 latA=0.5010 latP=0.2508 | scale_pen(llama)=5.6843e-14 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  211/334 | (warm-up text) | align=0.0002 | text_tf=9.3742 | latent_scale=0.31
  ðŸŒŸ NEW PEAK: first_acc_ema=6.6% (raw_batch=8.3%) at step 209 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='199' | gold='sub'
        âœ— pred='199' | gold='the'
        âœ— pred='200' | gold='E'
        âœ— pred='199' | gold='c'
        âœ— pred='a' | gold='focus'
      Prediction diversity: 3/24 unique tokens
      Top-3 predictions: '199'(17) 'a'(6) '200'(1) 
  step  213/334 | (warm-up text) | align=0.0002 | text_tf=8.2762 | latent_scale=0.32
  step  215/334 | (warm-up text) | align=0.0002 | text_tf=9.2290 | latent_scale=0.32
  step  217/334 | (warm-up text) | align=0.0002 | text_tf=9.6173 | latent_scale=0.32
  step  219/334 | (warm-up text) | align=0.0002 | text_tf=8.5105 | latent_scale=0.33
  step  220/334 | grad_norm=18.33 | sec/step~4.84 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=6.00 | llama(L): tf=10.3162 first=8.9093 kCE=10.6216 KD=4.3452 acc=0.042 [âœ“'199'] state=14.3075 ent=8.678 align=0.0000 latA=0.5003 latP=0.2505 | scale_pen(llama)=5.6843e-14 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  221/334 | (warm-up text) | align=0.0002 | text_tf=8.2708 | latent_scale=0.33
  step  223/334 | (warm-up text) | align=0.0002 | text_tf=8.4830 | latent_scale=0.33
  step  225/334 | (warm-up text) | align=0.0002 | text_tf=9.5293 | latent_scale=0.34
  step  227/334 | (warm-up text) | align=0.0002 | text_tf=8.1766 | latent_scale=0.34
  step  229/334 | (warm-up text) | align=0.0002 | text_tf=8.5124 | latent_scale=0.34
  step  230/334 | grad_norm=12.62 | sec/step~5.10 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=6.00 | llama(L): tf=10.5479 first=8.5754 kCE=10.6801 KD=4.6047 acc=0.000 state=14.5180 ent=7.850 align=0.0000 latA=0.5006 latP=0.2506 | scale_pen(llama)=5.6843e-14 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  231/334 | (warm-up text) | align=0.0002 | text_tf=8.0728 | latent_scale=0.34
  step  233/334 | (warm-up text) | align=0.0002 | text_tf=9.6660 | latent_scale=0.35
  step  235/334 | (warm-up text) | align=0.0002 | text_tf=9.4331 | latent_scale=0.35
  step  237/334 | (warm-up text) | align=0.0002 | text_tf=9.3171 | latent_scale=0.35
  step  239/334 | (warm-up text) | align=0.0002 | text_tf=9.1582 | latent_scale=0.36
  step  240/334 | grad_norm=5.85 | sec/step~5.78 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=6.00 | llama(L): tf=10.7489 first=8.7328 kCE=11.1292 KD=4.2642 acc=0.000 state=13.9101 ent=7.571 align=0.0000 latA=0.4996 latP=0.2509 | scale_pen(llama)=1.2790e-13 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  241/334 | (warm-up text) | align=0.0002 | text_tf=8.8197 | latent_scale=0.36
  ðŸŒŸ NEW PEAK: first_acc_ema=6.6% (raw_batch=8.3%) at step 239 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ“ pred='a' | gold='a'
        âœ— pred='a' | gold='pro'
        âœ— pred='a' | gold='Ab'
        âœ— pred='a' | gold='April'
        âœ— pred='a' | gold='Leon'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'a'(24) 
  step  243/334 | (warm-up text) | align=0.0002 | text_tf=8.4435 | latent_scale=0.36
  step  245/334 | (warm-up text) | align=0.0002 | text_tf=8.1605 | latent_scale=0.37
  step  247/334 | (warm-up text) | align=0.0002 | text_tf=9.1801 | latent_scale=0.37
  step  249/334 | (warm-up text) | align=0.0002 | text_tf=7.8552 | latent_scale=0.37
  step  250/334 | grad_norm=24.47 | sec/step~5.44 | lr=5.00e-05 | keep=0.70 | K=8 | first_w=6.00 | llama(L): tf=10.1434 first=8.4378 kCE=10.8793 KD=4.5033 acc=0.000 state=14.4637 ent=7.565 align=0.0000 latA=0.5019 latP=0.2508 | scale_pen(llama)=1.2790e-13 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  251/334 | (warm-up text) | align=0.0002 | text_tf=9.4707 | latent_scale=0.37
  ðŸŒŸ NEW PEAK: first_acc_ema=6.6% (raw_batch=8.3%) at step 249 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='a' | gold='fat'
        âœ— pred='a' | gold='M'
        âœ— pred='a' | gold='r'
        âœ— pred='a' | gold='California'
        âœ— pred='a' | gold='address'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'a'(24) 
  step  253/334 | (warm-up text) | align=0.0002 | text_tf=7.6900 | latent_scale=0.38
  step  255/334 | (warm-up text) | align=0.0002 | text_tf=9.2248 | latent_scale=0.38
  step  257/334 | (warm-up text) | align=0.0002 | text_tf=8.1027 | latent_scale=0.38
  ðŸŒŸ NEW PEAK: first_acc_ema=6.6% (raw_batch=8.3%) at step 255 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='misc'
        âœ— pred='the' | gold='drag'
        âœ— pred='the' | gold='at'
        âœ— pred='the' | gold='Jer'
        âœ— pred='the' | gold='for'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  259/334 | (warm-up text) | align=0.0002 | text_tf=8.2350 | latent_scale=0.39
  step  260/334 | grad_norm=12.26 | sec/step~4.96 | lr=5.00e-05 | keep=0.71 | K=8 | first_w=6.00 | llama(L): tf=10.1952 first=9.0175 kCE=10.3928 KD=4.5789 acc=0.000 state=13.5391 ent=7.952 align=0.0000 latA=0.5013 latP=0.2509 | scale_pen(llama)=1.7408e-13 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  261/334 | (warm-up text) | align=0.0002 | text_tf=8.5563 | latent_scale=0.39
  step  263/334 | (warm-up text) | align=0.0002 | text_tf=8.9648 | latent_scale=0.39
  step  265/334 | (warm-up text) | align=0.0002 | text_tf=6.9642 | latent_scale=0.40
  step  267/334 | (warm-up text) | align=0.0002 | text_tf=7.2709 | latent_scale=0.40
  step  269/334 | (warm-up text) | align=0.0002 | text_tf=8.7992 | latent_scale=0.40
  step  270/334 | grad_norm=7.65 | sec/step~6.02 | lr=5.00e-05 | keep=0.71 | K=8 | first_w=6.00 | llama(L): tf=9.9830 first=7.8156 kCE=10.2031 KD=4.2556 acc=0.250 [âœ“'the'] state=14.5805 ent=8.321 align=0.0000 latA=0.5001 latP=0.2510 | scale_pen(llama)=1.4211e-14 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  ðŸŒŸ NEW PEAK: first_acc_ema=6.6% (raw_batch=25.0%) at step 267 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='163'
        âœ— pred='the' | gold='social'
        âœ— pred='the' | gold='Cl'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='am'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  271/334 | (warm-up text) | align=0.0002 | text_tf=9.3348 | latent_scale=0.40
  ðŸŒŸ NEW PEAK: first_acc_ema=6.6% (raw_batch=8.3%) at step 269 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='Sam'
        âœ— pred='the' | gold='tw'
        âœ— pred='the' | gold='Anne'
        âœ— pred='the' | gold='The'
        âœ— pred='the' | gold='relations'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  273/334 | (warm-up text) | align=0.0002 | text_tf=8.1249 | latent_scale=0.41
  ðŸŒŸ NEW PEAK: first_acc_ema=6.6% (raw_batch=12.5%) at step 271 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='January'
        âœ— pred='the' | gold='Chair'
        âœ— pred='the' | gold='R'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='L'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  275/334 | (warm-up text) | align=0.0002 | text_tf=8.8506 | latent_scale=0.41
  step  277/334 | (warm-up text) | align=0.0002 | text_tf=8.3661 | latent_scale=0.41
  step  279/334 | (warm-up text) | align=0.0002 | text_tf=6.6671 | latent_scale=0.42
  step  280/334 | grad_norm=18.31 | sec/step~5.32 | lr=5.00e-05 | keep=0.71 | K=8 | first_w=6.00 | llama(L): tf=9.8595 first=7.3716 kCE=9.8801 KD=4.1472 acc=0.125 [âœ“'the'] state=14.3026 ent=8.316 align=0.0000 latA=0.4993 latP=0.2508 | scale_pen(llama)=1.2790e-13 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  ðŸŒŸ NEW PEAK: first_acc_ema=6.6% (raw_batch=12.5%) at step 277 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ“ pred='the' | gold='the'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='SH'
        âœ— pred='the' | gold='c'
        âœ— pred='the' | gold='R'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  281/334 | (warm-up text) | align=0.0002 | text_tf=7.8513 | latent_scale=0.42
  step  283/334 | (warm-up text) | align=0.0002 | text_tf=7.9430 | latent_scale=0.42
  step  285/334 | (warm-up text) | align=0.0002 | text_tf=7.9515 | latent_scale=0.43
  ðŸŒŸ NEW PEAK: first_acc_ema=6.6% (raw_batch=8.3%) at step 283 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='Queen'
        âœ— pred='the' | gold='Pol'
        âœ— pred='the' | gold='complex'
        âœ— pred='the' | gold='Z'
        âœ— pred='the' | gold='"F'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  287/334 | (warm-up text) | align=0.0002 | text_tf=9.3807 | latent_scale=0.43
  ðŸŒŸ NEW PEAK: first_acc_ema=6.6% (raw_batch=12.5%) at step 285 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='imp'
        âœ— pred='the' | gold='pro'
        âœ— pred='the' | gold='par'
        âœ— pred='the' | gold='50'
        âœ— pred='the' | gold='stre'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  289/334 | (warm-up text) | align=0.0002 | text_tf=8.2198 | latent_scale=0.43
  step  290/334 | grad_norm=14.71 | sec/step~4.95 | lr=5.00e-05 | keep=0.71 | K=8 | first_w=6.00 | llama(L): tf=9.8690 first=8.3559 kCE=10.0650 KD=4.4004 acc=0.042 [âœ“'the'] state=13.9120 ent=8.524 align=0.0000 latA=0.4985 latP=0.2507 | scale_pen(llama)=1.2790e-13 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  291/334 | (warm-up text) | align=0.0002 | text_tf=7.8483 | latent_scale=0.43
  ðŸŒŸ NEW PEAK: first_acc_ema=6.6% (raw_batch=8.3%) at step 289 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='Third'
        âœ— pred='the' | gold='mult'
        âœ— pred='the' | gold='Spanish'
        âœ— pred='the' | gold='D'
        âœ— pred='the' | gold='non'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  293/334 | (warm-up text) | align=0.0002 | text_tf=7.9886 | latent_scale=0.44
  step  295/334 | (warm-up text) | align=0.0002 | text_tf=8.6475 | latent_scale=0.44
  ðŸŒŸ NEW PEAK: first_acc_ema=6.6% (raw_batch=16.7%) at step 293 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='element'
        âœ— pred='the' | gold='Roger'
        âœ— pred='the' | gold='Prince'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='Pers'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  297/334 | (warm-up text) | align=0.0002 | text_tf=8.1086 | latent_scale=0.44
  step  299/334 | (warm-up text) | align=0.0002 | text_tf=8.1448 | latent_scale=0.45
  step  300/334 | grad_norm=9.95 | sec/step~5.05 | lr=5.00e-05 | keep=0.71 | K=8 | first_w=6.00 | llama(L): tf=9.8068 first=8.4977 kCE=10.1782 KD=4.4283 acc=0.000 state=13.0167 ent=8.638 align=0.0000 latA=0.4998 latP=0.2511 | scale_pen(llama)=1.4211e-14 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  301/334 | (warm-up text) | align=0.0002 | text_tf=8.0714 | latent_scale=0.45
  step  303/334 | (warm-up text) | align=0.0002 | text_tf=7.8536 | latent_scale=0.45
  ðŸŒŸ NEW PEAK: first_acc_ema=6.7% (raw_batch=16.7%) at step 301 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='President'
        âœ— pred='the' | gold='World'
        âœ— pred='the' | gold='Richard'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='Pale'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  305/334 | (warm-up text) | align=0.0002 | text_tf=8.3782 | latent_scale=0.46
  ðŸŒŸ NEW PEAK: first_acc_ema=6.9% (raw_batch=8.3%) at step 303 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='two'
        âœ— pred='the' | gold='power'
        âœ— pred='the' | gold='m'
        âœ“ pred='the' | gold='the'
        âœ“ pred='the' | gold='the'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  307/334 | (warm-up text) | align=0.0002 | text_tf=6.9474 | latent_scale=0.46
  step  309/334 | (warm-up text) | align=0.0002 | text_tf=8.0971 | latent_scale=0.46
  step  310/334 | grad_norm=4.69 | sec/step~4.72 | lr=5.00e-05 | keep=0.71 | K=8 | first_w=6.00 | llama(L): tf=9.6473 first=8.1056 kCE=9.7297 KD=4.2245 acc=0.000 state=13.0971 ent=8.442 align=0.0000 latA=0.5008 latP=0.2508 | scale_pen(llama)=2.8777e-13 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  311/334 | (warm-up text) | align=0.0002 | text_tf=8.1331 | latent_scale=0.46
  ðŸŒŸ NEW PEAK: first_acc_ema=6.9% (raw_batch=8.3%) at step 309 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='white'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='G'
        âœ— pred='the' | gold='52'
        âœ— pred='the' | gold='Asia'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  313/334 | (warm-up text) | align=0.0002 | text_tf=7.6334 | latent_scale=0.47
  step  315/334 | (warm-up text) | align=0.0002 | text_tf=8.0032 | latent_scale=0.47
  ðŸŒŸ NEW PEAK: first_acc_ema=6.9% (raw_batch=8.3%) at step 313 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='French'
        âœ— pred='the' | gold='187'
        âœ— pred='the' | gold='145'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='258'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  317/334 | (warm-up text) | align=0.0002 | text_tf=8.4793 | latent_scale=0.47
  ðŸŒŸ NEW PEAK: first_acc_ema=6.9% (raw_batch=8.3%) at step 315 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='carrier'
        âœ— pred='the' | gold='system'
        âœ— pred='the' | gold='Gram'
        âœ— pred='the' | gold='a'
        âœ— pred='the' | gold='Emp'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  319/334 | (warm-up text) | align=0.0002 | text_tf=7.6972 | latent_scale=0.48
  step  320/334 | grad_norm=11.76 | sec/step~4.82 | lr=5.00e-05 | keep=0.71 | K=8 | first_w=6.00 | llama(L): tf=9.5297 first=7.5500 kCE=9.5046 KD=4.2384 acc=0.083 [âœ“'the'] state=13.3505 ent=8.461 align=0.0000 latA=0.4986 latP=0.2508 | scale_pen(llama)=2.8777e-13 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  ðŸŒŸ NEW PEAK: first_acc_ema=6.9% (raw_batch=8.3%) at step 317 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='191'
        âœ— pred='the' | gold='without'
        âœ— pred='the' | gold='one'
        âœ— pred='the' | gold='527'
        âœ— pred='the' | gold='Ath'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  321/334 | (warm-up text) | align=0.0002 | text_tf=7.4299 | latent_scale=0.48
  step  323/334 | (warm-up text) | align=0.0002 | text_tf=7.3339 | latent_scale=0.48
  ðŸŒŸ NEW PEAK: first_acc_ema=6.9% (raw_batch=12.5%) at step 321 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='lake'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='path'
        âœ— pred='the' | gold='R'
        âœ— pred='the' | gold='K'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  325/334 | (warm-up text) | align=0.0002 | text_tf=8.0126 | latent_scale=0.49
  step  327/334 | (warm-up text) | align=0.0002 | text_tf=9.0378 | latent_scale=0.49
  ðŸŒŸ NEW PEAK: first_acc_ema=6.9% (raw_batch=8.3%) at step 325 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='in'
        âœ— pred='the' | gold='197'
        âœ— pred='the' | gold='The'
        âœ— pred='the' | gold='an'
        âœ— pred='the' | gold='ability'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  329/334 | (warm-up text) | align=0.0002 | text_tf=7.5452 | latent_scale=0.49
  step  330/334 | grad_norm=9.98 | sec/step~5.42 | lr=5.00e-05 | keep=0.71 | K=8 | first_w=6.00 | llama(L): tf=9.2432 first=7.4290 kCE=9.3260 KD=4.3255 acc=0.083 [âœ“'the'] state=13.8518 ent=8.221 align=0.0000 latA=0.4986 latP=0.2508 | scale_pen(llama)=6.9633e-13 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  ðŸŒŸ NEW PEAK: first_acc_ema=6.9% (raw_batch=8.3%) at step 327 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='At'
        âœ— pred='the' | gold='C'
        âœ— pred='the' | gold='mat'
        âœ— pred='the' | gold='E'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  331/334 | (warm-up text) | align=0.0002 | text_tf=7.3695 | latent_scale=0.49
NaN/Inf loss; skipping step
  step  333/334 | (warm-up text) | align=0.0002 | text_tf=8.2459 | latent_scale=0.50
  step  334/334 | grad_norm=12.40 | sec/step~4.78 | lr=5.00e-05 | keep=0.71 | K=8 | first_w=6.00 | llama(L): tf=10.1232 first=8.4673 kCE=10.3292 KD=4.0695 acc=0.000 state=13.7877 ent=8.272 align=0.0000 latA=0.4976 latP=0.2509 | scale_pen(llama)=7.9936e-13 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
Epoch 2/6
  ðŸŒŸ NEW PEAK: first_acc_ema=6.9% (raw_batch=8.3%) at step 331 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='birth'
        âœ— pred='the' | gold='25'
        âœ— pred='the' | gold='five'
        âœ— pred='the' | gold='co'
        âœ— pred='the' | gold='13'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=6.9% (raw_batch=8.3%) at step 332 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='balance'
        âœ— pred='the' | gold='national'
        âœ— pred='the' | gold='South'
        âœ— pred='the' | gold='14'
        âœ— pred='the' | gold='Ay'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=6.9% (raw_batch=8.3%) at step 333 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='po'
        âœ— pred='the' | gold='Spanish'
        âœ— pred='the' | gold='430'
        âœ— pred='the' | gold='ball'
        âœ— pred='the' | gold='Traditional'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.1% (raw_batch=12.5%) at step 334 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='comp'
        âœ— pred='the' | gold='var'
        âœ— pred='the' | gold='G'
        âœ— pred='the' | gold='The'
        âœ— pred='the' | gold='natural'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
[checkpoint] Freed 3.5KB before save.
[checkpoint] Saved latest: encoder.pt, state.pt, config.json, adapter_llama.pt, deep_prefix_llama.pt, refiner.pt
[checkpoint] Freed 0.0B after save (non-canonical).
  âœ… Saved (and pruned to) latest at step 334
  ðŸŒŸ NEW PEAK: first_acc_ema=7.1% (raw_batch=8.3%) at step 336 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='25'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='Wo'
        âœ— pred='the' | gold='An'
        âœ— pred='the' | gold='a'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.1% (raw_batch=8.3%) at step 339 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='Arch'
        âœ— pred='the' | gold='f'
        âœ— pred='the' | gold='Jack'
        âœ— pred='the' | gold='C'
        âœ— pred='the' | gold='50'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  10/334 | grad_norm=21.24 | sec/step~5.55 | lr=5.00e-05 | keep=0.71 | K=8 | first_w=6.00 | llama(L): tf=9.5504 first=7.2213 kCE=9.5278 KD=4.2214 acc=0.125 [âœ“'the'] state=14.6519 ent=7.983 align=0.0000 latA=0.5001 latP=0.2510 | scale_pen(llama)=7.9936e-13 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  ðŸŒŸ NEW PEAK: first_acc_ema=7.1% (raw_batch=12.5%) at step 340 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='K'
        âœ— pred='the' | gold='The'
        âœ— pred='the' | gold='early'
        âœ— pred='the' | gold='nine'
        âœ— pred='the' | gold='Russian'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.2% (raw_batch=12.5%) at step 342 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='B'
        âœ— pred='the' | gold='Hal'
        âœ— pred='the' | gold='Ex'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='163'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.3% (raw_batch=8.3%) at step 343 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='exp'
        âœ— pred='the' | gold='Port'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='young'
        âœ— pred='the' | gold='198'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.4% (raw_batch=8.3%) at step 344 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='Cou'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='L'
        âœ— pred='the' | gold='200'
        âœ“ pred='the' | gold='the'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.5% (raw_batch=8.3%) at step 345 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='Robert'
        âœ— pred='the' | gold='popular'
        âœ— pred='the' | gold='70'
        âœ— pred='the' | gold='M'
        âœ— pred='the' | gold='inter'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  20/334 | grad_norm=11.03 | sec/step~4.93 | lr=5.00e-05 | keep=0.71 | K=8 | first_w=6.00 | llama(L): tf=9.3340 first=7.4874 kCE=9.5570 KD=4.4120 acc=0.042 [âœ“'the'] state=12.8528 ent=8.365 align=0.0000 latA=0.4999 latP=0.2510 | scale_pen(llama)=2.0464e-12 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  ðŸŒŸ NEW PEAK: first_acc_ema=7.5% (raw_batch=8.3%) at step 351 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='art'
        âœ— pred='the' | gold='J'
        âœ— pred='the' | gold='Cal'
        âœ— pred='the' | gold='Alexander'
        âœ— pred='the' | gold='invest'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.5% (raw_batch=8.3%) at step 352 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='R'
        âœ— pred='the' | gold='six'
        âœ— pred='the' | gold='continental'
        âœ— pred='the' | gold='bo'
        âœ— pred='the' | gold='Flat'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.5% (raw_batch=12.5%) at step 354 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='10'
        âœ— pred='the' | gold='35'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='more'
        âœ— pred='the' | gold='Battle'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.5% (raw_batch=16.7%) at step 355 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='Amb'
        âœ— pred='the' | gold='Ed'
        âœ— pred='the' | gold='Cy'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='L'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  30/334 | grad_norm=5.55 | sec/step~4.63 | lr=5.00e-05 | keep=0.71 | K=8 | first_w=6.00 | llama(L): tf=9.4892 first=7.2054 kCE=9.6183 KD=3.9431 acc=0.125 [âœ“'the'] state=12.7932 ent=8.825 align=0.0000 latA=0.4983 latP=0.2510 | scale_pen(llama)=9.0949e-13 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  ðŸŒŸ NEW PEAK: first_acc_ema=7.5% (raw_batch=12.5%) at step 360 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='tour'
        âœ— pred='the' | gold='Q'
        âœ— pred='the' | gold='During'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='v'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.5% (raw_batch=12.5%) at step 362 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='Royal'
        âœ— pred='the' | gold='str'
        âœ— pred='the' | gold='cr'
        âœ— pred='the' | gold='God'
        âœ— pred='the' | gold='Simon'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.5% (raw_batch=8.3%) at step 363 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='Germany'
        âœ— pred='the' | gold='Chinese'
        âœ— pred='the' | gold='Western'
        âœ— pred='the' | gold='84'
        âœ— pred='the' | gold='b'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=12.5%) at step 364 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='nine'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='3'
        âœ— pred='the' | gold='Northern'
        âœ— pred='the' | gold='55'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  40/334 | grad_norm=17.00 | sec/step~5.22 | lr=5.00e-05 | keep=0.71 | K=8 | first_w=6.00 | llama(L): tf=9.7652 first=7.7155 kCE=9.6894 KD=4.1610 acc=0.083 [âœ“'the'] state=13.4122 ent=8.838 align=0.0000 latA=0.5003 latP=0.2510 | scale_pen(llama)=9.0949e-13 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=8.3%) at step 370 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='Br'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='225'
        âœ— pred='the' | gold='Apple'
        âœ— pred='the' | gold='Bur'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=8.3%) at step 377 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='12'
        âœ— pred='the' | gold='rac'
        âœ— pred='the' | gold='National'
        âœ— pred='the' | gold='K'
        âœ— pred='the' | gold='E'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=8.3%) at step 378 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='before'
        âœ— pred='the' | gold='dogs'
        âœ— pred='the' | gold='less'
        âœ— pred='the' | gold='supported'
        âœ— pred='the' | gold='G'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  50/334 | grad_norm=13.71 | sec/step~5.88 | lr=5.00e-05 | keep=0.71 | K=8 | first_w=6.00 | llama(L): tf=9.6361 first=7.0754 kCE=9.2569 KD=3.9865 acc=0.125 [âœ“'the'] state=13.3674 ent=8.786 align=0.0000 latA=0.5017 latP=0.2510 | scale_pen(llama)=5.1159e-13 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=12.5%) at step 380 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='more'
        âœ— pred='the' | gold='S'
        âœ— pred='the' | gold='40'
        âœ— pred='the' | gold='social'
        âœ— pred='the' | gold='progress'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=8.3%) at step 381 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='external'
        âœ— pred='the' | gold='Ge'
        âœ— pred='the' | gold='15'
        âœ— pred='the' | gold='Gas'
        âœ“ pred='the' | gold='the'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=8.3%) at step 382 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='P'
        âœ— pred='the' | gold='re'
        âœ— pred='the' | gold='The'
        âœ— pred='the' | gold='both'
        âœ— pred='the' | gold='private'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=8.3%) at step 384 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='bring'
        âœ— pred='the' | gold='16'
        âœ— pred='the' | gold='149'
        âœ— pred='the' | gold='Jur'
        âœ“ pred='the' | gold='the'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=8.3%) at step 385 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='V'
        âœ— pred='the' | gold='ego'
        âœ— pred='the' | gold='7'
        âœ— pred='the' | gold='one'
        âœ“ pred='the' | gold='the'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=16.7%) at step 386 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='$'
        âœ— pred='the' | gold='700'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='M'
        âœ— pred='the' | gold='M'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=8.3%) at step 387 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='j'
        âœ— pred='the' | gold='over'
        âœ— pred='the' | gold='start'
        âœ— pred='the' | gold='N'
        âœ— pred='the' | gold='Mari'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=8.3%) at step 389 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='rice'
        âœ— pred='the' | gold='Gab'
        âœ— pred='the' | gold='Nich'
        âœ— pred='the' | gold='Z'
        âœ— pred='the' | gold='eth'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  60/334 | grad_norm=7.45 | sec/step~5.25 | lr=5.00e-05 | keep=0.71 | K=8 | first_w=6.00 | llama(L): tf=9.1950 first=7.4191 kCE=9.0286 KD=4.0296 acc=0.000 state=11.5127 ent=8.182 align=0.0000 latA=0.5006 latP=0.2508 | scale_pen(llama)=1.0267e-12 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=8.3%) at step 391 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='Robert'
        âœ— pred='the' | gold='Con'
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='special'
        âœ— pred='the' | gold='President'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=12.5%) at step 392 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='from'
        âœ— pred='the' | gold='comm'
        âœ— pred='the' | gold='236'
        âœ— pred='the' | gold='unic'
        âœ— pred='the' | gold='an'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=8.3%) at step 396 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='104'
        âœ— pred='the' | gold='sentence'
        âœ— pred='the' | gold='number'
        âœ— pred='the' | gold='James'
        âœ— pred='the' | gold='pro'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=8.3%) at step 397 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='Anthony'
        âœ— pred='the' | gold='d'
        âœ— pred='the' | gold='Ã©t'
        âœ— pred='the' | gold='A'
        âœ— pred='the' | gold='Pa'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  70/334 | grad_norm=16.53 | sec/step~5.03 | lr=5.00e-05 | keep=0.71 | K=8 | first_w=6.00 | llama(L): tf=9.8978 first=7.6729 kCE=9.7393 KD=4.1874 acc=0.000 state=12.0365 ent=8.187 align=0.0000 latA=0.5000 latP=0.2508 | scale_pen(llama)=1.4211e-14 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=8.3%) at step 402 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ“ pred='the' | gold='the'
        âœ— pred='the' | gold='108'
        âœ— pred='the' | gold='tw'
        âœ— pred='the' | gold='191'
        âœ— pred='the' | gold='US'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=8.3%) at step 404 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='B'
        âœ— pred='the' | gold='194'
        âœ— pred='the' | gold='photo'
        âœ— pred='the' | gold='26'
        âœ— pred='the' | gold='Roman'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=8.3%) at step 408 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='172'
        âœ— pred='the' | gold='North'
        âœ— pred='the' | gold='H'
        âœ— pred='the' | gold='chunk'
        âœ— pred='the' | gold='I'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  step  80/334 | grad_norm=13.21 | sec/step~6.17 | lr=5.00e-05 | keep=0.71 | K=8 | first_w=6.00 | llama(L): tf=9.5560 first=7.6537 kCE=9.7731 KD=3.7445 acc=0.042 [âœ“'the'] state=13.8756 ent=7.926 align=0.0000 latA=0.4958 latP=0.2505 | scale_pen(llama)=1.4211e-14 | K=8 tau=4.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=8.3%) at step 413 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='Between'
        âœ— pred='the' | gold='"'
        âœ— pred='the' | gold='177'
        âœ— pred='the' | gold='C'
        âœ— pred='the' | gold='Eastern'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=12.5%) at step 414 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='l'
        âœ— pred='the' | gold='191'
        âœ— pred='the' | gold='DVD'
        âœ— pred='the' | gold='Miss'
        âœ“ pred='the' | gold='the'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
  ðŸŒŸ NEW PEAK: first_acc_ema=7.6% (raw_batch=8.3%) at step 415 â†’ saved to runs/hero/ckpt/stageA_best
      Sample predictions (first 5):
        âœ— pred='the' | gold='French'
        âœ— pred='the' | gold='199'
        âœ— pred='the' | gold='198'
        âœ— pred='the' | gold='201'
        âœ— pred='the' | gold='30'
      Prediction diversity: 1/24 unique tokens
      Top-3 predictions: 'the'(24) 
