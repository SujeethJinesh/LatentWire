
>>> Combination 1: m64_dz256_rl2_rh4
    RUN_TAG=hero

=== CUDA preflight ===
torch: 2.4.0+cu121 cuda: 12.1 available: True
CUDA_VISIBLE_DEVICES: 0,1,2,3

=== Stage A: Llama latent fit ===

/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading dataset subset...
Loading SQuAD subset...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 3434.44it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:06,  2.07s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.92s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.82s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.20s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.46s/it]
[meta-llama/Meta-Llama-3.1-8B-Instruct] hf_device_map: {'model.embed_tokens': 0, 'model.rotary_emb': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 2, 'model.layers.17': 2, 'model.layers.18': 2, 'model.layers.19': 2, 'model.layers.20': 2, 'model.layers.21': 2, 'model.layers.22': 2, 'model.layers.23': 2, 'model.layers.24': 3, 'model.layers.25': 3, 'model.layers.26': 3, 'model.layers.27': 3, 'model.layers.28': 3, 'model.layers.29': 3, 'model.layers.30': 3, 'model.layers.31': 3, 'model.norm': 3, 'lm_head': 3}
trainable params: 41,943,040 || all params: 8,072,204,288 || trainable%: 0.5196
Llama hidden size: 4096
[DeviceMap] Llama: {'model.embed_tokens': 0, 'model.rotary_emb': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 2, 'model.layers.17': 2, 'model.layers.18': 2, 'model.layers.19': 2, 'model.layers.20': 2, 'model.layers.21': 2, 'model.layers.22': 2, 'model.layers.23': 2, 'model.layers.24': 3, 'model.layers.25': 3, 'model.layers.26': 3, 'model.layers.27': 3, 'model.layers.28': 3, 'model.layers.29': 3, 'model.layers.30': 3, 'model.layers.31': 3, 'model.norm': 3, 'lm_head': 3}
[INFO] llama anchor tokens: 3
⚠️  No valid checkpoint found to resume; starting fresh.
[warmup] alternating text/latent for first 334 steps
Epoch 1/6
[warmup] step=0 mode=text (warm-up)
We detected that you are passing `past_key_values` as a tuple of tuples. This is deprecated and will be removed in v4.47. Please convert your cache or use an appropriate `Cache` class (https://huggingface.co/docs/transformers/kv_cache#legacy-cache-format)
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
  step  1/334 | (warm-up text) | align=0.0002 | text_tf=14.1440 | latent_scale=0.00
[warmup] step=1 mode=text (warm-up)
  step  2/334 | (warm-up text) | align=0.0002 | text_tf=16.1462 | latent_scale=0.00
[warmup] step=2 mode=text (warm-up)
  step  3/334 | (warm-up text) | align=0.0002 | text_tf=16.1955 | latent_scale=0.00
[warmup] step=3 mode=text (warm-up)
  step  4/334 | (warm-up text) | align=0.0002 | text_tf=13.8191 | latent_scale=0.00
[warmup] step=4 mode=text (warm-up)
  step  5/334 | (warm-up text) | align=0.0002 | text_tf=16.4431 | latent_scale=0.01
[warmup] step=5 mode=text (warm-up)
  step  6/334 | (warm-up text) | align=0.0002 | text_tf=13.6501 | latent_scale=0.01
[warmup] step=6 mode=text (warm-up)
  step  7/334 | (warm-up text) | align=0.0002 | text_tf=13.0606 | latent_scale=0.01
[warmup] step=7 mode=text (warm-up)
  step  8/334 | (warm-up text) | align=0.0002 | text_tf=14.0702 | latent_scale=0.01
[warmup] step=8 mode=text (warm-up)
  step  9/334 | (warm-up text) | align=0.0002 | text_tf=14.7693 | latent_scale=0.01
[warmup] step=9 mode=text (warm-up)
  step  10/334 | (warm-up text) | align=0.0002 | text_tf=14.9338 | latent_scale=0.01
  step  10/334 | grad_norm=1.23 | sec/step~5.28 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=0.1940 first=0.1758 kCE=0.1939 KD=0.0000 acc=0.000 state=0.1878 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  11/334 | (warm-up text) | align=0.0002 | text_tf=16.6695 | latent_scale=0.01
  step  12/334 | (warm-up text) | align=0.0002 | text_tf=13.7340 | latent_scale=0.02
  step  13/334 | (warm-up text) | align=0.0002 | text_tf=17.3862 | latent_scale=0.02
  step  14/334 | (warm-up text) | align=0.0002 | text_tf=15.8871 | latent_scale=0.02
  step  15/334 | (warm-up text) | align=0.0002 | text_tf=12.4202 | latent_scale=0.02
  step  16/334 | (warm-up text) | align=0.0002 | text_tf=13.4626 | latent_scale=0.02
  step  17/334 | (warm-up text) | align=0.0002 | text_tf=15.1276 | latent_scale=0.02
  step  18/334 | (warm-up text) | align=0.0002 | text_tf=13.0911 | latent_scale=0.03
  step  19/334 | (warm-up text) | align=0.0002 | text_tf=13.3765 | latent_scale=0.03
  step  20/334 | (warm-up text) | align=0.0002 | text_tf=12.5400 | latent_scale=0.03
  step  20/334 | grad_norm=8.35 | sec/step~5.25 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=1.1107 first=1.0875 kCE=1.4856 KD=0.0000 acc=0.000 state=0.3924 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.2790e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  21/334 | (warm-up text) | align=0.0002 | text_tf=11.4718 | latent_scale=0.03
  step  22/334 | (warm-up text) | align=0.0002 | text_tf=13.2771 | latent_scale=0.03
  step  23/334 | (warm-up text) | align=0.0002 | text_tf=14.1634 | latent_scale=0.03
  step  24/334 | (warm-up text) | align=0.0002 | text_tf=12.4660 | latent_scale=0.03
  step  25/334 | (warm-up text) | align=0.0002 | text_tf=13.0823 | latent_scale=0.04
  step  26/334 | (warm-up text) | align=0.0002 | text_tf=15.2088 | latent_scale=0.04
  step  27/334 | (warm-up text) | align=0.0002 | text_tf=15.0620 | latent_scale=0.04
  step  28/334 | (warm-up text) | align=0.0002 | text_tf=13.5021 | latent_scale=0.04
  step  29/334 | (warm-up text) | align=0.0002 | text_tf=11.1458 | latent_scale=0.04
  step  30/334 | (warm-up text) | align=0.0002 | text_tf=10.5441 | latent_scale=0.04
  step  30/334 | grad_norm=1.54 | sec/step~5.63 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=0.9075 first=0.7977 kCE=1.1604 KD=0.0000 acc=0.000 state=0.5732 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=8.8818e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  31/334 | (warm-up text) | align=0.0002 | text_tf=11.4273 | latent_scale=0.04
  step  32/334 | (warm-up text) | align=0.0002 | text_tf=11.1402 | latent_scale=0.05
  step  33/334 | (warm-up text) | align=0.0002 | text_tf=10.2619 | latent_scale=0.05
  step  34/334 | (warm-up text) | align=0.0002 | text_tf=10.1640 | latent_scale=0.05
  step  35/334 | (warm-up text) | align=0.0002 | text_tf=10.2746 | latent_scale=0.05
  step  36/334 | (warm-up text) | align=0.0002 | text_tf=10.8596 | latent_scale=0.05
  step  37/334 | (warm-up text) | align=0.0002 | text_tf=11.4166 | latent_scale=0.05
  step  38/334 | (warm-up text) | align=0.0002 | text_tf=11.3533 | latent_scale=0.06
  step  39/334 | (warm-up text) | align=0.0002 | text_tf=10.6857 | latent_scale=0.06
  step  40/334 | (warm-up text) | align=0.0002 | text_tf=9.8226 | latent_scale=0.06
  step  40/334 | grad_norm=10.57 | sec/step~5.36 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=1.1468 first=1.0973 kCE=1.6394 KD=0.0000 acc=0.000 state=0.8347 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=8.8818e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  41/334 | (warm-up text) | align=0.0002 | text_tf=11.9088 | latent_scale=0.06
  step  42/334 | (warm-up text) | align=0.0002 | text_tf=11.1069 | latent_scale=0.06
  step  43/334 | (warm-up text) | align=0.0002 | text_tf=10.3179 | latent_scale=0.06
  step  44/334 | (warm-up text) | align=0.0002 | text_tf=9.7606 | latent_scale=0.06
  step  45/334 | (warm-up text) | align=0.0002 | text_tf=10.6542 | latent_scale=0.07
  step  46/334 | (warm-up text) | align=0.0002 | text_tf=9.8082 | latent_scale=0.07
  step  47/334 | (warm-up text) | align=0.0002 | text_tf=10.3499 | latent_scale=0.07
  step  48/334 | (warm-up text) | align=0.0002 | text_tf=8.8461 | latent_scale=0.07
  step  49/334 | (warm-up text) | align=0.0002 | text_tf=10.6550 | latent_scale=0.07
  step  50/334 | (warm-up text) | align=0.0002 | text_tf=9.5190 | latent_scale=0.07
  step  50/334 | grad_norm=4.75 | sec/step~5.79 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=1.0136 first=0.7309 kCE=1.2034 KD=0.0000 acc=0.000 state=1.0890 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=2.2027e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  51/334 | (warm-up text) | align=0.0002 | text_tf=8.8853 | latent_scale=0.07
  step  52/334 | (warm-up text) | align=0.0002 | text_tf=9.4034 | latent_scale=0.08
  step  53/334 | (warm-up text) | align=0.0002 | text_tf=8.7780 | latent_scale=0.08
  step  54/334 | (warm-up text) | align=0.0002 | text_tf=9.5662 | latent_scale=0.08
  step  55/334 | (warm-up text) | align=0.0002 | text_tf=9.7892 | latent_scale=0.08
  step  56/334 | (warm-up text) | align=0.0002 | text_tf=10.4849 | latent_scale=0.08
  step  57/334 | (warm-up text) | align=0.0002 | text_tf=9.8006 | latent_scale=0.08
  step  58/334 | (warm-up text) | align=0.0002 | text_tf=10.0370 | latent_scale=0.09
  step  59/334 | (warm-up text) | align=0.0002 | text_tf=9.4935 | latent_scale=0.09
  step  60/334 | (warm-up text) | align=0.0002 | text_tf=10.3553 | latent_scale=0.09
  step  60/334 | grad_norm=2.94 | sec/step~5.23 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=1.2584 first=1.0692 kCE=1.1980 KD=0.0000 acc=0.000 state=1.2376 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=5.2879e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  61/334 | (warm-up text) | align=0.0002 | text_tf=9.2453 | latent_scale=0.09
  step  62/334 | (warm-up text) | align=0.0002 | text_tf=8.9584 | latent_scale=0.09
  step  63/334 | (warm-up text) | align=0.0002 | text_tf=9.6514 | latent_scale=0.09
  step  64/334 | (warm-up text) | align=0.0002 | text_tf=7.9586 | latent_scale=0.09
  step  65/334 | (warm-up text) | align=0.0002 | text_tf=10.2699 | latent_scale=0.10
  step  66/334 | (warm-up text) | align=0.0002 | text_tf=9.0137 | latent_scale=0.10
  step  67/334 | (warm-up text) | align=0.0002 | text_tf=9.0301 | latent_scale=0.10
  step  68/334 | (warm-up text) | align=0.0002 | text_tf=9.5589 | latent_scale=0.10
  step  69/334 | (warm-up text) | align=0.0002 | text_tf=8.1446 | latent_scale=0.10
  step  70/334 | (warm-up text) | align=0.0002 | text_tf=9.2704 | latent_scale=0.10
  step  70/334 | grad_norm=11.02 | sec/step~5.35 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=1.4555 first=1.2685 kCE=1.3842 KD=0.0000 acc=0.000 state=1.3987 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=2.4387e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  71/334 | (warm-up text) | align=0.0002 | text_tf=8.6604 | latent_scale=0.10
  step  72/334 | (warm-up text) | align=0.0002 | text_tf=9.3890 | latent_scale=0.11
  step  73/334 | (warm-up text) | align=0.0002 | text_tf=8.3710 | latent_scale=0.11
  step  74/334 | (warm-up text) | align=0.0002 | text_tf=9.7342 | latent_scale=0.11
  step  75/334 | (warm-up text) | align=0.0002 | text_tf=9.3054 | latent_scale=0.11
  step  76/334 | (warm-up text) | align=0.0002 | text_tf=8.5094 | latent_scale=0.11
  step  77/334 | (warm-up text) | align=0.0002 | text_tf=8.2203 | latent_scale=0.11
  step  78/334 | (warm-up text) | align=0.0002 | text_tf=7.7668 | latent_scale=0.12
  step  79/334 | (warm-up text) | align=0.0002 | text_tf=8.5534 | latent_scale=0.12
  step  80/334 | (warm-up text) | align=0.0002 | text_tf=8.9686 | latent_scale=0.12
  step  80/334 | grad_norm=6.87 | sec/step~5.46 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=1.6642 first=1.3769 kCE=1.5599 KD=0.0000 acc=0.042 state=1.7702 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=2.4387e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  81/334 | (warm-up text) | align=0.0002 | text_tf=8.8870 | latent_scale=0.12
  step  82/334 | (warm-up text) | align=0.0002 | text_tf=9.4787 | latent_scale=0.12
  step  83/334 | (warm-up text) | align=0.0002 | text_tf=9.4303 | latent_scale=0.12
  step  84/334 | (warm-up text) | align=0.0002 | text_tf=8.9599 | latent_scale=0.12
  step  85/334 | (warm-up text) | align=0.0002 | text_tf=7.8194 | latent_scale=0.13
  step  86/334 | (warm-up text) | align=0.0002 | text_tf=8.8271 | latent_scale=0.13
  step  87/334 | (warm-up text) | align=0.0002 | text_tf=8.8509 | latent_scale=0.13
  step  88/334 | (warm-up text) | align=0.0002 | text_tf=9.3579 | latent_scale=0.13
  step  89/334 | (warm-up text) | align=0.0002 | text_tf=8.7695 | latent_scale=0.13
  step  90/334 | (warm-up text) | align=0.0002 | text_tf=8.5129 | latent_scale=0.13
  step  90/334 | grad_norm=3.02 | sec/step~5.55 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=1.5581 first=1.2038 kCE=1.6716 KD=0.0000 acc=0.042 state=1.8384 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=2.7512e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  91/334 | (warm-up text) | align=0.0002 | text_tf=8.4138 | latent_scale=0.13
  step  92/334 | (warm-up text) | align=0.0002 | text_tf=8.5785 | latent_scale=0.14
  step  93/334 | (warm-up text) | align=0.0002 | text_tf=8.8773 | latent_scale=0.14
  step  94/334 | (warm-up text) | align=0.0002 | text_tf=10.1566 | latent_scale=0.14
  step  95/334 | (warm-up text) | align=0.0002 | text_tf=7.9897 | latent_scale=0.14
  step  96/334 | (warm-up text) | align=0.0002 | text_tf=8.7712 | latent_scale=0.14
  step  97/334 | (warm-up text) | align=0.0002 | text_tf=8.6114 | latent_scale=0.14
  step  98/334 | (warm-up text) | align=0.0002 | text_tf=8.3247 | latent_scale=0.15
  step  99/334 | (warm-up text) | align=0.0002 | text_tf=9.0878 | latent_scale=0.15
  step  100/334 | (warm-up text) | align=0.0002 | text_tf=9.9039 | latent_scale=0.15
  step  100/334 | grad_norm=0.61 | sec/step~5.44 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=1.5779 first=1.1651 kCE=1.8135 KD=0.0000 acc=0.125 state=2.1334 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=8.7571e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  101/334 | (warm-up text) | align=0.0002 | text_tf=7.7986 | latent_scale=0.15
  step  102/334 | (warm-up text) | align=0.0002 | text_tf=8.0051 | latent_scale=0.15
  step  103/334 | (warm-up text) | align=0.0002 | text_tf=8.9010 | latent_scale=0.15
  step  104/334 | (warm-up text) | align=0.0002 | text_tf=9.3300 | latent_scale=0.15
  step  105/334 | (warm-up text) | align=0.0002 | text_tf=8.2518 | latent_scale=0.16
  step  106/334 | (warm-up text) | align=0.0002 | text_tf=8.8943 | latent_scale=0.16
  step  107/334 | (warm-up text) | align=0.0002 | text_tf=8.0064 | latent_scale=0.16
  step  108/334 | (warm-up text) | align=0.0002 | text_tf=7.4834 | latent_scale=0.16
  step  109/334 | (warm-up text) | align=0.0002 | text_tf=8.2842 | latent_scale=0.16
  step  110/334 | (warm-up text) | align=0.0002 | text_tf=8.2200 | latent_scale=0.16
  step  110/334 | grad_norm=2.73 | sec/step~5.52 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=1.7368 first=1.5146 kCE=2.0578 KD=0.0000 acc=0.042 state=2.2576 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=8.7571e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  111/334 | (warm-up text) | align=0.0002 | text_tf=8.3257 | latent_scale=0.16
  step  112/334 | (warm-up text) | align=0.0002 | text_tf=8.0114 | latent_scale=0.17
  step  113/334 | (warm-up text) | align=0.0002 | text_tf=8.9009 | latent_scale=0.17
  step  114/334 | (warm-up text) | align=0.0002 | text_tf=9.2054 | latent_scale=0.17
  step  115/334 | (warm-up text) | align=0.0002 | text_tf=7.9911 | latent_scale=0.17
  step  116/334 | (warm-up text) | align=0.0002 | text_tf=8.2285 | latent_scale=0.17
  step  117/334 | (warm-up text) | align=0.0002 | text_tf=7.8243 | latent_scale=0.17
  step  118/334 | (warm-up text) | align=0.0002 | text_tf=8.0141 | latent_scale=0.18
  step  119/334 | (warm-up text) | align=0.0002 | text_tf=7.3316 | latent_scale=0.18
  step  120/334 | (warm-up text) | align=0.0002 | text_tf=8.6454 | latent_scale=0.18
  step  120/334 | grad_norm=3.06 | sec/step~5.69 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=1.8882 first=1.6374 kCE=2.2048 KD=0.0000 acc=0.000 state=2.5771 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.0267e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  121/334 | (warm-up text) | align=0.0002 | text_tf=7.6438 | latent_scale=0.18
  step  122/334 | (warm-up text) | align=0.0002 | text_tf=7.8005 | latent_scale=0.18
  step  123/334 | (warm-up text) | align=0.0002 | text_tf=6.8181 | latent_scale=0.18
  step  124/334 | (warm-up text) | align=0.0002 | text_tf=8.6526 | latent_scale=0.18
  step  125/334 | (warm-up text) | align=0.0002 | text_tf=8.8248 | latent_scale=0.19
  step  126/334 | (warm-up text) | align=0.0002 | text_tf=7.7613 | latent_scale=0.19
  step  127/334 | (warm-up text) | align=0.0002 | text_tf=7.4787 | latent_scale=0.19
  step  128/334 | (warm-up text) | align=0.0002 | text_tf=6.9872 | latent_scale=0.19
  step  129/334 | (warm-up text) | align=0.0002 | text_tf=8.3450 | latent_scale=0.19
  step  130/334 | (warm-up text) | align=0.0002 | text_tf=8.8952 | latent_scale=0.19
  step  130/334 | grad_norm=1.71 | sec/step~5.59 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=2.1072 first=1.6198 kCE=2.4108 KD=0.0000 acc=0.000 state=2.7794 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=5.6403e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  131/334 | (warm-up text) | align=0.0002 | text_tf=6.8934 | latent_scale=0.19
  step  132/334 | (warm-up text) | align=0.0002 | text_tf=6.9211 | latent_scale=0.20
  step  133/334 | (warm-up text) | align=0.0002 | text_tf=8.4107 | latent_scale=0.20
  step  134/334 | (warm-up text) | align=0.0002 | text_tf=8.3878 | latent_scale=0.20
  step  135/334 | (warm-up text) | align=0.0002 | text_tf=7.7749 | latent_scale=0.20
  step  136/334 | (warm-up text) | align=0.0002 | text_tf=7.7439 | latent_scale=0.20
  step  137/334 | (warm-up text) | align=0.0002 | text_tf=7.7809 | latent_scale=0.20
  step  138/334 | (warm-up text) | align=0.0002 | text_tf=7.9497 | latent_scale=0.21
  step  139/334 | (warm-up text) | align=0.0002 | text_tf=7.0175 | latent_scale=0.21
  step  140/334 | (warm-up text) | align=0.0002 | text_tf=8.5722 | latent_scale=0.21
  step  140/334 | grad_norm=5.86 | sec/step~5.77 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=2.1966 first=1.8061 kCE=2.6186 KD=0.0000 acc=0.000 state=2.8927 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=5.4627e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  141/334 | (warm-up text) | align=0.0002 | text_tf=8.1189 | latent_scale=0.21
  step  142/334 | (warm-up text) | align=0.0002 | text_tf=7.8229 | latent_scale=0.21
  step  143/334 | (warm-up text) | align=0.0002 | text_tf=7.9509 | latent_scale=0.21
  step  144/334 | (warm-up text) | align=0.0002 | text_tf=7.3170 | latent_scale=0.21
  step  145/334 | (warm-up text) | align=0.0002 | text_tf=8.0918 | latent_scale=0.22
  step  146/334 | (warm-up text) | align=0.0002 | text_tf=7.2104 | latent_scale=0.22
  step  147/334 | (warm-up text) | align=0.0002 | text_tf=7.5275 | latent_scale=0.22
  step  148/334 | (warm-up text) | align=0.0002 | text_tf=6.7001 | latent_scale=0.22
  step  149/334 | (warm-up text) | align=0.0002 | text_tf=7.4525 | latent_scale=0.22
  step  150/334 | (warm-up text) | align=0.0002 | text_tf=7.8780 | latent_scale=0.22
  step  150/334 | grad_norm=2.23 | sec/step~5.37 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=2.4745 first=1.9218 kCE=2.6701 KD=0.0000 acc=0.000 state=3.1054 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=5.4627e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  151/334 | (warm-up text) | align=0.0002 | text_tf=7.6655 | latent_scale=0.22
  step  152/334 | (warm-up text) | align=0.0002 | text_tf=7.8164 | latent_scale=0.23
  step  153/334 | (warm-up text) | align=0.0002 | text_tf=7.4998 | latent_scale=0.23
  step  154/334 | (warm-up text) | align=0.0002 | text_tf=6.7095 | latent_scale=0.23
  step  155/334 | (warm-up text) | align=0.0002 | text_tf=8.0671 | latent_scale=0.23
  step  156/334 | (warm-up text) | align=0.0002 | text_tf=5.9169 | latent_scale=0.23
  step  157/334 | (warm-up text) | align=0.0002 | text_tf=6.4212 | latent_scale=0.23
  step  158/334 | (warm-up text) | align=0.0002 | text_tf=6.9867 | latent_scale=0.24
  step  159/334 | (warm-up text) | align=0.0002 | text_tf=7.4727 | latent_scale=0.24
  step  160/334 | (warm-up text) | align=0.0002 | text_tf=6.8334 | latent_scale=0.24
  step  160/334 | grad_norm=2.14 | sec/step~5.86 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=2.5175 first=2.0166 kCE=2.5917 KD=0.0000 acc=0.000 state=3.4001 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=2.4475e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  161/334 | (warm-up text) | align=0.0002 | text_tf=8.0480 | latent_scale=0.24
  step  162/334 | (warm-up text) | align=0.0002 | text_tf=6.9228 | latent_scale=0.24
  step  163/334 | (warm-up text) | align=0.0002 | text_tf=6.6756 | latent_scale=0.24
  step  164/334 | (warm-up text) | align=0.0002 | text_tf=7.0730 | latent_scale=0.24
  step  165/334 | (warm-up text) | align=0.0002 | text_tf=7.9575 | latent_scale=0.25
  step  166/334 | (warm-up text) | align=0.0002 | text_tf=7.1128 | latent_scale=0.25
  step  167/334 | (warm-up text) | align=0.0002 | text_tf=6.8409 | latent_scale=0.25
  step  168/334 | (warm-up text) | align=0.0002 | text_tf=7.4175 | latent_scale=0.25
  step  169/334 | (warm-up text) | align=0.0002 | text_tf=7.3065 | latent_scale=0.25
  step  170/334 | (warm-up text) | align=0.0002 | text_tf=7.9376 | latent_scale=0.25
  step  170/334 | grad_norm=0.82 | sec/step~5.79 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=2.6693 first=2.2469 kCE=2.7108 KD=0.0000 acc=0.083 state=3.3183 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.2291e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  171/334 | (warm-up text) | align=0.0002 | text_tf=7.3970 | latent_scale=0.25
  step  172/334 | (warm-up text) | align=0.0002 | text_tf=5.8061 | latent_scale=0.26
  step  173/334 | (warm-up text) | align=0.0002 | text_tf=7.4392 | latent_scale=0.26
  step  174/334 | (warm-up text) | align=0.0002 | text_tf=7.6858 | latent_scale=0.26
  step  175/334 | (warm-up text) | align=0.0002 | text_tf=6.3060 | latent_scale=0.26
  step  176/334 | (warm-up text) | align=0.0002 | text_tf=6.5152 | latent_scale=0.26
  step  177/334 | (warm-up text) | align=0.0002 | text_tf=7.3492 | latent_scale=0.26
  step  178/334 | (warm-up text) | align=0.0002 | text_tf=6.9142 | latent_scale=0.26
  step  179/334 | (warm-up text) | align=0.0002 | text_tf=6.1288 | latent_scale=0.27
  step  180/334 | (warm-up text) | align=0.0002 | text_tf=6.3851 | latent_scale=0.27
  step  180/334 | grad_norm=4.40 | sec/step~5.37 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=2.6625 first=2.3221 kCE=2.7912 KD=0.0000 acc=0.000 state=3.7587 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.2291e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  181/334 | (warm-up text) | align=0.0002 | text_tf=7.0077 | latent_scale=0.27
  step  182/334 | (warm-up text) | align=0.0002 | text_tf=6.6727 | latent_scale=0.27
  step  183/334 | (warm-up text) | align=0.0002 | text_tf=6.4736 | latent_scale=0.27
  step  184/334 | (warm-up text) | align=0.0002 | text_tf=6.2441 | latent_scale=0.27
  step  185/334 | (warm-up text) | align=0.0002 | text_tf=7.0816 | latent_scale=0.28
  step  186/334 | (warm-up text) | align=0.0002 | text_tf=6.8706 | latent_scale=0.28
  step  187/334 | (warm-up text) | align=0.0002 | text_tf=6.4869 | latent_scale=0.28
  step  188/334 | (warm-up text) | align=0.0002 | text_tf=6.0030 | latent_scale=0.28
  step  189/334 | (warm-up text) | align=0.0002 | text_tf=6.8422 | latent_scale=0.28
  step  190/334 | (warm-up text) | align=0.0002 | text_tf=6.1358 | latent_scale=0.28
  step  190/334 | grad_norm=2.62 | sec/step~5.79 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=2.5943 first=2.3089 kCE=2.8963 KD=0.0000 acc=0.000 state=3.9860 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=4.5365e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  191/334 | (warm-up text) | align=0.0002 | text_tf=5.9868 | latent_scale=0.28
  step  192/334 | (warm-up text) | align=0.0002 | text_tf=6.1762 | latent_scale=0.29
  step  193/334 | (warm-up text) | align=0.0002 | text_tf=6.4217 | latent_scale=0.29
  step  194/334 | (warm-up text) | align=0.0002 | text_tf=5.8332 | latent_scale=0.29
  step  195/334 | (warm-up text) | align=0.0002 | text_tf=5.8153 | latent_scale=0.29
  step  196/334 | (warm-up text) | align=0.0002 | text_tf=6.8430 | latent_scale=0.29
  step  197/334 | (warm-up text) | align=0.0002 | text_tf=6.2434 | latent_scale=0.29
  step  198/334 | (warm-up text) | align=0.0002 | text_tf=6.6912 | latent_scale=0.29
  step  199/334 | (warm-up text) | align=0.0002 | text_tf=6.6564 | latent_scale=0.30
  step  200/334 | (warm-up text) | align=0.0002 | text_tf=6.0160 | latent_scale=0.30
  step  200/334 | grad_norm=1.41 | sec/step~5.98 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=2.9572 first=2.1751 kCE=3.0361 KD=0.0000 acc=0.083 state=4.3436 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.1951e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  201/334 | (warm-up text) | align=0.0002 | text_tf=5.7751 | latent_scale=0.30
  step  202/334 | (warm-up text) | align=0.0002 | text_tf=6.1037 | latent_scale=0.30
  step  203/334 | (warm-up text) | align=0.0002 | text_tf=6.7788 | latent_scale=0.30
  step  204/334 | (warm-up text) | align=0.0002 | text_tf=6.3883 | latent_scale=0.30
  step  205/334 | (warm-up text) | align=0.0002 | text_tf=6.4261 | latent_scale=0.31
  step  206/334 | (warm-up text) | align=0.0002 | text_tf=6.1388 | latent_scale=0.31
  step  207/334 | (warm-up text) | align=0.0002 | text_tf=7.1551 | latent_scale=0.31
  step  208/334 | (warm-up text) | align=0.0002 | text_tf=5.8478 | latent_scale=0.31
  step  209/334 | (warm-up text) | align=0.0002 | text_tf=7.5354 | latent_scale=0.31
  step  210/334 | (warm-up text) | align=0.0002 | text_tf=6.1907 | latent_scale=0.31
  step  210/334 | grad_norm=3.94 | sec/step~5.75 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=3.0917 first=2.5834 kCE=3.2120 KD=0.0000 acc=0.042 state=4.4543 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=7.9936e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  211/334 | (warm-up text) | align=0.0002 | text_tf=6.7271 | latent_scale=0.31
  step  212/334 | (warm-up text) | align=0.0002 | text_tf=6.6384 | latent_scale=0.32
  step  213/334 | (warm-up text) | align=0.0002 | text_tf=6.1613 | latent_scale=0.32
  step  214/334 | (warm-up text) | align=0.0002 | text_tf=6.1719 | latent_scale=0.32
  step  215/334 | (warm-up text) | align=0.0002 | text_tf=6.3439 | latent_scale=0.32
  step  216/334 | (warm-up text) | align=0.0002 | text_tf=6.7483 | latent_scale=0.32
  step  217/334 | (warm-up text) | align=0.0002 | text_tf=6.8262 | latent_scale=0.32
  step  218/334 | (warm-up text) | align=0.0002 | text_tf=6.4285 | latent_scale=0.32
  step  219/334 | (warm-up text) | align=0.0002 | text_tf=6.0793 | latent_scale=0.33
  step  220/334 | (warm-up text) | align=0.0002 | text_tf=6.0388 | latent_scale=0.33
  step  220/334 | grad_norm=2.00 | sec/step~6.06 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=3.0420 first=2.7105 kCE=3.1369 KD=0.0000 acc=0.083 state=4.5455 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=7.9936e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  221/334 | (warm-up text) | align=0.0002 | text_tf=6.0297 | latent_scale=0.33
  step  222/334 | (warm-up text) | align=0.0002 | text_tf=7.2834 | latent_scale=0.33
  step  223/334 | (warm-up text) | align=0.0002 | text_tf=6.2624 | latent_scale=0.33
  step  224/334 | (warm-up text) | align=0.0002 | text_tf=6.4429 | latent_scale=0.33
  step  225/334 | (warm-up text) | align=0.0002 | text_tf=6.6686 | latent_scale=0.34
  step  226/334 | (warm-up text) | align=0.0002 | text_tf=6.6919 | latent_scale=0.34
  step  227/334 | (warm-up text) | align=0.0002 | text_tf=6.4557 | latent_scale=0.34
  step  228/334 | (warm-up text) | align=0.0002 | text_tf=6.3893 | latent_scale=0.34
  step  229/334 | (warm-up text) | align=0.0002 | text_tf=5.5240 | latent_scale=0.34
  step  230/334 | (warm-up text) | align=0.0002 | text_tf=6.0384 | latent_scale=0.34
  step  230/334 | grad_norm=1.89 | sec/step~5.73 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=3.2208 first=2.8112 kCE=3.1275 KD=0.0000 acc=0.083 state=4.8202 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.4211e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  231/334 | (warm-up text) | align=0.0002 | text_tf=5.8497 | latent_scale=0.34
  step  232/334 | (warm-up text) | align=0.0002 | text_tf=6.0682 | latent_scale=0.35
  step  233/334 | (warm-up text) | align=0.0002 | text_tf=6.8173 | latent_scale=0.35
  step  234/334 | (warm-up text) | align=0.0002 | text_tf=5.5925 | latent_scale=0.35
  step  235/334 | (warm-up text) | align=0.0002 | text_tf=6.3760 | latent_scale=0.35
  step  236/334 | (warm-up text) | align=0.0002 | text_tf=6.6862 | latent_scale=0.35
  step  237/334 | (warm-up text) | align=0.0002 | text_tf=6.1670 | latent_scale=0.35
  step  238/334 | (warm-up text) | align=0.0002 | text_tf=6.0006 | latent_scale=0.35
  step  239/334 | (warm-up text) | align=0.0002 | text_tf=6.4053 | latent_scale=0.36
  step  240/334 | (warm-up text) | align=0.0002 | text_tf=6.2380 | latent_scale=0.36
  step  240/334 | grad_norm=0.91 | sec/step~5.44 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=3.5511 first=3.0123 kCE=3.1890 KD=0.0000 acc=0.042 state=4.8413 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=5.0310e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  241/334 | (warm-up text) | align=0.0002 | text_tf=6.1732 | latent_scale=0.36
  step  242/334 | (warm-up text) | align=0.0002 | text_tf=6.0709 | latent_scale=0.36
  step  243/334 | (warm-up text) | align=0.0002 | text_tf=6.3631 | latent_scale=0.36
  step  244/334 | (warm-up text) | align=0.0002 | text_tf=5.6712 | latent_scale=0.36
  step  245/334 | (warm-up text) | align=0.0002 | text_tf=6.2155 | latent_scale=0.37
  step  246/334 | (warm-up text) | align=0.0002 | text_tf=5.9286 | latent_scale=0.37
  step  247/334 | (warm-up text) | align=0.0002 | text_tf=6.5541 | latent_scale=0.37
  step  248/334 | (warm-up text) | align=0.0002 | text_tf=5.9173 | latent_scale=0.37
  step  249/334 | (warm-up text) | align=0.0002 | text_tf=5.8302 | latent_scale=0.37
  step  250/334 | (warm-up text) | align=0.0002 | text_tf=5.5498 | latent_scale=0.37
  step  250/334 | grad_norm=2.81 | sec/step~5.82 | keep=0.70 | K=8 | first_w=3.00 | llama(T): tf=3.4371 first=3.0631 kCE=3.2179 KD=0.0000 acc=0.000 state=5.2527 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=5.0310e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  251/334 | (warm-up text) | align=0.0002 | text_tf=6.4394 | latent_scale=0.37
  step  252/334 | (warm-up text) | align=0.0002 | text_tf=5.7594 | latent_scale=0.38
  step  253/334 | (warm-up text) | align=0.0002 | text_tf=5.3105 | latent_scale=0.38
  step  254/334 | (warm-up text) | align=0.0002 | text_tf=6.0345 | latent_scale=0.38
  step  255/334 | (warm-up text) | align=0.0002 | text_tf=6.3857 | latent_scale=0.38
  step  256/334 | (warm-up text) | align=0.0002 | text_tf=5.2934 | latent_scale=0.38
  step  257/334 | (warm-up text) | align=0.0002 | text_tf=5.9362 | latent_scale=0.38
  step  258/334 | (warm-up text) | align=0.0002 | text_tf=5.3571 | latent_scale=0.38
  step  259/334 | (warm-up text) | align=0.0002 | text_tf=5.9053 | latent_scale=0.39
  step  260/334 | (warm-up text) | align=0.0002 | text_tf=5.6150 | latent_scale=0.39
  step  260/334 | grad_norm=1.96 | sec/step~5.32 | keep=0.71 | K=8 | first_w=3.00 | llama(T): tf=3.6256 first=3.2585 kCE=3.2893 KD=0.0000 acc=0.000 state=5.1271 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=4.2210e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  261/334 | (warm-up text) | align=0.0002 | text_tf=5.7424 | latent_scale=0.39
  step  262/334 | (warm-up text) | align=0.0002 | text_tf=5.8257 | latent_scale=0.39
  step  263/334 | (warm-up text) | align=0.0002 | text_tf=6.3852 | latent_scale=0.39
  step  264/334 | (warm-up text) | align=0.0002 | text_tf=4.7437 | latent_scale=0.39
  step  265/334 | (warm-up text) | align=0.0002 | text_tf=5.2147 | latent_scale=0.40
  step  266/334 | (warm-up text) | align=0.0002 | text_tf=5.5725 | latent_scale=0.40
  step  267/334 | (warm-up text) | align=0.0002 | text_tf=5.5480 | latent_scale=0.40
  step  268/334 | (warm-up text) | align=0.0002 | text_tf=6.4019 | latent_scale=0.40
  step  269/334 | (warm-up text) | align=0.0002 | text_tf=6.1132 | latent_scale=0.40
  step  270/334 | (warm-up text) | align=0.0002 | text_tf=6.2576 | latent_scale=0.40
  step  270/334 | grad_norm=1.60 | sec/step~6.94 | keep=0.71 | K=8 | first_w=3.00 | llama(T): tf=3.7896 first=3.1093 kCE=3.3359 KD=0.0000 acc=0.250 state=5.6962 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  271/334 | (warm-up text) | align=0.0002 | text_tf=6.0871 | latent_scale=0.40
  step  272/334 | (warm-up text) | align=0.0002 | text_tf=6.4456 | latent_scale=0.41
  step  273/334 | (warm-up text) | align=0.0002 | text_tf=5.5525 | latent_scale=0.41
  step  274/334 | (warm-up text) | align=0.0002 | text_tf=6.1588 | latent_scale=0.41
  step  275/334 | (warm-up text) | align=0.0002 | text_tf=5.7518 | latent_scale=0.41
  step  276/334 | (warm-up text) | align=0.0002 | text_tf=5.6584 | latent_scale=0.41
  step  277/334 | (warm-up text) | align=0.0002 | text_tf=6.2877 | latent_scale=0.41
  step  278/334 | (warm-up text) | align=0.0002 | text_tf=5.9086 | latent_scale=0.41
  step  279/334 | (warm-up text) | align=0.0002 | text_tf=4.6169 | latent_scale=0.42
  step  280/334 | (warm-up text) | align=0.0002 | text_tf=5.5648 | latent_scale=0.42
  step  280/334 | grad_norm=3.87 | sec/step~5.85 | keep=0.71 | K=8 | first_w=3.00 | llama(T): tf=3.8799 first=3.0628 kCE=3.3209 KD=0.0000 acc=0.125 state=5.8563 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=4.2988e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0000 rms_cal~0.0106 embed_rms~0.01058]
  step  281/334 | (warm-up text) | align=0.0002 | text_tf=5.7904 | latent_scale=0.42
  step  282/334 | (warm-up text) | align=0.0002 | text_tf=5.2789 | latent_scale=0.42
  step  283/334 | (warm-up text) | align=0.0002 | text_tf=4.9365 | latent_scale=0.42
  step  284/334 | (warm-up text) | align=0.0002 | text_tf=5.1067 | latent_scale=0.42
  step  285/334 | (warm-up text) | align=0.0002 | text_tf=5.9499 | latent_scale=0.43
  step  286/334 | (warm-up text) | align=0.0002 | text_tf=5.6055 | latent_scale=0.43
  step  287/334 | (warm-up text) | align=0.0002 | text_tf=6.0660 | latent_scale=0.43
  step  288/334 | (warm-up text) | align=0.0002 | text_tf=6.0645 | latent_scale=0.43
  step  289/334 | (warm-up text) | align=0.0002 | text_tf=5.6772 | latent_scale=0.43
  step  290/334 | (warm-up text) | align=0.0002 | text_tf=5.2175 | latent_scale=0.43
  step  290/334 | grad_norm=2.96 | sec/step~5.49 | keep=0.71 | K=8 | first_w=3.00 | llama(T): tf=4.0768 first=3.4280 kCE=3.1903 KD=0.0000 acc=0.042 state=5.8986 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=4.2988e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  291/334 | (warm-up text) | align=0.0002 | text_tf=5.1806 | latent_scale=0.43
  step  292/334 | (warm-up text) | align=0.0002 | text_tf=5.9492 | latent_scale=0.44
  step  293/334 | (warm-up text) | align=0.0002 | text_tf=5.2770 | latent_scale=0.44
  step  294/334 | (warm-up text) | align=0.0002 | text_tf=5.9799 | latent_scale=0.44
  step  295/334 | (warm-up text) | align=0.0002 | text_tf=6.0577 | latent_scale=0.44
  step  296/334 | (warm-up text) | align=0.0002 | text_tf=5.8914 | latent_scale=0.44
  step  297/334 | (warm-up text) | align=0.0002 | text_tf=5.7293 | latent_scale=0.44
  step  298/334 | (warm-up text) | align=0.0002 | text_tf=5.9110 | latent_scale=0.44
  step  299/334 | (warm-up text) | align=0.0002 | text_tf=5.2682 | latent_scale=0.45
  step  300/334 | (warm-up text) | align=0.0002 | text_tf=5.8252 | latent_scale=0.45
  step  300/334 | grad_norm=2.18 | sec/step~5.29 | keep=0.71 | K=8 | first_w=3.00 | llama(T): tf=4.2204 first=3.6483 kCE=3.0374 KD=0.0000 acc=0.000 state=5.7033 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=4.6171e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  301/334 | (warm-up text) | align=0.0002 | text_tf=5.9153 | latent_scale=0.45
  step  302/334 | (warm-up text) | align=0.0002 | text_tf=6.1270 | latent_scale=0.45
  step  303/334 | (warm-up text) | align=0.0002 | text_tf=5.6037 | latent_scale=0.45
  step  304/334 | (warm-up text) | align=0.0002 | text_tf=6.7497 | latent_scale=0.45
  step  305/334 | (warm-up text) | align=0.0002 | text_tf=5.8303 | latent_scale=0.46
  step  306/334 | (warm-up text) | align=0.0002 | text_tf=4.9876 | latent_scale=0.46
  step  307/334 | (warm-up text) | align=0.0002 | text_tf=5.2206 | latent_scale=0.46
  step  308/334 | (warm-up text) | align=0.0002 | text_tf=5.4110 | latent_scale=0.46
  step  309/334 | (warm-up text) | align=0.0002 | text_tf=5.6718 | latent_scale=0.46
  step  310/334 | (warm-up text) | align=0.0002 | text_tf=5.5876 | latent_scale=0.46
  step  310/334 | grad_norm=1.30 | sec/step~5.44 | keep=0.71 | K=8 | first_w=3.00 | llama(T): tf=4.2788 first=3.7275 kCE=3.1430 KD=0.0000 acc=0.000 state=5.9177 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.4211e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  311/334 | (warm-up text) | align=0.0002 | text_tf=5.9581 | latent_scale=0.46
  step  312/334 | (warm-up text) | align=0.0002 | text_tf=5.7918 | latent_scale=0.47
  step  313/334 | (warm-up text) | align=0.0002 | text_tf=5.5410 | latent_scale=0.47
  step  314/334 | (warm-up text) | align=0.0002 | text_tf=5.2167 | latent_scale=0.47
  step  315/334 | (warm-up text) | align=0.0002 | text_tf=5.4152 | latent_scale=0.47
  step  316/334 | (warm-up text) | align=0.0002 | text_tf=5.6039 | latent_scale=0.47
  step  317/334 | (warm-up text) | align=0.0002 | text_tf=5.9120 | latent_scale=0.47
  step  318/334 | (warm-up text) | align=0.0002 | text_tf=5.9880 | latent_scale=0.47
  step  319/334 | (warm-up text) | align=0.0002 | text_tf=4.9230 | latent_scale=0.48
  step  320/334 | (warm-up text) | align=0.0002 | text_tf=5.6800 | latent_scale=0.48
  step  320/334 | grad_norm=5.43 | sec/step~5.32 | keep=0.71 | K=8 | first_w=3.00 | llama(T): tf=4.5104 first=3.6658 kCE=3.2629 KD=0.0000 acc=0.083 state=6.1895 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.4211e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  321/334 | (warm-up text) | align=0.0002 | text_tf=5.2108 | latent_scale=0.48
  step  322/334 | (warm-up text) | align=0.0002 | text_tf=5.5006 | latent_scale=0.48
  step  323/334 | (warm-up text) | align=0.0002 | text_tf=5.3419 | latent_scale=0.48
  step  324/334 | (warm-up text) | align=0.0002 | text_tf=5.6209 | latent_scale=0.48
  step  325/334 | (warm-up text) | align=0.0002 | text_tf=5.7640 | latent_scale=0.49
  step  326/334 | (warm-up text) | align=0.0002 | text_tf=4.7592 | latent_scale=0.49
  step  327/334 | (warm-up text) | align=0.0002 | text_tf=6.2584 | latent_scale=0.49
  step  328/334 | (warm-up text) | align=0.0002 | text_tf=5.1802 | latent_scale=0.49
  step  329/334 | (warm-up text) | align=0.0002 | text_tf=5.4824 | latent_scale=0.49
  step  330/334 | (warm-up text) | align=0.0002 | text_tf=5.2433 | latent_scale=0.49
  step  330/334 | grad_norm=5.27 | sec/step~5.41 | keep=0.71 | K=8 | first_w=3.00 | llama(T): tf=4.4226 first=3.7494 kCE=3.1311 KD=0.0000 acc=0.000 state=6.5935 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=2.0520e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  331/334 | (warm-up text) | align=0.0002 | text_tf=5.1627 | latent_scale=0.49
  step  332/334 | (warm-up text) | align=0.0002 | text_tf=4.5660 | latent_scale=0.50
  step  333/334 | (warm-up text) | align=0.0002 | text_tf=5.8400 | latent_scale=0.50
  step  334/334 | (warm-up text) | align=0.0002 | text_tf=6.1229 | latent_scale=0.50
  step  334/334 | grad_norm=7.35 | sec/step~4.07 | keep=0.71 | K=8 | first_w=3.00 | llama(T): tf=5.0145 first=4.1244 kCE=3.1462 KD=0.0000 acc=0.000 state=6.6852 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=6.4748e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
[checkpoint] Freed 3.5KB before save.
[checkpoint] Saved latest: encoder.pt, state.pt, config.json, adapter_llama.pt, deep_prefix_llama.pt, refiner.pt
[checkpoint] Freed 0.0B after save (non-canonical).
  ✅ Saved (and pruned to) latest at step 334
Epoch 2/6
  step  10/334 | grad_norm=17.11 | sec/step~4.03 | keep=0.71 | K=8 | first_w=3.00 | llama(L): tf=9.1228 first=6.9629 kCE=6.1789 KD=20.1000 acc=0.125 state=14.2304 align=0.0000 latA=0.4959 latP=0.2487 | scale_pen(llama)=6.4748e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  20/334 | grad_norm=12.74 | sec/step~3.72 | keep=0.71 | K=8 | first_w=3.00 | llama(L): tf=9.1627 first=7.4213 kCE=5.2224 KD=16.7058 acc=0.042 state=12.5353 align=0.0000 latA=0.4961 latP=0.2487 | scale_pen(llama)=1.0267e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  30/334 | grad_norm=41.29 | sec/step~3.55 | keep=0.71 | K=8 | first_w=3.00 | llama(L): tf=15.5220 first=10.0214 kCE=12.2444 KD=11.0073 acc=0.000 state=12.5129 align=0.0000 latA=0.4973 latP=0.2486 | scale_pen(llama)=1.1898e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  40/334 | grad_norm=244.10 | sec/step~3.58 | keep=0.71 | K=8 | first_w=3.00 | llama(L): tf=15.8177 first=10.2393 kCE=12.3035 KD=11.4169 acc=0.000 state=13.1946 align=0.0000 latA=0.4970 latP=0.2488 | scale_pen(llama)=1.1898e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  50/334 | grad_norm=10.80 | sec/step~3.65 | keep=0.71 | K=8 | first_w=3.00 | llama(L): tf=9.1390 first=6.9986 kCE=5.3703 KD=13.3096 acc=0.125 state=13.2222 align=0.0000 latA=0.4984 latP=0.2487 | scale_pen(llama)=1.3234e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  60/334 | grad_norm=11.49 | sec/step~3.49 | keep=0.71 | K=8 | first_w=3.00 | llama(L): tf=8.7377 first=7.1553 kCE=5.7186 KD=17.8037 acc=0.000 state=11.7385 align=0.0000 latA=0.4946 latP=0.2487 | scale_pen(llama)=1.0147e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  70/334 | grad_norm=37.80 | sec/step~3.90 | keep=0.71 | K=8 | first_w=3.00 | llama(L): tf=9.7309 first=7.4028 kCE=6.0231 KD=17.6255 acc=0.000 state=12.1549 align=0.0000 latA=0.4972 latP=0.2486 | scale_pen(llama)=6.2844e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  80/334 | grad_norm=31.23 | sec/step~3.86 | keep=0.71 | K=8 | first_w=3.00 | llama(L): tf=9.3493 first=7.4716 kCE=6.7969 KD=16.6592 acc=0.042 state=13.7603 align=0.0000 latA=0.4981 latP=0.2487 | scale_pen(llama)=6.2844e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  90/334 | grad_norm=9.80 | sec/step~3.60 | keep=0.71 | K=8 | first_w=3.00 | llama(L): tf=8.6469 first=7.2948 kCE=5.8747 KD=16.5365 acc=0.125 state=13.1016 align=0.0000 latA=0.4970 latP=0.2487 | scale_pen(llama)=2.8777e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  100/334 | grad_norm=2.88 | sec/step~3.91 | keep=0.71 | K=8 | first_w=3.00 | llama(L): tf=8.9869 first=7.9661 kCE=6.7790 KD=16.1467 acc=0.083 state=13.8071 align=0.0000 latA=0.4973 latP=0.2489 | scale_pen(llama)=4.6043e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  110/334 | grad_norm=15.21 | sec/step~3.72 | keep=0.71 | K=8 | first_w=3.00 | llama(L): tf=9.2514 first=8.1993 kCE=6.4745 KD=17.3626 acc=0.083 state=13.0670 align=0.0000 latA=0.4982 latP=0.2490 | scale_pen(llama)=4.6043e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  120/334 | grad_norm=10.09 | sec/step~3.88 | keep=0.72 | K=8 | first_w=3.00 | llama(L): tf=9.1906 first=8.5373 kCE=5.9268 KD=16.0405 acc=0.000 state=13.2070 align=0.0000 latA=0.4966 latP=0.2489 | scale_pen(llama)=1.4211e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  130/334 | grad_norm=4.83 | sec/step~3.98 | keep=0.72 | K=8 | first_w=3.00 | llama(L): tf=8.9990 first=7.8660 kCE=6.0852 KD=13.5292 acc=0.042 state=14.1310 align=0.0000 latA=0.4951 latP=0.2491 | scale_pen(llama)=1.5476e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  140/334 | grad_norm=14.83 | sec/step~3.79 | keep=0.72 | K=8 | first_w=3.00 | llama(L): tf=9.2266 first=9.1583 kCE=5.6347 KD=13.5056 acc=0.000 state=13.7528 align=0.0000 latA=0.4993 latP=0.2494 | scale_pen(llama)=2.8777e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  150/334 | grad_norm=8.75 | sec/step~3.82 | keep=0.72 | K=8 | first_w=3.00 | llama(L): tf=10.0684 first=7.3013 kCE=7.5379 KD=11.1702 acc=0.042 state=12.8033 align=0.0000 latA=0.4977 latP=0.2493 | scale_pen(llama)=2.8777e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  160/334 | grad_norm=9.02 | sec/step~3.71 | keep=0.72 | K=8 | first_w=3.00 | llama(L): tf=11.3708 first=7.3186 kCE=8.9800 KD=10.0643 acc=0.042 state=12.4416 align=0.0000 latA=0.4983 latP=0.2493 | scale_pen(llama)=2.5068e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  170/334 | grad_norm=3.02 | sec/step~3.63 | keep=0.72 | K=8 | first_w=3.00 | llama(L): tf=12.1370 first=7.3526 kCE=9.3725 KD=10.9622 acc=0.042 state=11.7224 align=0.0000 latA=0.4980 latP=0.2495 | scale_pen(llama)=1.3657e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  180/334 | grad_norm=14.73 | sec/step~3.94 | keep=0.72 | K=8 | first_w=3.00 | llama(L): tf=10.6811 first=7.3918 kCE=8.2285 KD=8.6269 acc=0.125 state=13.8885 align=0.0000 latA=0.4971 latP=0.2493 | scale_pen(llama)=1.3657e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  190/334 | grad_norm=6.99 | sec/step~3.64 | keep=0.72 | K=8 | first_w=3.00 | llama(L): tf=9.5360 first=7.0382 kCE=6.5422 KD=10.4356 acc=0.083 state=13.3604 align=0.0000 latA=0.4978 latP=0.2492 | scale_pen(llama)=2.7853e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  200/334 | grad_norm=5.23 | sec/step~3.82 | keep=0.72 | K=8 | first_w=3.00 | llama(L): tf=9.0051 first=7.7786 kCE=4.8612 KD=11.0062 acc=0.000 state=13.3799 align=0.0000 latA=0.4983 latP=0.2490 | scale_pen(llama)=6.9633e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  210/334 | grad_norm=15.35 | sec/step~3.86 | keep=0.72 | K=8 | first_w=3.00 | llama(L): tf=9.8952 first=7.0878 kCE=5.8480 KD=11.5188 acc=0.083 state=13.4714 align=0.0000 latA=0.4984 latP=0.2491 | scale_pen(llama)=8.8818e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  220/334 | grad_norm=10.62 | sec/step~3.98 | keep=0.72 | K=8 | first_w=3.00 | llama(L): tf=10.0700 first=7.9279 kCE=5.7399 KD=11.1737 acc=0.042 state=13.6309 align=0.0000 latA=0.4972 latP=0.2488 | scale_pen(llama)=8.8818e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  230/334 | grad_norm=7.02 | sec/step~4.08 | keep=0.72 | K=8 | first_w=3.00 | llama(L): tf=10.3629 first=7.8293 kCE=5.9121 KD=9.5397 acc=0.042 state=14.4160 align=0.0000 latA=0.4993 latP=0.2490 | scale_pen(llama)=1.7408e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  240/334 | grad_norm=2.46 | sec/step~4.00 | keep=0.72 | K=8 | first_w=3.00 | llama(L): tf=9.7440 first=8.3745 kCE=5.8245 KD=8.5555 acc=0.000 state=14.2734 align=0.0000 latA=0.4973 latP=0.2488 | scale_pen(llama)=1.7909e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  250/334 | grad_norm=8.35 | sec/step~3.49 | keep=0.73 | K=8 | first_w=3.00 | llama(L): tf=9.8705 first=8.3031 kCE=5.6978 KD=8.8773 acc=0.042 state=12.7826 align=0.0000 latA=0.4979 latP=0.2487 | scale_pen(llama)=1.7909e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  260/334 | grad_norm=9.61 | sec/step~4.04 | keep=0.73 | K=8 | first_w=3.00 | llama(L): tf=10.8034 first=7.8507 kCE=7.4282 KD=8.1522 acc=0.125 state=13.6914 align=0.0000 latA=0.4966 latP=0.2485 | scale_pen(llama)=6.8781e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  270/334 | grad_norm=4.63 | sec/step~4.02 | keep=0.73 | K=8 | first_w=3.00 | llama(L): tf=10.1708 first=7.6063 kCE=6.0674 KD=7.5531 acc=0.000 state=13.5772 align=0.0000 latA=0.4978 latP=0.2488 | scale_pen(llama)=1.7408e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  280/334 | grad_norm=15.88 | sec/step~3.57 | keep=0.73 | K=8 | first_w=3.00 | llama(L): tf=10.6074 first=6.5587 kCE=6.4327 KD=8.5976 acc=0.083 state=12.0094 align=0.0000 latA=0.4983 latP=0.2487 | scale_pen(llama)=2.7853e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  290/334 | grad_norm=8.57 | sec/step~4.02 | keep=0.73 | K=8 | first_w=3.00 | llama(L): tf=10.5567 first=8.0509 kCE=5.2887 KD=8.1166 acc=0.000 state=12.4411 align=0.0000 latA=0.4975 latP=0.2486 | scale_pen(llama)=2.7853e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  300/334 | grad_norm=7.07 | sec/step~3.62 | keep=0.73 | K=8 | first_w=3.00 | llama(L): tf=9.4811 first=7.4070 kCE=5.8432 KD=8.3525 acc=0.000 state=13.7378 align=0.0000 latA=0.4978 latP=0.2485 | scale_pen(llama)=8.8818e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  310/334 | grad_norm=1.98 | sec/step~3.75 | keep=0.73 | K=8 | first_w=3.00 | llama(L): tf=9.9382 first=8.6243 kCE=6.8651 KD=8.4711 acc=0.000 state=13.2057 align=0.0000 latA=0.4988 latP=0.2484 | scale_pen(llama)=1.1141e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0001 rms_cal~0.0106 embed_rms~0.01058]
  step  320/334 | grad_norm=7.24 | sec/step~3.79 | keep=0.73 | K=8 | first_w=3.00 | llama(L): tf=9.8933 first=7.7201 kCE=6.5349 KD=7.7953 acc=0.000 state=12.2937 align=0.0000 latA=0.4986 latP=0.2485 | scale_pen(llama)=1.1141e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  330/334 | grad_norm=7.44 | sec/step~3.88 | keep=0.73 | K=8 | first_w=3.00 | llama(L): tf=10.5033 first=8.1453 kCE=7.1399 KD=7.1013 acc=0.000 state=13.0987 align=0.0000 latA=0.4957 latP=0.2484 | scale_pen(llama)=4.1069e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  334/334 | grad_norm=10.86 | sec/step~3.85 | keep=0.73 | K=8 | first_w=3.00 | llama(L): tf=10.2493 first=9.4092 kCE=6.1802 KD=7.0629 acc=0.000 state=11.6771 align=0.0000 latA=0.4961 latP=0.2485 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
[checkpoint] Freed 0.0B before save.
[checkpoint] Saved latest: encoder.pt, state.pt, config.json, adapter_llama.pt, deep_prefix_llama.pt, refiner.pt
[checkpoint] Freed 0.0B after save (non-canonical).
  ✅ Saved (and pruned to) latest at step 668
Epoch 3/6
  step  10/334 | grad_norm=6.91 | sec/step~3.57 | keep=0.73 | K=8 | first_w=3.00 | llama(L): tf=9.9133 first=7.6964 kCE=6.6358 KD=6.9366 acc=0.083 state=12.6377 align=0.0000 latA=0.4969 latP=0.2484 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  20/334 | grad_norm=5.29 | sec/step~4.14 | keep=0.74 | K=8 | first_w=3.00 | llama(L): tf=9.7516 first=6.8082 kCE=6.2298 KD=6.3410 acc=0.000 state=13.0534 align=0.0000 latA=0.4998 latP=0.2485 | scale_pen(llama)=3.1974e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  30/334 | grad_norm=1.98 | sec/step~3.92 | keep=0.74 | K=8 | first_w=3.00 | llama(L): tf=9.5970 first=8.0585 kCE=6.2523 KD=8.2014 acc=0.042 state=12.0029 align=0.0000 latA=0.4961 latP=0.2482 | scale_pen(llama)=8.1855e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  40/334 | grad_norm=6.75 | sec/step~3.58 | keep=0.74 | K=8 | first_w=3.00 | llama(L): tf=9.8225 first=7.1865 kCE=6.0732 KD=7.2158 acc=0.042 state=11.8794 align=0.0000 latA=0.4970 latP=0.2485 | scale_pen(llama)=8.1855e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  50/334 | grad_norm=8.21 | sec/step~3.82 | keep=0.74 | K=8 | first_w=3.00 | llama(L): tf=9.1075 first=7.9787 kCE=5.4002 KD=8.5235 acc=0.083 state=11.4345 align=0.0000 latA=0.4967 latP=0.2483 | scale_pen(llama)=5.1301e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  60/334 | grad_norm=3.96 | sec/step~3.83 | keep=0.74 | K=8 | first_w=3.00 | llama(L): tf=9.1602 first=7.6607 kCE=6.0218 KD=8.0663 acc=0.042 state=10.8389 align=0.0000 latA=0.4954 latP=0.2482 | scale_pen(llama)=1.1511e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  70/334 | grad_norm=8.70 | sec/step~3.63 | keep=0.74 | K=8 | first_w=3.00 | llama(L): tf=9.2530 first=7.8984 kCE=5.8336 KD=6.8937 acc=0.083 state=9.9163 align=0.0000 latA=0.4974 latP=0.2483 | scale_pen(llama)=2.2737e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  80/334 | grad_norm=7.53 | sec/step~3.51 | keep=0.74 | K=8 | first_w=3.00 | llama(L): tf=9.0318 first=8.4876 kCE=4.7242 KD=7.4263 acc=0.000 state=8.9191 align=0.0000 latA=0.4984 latP=0.2482 | scale_pen(llama)=2.2737e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  90/334 | grad_norm=4.61 | sec/step~3.81 | keep=0.74 | K=8 | first_w=3.00 | llama(L): tf=9.2088 first=7.1716 kCE=4.9422 KD=6.9590 acc=0.042 state=6.4715 align=0.0000 latA=0.4959 latP=0.2482 | scale_pen(llama)=2.7853e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  100/334 | grad_norm=2.54 | sec/step~3.74 | keep=0.74 | K=8 | first_w=3.00 | llama(L): tf=8.9196 first=7.8543 kCE=4.8664 KD=6.5320 acc=0.083 state=5.1790 align=0.0000 latA=0.4945 latP=0.2481 | scale_pen(llama)=3.6380e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  110/334 | grad_norm=13.74 | sec/step~3.59 | keep=0.75 | K=8 | first_w=3.00 | llama(L): tf=9.5565 first=8.0163 kCE=5.7369 KD=6.2107 acc=0.042 state=5.0090 align=0.0000 latA=0.4964 latP=0.2481 | scale_pen(llama)=3.6380e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  120/334 | grad_norm=5.83 | sec/step~3.59 | keep=0.75 | K=8 | first_w=3.00 | llama(L): tf=8.8509 first=8.0870 kCE=5.3390 KD=6.0826 acc=0.042 state=1.9129 align=0.0000 latA=0.4984 latP=0.2481 | scale_pen(llama)=2.7853e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  130/334 | grad_norm=4.32 | sec/step~4.16 | keep=0.75 | K=8 | first_w=3.00 | llama(L): tf=8.9038 first=7.5318 kCE=5.5747 KD=6.5545 acc=0.125 state=2.4845 align=0.0000 latA=0.4979 latP=0.2481 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  140/334 | grad_norm=11.85 | sec/step~3.80 | keep=0.75 | K=8 | first_w=3.00 | llama(L): tf=8.9203 first=7.5470 kCE=6.1782 KD=6.7790 acc=0.000 state=2.3237 align=0.0000 latA=0.4978 latP=0.2482 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  150/334 | grad_norm=7.55 | sec/step~3.93 | keep=0.75 | K=8 | first_w=3.00 | llama(L): tf=9.0825 first=8.2147 kCE=5.5777 KD=8.3673 acc=0.042 state=1.4981 align=0.0000 latA=0.4977 latP=0.2480 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  160/334 | grad_norm=4.42 | sec/step~3.83 | keep=0.75 | K=8 | first_w=3.00 | llama(L): tf=9.1371 first=7.2785 kCE=5.3471 KD=5.8604 acc=0.083 state=1.1703 align=0.0000 latA=0.4990 latP=0.2480 | scale_pen(llama)=2.2204e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  170/334 | grad_norm=1.73 | sec/step~4.20 | keep=0.75 | K=8 | first_w=3.00 | llama(L): tf=9.4824 first=8.1280 kCE=5.1868 KD=8.2801 acc=0.000 state=1.1872 align=0.0000 latA=0.4986 latP=0.2480 | scale_pen(llama)=2.0464e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  180/334 | grad_norm=7.12 | sec/step~3.77 | keep=0.75 | K=8 | first_w=3.00 | llama(L): tf=9.2073 first=7.1480 kCE=5.9432 KD=5.6022 acc=0.042 state=1.1488 align=0.0000 latA=0.4982 latP=0.2481 | scale_pen(llama)=2.0464e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  190/334 | grad_norm=6.30 | sec/step~3.58 | keep=0.75 | K=8 | first_w=3.00 | llama(L): tf=9.1903 first=7.5323 kCE=5.5320 KD=7.3385 acc=0.042 state=1.1470 align=0.0000 latA=0.4963 latP=0.2478 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  200/334 | grad_norm=2.82 | sec/step~3.86 | keep=0.76 | K=8 | first_w=3.00 | llama(L): tf=8.8262 first=7.0430 kCE=5.4513 KD=5.5541 acc=0.125 state=1.1662 align=0.0000 latA=0.4969 latP=0.2475 | scale_pen(llama)=1.2790e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  210/334 | grad_norm=6.54 | sec/step~3.90 | keep=0.76 | K=8 | first_w=3.00 | llama(L): tf=9.3566 first=8.1574 kCE=5.2863 KD=5.6126 acc=0.042 state=1.1530 align=0.0000 latA=0.4987 latP=0.2477 | scale_pen(llama)=9.0949e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  220/334 | grad_norm=5.08 | sec/step~4.02 | keep=0.76 | K=8 | first_w=3.00 | llama(L): tf=9.4316 first=7.7152 kCE=5.8447 KD=5.3481 acc=0.042 state=1.1824 align=0.0000 latA=0.4990 latP=0.2477 | scale_pen(llama)=9.0949e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  230/334 | grad_norm=3.83 | sec/step~4.05 | keep=0.76 | K=8 | first_w=3.00 | llama(L): tf=8.6517 first=8.2071 kCE=5.2452 KD=5.3375 acc=0.042 state=1.2370 align=0.0000 latA=0.4983 latP=0.2476 | scale_pen(llama)=6.9633e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  240/334 | grad_norm=1.74 | sec/step~3.81 | keep=0.76 | K=8 | first_w=3.00 | llama(L): tf=8.6914 first=7.3073 kCE=6.1430 KD=6.4844 acc=0.083 state=1.1703 align=0.0000 latA=0.4970 latP=0.2474 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  250/334 | grad_norm=4.91 | sec/step~4.03 | keep=0.76 | K=8 | first_w=3.00 | llama(L): tf=8.3563 first=7.3529 kCE=4.4767 KD=5.3429 acc=0.000 state=1.4153 align=0.0000 latA=0.4970 latP=0.2473 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  260/334 | grad_norm=5.96 | sec/step~3.97 | keep=0.76 | K=8 | first_w=3.00 | llama(L): tf=8.9425 first=7.8281 kCE=5.3071 KD=5.6043 acc=0.000 state=1.2992 align=0.0000 latA=0.4987 latP=0.2474 | scale_pen(llama)=4.2988e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  270/334 | grad_norm=2.95 | sec/step~3.91 | keep=0.77 | K=8 | first_w=3.00 | llama(L): tf=9.1844 first=8.1078 kCE=5.3398 KD=4.7449 acc=0.000 state=1.2563 align=0.0000 latA=0.4974 latP=0.2471 | scale_pen(llama)=1.2825e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  280/334 | grad_norm=7.06 | sec/step~3.87 | keep=0.77 | K=8 | first_w=3.00 | llama(L): tf=8.8813 first=7.9948 kCE=5.2765 KD=4.8440 acc=0.042 state=1.1892 align=0.0000 latA=0.4974 latP=0.2473 | scale_pen(llama)=7.9936e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  290/334 | grad_norm=5.86 | sec/step~3.79 | keep=0.77 | K=8 | first_w=3.00 | llama(L): tf=8.9406 first=7.4737 kCE=4.9605 KD=5.4090 acc=0.000 state=1.1172 align=0.0000 latA=0.4963 latP=0.2469 | scale_pen(llama)=7.9936e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  300/334 | grad_norm=3.34 | sec/step~3.49 | keep=0.77 | K=8 | first_w=3.00 | llama(L): tf=8.4842 first=7.9050 kCE=5.8079 KD=4.7633 acc=0.000 state=1.0793 align=0.0000 latA=0.4940 latP=0.2467 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  310/334 | grad_norm=1.59 | sec/step~3.52 | keep=0.77 | K=8 | first_w=3.00 | llama(L): tf=8.8819 first=8.3089 kCE=5.7444 KD=5.7489 acc=0.000 state=1.0300 align=0.0000 latA=0.4937 latP=0.2463 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  320/334 | grad_norm=6.24 | sec/step~4.20 | keep=0.77 | K=8 | first_w=3.00 | llama(L): tf=8.4700 first=7.0737 kCE=5.1713 KD=6.2892 acc=0.042 state=1.0477 align=0.0000 latA=0.4942 latP=0.2464 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  330/334 | grad_norm=5.48 | sec/step~3.68 | keep=0.77 | K=8 | first_w=3.00 | llama(L): tf=8.4411 first=8.0425 kCE=4.4663 KD=4.5006 acc=0.000 state=1.0690 align=0.0000 latA=0.4962 latP=0.2462 | scale_pen(llama)=6.9633e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  334/334 | grad_norm=8.29 | sec/step~2.90 | keep=0.77 | K=8 | first_w=3.00 | llama(L): tf=9.3938 first=8.3405 kCE=5.4540 KD=12.1908 acc=0.000 state=1.0219 align=0.0000 latA=0.4977 latP=0.2461 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
[checkpoint] Freed 0.0B before save.
[checkpoint] Saved latest: encoder.pt, state.pt, config.json, adapter_llama.pt, deep_prefix_llama.pt, refiner.pt
[checkpoint] Freed 0.0B after save (non-canonical).
  ✅ Saved (and pruned to) latest at step 1002
Epoch 4/6
  step  10/334 | grad_norm=5.98 | sec/step~3.95 | keep=0.78 | K=8 | first_w=3.00 | llama(L): tf=8.3317 first=7.7128 kCE=5.7993 KD=5.3077 acc=0.042 state=1.0279 align=0.0000 latA=0.4970 latP=0.2462 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  20/334 | grad_norm=4.56 | sec/step~3.62 | keep=0.78 | K=8 | first_w=3.00 | llama(L): tf=8.7446 first=6.9551 kCE=5.0924 KD=4.4499 acc=0.125 state=0.9829 align=0.0000 latA=0.4950 latP=0.2458 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  30/334 | grad_norm=2.27 | sec/step~3.89 | keep=0.78 | K=8 | first_w=3.00 | llama(L): tf=8.5695 first=7.1596 kCE=5.0705 KD=5.8084 acc=0.000 state=0.9676 align=0.0000 latA=0.4967 latP=0.2458 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  40/334 | grad_norm=8.04 | sec/step~3.64 | keep=0.78 | K=8 | first_w=3.00 | llama(L): tf=8.4411 first=6.9267 kCE=5.2683 KD=4.2827 acc=0.125 state=0.9771 align=0.0000 latA=0.4991 latP=0.2460 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  50/334 | grad_norm=4.36 | sec/step~3.89 | keep=0.78 | K=8 | first_w=3.00 | llama(L): tf=8.9026 first=6.8022 kCE=5.3520 KD=5.9004 acc=0.167 state=1.0307 align=0.0000 latA=0.4940 latP=0.2456 | scale_pen(llama)=6.9633e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  60/334 | grad_norm=5.34 | sec/step~3.60 | keep=0.78 | K=8 | first_w=3.00 | llama(L): tf=9.0632 first=7.3840 kCE=5.1644 KD=4.7064 acc=0.042 state=1.0074 align=0.0000 latA=0.4949 latP=0.2453 | scale_pen(llama)=1.2790e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  70/334 | grad_norm=14.73 | sec/step~3.77 | keep=0.79 | K=8 | first_w=3.00 | llama(L): tf=8.4090 first=6.9072 kCE=5.8082 KD=4.3687 acc=0.125 state=0.9572 align=0.0000 latA=0.4966 latP=0.2455 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  80/334 | grad_norm=6.47 | sec/step~3.98 | keep=0.79 | K=8 | first_w=3.00 | llama(L): tf=8.3220 first=7.6111 kCE=4.7642 KD=5.0884 acc=0.083 state=1.0106 align=0.0000 latA=0.4946 latP=0.2452 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  90/334 | grad_norm=4.46 | sec/step~3.56 | keep=0.79 | K=8 | first_w=3.00 | llama(L): tf=9.2682 first=7.8332 kCE=4.5708 KD=5.3458 acc=0.042 state=1.0104 align=0.0000 latA=0.4943 latP=0.2450 | scale_pen(llama)=1.2790e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  100/334 | grad_norm=2.14 | sec/step~3.89 | keep=0.79 | K=8 | first_w=3.00 | llama(L): tf=8.9069 first=7.7282 kCE=5.3947 KD=7.0602 acc=0.083 state=0.9905 align=0.0000 latA=0.4949 latP=0.2448 | scale_pen(llama)=1.2790e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0002 rms_cal~0.0106 embed_rms~0.01058]
  step  110/334 | grad_norm=10.23 | sec/step~3.61 | keep=0.79 | K=8 | first_w=3.00 | llama(L): tf=8.8397 first=6.9305 kCE=4.3581 KD=4.1373 acc=0.042 state=1.0505 align=0.0000 latA=0.4908 latP=0.2444 | scale_pen(llama)=1.2790e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  120/334 | grad_norm=6.54 | sec/step~3.77 | keep=0.79 | K=8 | first_w=3.00 | llama(L): tf=8.9696 first=7.7461 kCE=5.5470 KD=6.6882 acc=0.125 state=1.0120 align=0.0000 latA=0.4950 latP=0.2446 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  130/334 | grad_norm=4.09 | sec/step~3.67 | keep=0.80 | K=8 | first_w=3.00 | llama(L): tf=8.4471 first=7.7757 kCE=5.5965 KD=5.2239 acc=0.000 state=1.0443 align=0.0000 latA=0.4937 latP=0.2449 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  140/334 | grad_norm=15.99 | sec/step~3.70 | keep=0.80 | K=8 | first_w=3.00 | llama(L): tf=8.2818 first=7.9968 kCE=4.6525 KD=5.6245 acc=0.083 state=1.1081 align=0.0000 latA=0.4933 latP=0.2440 | scale_pen(llama)=1.2790e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  150/334 | grad_norm=15.01 | sec/step~3.60 | keep=0.80 | K=8 | first_w=3.00 | llama(L): tf=8.8035 first=7.8355 kCE=5.3631 KD=5.6821 acc=0.042 state=0.9469 align=0.0000 latA=0.4933 latP=0.2442 | scale_pen(llama)=1.2790e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  160/334 | grad_norm=4.71 | sec/step~3.46 | keep=0.80 | K=8 | first_w=3.00 | llama(L): tf=8.1087 first=7.3236 kCE=4.2203 KD=6.5365 acc=0.000 state=0.8922 align=0.0000 latA=0.4923 latP=0.2440 | scale_pen(llama)=2.8777e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  170/334 | grad_norm=4.61 | sec/step~3.74 | keep=0.80 | K=8 | first_w=3.00 | llama(L): tf=7.9136 first=6.9262 kCE=5.0481 KD=5.6634 acc=0.083 state=0.7989 align=0.0000 latA=0.4911 latP=0.2436 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  180/334 | grad_norm=12.60 | sec/step~4.19 | keep=0.80 | K=8 | first_w=3.00 | llama(L): tf=8.0428 first=6.6434 kCE=4.6364 KD=4.7877 acc=0.083 state=0.8692 align=0.0000 latA=0.4923 latP=0.2438 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  190/334 | grad_norm=14.83 | sec/step~3.56 | keep=0.81 | K=8 | first_w=3.00 | llama(L): tf=8.7139 first=7.4143 kCE=5.2079 KD=4.3511 acc=0.083 state=0.7966 align=0.0000 latA=0.4972 latP=0.2437 | scale_pen(llama)=1.7408e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  200/334 | grad_norm=3.20 | sec/step~4.28 | keep=0.81 | K=8 | first_w=3.00 | llama(L): tf=8.6853 first=7.6990 kCE=4.1202 KD=5.6095 acc=0.000 state=0.7446 align=0.0000 latA=0.4959 latP=0.2434 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  210/334 | grad_norm=13.93 | sec/step~3.81 | keep=0.81 | K=8 | first_w=3.00 | llama(L): tf=8.1894 first=7.2135 kCE=4.3927 KD=4.4464 acc=0.042 state=0.7162 align=0.0000 latA=0.4938 latP=0.2434 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  220/334 | grad_norm=15.97 | sec/step~3.45 | keep=0.81 | K=8 | first_w=3.00 | llama(L): tf=8.8032 first=6.8701 kCE=5.1834 KD=7.0714 acc=0.042 state=0.6911 align=0.0000 latA=0.4917 latP=0.2432 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  230/334 | grad_norm=16.48 | sec/step~3.70 | keep=0.81 | K=8 | first_w=3.00 | llama(L): tf=8.5223 first=7.3198 kCE=4.7055 KD=6.3036 acc=0.042 state=0.7491 align=0.0000 latA=0.4945 latP=0.2431 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  240/334 | grad_norm=2.34 | sec/step~3.83 | keep=0.82 | K=8 | first_w=3.00 | llama(L): tf=8.4242 first=7.1287 kCE=4.5646 KD=5.7998 acc=0.042 state=0.7720 align=0.0000 latA=0.4940 latP=0.2431 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  250/334 | grad_norm=10.26 | sec/step~3.44 | keep=0.82 | K=8 | first_w=3.00 | llama(L): tf=7.9862 first=7.1475 kCE=5.1742 KD=4.6729 acc=0.083 state=0.7450 align=0.0000 latA=0.4923 latP=0.2431 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  260/334 | grad_norm=13.56 | sec/step~3.59 | keep=0.82 | K=8 | first_w=3.00 | llama(L): tf=8.7648 first=7.8161 kCE=5.5857 KD=6.0420 acc=0.042 state=0.8169 align=0.0000 latA=0.4948 latP=0.2430 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  270/334 | grad_norm=6.69 | sec/step~3.96 | keep=0.82 | K=8 | first_w=3.00 | llama(L): tf=8.6370 first=7.8513 kCE=5.4180 KD=4.3076 acc=0.042 state=0.7126 align=0.0000 latA=0.4916 latP=0.2429 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  280/334 | grad_norm=19.71 | sec/step~3.97 | keep=0.82 | K=8 | first_w=3.00 | llama(L): tf=8.3564 first=7.2090 kCE=5.0481 KD=5.7065 acc=0.042 state=0.7560 align=0.0000 latA=0.4908 latP=0.2429 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  290/334 | grad_norm=6.91 | sec/step~3.77 | keep=0.82 | K=8 | first_w=3.00 | llama(L): tf=8.2649 first=7.6778 kCE=5.0656 KD=4.6971 acc=0.042 state=0.7414 align=0.0000 latA=0.4931 latP=0.2427 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  300/334 | grad_norm=4.64 | sec/step~3.77 | keep=0.83 | K=8 | first_w=3.00 | llama(L): tf=8.6243 first=7.3260 kCE=5.0724 KD=3.8824 acc=0.083 state=0.6621 align=0.0000 latA=0.4910 latP=0.2426 | scale_pen(llama)=8.8818e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  310/334 | grad_norm=4.57 | sec/step~3.79 | keep=0.83 | K=8 | first_w=3.00 | llama(L): tf=7.6092 first=6.9657 kCE=4.2683 KD=4.5066 acc=0.083 state=0.6606 align=0.0000 latA=0.4926 latP=0.2424 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  320/334 | grad_norm=6.82 | sec/step~3.58 | keep=0.83 | K=8 | first_w=3.00 | llama(L): tf=8.6096 first=6.8802 kCE=5.2583 KD=5.8098 acc=0.042 state=0.7478 align=0.0000 latA=0.4940 latP=0.2428 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  330/334 | grad_norm=12.48 | sec/step~3.69 | keep=0.83 | K=8 | first_w=3.00 | llama(L): tf=8.5556 first=7.6341 kCE=5.7334 KD=4.2822 acc=0.042 state=0.6815 align=0.0000 latA=0.4962 latP=0.2425 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  334/334 | grad_norm=19.96 | sec/step~3.00 | keep=0.83 | K=8 | first_w=3.00 | llama(L): tf=8.8342 first=7.2947 kCE=5.7757 KD=5.1218 acc=0.000 state=0.7781 align=0.0000 latA=0.4976 latP=0.2425 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
[checkpoint] Freed 0.0B before save.
[checkpoint] Saved latest: encoder.pt, state.pt, config.json, adapter_llama.pt, deep_prefix_llama.pt, refiner.pt
[checkpoint] Freed 0.0B after save (non-canonical).
  ✅ Saved (and pruned to) latest at step 1336
Epoch 5/6
  step  10/334 | grad_norm=5.44 | sec/step~3.46 | keep=0.84 | K=8 | first_w=3.00 | llama(L): tf=9.0216 first=7.0395 kCE=5.2126 KD=5.3261 acc=0.042 state=0.6304 align=0.0000 latA=0.4922 latP=0.2421 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  20/334 | grad_norm=7.02 | sec/step~3.58 | keep=0.84 | K=8 | first_w=3.00 | llama(L): tf=8.3063 first=6.7144 kCE=4.7679 KD=5.1963 acc=0.042 state=0.6491 align=0.0000 latA=0.4925 latP=0.2423 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  30/334 | grad_norm=2.11 | sec/step~3.54 | keep=0.84 | K=8 | first_w=3.00 | llama(L): tf=8.5717 first=7.3168 kCE=5.0414 KD=4.6653 acc=0.042 state=0.7786 align=0.0000 latA=0.4947 latP=0.2421 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  40/334 | grad_norm=6.35 | sec/step~3.80 | keep=0.84 | K=8 | first_w=3.00 | llama(L): tf=8.7104 first=8.0944 kCE=4.6445 KD=11.0215 acc=0.042 state=0.6223 align=0.0000 latA=0.4933 latP=0.2416 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  50/334 | grad_norm=19.28 | sec/step~4.04 | keep=0.84 | K=8 | first_w=3.00 | llama(L): tf=8.5933 first=7.1488 kCE=4.2365 KD=4.1456 acc=0.042 state=0.7871 align=0.0000 latA=0.4924 latP=0.2416 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  60/334 | grad_norm=3.18 | sec/step~3.86 | keep=0.85 | K=8 | first_w=3.00 | llama(L): tf=8.6954 first=8.0245 kCE=5.3061 KD=3.7503 acc=0.125 state=0.6428 align=0.0000 latA=0.4910 latP=0.2415 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  70/334 | grad_norm=6.91 | sec/step~3.70 | keep=0.85 | K=8 | first_w=3.00 | llama(L): tf=8.3677 first=6.5366 kCE=5.0097 KD=4.3287 acc=0.083 state=0.6309 align=0.0000 latA=0.4904 latP=0.2419 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  80/334 | grad_norm=192.58 | sec/step~3.60 | keep=0.85 | K=8 | first_w=3.00 | llama(L): tf=8.1549 first=7.0310 kCE=4.5744 KD=3.8559 acc=0.083 state=9.7921 align=0.0000 latA=0.4919 latP=0.2413 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  90/334 | grad_norm=15.72 | sec/step~3.90 | keep=0.85 | K=8 | first_w=3.00 | llama(L): tf=8.6666 first=6.5021 kCE=5.2555 KD=3.6011 acc=0.083 state=2.5961 align=0.0000 latA=0.4903 latP=0.2422 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  100/334 | grad_norm=21.99 | sec/step~3.60 | keep=0.85 | K=8 | first_w=3.00 | llama(L): tf=8.9205 first=7.5869 kCE=5.3017 KD=6.4475 acc=0.042 state=11.0783 align=0.0000 latA=0.4936 latP=0.2420 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  110/334 | grad_norm=124.36 | sec/step~3.43 | keep=0.86 | K=8 | first_w=3.00 | llama(L): tf=9.8734 first=7.3830 kCE=5.2716 KD=7.1081 acc=0.000 state=11.4457 align=0.0000 latA=0.4917 latP=0.2415 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  120/334 | grad_norm=27.56 | sec/step~3.56 | keep=0.86 | K=8 | first_w=3.00 | llama(L): tf=9.2515 first=6.5245 kCE=4.2316 KD=4.6713 acc=0.125 state=3.7815 align=0.0000 latA=0.4904 latP=0.2410 | scale_pen(llama)=3.1974e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  130/334 | grad_norm=15.60 | sec/step~3.80 | keep=0.86 | K=8 | first_w=3.00 | llama(L): tf=8.0945 first=6.9620 kCE=5.0405 KD=4.2560 acc=0.042 state=7.6718 align=0.0000 latA=0.4904 latP=0.2411 | scale_pen(llama)=8.8818e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  140/334 | grad_norm=51.04 | sec/step~3.58 | keep=0.86 | K=8 | first_w=3.00 | llama(L): tf=8.8662 first=7.8391 kCE=4.6437 KD=3.9201 acc=0.000 state=7.2634 align=0.0000 latA=0.4926 latP=0.2410 | scale_pen(llama)=1.7408e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  150/334 | grad_norm=12.95 | sec/step~3.58 | keep=0.86 | K=8 | first_w=3.00 | llama(L): tf=8.3201 first=6.9387 kCE=5.0783 KD=4.2123 acc=0.083 state=2.7170 align=0.0000 latA=0.4908 latP=0.2416 | scale_pen(llama)=1.7408e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  160/334 | grad_norm=10.03 | sec/step~3.61 | keep=0.87 | K=8 | first_w=3.00 | llama(L): tf=8.4350 first=7.2459 kCE=5.1272 KD=7.3145 acc=0.042 state=1.7297 align=0.0000 latA=0.4940 latP=0.2413 | scale_pen(llama)=1.7408e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  170/334 | grad_norm=2.61 | sec/step~3.75 | keep=0.87 | K=8 | first_w=3.00 | llama(L): tf=8.2581 first=7.7268 kCE=5.0302 KD=4.0110 acc=0.000 state=1.5147 align=0.0000 latA=0.4930 latP=0.2413 | scale_pen(llama)=8.8818e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  180/334 | grad_norm=7.08 | sec/step~4.21 | keep=0.87 | K=8 | first_w=3.00 | llama(L): tf=8.1751 first=7.2700 kCE=5.5645 KD=4.2112 acc=0.125 state=1.5863 align=0.0000 latA=0.4938 latP=0.2415 | scale_pen(llama)=8.8818e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  190/334 | grad_norm=9.67 | sec/step~4.16 | keep=0.87 | K=8 | first_w=3.00 | llama(L): tf=8.4855 first=7.3178 kCE=5.1827 KD=5.3051 acc=0.042 state=1.6303 align=0.0000 latA=0.4899 latP=0.2409 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  200/334 | grad_norm=4.22 | sec/step~3.90 | keep=0.88 | K=8 | first_w=3.00 | llama(L): tf=8.2166 first=7.0916 kCE=5.2768 KD=3.7996 acc=0.083 state=1.6813 align=0.0000 latA=0.4927 latP=0.2410 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  210/334 | grad_norm=16.30 | sec/step~3.77 | keep=0.88 | K=8 | first_w=3.00 | llama(L): tf=8.8660 first=7.3641 kCE=5.3404 KD=4.0344 acc=0.083 state=1.6430 align=0.0000 latA=0.4901 latP=0.2412 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  220/334 | grad_norm=6.84 | sec/step~3.97 | keep=0.88 | K=8 | first_w=3.00 | llama(L): tf=9.0272 first=6.5448 kCE=6.0214 KD=4.4002 acc=0.125 state=1.6781 align=0.0000 latA=0.4896 latP=0.2413 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  230/334 | grad_norm=4.34 | sec/step~3.91 | keep=0.88 | K=8 | first_w=3.00 | llama(L): tf=8.1927 first=7.0065 kCE=4.8411 KD=6.8921 acc=0.042 state=1.7533 align=0.0000 latA=0.4916 latP=0.2410 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  240/334 | grad_norm=2.28 | sec/step~4.13 | keep=0.89 | K=8 | first_w=3.00 | llama(L): tf=8.8831 first=7.1598 kCE=5.0206 KD=3.8549 acc=0.083 state=1.8864 align=0.0000 latA=0.4915 latP=0.2402 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  250/334 | grad_norm=7.80 | sec/step~3.69 | keep=0.89 | K=8 | first_w=3.00 | llama(L): tf=8.2373 first=6.5111 kCE=5.4499 KD=4.9434 acc=0.167 state=1.7552 align=0.0000 latA=0.4899 latP=0.2406 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  260/334 | grad_norm=12.01 | sec/step~3.65 | keep=0.89 | K=8 | first_w=3.00 | llama(L): tf=8.3028 first=6.7896 kCE=4.5438 KD=4.0770 acc=0.000 state=1.6650 align=0.0000 latA=0.4916 latP=0.2405 | scale_pen(llama)=3.1974e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  270/334 | grad_norm=3.15 | sec/step~4.19 | keep=0.89 | K=8 | first_w=3.00 | llama(L): tf=8.3418 first=7.0868 kCE=5.5536 KD=4.4499 acc=0.042 state=1.7466 align=0.0000 latA=0.4908 latP=0.2409 | scale_pen(llama)=8.8818e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  280/334 | grad_norm=7.10 | sec/step~3.88 | keep=0.90 | K=8 | first_w=3.00 | llama(L): tf=8.0369 first=6.9622 kCE=4.9858 KD=3.9869 acc=0.042 state=1.5813 align=0.0000 latA=0.4907 latP=0.2404 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  290/334 | grad_norm=11.26 | sec/step~3.66 | keep=0.90 | K=8 | first_w=3.00 | llama(L): tf=8.7121 first=6.8158 kCE=5.6424 KD=3.7239 acc=0.083 state=1.5660 align=0.0000 latA=0.4882 latP=0.2409 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  300/334 | grad_norm=6.48 | sec/step~4.04 | keep=0.90 | K=8 | first_w=3.00 | llama(L): tf=8.5714 first=7.1001 kCE=5.1001 KD=4.4951 acc=0.125 state=1.4802 align=0.0000 latA=0.4889 latP=0.2402 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  310/334 | grad_norm=3.95 | sec/step~3.68 | keep=0.90 | K=8 | first_w=3.00 | llama(L): tf=9.0118 first=7.0938 kCE=4.7634 KD=3.7112 acc=0.042 state=1.4508 align=0.0000 latA=0.4931 latP=0.2398 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  320/334 | grad_norm=7.18 | sec/step~3.72 | keep=0.90 | K=8 | first_w=3.00 | llama(L): tf=8.5605 first=7.0697 kCE=4.9475 KD=4.8147 acc=0.042 state=1.4613 align=0.0000 latA=0.4888 latP=0.2398 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  330/334 | grad_norm=8.28 | sec/step~3.73 | keep=0.91 | K=8 | first_w=3.00 | llama(L): tf=8.1529 first=6.2118 kCE=5.1758 KD=4.4147 acc=0.042 state=1.4125 align=0.0000 latA=0.4908 latP=0.2402 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  334/334 | grad_norm=13.11 | sec/step~2.66 | keep=0.91 | K=8 | first_w=3.00 | llama(L): tf=8.4115 first=6.9788 kCE=4.3381 KD=12.0479 acc=0.000 state=1.4199 align=0.0000 latA=0.4919 latP=0.2392 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
[checkpoint] Freed 0.0B before save.
[checkpoint] Saved latest: encoder.pt, state.pt, config.json, adapter_llama.pt, deep_prefix_llama.pt, refiner.pt
[checkpoint] Freed 0.0B after save (non-canonical).
  ✅ Saved (and pruned to) latest at step 1670
Epoch 6/6
  step  10/334 | grad_norm=11.20 | sec/step~3.59 | keep=0.91 | K=8 | first_w=3.00 | llama(L): tf=8.2306 first=7.1918 kCE=5.2410 KD=4.8658 acc=0.042 state=1.4923 align=0.0000 latA=0.4890 latP=0.2399 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  20/334 | grad_norm=7.70 | sec/step~3.47 | keep=0.91 | K=8 | first_w=3.00 | llama(L): tf=8.0826 first=7.1449 kCE=4.7422 KD=4.2686 acc=0.083 state=1.4366 align=0.0000 latA=0.4937 latP=0.2395 | scale_pen(llama)=8.8818e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  30/334 | grad_norm=2.38 | sec/step~4.29 | keep=0.92 | K=8 | first_w=3.00 | llama(L): tf=8.5857 first=7.7520 kCE=5.3068 KD=4.1162 acc=0.042 state=1.4364 align=0.0000 latA=0.4916 latP=0.2397 | scale_pen(llama)=1.7408e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  40/334 | grad_norm=7.26 | sec/step~3.83 | keep=0.92 | K=8 | first_w=3.00 | llama(L): tf=8.2429 first=7.0718 kCE=4.7151 KD=3.9742 acc=0.000 state=1.4275 align=0.0000 latA=0.4906 latP=0.2396 | scale_pen(llama)=1.7408e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  50/334 | grad_norm=9.06 | sec/step~3.63 | keep=0.92 | K=8 | first_w=3.00 | llama(L): tf=7.6771 first=7.2173 kCE=4.7665 KD=3.7732 acc=0.000 state=1.3858 align=0.0000 latA=0.4915 latP=0.2396 | scale_pen(llama)=8.8818e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  60/334 | grad_norm=4.16 | sec/step~3.66 | keep=0.92 | K=8 | first_w=3.00 | llama(L): tf=8.0682 first=6.9315 kCE=5.0742 KD=3.6248 acc=0.000 state=1.3402 align=0.0000 latA=0.4922 latP=0.2396 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  70/334 | grad_norm=10.55 | sec/step~4.07 | keep=0.93 | K=8 | first_w=3.00 | llama(L): tf=7.8561 first=6.8225 kCE=4.3627 KD=5.5273 acc=0.042 state=1.3744 align=0.0000 latA=0.4935 latP=0.2391 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  80/334 | grad_norm=19.34 | sec/step~4.26 | keep=0.93 | K=8 | first_w=3.00 | llama(L): tf=7.9173 first=6.3929 kCE=4.5230 KD=3.5007 acc=0.042 state=1.4216 align=0.0000 latA=0.4889 latP=0.2386 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  90/334 | grad_norm=5.12 | sec/step~3.68 | keep=0.93 | K=8 | first_w=3.00 | llama(L): tf=8.0605 first=6.7933 kCE=4.5628 KD=6.5191 acc=0.042 state=1.2966 align=0.0000 latA=0.4913 latP=0.2388 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  100/334 | grad_norm=3.19 | sec/step~3.72 | keep=0.93 | K=8 | first_w=3.00 | llama(L): tf=8.2958 first=6.8441 kCE=4.6251 KD=3.8082 acc=0.042 state=1.2992 align=0.0000 latA=0.4881 latP=0.2394 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  110/334 | grad_norm=12.81 | sec/step~3.48 | keep=0.94 | K=8 | first_w=3.00 | llama(L): tf=8.2878 first=6.6376 kCE=4.4528 KD=3.8552 acc=0.083 state=1.2568 align=0.0000 latA=0.4897 latP=0.2389 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  120/334 | grad_norm=6.31 | sec/step~3.70 | keep=0.94 | K=8 | first_w=3.00 | llama(L): tf=8.7413 first=7.0451 kCE=5.2924 KD=3.3501 acc=0.042 state=1.3193 align=0.0000 latA=0.4901 latP=0.2384 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  130/334 | grad_norm=4.20 | sec/step~3.65 | keep=0.94 | K=8 | first_w=3.00 | llama(L): tf=7.6030 first=7.0540 kCE=5.2475 KD=5.6300 acc=0.125 state=1.2522 align=0.0000 latA=0.4898 latP=0.2388 | scale_pen(llama)=3.1974e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  140/334 | grad_norm=11.89 | sec/step~4.22 | keep=0.94 | K=8 | first_w=3.00 | llama(L): tf=8.1088 first=6.2080 kCE=4.4491 KD=4.0348 acc=0.042 state=1.3211 align=0.0000 latA=0.4850 latP=0.2384 | scale_pen(llama)=8.8818e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  150/334 | grad_norm=12.34 | sec/step~3.84 | keep=0.95 | K=8 | first_w=3.00 | llama(L): tf=8.2823 first=7.3306 kCE=4.9655 KD=4.2925 acc=0.000 state=1.2424 align=0.0000 latA=0.4927 latP=0.2382 | scale_pen(llama)=8.8818e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  160/334 | grad_norm=8.22 | sec/step~3.63 | keep=0.95 | K=8 | first_w=3.00 | llama(L): tf=8.4150 first=6.9694 kCE=5.2733 KD=4.7968 acc=0.000 state=1.1748 align=0.0000 latA=0.4913 latP=0.2383 | scale_pen(llama)=8.8818e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  170/334 | grad_norm=4.55 | sec/step~3.86 | keep=0.95 | K=8 | first_w=3.00 | llama(L): tf=8.2922 first=6.8006 kCE=4.7241 KD=4.7933 acc=0.000 state=1.1693 align=0.0000 latA=0.4906 latP=0.2381 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  180/334 | grad_norm=13.30 | sec/step~3.62 | keep=0.96 | K=8 | first_w=3.00 | llama(L): tf=7.5205 first=7.1271 kCE=4.5864 KD=3.6111 acc=0.042 state=1.1801 align=0.0000 latA=0.4852 latP=0.2389 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  190/334 | grad_norm=8.82 | sec/step~3.73 | keep=0.96 | K=8 | first_w=3.00 | llama(L): tf=7.8895 first=6.9341 kCE=4.9992 KD=3.7557 acc=0.042 state=1.1919 align=0.0000 latA=0.4901 latP=0.2385 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  200/334 | grad_norm=4.54 | sec/step~4.44 | keep=0.96 | K=8 | first_w=3.00 | llama(L): tf=8.2763 first=7.5141 kCE=5.0508 KD=4.0440 acc=0.042 state=1.1814 align=0.0000 latA=0.4906 latP=0.2377 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  210/334 | grad_norm=13.45 | sec/step~3.45 | keep=0.96 | K=8 | first_w=3.00 | llama(L): tf=7.6065 first=6.9120 kCE=4.5380 KD=3.8666 acc=0.042 state=1.1195 align=0.0000 latA=0.4886 latP=0.2375 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  220/334 | grad_norm=8.52 | sec/step~4.04 | keep=0.97 | K=8 | first_w=3.00 | llama(L): tf=8.2176 first=7.2704 kCE=5.2210 KD=4.7247 acc=0.042 state=1.1913 align=0.0000 latA=0.4895 latP=0.2374 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  230/334 | grad_norm=4.16 | sec/step~3.84 | keep=0.97 | K=8 | first_w=3.00 | llama(L): tf=8.2280 first=6.8353 kCE=4.4192 KD=3.4578 acc=0.083 state=1.0700 align=0.0000 latA=0.4898 latP=0.2376 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  240/334 | grad_norm=2.46 | sec/step~3.81 | keep=0.97 | K=8 | first_w=3.00 | llama(L): tf=7.4843 first=5.9810 kCE=4.1110 KD=3.6626 acc=0.125 state=1.0617 align=0.0000 latA=0.4874 latP=0.2368 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  250/334 | grad_norm=10.75 | sec/step~4.32 | keep=0.98 | K=8 | first_w=3.00 | llama(L): tf=8.3644 first=7.0012 kCE=4.8943 KD=3.6189 acc=0.083 state=1.0980 align=0.0000 latA=0.4862 latP=0.2369 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  260/334 | grad_norm=6.14 | sec/step~4.17 | keep=0.98 | K=8 | first_w=3.00 | llama(L): tf=8.0677 first=7.7819 kCE=4.2993 KD=4.1833 acc=0.000 state=1.0422 align=0.0000 latA=0.4898 latP=0.2367 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  270/334 | grad_norm=3.16 | sec/step~3.80 | keep=0.98 | K=8 | first_w=3.00 | llama(L): tf=8.0583 first=6.2791 kCE=4.8075 KD=4.4590 acc=0.083 state=0.9821 align=0.0000 latA=0.4931 latP=0.2374 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  280/334 | grad_norm=6.37 | sec/step~3.92 | keep=0.98 | K=8 | first_w=3.00 | llama(L): tf=8.2152 first=7.3667 kCE=5.1456 KD=4.1212 acc=0.042 state=0.9709 align=0.0000 latA=0.4923 latP=0.2376 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  290/334 | grad_norm=6.87 | sec/step~3.74 | keep=0.99 | K=8 | first_w=3.00 | llama(L): tf=8.4776 first=7.2979 kCE=4.6068 KD=4.0968 acc=0.083 state=0.9974 align=0.0000 latA=0.4878 latP=0.2366 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  300/334 | grad_norm=4.68 | sec/step~3.64 | keep=0.99 | K=8 | first_w=3.00 | llama(L): tf=8.1749 first=7.0794 kCE=4.5562 KD=3.5405 acc=0.042 state=0.9699 align=0.0000 latA=0.4909 latP=0.2369 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  310/334 | grad_norm=2.38 | sec/step~3.87 | keep=0.99 | K=8 | first_w=3.00 | llama(L): tf=7.9276 first=6.7397 kCE=4.6893 KD=6.0007 acc=0.083 state=0.9948 align=0.0000 latA=0.4874 latP=0.2366 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  320/334 | grad_norm=8.55 | sec/step~3.91 | keep=1.00 | K=8 | first_w=3.00 | llama(L): tf=8.0112 first=7.5642 kCE=4.4766 KD=4.4927 acc=0.042 state=0.9626 align=0.0000 latA=0.4900 latP=0.2355 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  330/334 | grad_norm=7.54 | sec/step~3.85 | keep=1.00 | K=8 | first_w=3.00 | llama(L): tf=8.0555 first=6.5708 kCE=4.1537 KD=3.7368 acc=0.000 state=0.9411 align=0.0000 latA=0.4858 latP=0.2358 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  334/334 | grad_norm=9.26 | sec/step~3.11 | keep=1.00 | K=8 | first_w=3.00 | llama(L): tf=8.3179 first=7.3786 kCE=5.0028 KD=5.2262 acc=0.125 state=0.9090 align=0.0000 latA=0.4830 latP=0.2360 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
[checkpoint] Freed 0.0B before save.
[checkpoint] Saved latest: encoder.pt, state.pt, config.json, adapter_llama.pt, deep_prefix_llama.pt, refiner.pt
[checkpoint] Freed 0.0B after save (non-canonical).
  ✅ Saved (and pruned to) latest at step 2004
[checkpoint] Freed 0.0B before save.
[checkpoint] Saved latest: encoder.pt, state.pt, config.json, adapter_llama.pt, deep_prefix_llama.pt, refiner.pt
[checkpoint] Freed 0.0B after save (non-canonical).
✅ Saved latest checkpoint to runs/hero/ckpt/stageA
📝 Saved LoRA adapters for Llama
📝 Saved training_stats.json: {'llama': {'rms_mean_raw': 1.0003098156340346, 'rms_mean_cal': 0.01057136222114136, 'embed_rms': 0.01057521253824234, 'count': 2004}}

=== Stage B: Llama prefix training + warm-up ===

/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading dataset subset...
Loading SQuAD subset...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 3445.72it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:05,  1.84s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:02,  1.49s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.42s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.04it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.17s/it]
[meta-llama/Meta-Llama-3.1-8B-Instruct] hf_device_map: {'model.embed_tokens': 0, 'model.rotary_emb': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 2, 'model.layers.17': 2, 'model.layers.18': 2, 'model.layers.19': 2, 'model.layers.20': 2, 'model.layers.21': 2, 'model.layers.22': 2, 'model.layers.23': 2, 'model.layers.24': 3, 'model.layers.25': 3, 'model.layers.26': 3, 'model.layers.27': 3, 'model.layers.28': 3, 'model.layers.29': 3, 'model.layers.30': 3, 'model.layers.31': 3, 'model.norm': 3, 'lm_head': 3}
trainable params: 41,943,040 || all params: 8,072,204,288 || trainable%: 0.5196
/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.
  warnings.warn(
trainable params: 272,801,792 || all params: 8,345,006,080 || trainable%: 3.2690
Llama hidden size: 4096
[DeviceMap] Llama: {'model.embed_tokens': 0, 'model.rotary_emb': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 2, 'model.layers.17': 2, 'model.layers.18': 2, 'model.layers.19': 2, 'model.layers.20': 2, 'model.layers.21': 2, 'model.layers.22': 2, 'model.layers.23': 2, 'model.layers.24': 3, 'model.layers.25': 3, 'model.layers.26': 3, 'model.layers.27': 3, 'model.layers.28': 3, 'model.layers.29': 3, 'model.layers.30': 3, 'model.layers.31': 3, 'model.norm': 3, 'lm_head': 3}
[INFO] llama anchor tokens: 3
⏪ Resuming from: runs/hero/ckpt/stageA/state.pt
   -> loaded encoder/adapters/deep_prefix/refiner FROM state.pt
   -> restored RNG state
   -> reset epoch/global_step to zero as requested
   -> start_epoch=0, global_step=0
[warmup] alternating text/latent for first 890 steps
Epoch 1/10
[warmup] step=0 mode=text (warm-up)
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
  step  1/445 | (warm-up text) | align=0.0003 | text_tf=12.0193 | latent_scale=0.20
[warmup] step=1 mode=text (warm-up)
  step  2/445 | (warm-up text) | align=0.0003 | text_tf=11.4309 | latent_scale=0.20
[warmup] step=2 mode=text (warm-up)
  step  3/445 | (warm-up text) | align=0.0003 | text_tf=11.4918 | latent_scale=0.20
[warmup] step=3 mode=text (warm-up)
  step  4/445 | (warm-up text) | align=0.0003 | text_tf=11.8944 | latent_scale=0.20
[warmup] step=4 mode=text (warm-up)
  step  5/445 | (warm-up text) | align=0.0003 | text_tf=11.0769 | latent_scale=0.20
[warmup] step=5 mode=text (warm-up)
  step  6/445 | (warm-up text) | align=0.0003 | text_tf=11.5838 | latent_scale=0.20
[warmup] step=6 mode=text (warm-up)
  step  7/445 | (warm-up text) | align=0.0003 | text_tf=11.3334 | latent_scale=0.21
[warmup] step=7 mode=text (warm-up)
  step  8/445 | (warm-up text) | align=0.0003 | text_tf=12.0995 | latent_scale=0.21
[warmup] step=8 mode=text (warm-up)
  step  9/445 | (warm-up text) | align=0.0003 | text_tf=11.3804 | latent_scale=0.21
[warmup] step=9 mode=text (warm-up)
  step  10/445 | (warm-up text) | align=0.0003 | text_tf=11.5047 | latent_scale=0.21
  step  10/445 | grad_norm=0.00 | sec/step~8.74 | keep=0.50 | K=8 | llama(T): tf=2.5315 first=3.2240 kCE=2.5518 KD=0.0000 acc=0.000 state=8.4681 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  11/445 | (warm-up text) | align=0.0003 | text_tf=11.1962 | latent_scale=0.21
  step  12/445 | (warm-up text) | align=0.0003 | text_tf=11.2461 | latent_scale=0.21
  step  13/445 | (warm-up text) | align=0.0003 | text_tf=10.0965 | latent_scale=0.21
  step  14/445 | (warm-up text) | align=0.0003 | text_tf=9.4715 | latent_scale=0.21
  step  15/445 | (warm-up text) | align=0.0003 | text_tf=10.3158 | latent_scale=0.21
  step  16/445 | (warm-up text) | align=0.0003 | text_tf=9.8965 | latent_scale=0.21
  step  17/445 | (warm-up text) | align=0.0003 | text_tf=10.1093 | latent_scale=0.21
  step  18/445 | (warm-up text) | align=0.0003 | text_tf=10.2317 | latent_scale=0.22
  step  19/445 | (warm-up text) | align=0.0003 | text_tf=10.2717 | latent_scale=0.22
  step  20/445 | (warm-up text) | align=0.0003 | text_tf=9.5556 | latent_scale=0.22
  step  20/445 | grad_norm=0.00 | sec/step~8.74 | keep=0.50 | K=8 | llama(T): tf=2.3974 first=2.4900 kCE=2.2968 KD=0.0000 acc=0.000 state=8.8339 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=2.8777e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  21/445 | (warm-up text) | align=0.0003 | text_tf=10.0131 | latent_scale=0.22
  step  22/445 | (warm-up text) | align=0.0003 | text_tf=9.8288 | latent_scale=0.22
  step  23/445 | (warm-up text) | align=0.0003 | text_tf=10.2443 | latent_scale=0.22
  step  24/445 | (warm-up text) | align=0.0003 | text_tf=10.0124 | latent_scale=0.22
  step  25/445 | (warm-up text) | align=0.0003 | text_tf=9.3419 | latent_scale=0.22
  step  26/445 | (warm-up text) | align=0.0003 | text_tf=9.2805 | latent_scale=0.22
  step  27/445 | (warm-up text) | align=0.0003 | text_tf=9.2589 | latent_scale=0.22
  step  28/445 | (warm-up text) | align=0.0003 | text_tf=9.0009 | latent_scale=0.22
  step  29/445 | (warm-up text) | align=0.0003 | text_tf=9.0647 | latent_scale=0.23
  step  30/445 | (warm-up text) | align=0.0003 | text_tf=9.1952 | latent_scale=0.23
  step  30/445 | grad_norm=0.00 | sec/step~8.86 | keep=0.50 | K=8 | llama(T): tf=2.4370 first=2.1127 kCE=2.6394 KD=0.0000 acc=0.000 state=9.2419 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=8.0496e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  31/445 | (warm-up text) | align=0.0003 | text_tf=8.7941 | latent_scale=0.23
  step  32/445 | (warm-up text) | align=0.0003 | text_tf=9.5137 | latent_scale=0.23
  step  33/445 | (warm-up text) | align=0.0003 | text_tf=9.4643 | latent_scale=0.23
  step  34/445 | (warm-up text) | align=0.0003 | text_tf=9.0915 | latent_scale=0.23
  step  35/445 | (warm-up text) | align=0.0003 | text_tf=9.7837 | latent_scale=0.23
  step  36/445 | (warm-up text) | align=0.0003 | text_tf=9.7194 | latent_scale=0.23
  step  37/445 | (warm-up text) | align=0.0003 | text_tf=8.8895 | latent_scale=0.23
  step  38/445 | (warm-up text) | align=0.0003 | text_tf=8.7823 | latent_scale=0.23
  step  39/445 | (warm-up text) | align=0.0003 | text_tf=8.6778 | latent_scale=0.23
  step  40/445 | (warm-up text) | align=0.0003 | text_tf=8.7967 | latent_scale=0.24
  step  40/445 | grad_norm=0.00 | sec/step~9.10 | keep=0.50 | K=8 | llama(T): tf=2.3430 first=1.9329 kCE=2.6309 KD=0.0000 acc=0.028 state=8.8674 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.0747e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  41/445 | (warm-up text) | align=0.0003 | text_tf=8.6847 | latent_scale=0.24
  step  42/445 | (warm-up text) | align=0.0003 | text_tf=8.7944 | latent_scale=0.24
  step  43/445 | (warm-up text) | align=0.0003 | text_tf=8.7009 | latent_scale=0.24
  step  44/445 | (warm-up text) | align=0.0003 | text_tf=8.7080 | latent_scale=0.24
  step  45/445 | (warm-up text) | align=0.0003 | text_tf=8.7162 | latent_scale=0.24
  step  46/445 | (warm-up text) | align=0.0003 | text_tf=8.7706 | latent_scale=0.24
  step  47/445 | (warm-up text) | align=0.0003 | text_tf=8.5166 | latent_scale=0.24
  step  48/445 | (warm-up text) | align=0.0003 | text_tf=9.0226 | latent_scale=0.24
  step  49/445 | (warm-up text) | align=0.0003 | text_tf=8.2565 | latent_scale=0.24
  step  50/445 | (warm-up text) | align=0.0003 | text_tf=8.6052 | latent_scale=0.24
  step  50/445 | grad_norm=0.00 | sec/step~9.31 | keep=0.50 | K=8 | llama(T): tf=2.3928 first=1.9765 kCE=2.8536 KD=0.0000 acc=0.028 state=8.5581 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=6.6609e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  51/445 | (warm-up text) | align=0.0003 | text_tf=8.3012 | latent_scale=0.24
  step  52/445 | (warm-up text) | align=0.0003 | text_tf=8.4722 | latent_scale=0.25
  step  53/445 | (warm-up text) | align=0.0003 | text_tf=7.9010 | latent_scale=0.25
  step  54/445 | (warm-up text) | align=0.0003 | text_tf=8.6514 | latent_scale=0.25
  step  55/445 | (warm-up text) | align=0.0003 | text_tf=7.8655 | latent_scale=0.25
  step  56/445 | (warm-up text) | align=0.0003 | text_tf=8.5733 | latent_scale=0.25
  step  57/445 | (warm-up text) | align=0.0003 | text_tf=8.3824 | latent_scale=0.25
  step  58/445 | (warm-up text) | align=0.0003 | text_tf=8.3816 | latent_scale=0.25
  step  59/445 | (warm-up text) | align=0.0003 | text_tf=8.5799 | latent_scale=0.25
  step  60/445 | (warm-up text) | align=0.0003 | text_tf=8.5295 | latent_scale=0.25
  step  60/445 | grad_norm=0.00 | sec/step~8.91 | keep=0.50 | K=8 | llama(T): tf=2.4310 first=2.1200 kCE=2.8931 KD=0.0000 acc=0.000 state=8.7309 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=4.8112e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  61/445 | (warm-up text) | align=0.0003 | text_tf=8.2407 | latent_scale=0.25
  step  62/445 | (warm-up text) | align=0.0003 | text_tf=8.1576 | latent_scale=0.25
  step  63/445 | (warm-up text) | align=0.0003 | text_tf=7.9354 | latent_scale=0.26
  step  64/445 | (warm-up text) | align=0.0003 | text_tf=8.1466 | latent_scale=0.26
  step  65/445 | (warm-up text) | align=0.0003 | text_tf=8.2997 | latent_scale=0.26
  step  66/445 | (warm-up text) | align=0.0003 | text_tf=8.0562 | latent_scale=0.26
  step  67/445 | (warm-up text) | align=0.0003 | text_tf=8.2903 | latent_scale=0.26
  step  68/445 | (warm-up text) | align=0.0003 | text_tf=8.2644 | latent_scale=0.26
  step  69/445 | (warm-up text) | align=0.0003 | text_tf=8.6099 | latent_scale=0.26
  step  70/445 | (warm-up text) | align=0.0003 | text_tf=7.9509 | latent_scale=0.26
  step  70/445 | grad_norm=0.00 | sec/step~8.83 | keep=0.50 | K=8 | llama(T): tf=2.4684 first=2.1738 kCE=2.8487 KD=0.0000 acc=0.028 state=7.9848 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=4.8112e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  71/445 | (warm-up text) | align=0.0003 | text_tf=8.0985 | latent_scale=0.26
  step  72/445 | (warm-up text) | align=0.0003 | text_tf=8.2364 | latent_scale=0.26
  step  73/445 | (warm-up text) | align=0.0003 | text_tf=8.0740 | latent_scale=0.26
  step  74/445 | (warm-up text) | align=0.0003 | text_tf=7.6785 | latent_scale=0.27
  step  75/445 | (warm-up text) | align=0.0003 | text_tf=7.5972 | latent_scale=0.27
  step  76/445 | (warm-up text) | align=0.0003 | text_tf=7.9876 | latent_scale=0.27
  step  77/445 | (warm-up text) | align=0.0003 | text_tf=7.4788 | latent_scale=0.27
  step  78/445 | (warm-up text) | align=0.0003 | text_tf=7.9047 | latent_scale=0.27
  step  79/445 | (warm-up text) | align=0.0003 | text_tf=7.7986 | latent_scale=0.27
  step  80/445 | (warm-up text) | align=0.0003 | text_tf=7.7728 | latent_scale=0.27
  step  80/445 | grad_norm=0.00 | sec/step~9.69 | keep=0.50 | K=8 | llama(T): tf=2.5437 first=2.0569 kCE=3.1056 KD=0.0000 acc=0.056 state=7.5726 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=3.9918e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  81/445 | (warm-up text) | align=0.0003 | text_tf=7.5100 | latent_scale=0.27
  step  82/445 | (warm-up text) | align=0.0003 | text_tf=8.1683 | latent_scale=0.27
  step  83/445 | (warm-up text) | align=0.0003 | text_tf=8.3810 | latent_scale=0.27
  step  84/445 | (warm-up text) | align=0.0003 | text_tf=7.6202 | latent_scale=0.27
  step  85/445 | (warm-up text) | align=0.0003 | text_tf=7.6788 | latent_scale=0.28
  step  86/445 | (warm-up text) | align=0.0003 | text_tf=7.4724 | latent_scale=0.28
  step  87/445 | (warm-up text) | align=0.0003 | text_tf=7.6823 | latent_scale=0.28
  step  88/445 | (warm-up text) | align=0.0003 | text_tf=7.4084 | latent_scale=0.28
  step  89/445 | (warm-up text) | align=0.0003 | text_tf=7.2791 | latent_scale=0.28
  step  90/445 | (warm-up text) | align=0.0003 | text_tf=7.3639 | latent_scale=0.28
  step  90/445 | grad_norm=0.00 | sec/step~8.75 | keep=0.50 | K=8 | llama(T): tf=2.7729 first=2.2994 kCE=3.5143 KD=0.0000 acc=0.000 state=6.5243 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.1511e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  91/445 | (warm-up text) | align=0.0003 | text_tf=7.4666 | latent_scale=0.28
  step  92/445 | (warm-up text) | align=0.0003 | text_tf=7.9434 | latent_scale=0.28
  step  93/445 | (warm-up text) | align=0.0003 | text_tf=7.1790 | latent_scale=0.28
  step  94/445 | (warm-up text) | align=0.0003 | text_tf=8.0874 | latent_scale=0.28
  step  95/445 | (warm-up text) | align=0.0003 | text_tf=7.5119 | latent_scale=0.28
  step  96/445 | (warm-up text) | align=0.0003 | text_tf=7.6207 | latent_scale=0.29
  step  97/445 | (warm-up text) | align=0.0003 | text_tf=7.0443 | latent_scale=0.29
  step  98/445 | (warm-up text) | align=0.0003 | text_tf=7.0469 | latent_scale=0.29
  step  99/445 | (warm-up text) | align=0.0003 | text_tf=7.0411 | latent_scale=0.29
  step  100/445 | (warm-up text) | align=0.0003 | text_tf=7.5922 | latent_scale=0.29
  step  100/445 | grad_norm=0.00 | sec/step~8.77 | keep=0.50 | K=8 | llama(T): tf=2.8140 first=2.2448 kCE=3.6184 KD=0.0000 acc=0.028 state=6.0700 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=3.7757e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  101/445 | (warm-up text) | align=0.0003 | text_tf=7.4926 | latent_scale=0.29
  step  102/445 | (warm-up text) | align=0.0003 | text_tf=7.2377 | latent_scale=0.29
  step  103/445 | (warm-up text) | align=0.0003 | text_tf=7.1757 | latent_scale=0.29
  step  104/445 | (warm-up text) | align=0.0003 | text_tf=7.0022 | latent_scale=0.29
  step  105/445 | (warm-up text) | align=0.0003 | text_tf=7.0626 | latent_scale=0.29
  step  106/445 | (warm-up text) | align=0.0003 | text_tf=7.0160 | latent_scale=0.29
  step  107/445 | (warm-up text) | align=0.0003 | text_tf=7.3106 | latent_scale=0.30
  step  108/445 | (warm-up text) | align=0.0003 | text_tf=7.2933 | latent_scale=0.30
  step  109/445 | (warm-up text) | align=0.0003 | text_tf=6.8636 | latent_scale=0.30
  step  110/445 | (warm-up text) | align=0.0003 | text_tf=7.3965 | latent_scale=0.30
  step  110/445 | grad_norm=0.00 | sec/step~8.53 | keep=0.50 | K=8 | llama(T): tf=2.8533 first=2.0486 kCE=3.6344 KD=0.0000 acc=0.167 state=5.3228 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=2.9060e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  111/445 | (warm-up text) | align=0.0003 | text_tf=7.2749 | latent_scale=0.30
  step  112/445 | (warm-up text) | align=0.0003 | text_tf=6.6252 | latent_scale=0.30
  step  113/445 | (warm-up text) | align=0.0003 | text_tf=7.1973 | latent_scale=0.30
  step  114/445 | (warm-up text) | align=0.0003 | text_tf=6.7218 | latent_scale=0.30
  step  115/445 | (warm-up text) | align=0.0003 | text_tf=7.2374 | latent_scale=0.30
  step  116/445 | (warm-up text) | align=0.0003 | text_tf=6.9433 | latent_scale=0.30
  step  117/445 | (warm-up text) | align=0.0003 | text_tf=6.8500 | latent_scale=0.30
  step  118/445 | (warm-up text) | align=0.0003 | text_tf=7.0927 | latent_scale=0.31
  step  119/445 | (warm-up text) | align=0.0003 | text_tf=6.6643 | latent_scale=0.31
  step  120/445 | (warm-up text) | align=0.0003 | text_tf=7.0915 | latent_scale=0.31
  step  120/445 | grad_norm=0.00 | sec/step~8.98 | keep=0.50 | K=8 | llama(T): tf=3.0172 first=2.4542 kCE=3.6600 KD=0.0000 acc=0.056 state=5.8288 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=5.1159e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  121/445 | (warm-up text) | align=0.0003 | text_tf=6.5058 | latent_scale=0.31
  step  122/445 | (warm-up text) | align=0.0003 | text_tf=7.4377 | latent_scale=0.31
  step  123/445 | (warm-up text) | align=0.0003 | text_tf=6.8167 | latent_scale=0.31
  step  124/445 | (warm-up text) | align=0.0003 | text_tf=6.8768 | latent_scale=0.31
  step  125/445 | (warm-up text) | align=0.0003 | text_tf=6.4747 | latent_scale=0.31
  step  126/445 | (warm-up text) | align=0.0003 | text_tf=6.6615 | latent_scale=0.31
  step  127/445 | (warm-up text) | align=0.0003 | text_tf=7.3705 | latent_scale=0.31
  step  128/445 | (warm-up text) | align=0.0003 | text_tf=7.2505 | latent_scale=0.31
  step  129/445 | (warm-up text) | align=0.0003 | text_tf=6.7763 | latent_scale=0.32
  step  130/445 | (warm-up text) | align=0.0003 | text_tf=7.1735 | latent_scale=0.32
  step  130/445 | grad_norm=0.00 | sec/step~8.70 | keep=0.50 | K=8 | llama(T): tf=3.0849 first=2.3889 kCE=3.8391 KD=0.0000 acc=0.083 state=5.6014 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=5.1159e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  131/445 | (warm-up text) | align=0.0003 | text_tf=6.7663 | latent_scale=0.32
  step  132/445 | (warm-up text) | align=0.0003 | text_tf=6.8816 | latent_scale=0.32
  step  133/445 | (warm-up text) | align=0.0003 | text_tf=6.7134 | latent_scale=0.32
  step  134/445 | (warm-up text) | align=0.0003 | text_tf=6.8966 | latent_scale=0.32
  step  135/445 | (warm-up text) | align=0.0003 | text_tf=7.0032 | latent_scale=0.32
  step  136/445 | (warm-up text) | align=0.0003 | text_tf=6.7700 | latent_scale=0.32
  step  137/445 | (warm-up text) | align=0.0003 | text_tf=6.6964 | latent_scale=0.32
  step  138/445 | (warm-up text) | align=0.0003 | text_tf=7.0611 | latent_scale=0.32
  step  139/445 | (warm-up text) | align=0.0003 | text_tf=7.2521 | latent_scale=0.32
  step  140/445 | (warm-up text) | align=0.0003 | text_tf=7.3890 | latent_scale=0.32
  step  140/445 | grad_norm=0.00 | sec/step~9.27 | keep=0.50 | K=8 | llama(T): tf=3.1599 first=2.4901 kCE=3.8250 KD=0.0000 acc=0.056 state=5.7231 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=2.3888e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  141/445 | (warm-up text) | align=0.0003 | text_tf=6.6670 | latent_scale=0.33
  step  142/445 | (warm-up text) | align=0.0003 | text_tf=6.9872 | latent_scale=0.33
  step  143/445 | (warm-up text) | align=0.0003 | text_tf=6.8618 | latent_scale=0.33
  step  144/445 | (warm-up text) | align=0.0003 | text_tf=7.3097 | latent_scale=0.33
  step  145/445 | (warm-up text) | align=0.0003 | text_tf=6.1750 | latent_scale=0.33
  step  146/445 | (warm-up text) | align=0.0003 | text_tf=7.3322 | latent_scale=0.33
  step  147/445 | (warm-up text) | align=0.0003 | text_tf=6.3484 | latent_scale=0.33
  step  148/445 | (warm-up text) | align=0.0003 | text_tf=6.4607 | latent_scale=0.33
  step  149/445 | (warm-up text) | align=0.0003 | text_tf=7.0013 | latent_scale=0.33
  step  150/445 | (warm-up text) | align=0.0003 | text_tf=6.5208 | latent_scale=0.33
  step  150/445 | grad_norm=0.00 | sec/step~9.95 | keep=0.50 | K=8 | llama(T): tf=3.0273 first=2.5924 kCE=4.1145 KD=0.0000 acc=0.056 state=6.1107 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.8307e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  151/445 | (warm-up text) | align=0.0003 | text_tf=6.8603 | latent_scale=0.33
  step  152/445 | (warm-up text) | align=0.0003 | text_tf=6.3761 | latent_scale=0.34
  step  153/445 | (warm-up text) | align=0.0003 | text_tf=6.6968 | latent_scale=0.34
  step  154/445 | (warm-up text) | align=0.0003 | text_tf=6.8089 | latent_scale=0.34
  step  155/445 | (warm-up text) | align=0.0003 | text_tf=6.7683 | latent_scale=0.34
  step  156/445 | (warm-up text) | align=0.0003 | text_tf=6.3158 | latent_scale=0.34
  step  157/445 | (warm-up text) | align=0.0003 | text_tf=6.4624 | latent_scale=0.34
  step  158/445 | (warm-up text) | align=0.0003 | text_tf=6.6389 | latent_scale=0.34
  step  159/445 | (warm-up text) | align=0.0003 | text_tf=6.7943 | latent_scale=0.34
  step  160/445 | (warm-up text) | align=0.0003 | text_tf=6.2363 | latent_scale=0.34
  step  160/445 | grad_norm=0.00 | sec/step~8.74 | keep=0.50 | K=8 | llama(T): tf=3.1812 first=2.8178 kCE=4.0848 KD=0.0000 acc=0.028 state=5.6195 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=2.3283e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  161/445 | (warm-up text) | align=0.0003 | text_tf=6.4225 | latent_scale=0.34
  step  162/445 | (warm-up text) | align=0.0003 | text_tf=6.6279 | latent_scale=0.34
  step  163/445 | (warm-up text) | align=0.0003 | text_tf=6.7616 | latent_scale=0.35
  step  164/445 | (warm-up text) | align=0.0003 | text_tf=6.7026 | latent_scale=0.35
  step  165/445 | (warm-up text) | align=0.0003 | text_tf=6.6467 | latent_scale=0.35
  step  166/445 | (warm-up text) | align=0.0003 | text_tf=6.7058 | latent_scale=0.35
  step  167/445 | (warm-up text) | align=0.0003 | text_tf=6.0967 | latent_scale=0.35
  step  168/445 | (warm-up text) | align=0.0003 | text_tf=6.7260 | latent_scale=0.35
  step  169/445 | (warm-up text) | align=0.0003 | text_tf=6.2894 | latent_scale=0.35
  step  170/445 | (warm-up text) | align=0.0003 | text_tf=6.4442 | latent_scale=0.35
  step  170/445 | grad_norm=0.00 | sec/step~9.91 | keep=0.50 | K=8 | llama(T): tf=3.2308 first=2.6116 kCE=4.0252 KD=0.0000 acc=0.056 state=6.4698 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.0756e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  171/445 | (warm-up text) | align=0.0003 | text_tf=6.3550 | latent_scale=0.35
  step  172/445 | (warm-up text) | align=0.0003 | text_tf=6.0975 | latent_scale=0.35
  step  173/445 | (warm-up text) | align=0.0003 | text_tf=6.5411 | latent_scale=0.35
  step  174/445 | (warm-up text) | align=0.0003 | text_tf=6.6957 | latent_scale=0.36
  step  175/445 | (warm-up text) | align=0.0003 | text_tf=6.7183 | latent_scale=0.36
  step  176/445 | (warm-up text) | align=0.0003 | text_tf=6.7028 | latent_scale=0.36
  step  177/445 | (warm-up text) | align=0.0003 | text_tf=6.0200 | latent_scale=0.36
  step  178/445 | (warm-up text) | align=0.0003 | text_tf=6.3657 | latent_scale=0.36
  step  179/445 | (warm-up text) | align=0.0003 | text_tf=6.7360 | latent_scale=0.36
  step  180/445 | (warm-up text) | align=0.0003 | text_tf=6.5652 | latent_scale=0.36
  step  180/445 | grad_norm=0.00 | sec/step~8.96 | keep=0.50 | K=8 | llama(T): tf=3.3826 first=2.8476 kCE=4.6288 KD=0.0000 acc=0.056 state=6.0259 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=3.1974e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  181/445 | (warm-up text) | align=0.0003 | text_tf=6.2007 | latent_scale=0.36
  step  182/445 | (warm-up text) | align=0.0003 | text_tf=6.2621 | latent_scale=0.36
  step  183/445 | (warm-up text) | align=0.0003 | text_tf=6.3081 | latent_scale=0.36
  step  184/445 | (warm-up text) | align=0.0003 | text_tf=6.5237 | latent_scale=0.36
  step  185/445 | (warm-up text) | align=0.0003 | text_tf=5.9531 | latent_scale=0.37
  step  186/445 | (warm-up text) | align=0.0003 | text_tf=6.6913 | latent_scale=0.37
  step  187/445 | (warm-up text) | align=0.0003 | text_tf=6.4165 | latent_scale=0.37
  step  188/445 | (warm-up text) | align=0.0003 | text_tf=6.1208 | latent_scale=0.37
  step  189/445 | (warm-up text) | align=0.0003 | text_tf=6.3055 | latent_scale=0.37
  step  190/445 | (warm-up text) | align=0.0003 | text_tf=6.0084 | latent_scale=0.37
  step  190/445 | grad_norm=0.00 | sec/step~10.32 | keep=0.50 | K=8 | llama(T): tf=3.1882 first=2.6101 kCE=4.2983 KD=0.0000 acc=0.056 state=7.0714 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=3.1974e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  191/445 | (warm-up text) | align=0.0003 | text_tf=5.8988 | latent_scale=0.37
  step  192/445 | (warm-up text) | align=0.0003 | text_tf=6.0912 | latent_scale=0.37
  step  193/445 | (warm-up text) | align=0.0003 | text_tf=6.3688 | latent_scale=0.37
  step  194/445 | (warm-up text) | align=0.0003 | text_tf=5.7797 | latent_scale=0.37
  step  195/445 | (warm-up text) | align=0.0003 | text_tf=6.2428 | latent_scale=0.37
  step  196/445 | (warm-up text) | align=0.0003 | text_tf=6.3447 | latent_scale=0.38
  step  197/445 | (warm-up text) | align=0.0003 | text_tf=6.5445 | latent_scale=0.38
  step  198/445 | (warm-up text) | align=0.0003 | text_tf=6.3466 | latent_scale=0.38
  step  199/445 | (warm-up text) | align=0.0003 | text_tf=6.2571 | latent_scale=0.38
  step  200/445 | (warm-up text) | align=0.0003 | text_tf=6.2405 | latent_scale=0.38
  step  200/445 | grad_norm=0.00 | sec/step~9.01 | keep=0.50 | K=8 | llama(T): tf=3.4368 first=3.1605 kCE=4.4185 KD=0.0000 acc=0.000 state=6.0941 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=4.4565e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  201/445 | (warm-up text) | align=0.0003 | text_tf=5.8749 | latent_scale=0.38
  step  202/445 | (warm-up text) | align=0.0003 | text_tf=6.2260 | latent_scale=0.38
  step  203/445 | (warm-up text) | align=0.0003 | text_tf=6.2361 | latent_scale=0.38
  step  204/445 | (warm-up text) | align=0.0003 | text_tf=6.0724 | latent_scale=0.38
  step  205/445 | (warm-up text) | align=0.0003 | text_tf=6.3676 | latent_scale=0.38
  step  206/445 | (warm-up text) | align=0.0003 | text_tf=6.2744 | latent_scale=0.38
  step  207/445 | (warm-up text) | align=0.0003 | text_tf=5.9840 | latent_scale=0.39
  step  208/445 | (warm-up text) | align=0.0003 | text_tf=6.3461 | latent_scale=0.39
  step  209/445 | (warm-up text) | align=0.0003 | text_tf=5.8736 | latent_scale=0.39
  step  210/445 | (warm-up text) | align=0.0003 | text_tf=5.9713 | latent_scale=0.39
  step  210/445 | grad_norm=0.00 | sec/step~9.17 | keep=0.50 | K=8 | llama(T): tf=3.5721 first=2.9116 kCE=4.3356 KD=0.0000 acc=0.083 state=6.3843 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.3097e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  211/445 | (warm-up text) | align=0.0003 | text_tf=6.2047 | latent_scale=0.39
  step  212/445 | (warm-up text) | align=0.0003 | text_tf=6.0851 | latent_scale=0.39
  step  213/445 | (warm-up text) | align=0.0003 | text_tf=6.0779 | latent_scale=0.39
  step  214/445 | (warm-up text) | align=0.0003 | text_tf=5.9893 | latent_scale=0.39
  step  215/445 | (warm-up text) | align=0.0003 | text_tf=5.4602 | latent_scale=0.39
  step  216/445 | (warm-up text) | align=0.0003 | text_tf=6.2145 | latent_scale=0.39
  step  217/445 | (warm-up text) | align=0.0003 | text_tf=5.9331 | latent_scale=0.39
  step  218/445 | (warm-up text) | align=0.0003 | text_tf=5.9102 | latent_scale=0.40
  step  219/445 | (warm-up text) | align=0.0003 | text_tf=6.2017 | latent_scale=0.40
  step  220/445 | (warm-up text) | align=0.0003 | text_tf=6.1511 | latent_scale=0.40
  step  220/445 | grad_norm=0.00 | sec/step~8.50 | keep=0.50 | K=8 | llama(T): tf=3.6460 first=3.1709 kCE=4.5066 KD=0.0000 acc=0.028 state=6.1406 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.2028e-10 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  221/445 | (warm-up text) | align=0.0003 | text_tf=6.3814 | latent_scale=0.40
  step  222/445 | (warm-up text) | align=0.0003 | text_tf=5.8779 | latent_scale=0.40
  step  223/445 | (warm-up text) | align=0.0003 | text_tf=6.4571 | latent_scale=0.40
  step  224/445 | (warm-up text) | align=0.0003 | text_tf=5.4261 | latent_scale=0.40
  step  225/445 | (warm-up text) | align=0.0003 | text_tf=5.7452 | latent_scale=0.40
  step  226/445 | (warm-up text) | align=0.0003 | text_tf=5.9342 | latent_scale=0.40
  step  227/445 | (warm-up text) | align=0.0003 | text_tf=6.0269 | latent_scale=0.40
  step  228/445 | (warm-up text) | align=0.0003 | text_tf=5.4528 | latent_scale=0.40
  step  229/445 | (warm-up text) | align=0.0003 | text_tf=5.9025 | latent_scale=0.40
  step  230/445 | (warm-up text) | align=0.0003 | text_tf=5.4942 | latent_scale=0.41
  step  230/445 | grad_norm=0.00 | sec/step~9.14 | keep=0.50 | K=8 | llama(T): tf=3.5014 first=2.9998 kCE=4.2665 KD=0.0000 acc=0.056 state=6.9758 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=3.5527e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  231/445 | (warm-up text) | align=0.0003 | text_tf=6.2612 | latent_scale=0.41
  step  232/445 | (warm-up text) | align=0.0003 | text_tf=6.0027 | latent_scale=0.41
  step  233/445 | (warm-up text) | align=0.0002 | text_tf=5.2025 | latent_scale=0.41
  step  234/445 | (warm-up text) | align=0.0003 | text_tf=6.1604 | latent_scale=0.41
  step  235/445 | (warm-up text) | align=0.0003 | text_tf=5.6294 | latent_scale=0.41
  step  236/445 | (warm-up text) | align=0.0003 | text_tf=6.1456 | latent_scale=0.41
  step  237/445 | (warm-up text) | align=0.0003 | text_tf=5.5704 | latent_scale=0.41
  step  238/445 | (warm-up text) | align=0.0003 | text_tf=6.1380 | latent_scale=0.41
  step  239/445 | (warm-up text) | align=0.0003 | text_tf=5.9952 | latent_scale=0.41
  step  240/445 | (warm-up text) | align=0.0003 | text_tf=6.0230 | latent_scale=0.41
  step  240/445 | grad_norm=0.00 | sec/step~8.61 | keep=0.50 | K=8 | llama(T): tf=3.8377 first=3.4469 kCE=4.5241 KD=0.0000 acc=0.000 state=6.3525 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.2825e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  241/445 | (warm-up text) | align=0.0003 | text_tf=6.1343 | latent_scale=0.42
  step  242/445 | (warm-up text) | align=0.0003 | text_tf=6.5894 | latent_scale=0.42
  step  243/445 | (warm-up text) | align=0.0003 | text_tf=5.6075 | latent_scale=0.42
  step  244/445 | (warm-up text) | align=0.0003 | text_tf=6.1500 | latent_scale=0.42
  step  245/445 | (warm-up text) | align=0.0003 | text_tf=5.7334 | latent_scale=0.42
  step  246/445 | (warm-up text) | align=0.0003 | text_tf=5.9815 | latent_scale=0.42
  step  247/445 | (warm-up text) | align=0.0003 | text_tf=6.1020 | latent_scale=0.42
  step  248/445 | (warm-up text) | align=0.0003 | text_tf=5.6465 | latent_scale=0.42
  step  249/445 | (warm-up text) | align=0.0003 | text_tf=5.4588 | latent_scale=0.42
  step  250/445 | (warm-up text) | align=0.0003 | text_tf=5.7210 | latent_scale=0.42
  step  250/445 | grad_norm=0.00 | sec/step~9.50 | keep=0.50 | K=8 | llama(T): tf=3.8553 first=3.0766 kCE=4.4796 KD=0.0000 acc=0.083 state=7.2458 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.2825e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0003 rms_cal~0.0106 embed_rms~0.01058]
  step  251/445 | (warm-up text) | align=0.0003 | text_tf=5.6487 | latent_scale=0.42
  step  252/445 | (warm-up text) | align=0.0003 | text_tf=5.6475 | latent_scale=0.43
  step  253/445 | (warm-up text) | align=0.0002 | text_tf=5.8707 | latent_scale=0.43
  step  254/445 | (warm-up text) | align=0.0003 | text_tf=5.6448 | latent_scale=0.43
  step  255/445 | (warm-up text) | align=0.0003 | text_tf=5.3834 | latent_scale=0.43
  step  256/445 | (warm-up text) | align=0.0003 | text_tf=5.4911 | latent_scale=0.43
  step  257/445 | (warm-up text) | align=0.0003 | text_tf=5.6039 | latent_scale=0.43
  step  258/445 | (warm-up text) | align=0.0003 | text_tf=5.9159 | latent_scale=0.43
  step  259/445 | (warm-up text) | align=0.0003 | text_tf=5.9727 | latent_scale=0.43
  step  260/445 | (warm-up text) | align=0.0003 | text_tf=5.6905 | latent_scale=0.43
  step  260/445 | grad_norm=0.00 | sec/step~9.56 | keep=0.50 | K=8 | llama(T): tf=3.7279 first=3.2299 kCE=4.2581 KD=0.0000 acc=0.028 state=6.7357 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=5.1159e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  261/445 | (warm-up text) | align=0.0003 | text_tf=6.3422 | latent_scale=0.43
  step  262/445 | (warm-up text) | align=0.0003 | text_tf=5.6875 | latent_scale=0.43
  step  263/445 | (warm-up text) | align=0.0003 | text_tf=5.5654 | latent_scale=0.44
  step  264/445 | (warm-up text) | align=0.0003 | text_tf=6.0452 | latent_scale=0.44
  step  265/445 | (warm-up text) | align=0.0003 | text_tf=5.9186 | latent_scale=0.44
  step  266/445 | (warm-up text) | align=0.0003 | text_tf=6.1924 | latent_scale=0.44
  step  267/445 | (warm-up text) | align=0.0003 | text_tf=5.5147 | latent_scale=0.44
  step  268/445 | (warm-up text) | align=0.0003 | text_tf=5.7524 | latent_scale=0.44
  step  269/445 | (warm-up text) | align=0.0003 | text_tf=5.5861 | latent_scale=0.44
  step  270/445 | (warm-up text) | align=0.0003 | text_tf=5.5144 | latent_scale=0.44
  step  270/445 | grad_norm=0.00 | sec/step~9.74 | keep=0.50 | K=8 | llama(T): tf=3.8881 first=3.3452 kCE=4.1860 KD=0.0000 acc=0.083 state=7.7091 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=9.2090e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  271/445 | (warm-up text) | align=0.0003 | text_tf=5.7419 | latent_scale=0.44
  step  272/445 | (warm-up text) | align=0.0002 | text_tf=4.8784 | latent_scale=0.44
  step  273/445 | (warm-up text) | align=0.0002 | text_tf=5.8600 | latent_scale=0.44
  step  274/445 | (warm-up text) | align=0.0003 | text_tf=6.0831 | latent_scale=0.45
  step  275/445 | (warm-up text) | align=0.0003 | text_tf=5.6714 | latent_scale=0.45
  step  276/445 | (warm-up text) | align=0.0003 | text_tf=5.3440 | latent_scale=0.45
  step  277/445 | (warm-up text) | align=0.0003 | text_tf=5.6785 | latent_scale=0.45
  step  278/445 | (warm-up text) | align=0.0003 | text_tf=5.6987 | latent_scale=0.45
  step  279/445 | (warm-up text) | align=0.0002 | text_tf=5.7659 | latent_scale=0.45
  step  280/445 | (warm-up text) | align=0.0003 | text_tf=5.6301 | latent_scale=0.45
  step  280/445 | grad_norm=0.00 | sec/step~8.94 | keep=0.50 | K=8 | llama(T): tf=3.9819 first=3.4531 kCE=4.0767 KD=0.0000 acc=0.028 state=7.3784 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=6.0968e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  281/445 | (warm-up text) | align=0.0002 | text_tf=5.5774 | latent_scale=0.45
  step  282/445 | (warm-up text) | align=0.0003 | text_tf=5.0205 | latent_scale=0.45
  step  283/445 | (warm-up text) | align=0.0002 | text_tf=5.6693 | latent_scale=0.45
  step  284/445 | (warm-up text) | align=0.0003 | text_tf=5.8486 | latent_scale=0.45
  step  285/445 | (warm-up text) | align=0.0003 | text_tf=6.0488 | latent_scale=0.46
  step  286/445 | (warm-up text) | align=0.0002 | text_tf=5.1236 | latent_scale=0.46
  step  287/445 | (warm-up text) | align=0.0002 | text_tf=5.1493 | latent_scale=0.46
  step  288/445 | (warm-up text) | align=0.0003 | text_tf=5.9403 | latent_scale=0.46
  step  289/445 | (warm-up text) | align=0.0003 | text_tf=4.9513 | latent_scale=0.46
  step  290/445 | (warm-up text) | align=0.0003 | text_tf=5.6377 | latent_scale=0.46
  step  290/445 | grad_norm=0.00 | sec/step~9.74 | keep=0.50 | K=8 | llama(T): tf=4.0077 first=3.2380 kCE=3.7925 KD=0.0000 acc=0.028 state=7.9528 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=8.8818e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  291/445 | (warm-up text) | align=0.0002 | text_tf=5.1167 | latent_scale=0.46
  step  292/445 | (warm-up text) | align=0.0003 | text_tf=5.6693 | latent_scale=0.46
  step  293/445 | (warm-up text) | align=0.0002 | text_tf=5.3815 | latent_scale=0.46
  step  294/445 | (warm-up text) | align=0.0003 | text_tf=5.5856 | latent_scale=0.46
  step  295/445 | (warm-up text) | align=0.0003 | text_tf=5.2348 | latent_scale=0.46
  step  296/445 | (warm-up text) | align=0.0003 | text_tf=6.1644 | latent_scale=0.47
  step  297/445 | (warm-up text) | align=0.0003 | text_tf=5.2505 | latent_scale=0.47
  step  298/445 | (warm-up text) | align=0.0003 | text_tf=5.5807 | latent_scale=0.47
  step  299/445 | (warm-up text) | align=0.0003 | text_tf=6.2189 | latent_scale=0.47
  step  300/445 | (warm-up text) | align=0.0003 | text_tf=5.4729 | latent_scale=0.47
  step  300/445 | grad_norm=0.00 | sec/step~9.63 | keep=0.50 | K=8 | llama(T): tf=4.1207 first=3.8708 kCE=3.9250 KD=0.0000 acc=0.000 state=8.1522 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=6.8781e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  301/445 | (warm-up text) | align=0.0002 | text_tf=5.3220 | latent_scale=0.47
  step  302/445 | (warm-up text) | align=0.0002 | text_tf=5.3057 | latent_scale=0.47
  step  303/445 | (warm-up text) | align=0.0003 | text_tf=5.5431 | latent_scale=0.47
  step  304/445 | (warm-up text) | align=0.0003 | text_tf=6.0272 | latent_scale=0.47
  step  305/445 | (warm-up text) | align=0.0003 | text_tf=5.8817 | latent_scale=0.47
  step  306/445 | (warm-up text) | align=0.0002 | text_tf=5.0310 | latent_scale=0.47
  step  307/445 | (warm-up text) | align=0.0003 | text_tf=5.7697 | latent_scale=0.48
  step  308/445 | (warm-up text) | align=0.0003 | text_tf=5.3538 | latent_scale=0.48
  step  309/445 | (warm-up text) | align=0.0003 | text_tf=5.5343 | latent_scale=0.48
  step  310/445 | (warm-up text) | align=0.0003 | text_tf=5.8507 | latent_scale=0.48
  step  310/445 | grad_norm=0.00 | sec/step~8.70 | keep=0.50 | K=8 | llama(T): tf=4.1621 first=3.8134 kCE=3.5198 KD=0.0000 acc=0.000 state=6.7461 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=6.8781e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  311/445 | (warm-up text) | align=0.0003 | text_tf=5.3637 | latent_scale=0.48
  step  312/445 | (warm-up text) | align=0.0003 | text_tf=5.3949 | latent_scale=0.48
  step  313/445 | (warm-up text) | align=0.0003 | text_tf=5.0890 | latent_scale=0.48
  step  314/445 | (warm-up text) | align=0.0002 | text_tf=5.1888 | latent_scale=0.48
  step  315/445 | (warm-up text) | align=0.0003 | text_tf=5.1556 | latent_scale=0.48
  step  316/445 | (warm-up text) | align=0.0003 | text_tf=5.2538 | latent_scale=0.48
  step  317/445 | (warm-up text) | align=0.0003 | text_tf=5.6386 | latent_scale=0.48
  step  318/445 | (warm-up text) | align=0.0002 | text_tf=5.3133 | latent_scale=0.48
  step  319/445 | (warm-up text) | align=0.0003 | text_tf=6.1680 | latent_scale=0.49
  step  320/445 | (warm-up text) | align=0.0003 | text_tf=5.2686 | latent_scale=0.49
  step  320/445 | grad_norm=0.00 | sec/step~9.23 | keep=0.50 | K=8 | llama(T): tf=4.2615 first=3.6765 kCE=3.5186 KD=0.0000 acc=0.000 state=7.7968 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=4.2988e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  321/445 | (warm-up text) | align=0.0003 | text_tf=5.3330 | latent_scale=0.49
  step  322/445 | (warm-up text) | align=0.0003 | text_tf=4.9605 | latent_scale=0.49
  step  323/445 | (warm-up text) | align=0.0002 | text_tf=5.8760 | latent_scale=0.49
  step  324/445 | (warm-up text) | align=0.0003 | text_tf=5.0965 | latent_scale=0.49
  step  325/445 | (warm-up text) | align=0.0003 | text_tf=5.4842 | latent_scale=0.49
  step  326/445 | (warm-up text) | align=0.0002 | text_tf=4.9537 | latent_scale=0.49
  step  327/445 | (warm-up text) | align=0.0003 | text_tf=5.7884 | latent_scale=0.49
  step  328/445 | (warm-up text) | align=0.0003 | text_tf=5.7601 | latent_scale=0.49
  step  329/445 | (warm-up text) | align=0.0003 | text_tf=5.7863 | latent_scale=0.49
  step  330/445 | (warm-up text) | align=0.0003 | text_tf=5.3386 | latent_scale=0.50
  step  330/445 | grad_norm=0.00 | sec/step~9.00 | keep=0.50 | K=8 | llama(T): tf=4.4319 first=3.7290 kCE=3.4027 KD=0.0000 acc=0.028 state=8.2810 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=5.2879e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  331/445 | (warm-up text) | align=0.0003 | text_tf=5.3477 | latent_scale=0.50
  step  332/445 | (warm-up text) | align=0.0002 | text_tf=5.8535 | latent_scale=0.50
  step  333/445 | (warm-up text) | align=0.0003 | text_tf=5.1748 | latent_scale=0.50
  step  334/445 | (warm-up text) | align=0.0003 | text_tf=4.9156 | latent_scale=0.50
  step  335/445 | (warm-up text) | align=0.0002 | text_tf=6.0089 | latent_scale=0.50
  step  336/445 | (warm-up text) | align=0.0003 | text_tf=5.0653 | latent_scale=0.50
  step  337/445 | (warm-up text) | align=0.0002 | text_tf=5.1814 | latent_scale=0.50
  step  338/445 | (warm-up text) | align=0.0002 | text_tf=5.5606 | latent_scale=0.50
  step  339/445 | (warm-up text) | align=0.0003 | text_tf=5.9184 | latent_scale=0.50
  step  340/445 | (warm-up text) | align=0.0002 | text_tf=5.2413 | latent_scale=0.50
  step  340/445 | grad_norm=0.00 | sec/step~8.69 | keep=0.50 | K=8 | llama(T): tf=4.3236 first=3.7019 kCE=3.3347 KD=0.0000 acc=0.083 state=7.3407 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=2.1615e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  341/445 | (warm-up text) | align=0.0003 | text_tf=5.5573 | latent_scale=0.51
  step  342/445 | (warm-up text) | align=0.0003 | text_tf=5.5708 | latent_scale=0.51
  step  343/445 | (warm-up text) | align=0.0003 | text_tf=5.2077 | latent_scale=0.51
  step  344/445 | (warm-up text) | align=0.0003 | text_tf=5.2912 | latent_scale=0.51
  step  345/445 | (warm-up text) | align=0.0003 | text_tf=5.7969 | latent_scale=0.51
  step  346/445 | (warm-up text) | align=0.0002 | text_tf=5.4200 | latent_scale=0.51
  step  347/445 | (warm-up text) | align=0.0003 | text_tf=5.4745 | latent_scale=0.51
  step  348/445 | (warm-up text) | align=0.0002 | text_tf=5.4180 | latent_scale=0.51
  step  349/445 | (warm-up text) | align=0.0003 | text_tf=4.9712 | latent_scale=0.51
  step  350/445 | (warm-up text) | align=0.0002 | text_tf=5.1133 | latent_scale=0.51
  step  350/445 | grad_norm=0.00 | sec/step~8.87 | keep=0.50 | K=8 | llama(T): tf=4.3607 first=3.9746 kCE=2.9543 KD=0.0000 acc=0.028 state=8.9004 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  351/445 | (warm-up text) | align=0.0002 | text_tf=4.9623 | latent_scale=0.51
  step  352/445 | (warm-up text) | align=0.0002 | text_tf=5.0207 | latent_scale=0.52
  step  353/445 | (warm-up text) | align=0.0003 | text_tf=5.3775 | latent_scale=0.52
  step  354/445 | (warm-up text) | align=0.0002 | text_tf=5.2253 | latent_scale=0.52
  step  355/445 | (warm-up text) | align=0.0002 | text_tf=4.9806 | latent_scale=0.52
  step  356/445 | (warm-up text) | align=0.0002 | text_tf=4.7465 | latent_scale=0.52
  step  357/445 | (warm-up text) | align=0.0002 | text_tf=5.3517 | latent_scale=0.52
  step  358/445 | (warm-up text) | align=0.0002 | text_tf=5.1057 | latent_scale=0.52
  step  359/445 | (warm-up text) | align=0.0003 | text_tf=5.4678 | latent_scale=0.52
  step  360/445 | (warm-up text) | align=0.0002 | text_tf=5.0556 | latent_scale=0.52
  step  360/445 | grad_norm=0.00 | sec/step~9.03 | keep=0.50 | K=8 | llama(T): tf=4.4937 first=3.9398 kCE=3.3206 KD=0.0000 acc=0.083 state=8.2230 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.5948e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  361/445 | (warm-up text) | align=0.0002 | text_tf=4.5907 | latent_scale=0.52
  step  362/445 | (warm-up text) | align=0.0002 | text_tf=5.2532 | latent_scale=0.52
  step  363/445 | (warm-up text) | align=0.0002 | text_tf=5.4892 | latent_scale=0.53
  step  364/445 | (warm-up text) | align=0.0002 | text_tf=4.9012 | latent_scale=0.53
  step  365/445 | (warm-up text) | align=0.0002 | text_tf=5.0429 | latent_scale=0.53
  step  366/445 | (warm-up text) | align=0.0003 | text_tf=5.1172 | latent_scale=0.53
  step  367/445 | (warm-up text) | align=0.0002 | text_tf=5.2991 | latent_scale=0.53
  step  368/445 | (warm-up text) | align=0.0003 | text_tf=5.3930 | latent_scale=0.53
  step  369/445 | (warm-up text) | align=0.0002 | text_tf=5.1978 | latent_scale=0.53
  step  370/445 | (warm-up text) | align=0.0002 | text_tf=5.2553 | latent_scale=0.53
  step  370/445 | grad_norm=0.00 | sec/step~9.01 | keep=0.50 | K=8 | llama(T): tf=4.5869 first=3.7411 kCE=3.0798 KD=0.0000 acc=0.139 state=9.1116 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.5948e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  371/445 | (warm-up text) | align=0.0002 | text_tf=5.2980 | latent_scale=0.53
  step  372/445 | (warm-up text) | align=0.0002 | text_tf=5.0147 | latent_scale=0.53
  step  373/445 | (warm-up text) | align=0.0002 | text_tf=5.3988 | latent_scale=0.53
  step  374/445 | (warm-up text) | align=0.0003 | text_tf=5.0571 | latent_scale=0.54
  step  375/445 | (warm-up text) | align=0.0002 | text_tf=5.1705 | latent_scale=0.54
  step  376/445 | (warm-up text) | align=0.0002 | text_tf=4.8080 | latent_scale=0.54
  step  377/445 | (warm-up text) | align=0.0003 | text_tf=5.6648 | latent_scale=0.54
  step  378/445 | (warm-up text) | align=0.0003 | text_tf=4.7366 | latent_scale=0.54
  step  379/445 | (warm-up text) | align=0.0002 | text_tf=4.9917 | latent_scale=0.54
  step  380/445 | (warm-up text) | align=0.0003 | text_tf=5.5500 | latent_scale=0.54
  step  380/445 | grad_norm=0.00 | sec/step~8.89 | keep=0.50 | K=8 | llama(T): tf=4.8486 first=4.1997 kCE=3.1340 KD=0.0000 acc=0.056 state=8.8418 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=3.6962e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  381/445 | (warm-up text) | align=0.0002 | text_tf=5.1566 | latent_scale=0.54
  step  382/445 | (warm-up text) | align=0.0003 | text_tf=5.0766 | latent_scale=0.54
  step  383/445 | (warm-up text) | align=0.0002 | text_tf=4.8273 | latent_scale=0.54
  step  384/445 | (warm-up text) | align=0.0003 | text_tf=5.0692 | latent_scale=0.54
  step  385/445 | (warm-up text) | align=0.0003 | text_tf=5.0640 | latent_scale=0.55
  step  386/445 | (warm-up text) | align=0.0002 | text_tf=4.8619 | latent_scale=0.55
  step  387/445 | (warm-up text) | align=0.0002 | text_tf=5.1687 | latent_scale=0.55
  step  388/445 | (warm-up text) | align=0.0002 | text_tf=4.8317 | latent_scale=0.55
  step  389/445 | (warm-up text) | align=0.0002 | text_tf=4.8088 | latent_scale=0.55
  step  390/445 | (warm-up text) | align=0.0002 | text_tf=5.3474 | latent_scale=0.55
  step  390/445 | grad_norm=0.00 | sec/step~9.35 | keep=0.50 | K=8 | llama(T): tf=4.9299 first=4.2169 kCE=3.3766 KD=0.0000 acc=0.056 state=8.4968 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=2.7512e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  391/445 | (warm-up text) | align=0.0002 | text_tf=5.1919 | latent_scale=0.55
  step  392/445 | (warm-up text) | align=0.0002 | text_tf=5.2154 | latent_scale=0.55
  step  393/445 | (warm-up text) | align=0.0002 | text_tf=5.1157 | latent_scale=0.55
  step  394/445 | (warm-up text) | align=0.0002 | text_tf=4.8918 | latent_scale=0.55
  step  395/445 | (warm-up text) | align=0.0002 | text_tf=5.0202 | latent_scale=0.55
  step  396/445 | (warm-up text) | align=0.0003 | text_tf=5.0447 | latent_scale=0.56
  step  397/445 | (warm-up text) | align=0.0002 | text_tf=5.2227 | latent_scale=0.56
  step  398/445 | (warm-up text) | align=0.0002 | text_tf=4.6600 | latent_scale=0.56
  step  399/445 | (warm-up text) | align=0.0002 | text_tf=5.0014 | latent_scale=0.56
  step  400/445 | (warm-up text) | align=0.0002 | text_tf=4.7032 | latent_scale=0.56
  step  400/445 | grad_norm=0.00 | sec/step~8.91 | keep=0.50 | K=8 | llama(T): tf=5.0615 first=4.2384 kCE=3.3462 KD=0.0000 acc=0.083 state=8.3580 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=4.6043e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  401/445 | (warm-up text) | align=0.0002 | text_tf=4.5484 | latent_scale=0.56
  step  402/445 | (warm-up text) | align=0.0002 | text_tf=5.2068 | latent_scale=0.56
  step  403/445 | (warm-up text) | align=0.0002 | text_tf=4.5414 | latent_scale=0.56
  step  404/445 | (warm-up text) | align=0.0002 | text_tf=4.8527 | latent_scale=0.56
  step  405/445 | (warm-up text) | align=0.0002 | text_tf=5.1725 | latent_scale=0.56
  step  406/445 | (warm-up text) | align=0.0003 | text_tf=4.7721 | latent_scale=0.56
  step  407/445 | (warm-up text) | align=0.0002 | text_tf=5.1561 | latent_scale=0.56
  step  408/445 | (warm-up text) | align=0.0002 | text_tf=5.2580 | latent_scale=0.57
  step  409/445 | (warm-up text) | align=0.0002 | text_tf=4.8916 | latent_scale=0.57
  step  410/445 | (warm-up text) | align=0.0002 | text_tf=5.0518 | latent_scale=0.57
  step  410/445 | grad_norm=0.00 | sec/step~8.87 | keep=0.50 | K=8 | llama(T): tf=4.8996 first=4.2923 kCE=3.2765 KD=0.0000 acc=0.056 state=9.0403 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=2.7853e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  411/445 | (warm-up text) | align=0.0002 | text_tf=4.8636 | latent_scale=0.57
  step  412/445 | (warm-up text) | align=0.0003 | text_tf=5.4278 | latent_scale=0.57
  step  413/445 | (warm-up text) | align=0.0003 | text_tf=5.2866 | latent_scale=0.57
  step  414/445 | (warm-up text) | align=0.0002 | text_tf=5.3657 | latent_scale=0.57
  step  415/445 | (warm-up text) | align=0.0002 | text_tf=4.7629 | latent_scale=0.57
  step  416/445 | (warm-up text) | align=0.0002 | text_tf=4.7711 | latent_scale=0.57
  step  417/445 | (warm-up text) | align=0.0002 | text_tf=5.2722 | latent_scale=0.57
  step  418/445 | (warm-up text) | align=0.0002 | text_tf=4.4244 | latent_scale=0.57
  step  419/445 | (warm-up text) | align=0.0002 | text_tf=5.3092 | latent_scale=0.58
  step  420/445 | (warm-up text) | align=0.0003 | text_tf=4.8194 | latent_scale=0.58
  step  420/445 | grad_norm=0.00 | sec/step~8.58 | keep=0.50 | K=8 | llama(T): tf=4.8923 first=4.4594 kCE=3.5631 KD=0.0000 acc=0.028 state=8.8410 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.8417e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  421/445 | (warm-up text) | align=0.0002 | text_tf=4.9431 | latent_scale=0.58
  step  422/445 | (warm-up text) | align=0.0002 | text_tf=4.5773 | latent_scale=0.58
  step  423/445 | (warm-up text) | align=0.0002 | text_tf=5.2460 | latent_scale=0.58
  step  424/445 | (warm-up text) | align=0.0002 | text_tf=4.8358 | latent_scale=0.58
  step  425/445 | (warm-up text) | align=0.0002 | text_tf=4.7488 | latent_scale=0.58
  step  426/445 | (warm-up text) | align=0.0002 | text_tf=4.7067 | latent_scale=0.58
  step  427/445 | (warm-up text) | align=0.0002 | text_tf=4.5548 | latent_scale=0.58
  step  428/445 | (warm-up text) | align=0.0003 | text_tf=5.7616 | latent_scale=0.58
  step  429/445 | (warm-up text) | align=0.0002 | text_tf=5.0237 | latent_scale=0.58
  step  430/445 | (warm-up text) | align=0.0002 | text_tf=4.7814 | latent_scale=0.59
  step  430/445 | grad_norm=0.00 | sec/step~8.87 | keep=0.50 | K=8 | llama(T): tf=4.8719 first=4.3907 kCE=3.2939 KD=0.0000 acc=0.056 state=9.5889 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.8417e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  431/445 | (warm-up text) | align=0.0002 | text_tf=5.3502 | latent_scale=0.59
  step  432/445 | (warm-up text) | align=0.0002 | text_tf=5.3716 | latent_scale=0.59
  step  433/445 | (warm-up text) | align=0.0002 | text_tf=5.3792 | latent_scale=0.59
  step  434/445 | (warm-up text) | align=0.0002 | text_tf=5.2315 | latent_scale=0.59
  step  435/445 | (warm-up text) | align=0.0002 | text_tf=4.8599 | latent_scale=0.59
  step  436/445 | (warm-up text) | align=0.0002 | text_tf=5.5621 | latent_scale=0.59
  step  437/445 | (warm-up text) | align=0.0002 | text_tf=4.6427 | latent_scale=0.59
  step  438/445 | (warm-up text) | align=0.0002 | text_tf=4.9307 | latent_scale=0.59
  step  439/445 | (warm-up text) | align=0.0002 | text_tf=4.8048 | latent_scale=0.59
  step  440/445 | (warm-up text) | align=0.0002 | text_tf=4.8852 | latent_scale=0.59
  step  440/445 | grad_norm=0.00 | sec/step~8.68 | keep=0.50 | K=8 | llama(T): tf=5.0724 first=4.2338 kCE=3.4665 KD=0.0000 acc=0.139 state=9.6972 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=2.1615e-11 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  441/445 | (warm-up text) | align=0.0003 | text_tf=5.5646 | latent_scale=0.60
  step  442/445 | (warm-up text) | align=0.0002 | text_tf=5.0240 | latent_scale=0.60
  step  443/445 | (warm-up text) | align=0.0002 | text_tf=4.5923 | latent_scale=0.60
  step  444/445 | (warm-up text) | align=0.0002 | text_tf=5.2476 | latent_scale=0.60
  step  445/445 | (warm-up text) | align=0.0003 | text_tf=5.5021 | latent_scale=0.60
  step  445/445 | grad_norm=0.00 | sec/step~5.51 | keep=0.50 | K=8 | llama(T): tf=5.1707 first=4.7378 kCE=3.2275 KD=0.0000 acc=0.062 state=10.6688 align=0.0003 latA=0.0000 latP=0.0000 | scale_pen(llama)=5.1159e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
[checkpoint] Freed 3.7KB before save.
[checkpoint] Saved latest: encoder.pt, state.pt, config.json, adapter_llama.pt, deep_prefix_llama.pt, refiner.pt
[checkpoint] Freed 0.0B after save (non-canonical).
  ✅ Saved (and pruned to) latest at step 445
Epoch 2/10
  step  1/445 | (warm-up text) | align=0.0002 | text_tf=4.8545 | latent_scale=0.60
  step  2/445 | (warm-up text) | align=0.0002 | text_tf=4.6227 | latent_scale=0.60
  step  3/445 | (warm-up text) | align=0.0002 | text_tf=4.8475 | latent_scale=0.60
  step  4/445 | (warm-up text) | align=0.0002 | text_tf=5.0316 | latent_scale=0.60
  step  5/445 | (warm-up text) | align=0.0002 | text_tf=4.6554 | latent_scale=0.60
  step  6/445 | (warm-up text) | align=0.0002 | text_tf=5.0875 | latent_scale=0.60
  step  7/445 | (warm-up text) | align=0.0003 | text_tf=5.1370 | latent_scale=0.61
  step  8/445 | (warm-up text) | align=0.0002 | text_tf=4.8103 | latent_scale=0.61
  step  9/445 | (warm-up text) | align=0.0002 | text_tf=5.0423 | latent_scale=0.61
  step  10/445 | (warm-up text) | align=0.0002 | text_tf=4.7040 | latent_scale=0.61
  step  10/445 | grad_norm=0.00 | sec/step~8.71 | keep=0.51 | K=8 | llama(T): tf=5.1274 first=4.7446 kCE=3.4521 KD=0.0000 acc=0.000 state=10.1991 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=5.1159e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  11/445 | (warm-up text) | align=0.0002 | text_tf=4.9183 | latent_scale=0.61
  step  12/445 | (warm-up text) | align=0.0002 | text_tf=5.1434 | latent_scale=0.61
  step  13/445 | (warm-up text) | align=0.0002 | text_tf=4.7142 | latent_scale=0.61
  step  14/445 | (warm-up text) | align=0.0002 | text_tf=4.6460 | latent_scale=0.61
  step  15/445 | (warm-up text) | align=0.0002 | text_tf=4.2440 | latent_scale=0.61
  step  16/445 | (warm-up text) | align=0.0002 | text_tf=4.2844 | latent_scale=0.61
  step  17/445 | (warm-up text) | align=0.0002 | text_tf=5.5877 | latent_scale=0.61
  step  18/445 | (warm-up text) | align=0.0002 | text_tf=4.2339 | latent_scale=0.62
  step  19/445 | (warm-up text) | align=0.0002 | text_tf=4.6757 | latent_scale=0.62
  step  20/445 | (warm-up text) | align=0.0002 | text_tf=5.0671 | latent_scale=0.62
  step  20/445 | grad_norm=0.00 | sec/step~8.91 | keep=0.51 | K=8 | llama(T): tf=5.4126 first=4.8896 kCE=3.2703 KD=0.0000 acc=0.111 state=10.4537 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=2.0464e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  21/445 | (warm-up text) | align=0.0002 | text_tf=4.8639 | latent_scale=0.62
  step  22/445 | (warm-up text) | align=0.0002 | text_tf=4.3449 | latent_scale=0.62
  step  23/445 | (warm-up text) | align=0.0002 | text_tf=4.2250 | latent_scale=0.62
  step  24/445 | (warm-up text) | align=0.0002 | text_tf=5.4938 | latent_scale=0.62
  step  25/445 | (warm-up text) | align=0.0002 | text_tf=5.2252 | latent_scale=0.62
  step  26/445 | (warm-up text) | align=0.0002 | text_tf=4.6467 | latent_scale=0.62
  step  27/445 | (warm-up text) | align=0.0002 | text_tf=5.0302 | latent_scale=0.62
  step  28/445 | (warm-up text) | align=0.0002 | text_tf=4.5746 | latent_scale=0.62
  step  29/445 | (warm-up text) | align=0.0002 | text_tf=4.8394 | latent_scale=0.63
  step  30/445 | (warm-up text) | align=0.0002 | text_tf=4.2874 | latent_scale=0.63
  step  30/445 | grad_norm=0.00 | sec/step~9.06 | keep=0.51 | K=8 | llama(T): tf=5.4851 first=4.4223 kCE=3.9388 KD=0.0000 acc=0.028 state=10.2488 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=7.5175e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  31/445 | (warm-up text) | align=0.0002 | text_tf=4.6968 | latent_scale=0.63
  step  32/445 | (warm-up text) | align=0.0002 | text_tf=5.5992 | latent_scale=0.63
  step  33/445 | (warm-up text) | align=0.0002 | text_tf=4.6455 | latent_scale=0.63
  step  34/445 | (warm-up text) | align=0.0002 | text_tf=5.0095 | latent_scale=0.63
  step  35/445 | (warm-up text) | align=0.0002 | text_tf=4.9786 | latent_scale=0.63
  step  36/445 | (warm-up text) | align=0.0002 | text_tf=4.7272 | latent_scale=0.63
  step  37/445 | (warm-up text) | align=0.0002 | text_tf=5.2433 | latent_scale=0.63
  step  38/445 | (warm-up text) | align=0.0002 | text_tf=4.7885 | latent_scale=0.63
  step  39/445 | (warm-up text) | align=0.0002 | text_tf=4.3061 | latent_scale=0.63
  step  40/445 | (warm-up text) | align=0.0002 | text_tf=4.6587 | latent_scale=0.64
  step  40/445 | grad_norm=0.00 | sec/step~8.98 | keep=0.51 | K=8 | llama(T): tf=5.3335 first=4.8240 kCE=3.5556 KD=0.0000 acc=0.028 state=11.2917 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=6.8781e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  41/445 | (warm-up text) | align=0.0002 | text_tf=4.9080 | latent_scale=0.64
  step  42/445 | (warm-up text) | align=0.0002 | text_tf=5.2592 | latent_scale=0.64
  step  43/445 | (warm-up text) | align=0.0002 | text_tf=4.4095 | latent_scale=0.64
  step  44/445 | (warm-up text) | align=0.0002 | text_tf=4.2398 | latent_scale=0.64
  step  45/445 | (warm-up text) | align=0.0003 | text_tf=5.3282 | latent_scale=0.64
  step  46/445 | (warm-up text) | align=0.0002 | text_tf=4.2988 | latent_scale=0.64
  step  47/445 | (warm-up text) | align=0.0002 | text_tf=4.7849 | latent_scale=0.64
  step  48/445 | (warm-up text) | align=0.0002 | text_tf=4.7309 | latent_scale=0.64
  step  49/445 | (warm-up text) | align=0.0002 | text_tf=4.8148 | latent_scale=0.64
  step  50/445 | (warm-up text) | align=0.0002 | text_tf=5.1846 | latent_scale=0.64
  step  50/445 | grad_norm=0.00 | sec/step~9.23 | keep=0.51 | K=8 | llama(T): tf=5.5132 first=5.1313 kCE=3.6373 KD=0.0000 acc=0.000 state=10.6778 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.4211e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  51/445 | (warm-up text) | align=0.0002 | text_tf=4.1800 | latent_scale=0.64
  step  52/445 | (warm-up text) | align=0.0002 | text_tf=4.4319 | latent_scale=0.65
  step  53/445 | (warm-up text) | align=0.0002 | text_tf=4.0068 | latent_scale=0.65
  step  54/445 | (warm-up text) | align=0.0002 | text_tf=4.8570 | latent_scale=0.65
  step  55/445 | (warm-up text) | align=0.0002 | text_tf=4.3643 | latent_scale=0.65
  step  56/445 | (warm-up text) | align=0.0002 | text_tf=4.3491 | latent_scale=0.65
  step  57/445 | (warm-up text) | align=0.0002 | text_tf=4.5570 | latent_scale=0.65
  step  58/445 | (warm-up text) | align=0.0002 | text_tf=4.3309 | latent_scale=0.65
  step  59/445 | (warm-up text) | align=0.0002 | text_tf=4.8851 | latent_scale=0.65
  step  60/445 | (warm-up text) | align=0.0002 | text_tf=4.0504 | latent_scale=0.65
  step  60/445 | grad_norm=0.00 | sec/step~9.35 | keep=0.51 | K=8 | llama(T): tf=5.2874 first=4.2602 kCE=3.8905 KD=0.0000 acc=0.111 state=11.6839 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  61/445 | (warm-up text) | align=0.0002 | text_tf=4.8174 | latent_scale=0.65
  step  62/445 | (warm-up text) | align=0.0003 | text_tf=4.0765 | latent_scale=0.65
  step  63/445 | (warm-up text) | align=0.0002 | text_tf=4.7417 | latent_scale=0.66
  step  64/445 | (warm-up text) | align=0.0002 | text_tf=4.8416 | latent_scale=0.66
  step  65/445 | (warm-up text) | align=0.0002 | text_tf=4.8030 | latent_scale=0.66
  step  66/445 | (warm-up text) | align=0.0003 | text_tf=4.8163 | latent_scale=0.66
  step  67/445 | (warm-up text) | align=0.0002 | text_tf=4.6869 | latent_scale=0.66
  step  68/445 | (warm-up text) | align=0.0002 | text_tf=4.4682 | latent_scale=0.66
  step  69/445 | (warm-up text) | align=0.0002 | text_tf=4.3409 | latent_scale=0.66
  step  70/445 | (warm-up text) | align=0.0002 | text_tf=4.3666 | latent_scale=0.66
  step  70/445 | grad_norm=0.00 | sec/step~8.94 | keep=0.51 | K=8 | llama(T): tf=5.6093 first=4.9096 kCE=3.6885 KD=0.0000 acc=0.000 state=10.6593 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  71/445 | (warm-up text) | align=0.0002 | text_tf=4.8557 | latent_scale=0.66
  step  72/445 | (warm-up text) | align=0.0002 | text_tf=4.6302 | latent_scale=0.66
  step  73/445 | (warm-up text) | align=0.0002 | text_tf=5.2507 | latent_scale=0.66
  step  74/445 | (warm-up text) | align=0.0002 | text_tf=4.1892 | latent_scale=0.67
  step  75/445 | (warm-up text) | align=0.0002 | text_tf=5.1678 | latent_scale=0.67
  step  76/445 | (warm-up text) | align=0.0002 | text_tf=4.2506 | latent_scale=0.67
  step  77/445 | (warm-up text) | align=0.0002 | text_tf=4.5297 | latent_scale=0.67
  step  78/445 | (warm-up text) | align=0.0002 | text_tf=4.7202 | latent_scale=0.67
  step  79/445 | (warm-up text) | align=0.0002 | text_tf=4.8368 | latent_scale=0.67
  step  80/445 | (warm-up text) | align=0.0002 | text_tf=5.1469 | latent_scale=0.67
  step  80/445 | grad_norm=0.00 | sec/step~8.59 | keep=0.51 | K=8 | llama(T): tf=5.4565 first=4.2828 kCE=3.6798 KD=0.0000 acc=0.111 state=10.4741 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=3.6380e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  81/445 | (warm-up text) | align=0.0002 | text_tf=4.6123 | latent_scale=0.67
  step  82/445 | (warm-up text) | align=0.0002 | text_tf=4.5105 | latent_scale=0.67
  step  83/445 | (warm-up text) | align=0.0002 | text_tf=5.2920 | latent_scale=0.67
  step  84/445 | (warm-up text) | align=0.0002 | text_tf=4.0122 | latent_scale=0.67
  step  85/445 | (warm-up text) | align=0.0002 | text_tf=4.0629 | latent_scale=0.68
  step  86/445 | (warm-up text) | align=0.0002 | text_tf=4.4511 | latent_scale=0.68
  step  87/445 | (warm-up text) | align=0.0002 | text_tf=4.6723 | latent_scale=0.68
  step  88/445 | (warm-up text) | align=0.0002 | text_tf=4.9366 | latent_scale=0.68
  step  89/445 | (warm-up text) | align=0.0002 | text_tf=4.5212 | latent_scale=0.68
  step  90/445 | (warm-up text) | align=0.0002 | text_tf=5.4141 | latent_scale=0.68
  step  90/445 | grad_norm=0.00 | sec/step~8.62 | keep=0.51 | K=8 | llama(T): tf=5.9091 first=5.1820 kCE=3.7581 KD=0.0000 acc=0.028 state=11.0521 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=4.1069e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0004 rms_cal~0.0106 embed_rms~0.01058]
  step  91/445 | (warm-up text) | align=0.0002 | text_tf=4.3294 | latent_scale=0.68
  step  92/445 | (warm-up text) | align=0.0002 | text_tf=4.5686 | latent_scale=0.68
  step  93/445 | (warm-up text) | align=0.0003 | text_tf=5.3134 | latent_scale=0.68
  step  94/445 | (warm-up text) | align=0.0002 | text_tf=4.6754 | latent_scale=0.68
  step  95/445 | (warm-up text) | align=0.0002 | text_tf=4.2545 | latent_scale=0.68
  step  96/445 | (warm-up text) | align=0.0002 | text_tf=4.2987 | latent_scale=0.69
  step  97/445 | (warm-up text) | align=0.0002 | text_tf=4.8214 | latent_scale=0.69
  step  98/445 | (warm-up text) | align=0.0002 | text_tf=5.1903 | latent_scale=0.69
  step  99/445 | (warm-up text) | align=0.0002 | text_tf=5.2324 | latent_scale=0.69
  step  100/445 | (warm-up text) | align=0.0002 | text_tf=4.6202 | latent_scale=0.69
  step  100/445 | grad_norm=0.00 | sec/step~9.11 | keep=0.51 | K=8 | llama(T): tf=5.8492 first=5.5228 kCE=3.9893 KD=0.0000 acc=0.028 state=12.2265 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.1511e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0005 rms_cal~0.0106 embed_rms~0.01058]
  step  101/445 | (warm-up text) | align=0.0002 | text_tf=4.2925 | latent_scale=0.69
  step  102/445 | (warm-up text) | align=0.0002 | text_tf=4.6152 | latent_scale=0.69
  step  103/445 | (warm-up text) | align=0.0002 | text_tf=4.8135 | latent_scale=0.69
  step  104/445 | (warm-up text) | align=0.0002 | text_tf=4.6142 | latent_scale=0.69
  step  105/445 | (warm-up text) | align=0.0002 | text_tf=4.1522 | latent_scale=0.69
  step  106/445 | (warm-up text) | align=0.0002 | text_tf=4.4680 | latent_scale=0.69
  step  107/445 | (warm-up text) | align=0.0002 | text_tf=4.6852 | latent_scale=0.70
  step  108/445 | (warm-up text) | align=0.0002 | text_tf=4.5766 | latent_scale=0.70
  step  109/445 | (warm-up text) | align=0.0002 | text_tf=4.5927 | latent_scale=0.70
  step  110/445 | (warm-up text) | align=0.0002 | text_tf=4.5420 | latent_scale=0.70
  step  110/445 | grad_norm=0.00 | sec/step~9.52 | keep=0.51 | K=8 | llama(T): tf=5.7876 first=4.9194 kCE=3.9748 KD=0.0000 acc=0.083 state=13.1028 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.7408e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0005 rms_cal~0.0106 embed_rms~0.01058]
  step  111/445 | (warm-up text) | align=0.0002 | text_tf=5.2640 | latent_scale=0.70
  step  112/445 | (warm-up text) | align=0.0002 | text_tf=4.1682 | latent_scale=0.70
  step  113/445 | (warm-up text) | align=0.0002 | text_tf=4.8992 | latent_scale=0.70
  step  114/445 | (warm-up text) | align=0.0002 | text_tf=4.2905 | latent_scale=0.70
  step  115/445 | (warm-up text) | align=0.0002 | text_tf=4.6842 | latent_scale=0.70
  step  116/445 | (warm-up text) | align=0.0002 | text_tf=4.5187 | latent_scale=0.70
  step  117/445 | (warm-up text) | align=0.0002 | text_tf=4.6583 | latent_scale=0.70
  step  118/445 | (warm-up text) | align=0.0002 | text_tf=4.4025 | latent_scale=0.71
  step  119/445 | (warm-up text) | align=0.0002 | text_tf=4.5871 | latent_scale=0.71
  step  120/445 | (warm-up text) | align=0.0002 | text_tf=4.5491 | latent_scale=0.71
  step  120/445 | grad_norm=0.00 | sec/step~9.09 | keep=0.51 | K=8 | llama(T): tf=5.8968 first=5.1669 kCE=4.2334 KD=0.0000 acc=0.056 state=12.1445 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=2.5899e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0005 rms_cal~0.0106 embed_rms~0.01058]
  step  121/445 | (warm-up text) | align=0.0002 | text_tf=4.3000 | latent_scale=0.71
  step  122/445 | (warm-up text) | align=0.0002 | text_tf=4.5570 | latent_scale=0.71
  step  123/445 | (warm-up text) | align=0.0002 | text_tf=4.6304 | latent_scale=0.71
  step  124/445 | (warm-up text) | align=0.0002 | text_tf=4.6802 | latent_scale=0.71
  step  125/445 | (warm-up text) | align=0.0002 | text_tf=4.3458 | latent_scale=0.71
  step  126/445 | (warm-up text) | align=0.0002 | text_tf=4.1087 | latent_scale=0.71
  step  127/445 | (warm-up text) | align=0.0002 | text_tf=4.8311 | latent_scale=0.71
  step  128/445 | (warm-up text) | align=0.0002 | text_tf=4.5679 | latent_scale=0.71
  step  129/445 | (warm-up text) | align=0.0002 | text_tf=4.9526 | latent_scale=0.72
  step  130/445 | (warm-up text) | align=0.0002 | text_tf=4.7687 | latent_scale=0.72
  step  130/445 | grad_norm=0.00 | sec/step~8.52 | keep=0.51 | K=8 | llama(T): tf=6.0905 first=5.2901 kCE=4.0876 KD=0.0000 acc=0.111 state=10.5633 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=2.5899e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0005 rms_cal~0.0106 embed_rms~0.01058]
  step  131/445 | (warm-up text) | align=0.0002 | text_tf=4.8453 | latent_scale=0.72
  step  132/445 | (warm-up text) | align=0.0002 | text_tf=4.5355 | latent_scale=0.72
  step  133/445 | (warm-up text) | align=0.0002 | text_tf=4.8975 | latent_scale=0.72
  step  134/445 | (warm-up text) | align=0.0002 | text_tf=4.7323 | latent_scale=0.72
  step  135/445 | (warm-up text) | align=0.0002 | text_tf=4.4300 | latent_scale=0.72
  step  136/445 | (warm-up text) | align=0.0002 | text_tf=5.0135 | latent_scale=0.72
  step  137/445 | (warm-up text) | align=0.0002 | text_tf=4.2297 | latent_scale=0.72
  step  138/445 | (warm-up text) | align=0.0002 | text_tf=4.1203 | latent_scale=0.72
  step  139/445 | (warm-up text) | align=0.0002 | text_tf=4.5886 | latent_scale=0.72
  step  140/445 | (warm-up text) | align=0.0002 | text_tf=4.2923 | latent_scale=0.72
  step  140/445 | grad_norm=0.00 | sec/step~9.10 | keep=0.51 | K=8 | llama(T): tf=5.4784 first=5.3044 kCE=3.7134 KD=0.0000 acc=0.000 state=12.0663 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=3.4142e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0005 rms_cal~0.0106 embed_rms~0.01058]
  step  141/445 | (warm-up text) | align=0.0002 | text_tf=4.4371 | latent_scale=0.73
  step  142/445 | (warm-up text) | align=0.0002 | text_tf=4.6958 | latent_scale=0.73
  step  143/445 | (warm-up text) | align=0.0002 | text_tf=4.5747 | latent_scale=0.73
  step  144/445 | (warm-up text) | align=0.0002 | text_tf=4.3859 | latent_scale=0.73
  step  145/445 | (warm-up text) | align=0.0002 | text_tf=4.5158 | latent_scale=0.73
  step  146/445 | (warm-up text) | align=0.0002 | text_tf=4.2202 | latent_scale=0.73
  step  147/445 | (warm-up text) | align=0.0002 | text_tf=5.0198 | latent_scale=0.73
  step  148/445 | (warm-up text) | align=0.0002 | text_tf=4.3720 | latent_scale=0.73
  step  149/445 | (warm-up text) | align=0.0002 | text_tf=5.1542 | latent_scale=0.73
  step  150/445 | (warm-up text) | align=0.0002 | text_tf=4.7064 | latent_scale=0.73
  step  150/445 | grad_norm=0.00 | sec/step~8.88 | keep=0.51 | K=8 | llama(T): tf=6.3621 first=5.6606 kCE=3.9767 KD=0.0000 acc=0.000 state=12.3674 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.1511e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0005 rms_cal~0.0106 embed_rms~0.01058]
  step  151/445 | (warm-up text) | align=0.0002 | text_tf=4.5696 | latent_scale=0.73
  step  152/445 | (warm-up text) | align=0.0002 | text_tf=4.7102 | latent_scale=0.74
  step  153/445 | (warm-up text) | align=0.0002 | text_tf=4.4329 | latent_scale=0.74
  step  154/445 | (warm-up text) | align=0.0002 | text_tf=4.1688 | latent_scale=0.74
  step  155/445 | (warm-up text) | align=0.0002 | text_tf=4.6833 | latent_scale=0.74
  step  156/445 | (warm-up text) | align=0.0002 | text_tf=4.5082 | latent_scale=0.74
  step  157/445 | (warm-up text) | align=0.0002 | text_tf=4.2418 | latent_scale=0.74
  step  158/445 | (warm-up text) | align=0.0002 | text_tf=4.7807 | latent_scale=0.74
  step  159/445 | (warm-up text) | align=0.0002 | text_tf=4.2980 | latent_scale=0.74
  step  160/445 | (warm-up text) | align=0.0002 | text_tf=5.2455 | latent_scale=0.74
  step  160/445 | grad_norm=0.00 | sec/step~8.96 | keep=0.51 | K=8 | llama(T): tf=6.5972 first=6.3217 kCE=3.8101 KD=0.0000 acc=0.000 state=12.5790 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0005 rms_cal~0.0106 embed_rms~0.01058]
  step  161/445 | (warm-up text) | align=0.0002 | text_tf=4.8080 | latent_scale=0.74
  step  162/445 | (warm-up text) | align=0.0002 | text_tf=4.8007 | latent_scale=0.74
  step  163/445 | (warm-up text) | align=0.0002 | text_tf=4.4551 | latent_scale=0.75
  step  164/445 | (warm-up text) | align=0.0002 | text_tf=4.6963 | latent_scale=0.75
  step  165/445 | (warm-up text) | align=0.0002 | text_tf=4.5480 | latent_scale=0.75
  step  166/445 | (warm-up text) | align=0.0002 | text_tf=4.0958 | latent_scale=0.75
  step  167/445 | (warm-up text) | align=0.0002 | text_tf=4.4256 | latent_scale=0.75
  step  168/445 | (warm-up text) | align=0.0002 | text_tf=4.1699 | latent_scale=0.75
  step  169/445 | (warm-up text) | align=0.0002 | text_tf=4.2164 | latent_scale=0.75
  step  170/445 | (warm-up text) | align=0.0002 | text_tf=3.8142 | latent_scale=0.75
  step  170/445 | grad_norm=0.00 | sec/step~9.13 | keep=0.51 | K=8 | llama(T): tf=6.3080 first=5.7506 kCE=4.0228 KD=0.0000 acc=0.000 state=12.9360 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.1511e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0005 rms_cal~0.0106 embed_rms~0.01058]
  step  171/445 | (warm-up text) | align=0.0002 | text_tf=4.6671 | latent_scale=0.75
  step  172/445 | (warm-up text) | align=0.0002 | text_tf=4.0657 | latent_scale=0.75
  step  173/445 | (warm-up text) | align=0.0002 | text_tf=3.9277 | latent_scale=0.75
  step  174/445 | (warm-up text) | align=0.0002 | text_tf=4.6308 | latent_scale=0.76
  step  175/445 | (warm-up text) | align=0.0002 | text_tf=4.9520 | latent_scale=0.76
  step  176/445 | (warm-up text) | align=0.0002 | text_tf=4.5982 | latent_scale=0.76
  step  177/445 | (warm-up text) | align=0.0002 | text_tf=4.2554 | latent_scale=0.76
  step  178/445 | (warm-up text) | align=0.0002 | text_tf=4.9839 | latent_scale=0.76
  step  179/445 | (warm-up text) | align=0.0002 | text_tf=4.3845 | latent_scale=0.76
  step  180/445 | (warm-up text) | align=0.0002 | text_tf=4.3499 | latent_scale=0.76
  step  180/445 | grad_norm=0.00 | sec/step~8.85 | keep=0.51 | K=8 | llama(T): tf=6.3082 first=5.5215 kCE=4.0414 KD=0.0000 acc=0.056 state=11.8066 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.7195e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0005 rms_cal~0.0106 embed_rms~0.01058]
  step  181/445 | (warm-up text) | align=0.0002 | text_tf=4.3214 | latent_scale=0.76
  step  182/445 | (warm-up text) | align=0.0002 | text_tf=4.3097 | latent_scale=0.76
  step  183/445 | (warm-up text) | align=0.0002 | text_tf=4.1383 | latent_scale=0.76
  step  184/445 | (warm-up text) | align=0.0002 | text_tf=4.5578 | latent_scale=0.76
  step  185/445 | (warm-up text) | align=0.0002 | text_tf=4.4842 | latent_scale=0.77
  step  186/445 | (warm-up text) | align=0.0002 | text_tf=4.7107 | latent_scale=0.77
  step  187/445 | (warm-up text) | align=0.0002 | text_tf=4.7545 | latent_scale=0.77
  step  188/445 | (warm-up text) | align=0.0002 | text_tf=4.5142 | latent_scale=0.77
  step  189/445 | (warm-up text) | align=0.0002 | text_tf=4.5614 | latent_scale=0.77
  step  190/445 | (warm-up text) | align=0.0002 | text_tf=3.9476 | latent_scale=0.77
  step  190/445 | grad_norm=0.00 | sec/step~9.11 | keep=0.51 | K=8 | llama(T): tf=6.4157 first=5.5095 kCE=4.5045 KD=0.0000 acc=0.028 state=13.0230 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.7195e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0005 rms_cal~0.0106 embed_rms~0.01058]
  step  191/445 | (warm-up text) | align=0.0002 | text_tf=4.8370 | latent_scale=0.77
  step  192/445 | (warm-up text) | align=0.0002 | text_tf=4.4591 | latent_scale=0.77
  step  193/445 | (warm-up text) | align=0.0002 | text_tf=4.0381 | latent_scale=0.77
  step  194/445 | (warm-up text) | align=0.0002 | text_tf=4.1315 | latent_scale=0.77
  step  195/445 | (warm-up text) | align=0.0002 | text_tf=3.8672 | latent_scale=0.77
  step  196/445 | (warm-up text) | align=0.0002 | text_tf=4.6230 | latent_scale=0.78
  step  197/445 | (warm-up text) | align=0.0002 | text_tf=4.6757 | latent_scale=0.78
  step  198/445 | (warm-up text) | align=0.0002 | text_tf=3.8037 | latent_scale=0.78
  step  199/445 | (warm-up text) | align=0.0002 | text_tf=4.2191 | latent_scale=0.78
  step  200/445 | (warm-up text) | align=0.0002 | text_tf=4.1992 | latent_scale=0.78
  step  200/445 | grad_norm=0.00 | sec/step~10.29 | keep=0.51 | K=8 | llama(T): tf=6.1410 first=5.6160 kCE=4.1423 KD=0.0000 acc=0.056 state=14.7785 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=5.1159e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0005 rms_cal~0.0106 embed_rms~0.01058]
  step  201/445 | (warm-up text) | align=0.0002 | text_tf=4.0346 | latent_scale=0.78
  step  202/445 | (warm-up text) | align=0.0002 | text_tf=5.1466 | latent_scale=0.78
  step  203/445 | (warm-up text) | align=0.0002 | text_tf=4.7665 | latent_scale=0.78
  step  204/445 | (warm-up text) | align=0.0002 | text_tf=4.2722 | latent_scale=0.78
  step  205/445 | (warm-up text) | align=0.0002 | text_tf=4.4096 | latent_scale=0.78
  step  206/445 | (warm-up text) | align=0.0002 | text_tf=4.4602 | latent_scale=0.78
  step  207/445 | (warm-up text) | align=0.0002 | text_tf=4.4722 | latent_scale=0.79
  step  208/445 | (warm-up text) | align=0.0002 | text_tf=4.5468 | latent_scale=0.79
  step  209/445 | (warm-up text) | align=0.0002 | text_tf=4.0937 | latent_scale=0.79
  step  210/445 | (warm-up text) | align=0.0002 | text_tf=5.0514 | latent_scale=0.79
  step  210/445 | grad_norm=0.00 | sec/step~8.83 | keep=0.51 | K=8 | llama(T): tf=7.2328 first=6.6897 kCE=3.9045 KD=0.0000 acc=0.028 state=13.1699 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0005 rms_cal~0.0106 embed_rms~0.01058]
  step  211/445 | (warm-up text) | align=0.0002 | text_tf=3.8394 | latent_scale=0.79
  step  212/445 | (warm-up text) | align=0.0002 | text_tf=3.8788 | latent_scale=0.79
  step  213/445 | (warm-up text) | align=0.0002 | text_tf=4.4486 | latent_scale=0.79
  step  214/445 | (warm-up text) | align=0.0002 | text_tf=5.1612 | latent_scale=0.79
  step  215/445 | (warm-up text) | align=0.0002 | text_tf=4.1134 | latent_scale=0.79
  step  216/445 | (warm-up text) | align=0.0002 | text_tf=4.5435 | latent_scale=0.79
  step  217/445 | (warm-up text) | align=0.0002 | text_tf=4.6027 | latent_scale=0.79
  step  218/445 | (warm-up text) | align=0.0002 | text_tf=3.9455 | latent_scale=0.80
  step  219/445 | (warm-up text) | align=0.0002 | text_tf=4.6327 | latent_scale=0.80
  step  220/445 | (warm-up text) | align=0.0002 | text_tf=4.4523 | latent_scale=0.80
  step  220/445 | grad_norm=0.00 | sec/step~8.42 | keep=0.51 | K=8 | llama(T): tf=6.4550 first=6.2411 kCE=4.2339 KD=0.0000 acc=0.028 state=12.4178 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.0267e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0005 rms_cal~0.0106 embed_rms~0.01058]
  step  221/445 | (warm-up text) | align=0.0002 | text_tf=3.9540 | latent_scale=0.80
  step  222/445 | (warm-up text) | align=0.0002 | text_tf=4.4925 | latent_scale=0.80
  step  223/445 | (warm-up text) | align=0.0002 | text_tf=3.9311 | latent_scale=0.80
  step  224/445 | (warm-up text) | align=0.0002 | text_tf=4.1280 | latent_scale=0.80
  step  225/445 | (warm-up text) | align=0.0002 | text_tf=4.0982 | latent_scale=0.80
  step  226/445 | (warm-up text) | align=0.0002 | text_tf=4.3391 | latent_scale=0.80
  step  227/445 | (warm-up text) | align=0.0002 | text_tf=4.3592 | latent_scale=0.80
  step  228/445 | (warm-up text) | align=0.0002 | text_tf=4.4903 | latent_scale=0.80
  step  229/445 | (warm-up text) | align=0.0002 | text_tf=4.2289 | latent_scale=0.80
  step  230/445 | (warm-up text) | align=0.0002 | text_tf=4.8614 | latent_scale=0.81
  step  230/445 | grad_norm=0.00 | sec/step~9.75 | keep=0.51 | K=8 | llama(T): tf=6.8827 first=6.6758 kCE=4.1793 KD=0.0000 acc=0.000 state=14.2386 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.2825e-12 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0005 rms_cal~0.0106 embed_rms~0.01058]
  step  231/445 | (warm-up text) | align=0.0002 | text_tf=4.0795 | latent_scale=0.81
  step  232/445 | (warm-up text) | align=0.0002 | text_tf=4.4268 | latent_scale=0.81
  step  233/445 | (warm-up text) | align=0.0002 | text_tf=5.1209 | latent_scale=0.81
  step  234/445 | (warm-up text) | align=0.0002 | text_tf=4.7723 | latent_scale=0.81
  step  235/445 | (warm-up text) | align=0.0002 | text_tf=4.1110 | latent_scale=0.81
  step  236/445 | (warm-up text) | align=0.0002 | text_tf=4.5707 | latent_scale=0.81
  step  237/445 | (warm-up text) | align=0.0002 | text_tf=3.8638 | latent_scale=0.81
  step  238/445 | (warm-up text) | align=0.0002 | text_tf=3.8378 | latent_scale=0.81
  step  239/445 | (warm-up text) | align=0.0002 | text_tf=4.5931 | latent_scale=0.81
  step  240/445 | (warm-up text) | align=0.0002 | text_tf=4.3702 | latent_scale=0.81
  step  240/445 | grad_norm=0.00 | sec/step~9.43 | keep=0.51 | K=8 | llama(T): tf=6.6761 first=5.9079 kCE=4.2367 KD=0.0000 acc=0.111 state=14.3209 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=4.2988e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0005 rms_cal~0.0106 embed_rms~0.01058]
  step  241/445 | (warm-up text) | align=0.0002 | text_tf=3.9600 | latent_scale=0.82
  step  242/445 | (warm-up text) | align=0.0002 | text_tf=4.4841 | latent_scale=0.82
  step  243/445 | (warm-up text) | align=0.0002 | text_tf=4.3029 | latent_scale=0.82
  step  244/445 | (warm-up text) | align=0.0002 | text_tf=4.8492 | latent_scale=0.82
  step  245/445 | (warm-up text) | align=0.0002 | text_tf=4.4903 | latent_scale=0.82
  step  246/445 | (warm-up text) | align=0.0002 | text_tf=3.9117 | latent_scale=0.82
  step  247/445 | (warm-up text) | align=0.0002 | text_tf=4.7652 | latent_scale=0.82
  step  248/445 | (warm-up text) | align=0.0002 | text_tf=4.0609 | latent_scale=0.82
  step  249/445 | (warm-up text) | align=0.0002 | text_tf=4.8520 | latent_scale=0.82
  step  250/445 | (warm-up text) | align=0.0002 | text_tf=4.2918 | latent_scale=0.82
  step  250/445 | grad_norm=0.00 | sec/step~9.00 | keep=0.51 | K=8 | llama(T): tf=7.0026 first=6.6963 kCE=4.1500 KD=0.0000 acc=0.028 state=13.4205 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=4.2988e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0005 rms_cal~0.0106 embed_rms~0.01058]
  step  251/445 | (warm-up text) | align=0.0002 | text_tf=4.7149 | latent_scale=0.82
  step  252/445 | (warm-up text) | align=0.0002 | text_tf=4.8772 | latent_scale=0.83
  step  253/445 | (warm-up text) | align=0.0002 | text_tf=4.4682 | latent_scale=0.83
  step  254/445 | (warm-up text) | align=0.0002 | text_tf=4.2903 | latent_scale=0.83
  step  255/445 | (warm-up text) | align=0.0002 | text_tf=4.0523 | latent_scale=0.83
  step  256/445 | (warm-up text) | align=0.0002 | text_tf=4.6653 | latent_scale=0.83
  step  257/445 | (warm-up text) | align=0.0002 | text_tf=4.5086 | latent_scale=0.83
  step  258/445 | (warm-up text) | align=0.0002 | text_tf=4.3514 | latent_scale=0.83
  step  259/445 | (warm-up text) | align=0.0002 | text_tf=3.8748 | latent_scale=0.83
  step  260/445 | (warm-up text) | align=0.0002 | text_tf=4.3914 | latent_scale=0.83
  step  260/445 | grad_norm=0.00 | sec/step~8.81 | keep=0.51 | K=8 | llama(T): tf=6.9177 first=6.0216 kCE=4.2389 KD=0.0000 acc=0.139 state=14.3825 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0006 rms_cal~0.0106 embed_rms~0.01058]
  step  261/445 | (warm-up text) | align=0.0002 | text_tf=4.4330 | latent_scale=0.83
  step  262/445 | (warm-up text) | align=0.0002 | text_tf=3.9439 | latent_scale=0.83
  step  263/445 | (warm-up text) | align=0.0002 | text_tf=3.8853 | latent_scale=0.84
  step  264/445 | (warm-up text) | align=0.0002 | text_tf=4.2003 | latent_scale=0.84
  step  265/445 | (warm-up text) | align=0.0002 | text_tf=4.2226 | latent_scale=0.84
  step  266/445 | (warm-up text) | align=0.0002 | text_tf=4.8595 | latent_scale=0.84
  step  267/445 | (warm-up text) | align=0.0002 | text_tf=4.2323 | latent_scale=0.84
  step  268/445 | (warm-up text) | align=0.0002 | text_tf=4.0342 | latent_scale=0.84
  step  269/445 | (warm-up text) | align=0.0002 | text_tf=4.4025 | latent_scale=0.84
  step  270/445 | (warm-up text) | align=0.0002 | text_tf=4.0981 | latent_scale=0.84
  step  270/445 | grad_norm=0.00 | sec/step~10.14 | keep=0.51 | K=8 | llama(T): tf=6.8175 first=6.2998 kCE=4.0907 KD=0.0000 acc=0.056 state=15.2484 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=5.1159e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0006 rms_cal~0.0106 embed_rms~0.01058]
  step  271/445 | (warm-up text) | align=0.0002 | text_tf=4.0636 | latent_scale=0.84
  step  272/445 | (warm-up text) | align=0.0002 | text_tf=4.0560 | latent_scale=0.84
  step  273/445 | (warm-up text) | align=0.0002 | text_tf=4.0562 | latent_scale=0.84
  step  274/445 | (warm-up text) | align=0.0002 | text_tf=4.4153 | latent_scale=0.85
  step  275/445 | (warm-up text) | align=0.0002 | text_tf=3.8127 | latent_scale=0.85
  step  276/445 | (warm-up text) | align=0.0002 | text_tf=4.3964 | latent_scale=0.85
  step  277/445 | (warm-up text) | align=0.0002 | text_tf=3.4626 | latent_scale=0.85
  step  278/445 | (warm-up text) | align=0.0002 | text_tf=3.4144 | latent_scale=0.85
  step  279/445 | (warm-up text) | align=0.0002 | text_tf=4.0325 | latent_scale=0.85
  step  280/445 | (warm-up text) | align=0.0002 | text_tf=4.3474 | latent_scale=0.85
  step  280/445 | grad_norm=0.00 | sec/step~9.09 | keep=0.51 | K=8 | llama(T): tf=7.1578 first=6.6671 kCE=4.0665 KD=0.0000 acc=0.000 state=14.9847 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=6.9633e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0006 rms_cal~0.0106 embed_rms~0.01058]
  step  281/445 | (warm-up text) | align=0.0002 | text_tf=4.2606 | latent_scale=0.85
  step  282/445 | (warm-up text) | align=0.0002 | text_tf=4.1435 | latent_scale=0.85
  step  283/445 | (warm-up text) | align=0.0002 | text_tf=3.7408 | latent_scale=0.85
  step  284/445 | (warm-up text) | align=0.0002 | text_tf=3.7298 | latent_scale=0.85
  step  285/445 | (warm-up text) | align=0.0002 | text_tf=4.4402 | latent_scale=0.86
  step  286/445 | (warm-up text) | align=0.0002 | text_tf=3.6256 | latent_scale=0.86
  step  287/445 | (warm-up text) | align=0.0002 | text_tf=3.7697 | latent_scale=0.86
  step  288/445 | (warm-up text) | align=0.0002 | text_tf=4.1014 | latent_scale=0.86
  step  289/445 | (warm-up text) | align=0.0002 | text_tf=3.8183 | latent_scale=0.86
  step  290/445 | (warm-up text) | align=0.0002 | text_tf=4.6670 | latent_scale=0.86
  step  290/445 | grad_norm=0.00 | sec/step~8.91 | keep=0.51 | K=8 | llama(T): tf=7.4807 first=6.7922 kCE=4.7902 KD=0.0000 acc=0.028 state=13.8594 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.2790e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0006 rms_cal~0.0106 embed_rms~0.01058]
  step  291/445 | (warm-up text) | align=0.0002 | text_tf=4.2605 | latent_scale=0.86
  step  292/445 | (warm-up text) | align=0.0002 | text_tf=4.2508 | latent_scale=0.86
  step  293/445 | (warm-up text) | align=0.0002 | text_tf=3.8773 | latent_scale=0.86
  step  294/445 | (warm-up text) | align=0.0002 | text_tf=4.2624 | latent_scale=0.86
  step  295/445 | (warm-up text) | align=0.0002 | text_tf=4.6994 | latent_scale=0.86
  step  296/445 | (warm-up text) | align=0.0002 | text_tf=4.2797 | latent_scale=0.87
  step  297/445 | (warm-up text) | align=0.0002 | text_tf=3.6252 | latent_scale=0.87
  step  298/445 | (warm-up text) | align=0.0002 | text_tf=4.2977 | latent_scale=0.87
  step  299/445 | (warm-up text) | align=0.0002 | text_tf=4.4587 | latent_scale=0.87
  step  300/445 | (warm-up text) | align=0.0002 | text_tf=3.9998 | latent_scale=0.87
  step  300/445 | grad_norm=0.00 | sec/step~9.25 | keep=0.51 | K=8 | llama(T): tf=7.3929 first=6.1215 kCE=4.3898 KD=0.0000 acc=0.056 state=15.3891 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.2790e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0006 rms_cal~0.0106 embed_rms~0.01058]
  step  301/445 | (warm-up text) | align=0.0002 | text_tf=4.6648 | latent_scale=0.87
  step  302/445 | (warm-up text) | align=0.0002 | text_tf=4.4021 | latent_scale=0.87
  step  303/445 | (warm-up text) | align=0.0002 | text_tf=3.9782 | latent_scale=0.87
  step  304/445 | (warm-up text) | align=0.0002 | text_tf=4.1695 | latent_scale=0.87
  step  305/445 | (warm-up text) | align=0.0002 | text_tf=4.3320 | latent_scale=0.87
  step  306/445 | (warm-up text) | align=0.0002 | text_tf=3.9734 | latent_scale=0.87
  step  307/445 | (warm-up text) | align=0.0002 | text_tf=4.1221 | latent_scale=0.88
  step  308/445 | (warm-up text) | align=0.0002 | text_tf=3.9840 | latent_scale=0.88
  step  309/445 | (warm-up text) | align=0.0002 | text_tf=3.9448 | latent_scale=0.88
  step  310/445 | (warm-up text) | align=0.0002 | text_tf=4.5092 | latent_scale=0.88
  step  310/445 | grad_norm=0.00 | sec/step~9.12 | keep=0.51 | K=8 | llama(T): tf=7.1577 first=6.0773 kCE=4.4019 KD=0.0000 acc=0.056 state=14.4245 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.2790e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0006 rms_cal~0.0106 embed_rms~0.01058]
  step  311/445 | (warm-up text) | align=0.0002 | text_tf=4.6492 | latent_scale=0.88
  step  312/445 | (warm-up text) | align=0.0002 | text_tf=3.6408 | latent_scale=0.88
  step  313/445 | (warm-up text) | align=0.0002 | text_tf=4.2869 | latent_scale=0.88
  step  314/445 | (warm-up text) | align=0.0002 | text_tf=4.0861 | latent_scale=0.88
  step  315/445 | (warm-up text) | align=0.0002 | text_tf=4.6306 | latent_scale=0.88
  step  316/445 | (warm-up text) | align=0.0002 | text_tf=3.8587 | latent_scale=0.88
  step  317/445 | (warm-up text) | align=0.0002 | text_tf=4.1053 | latent_scale=0.88
  step  318/445 | (warm-up text) | align=0.0002 | text_tf=3.8650 | latent_scale=0.88
  step  319/445 | (warm-up text) | align=0.0002 | text_tf=3.7211 | latent_scale=0.89
  step  320/445 | (warm-up text) | align=0.0002 | text_tf=4.5919 | latent_scale=0.89
  step  320/445 | grad_norm=0.00 | sec/step~8.93 | keep=0.51 | K=8 | llama(T): tf=7.9499 first=6.9650 kCE=4.8791 KD=0.0000 acc=0.056 state=14.9700 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=6.9633e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0006 rms_cal~0.0106 embed_rms~0.01058]
  step  321/445 | (warm-up text) | align=0.0002 | text_tf=3.8370 | latent_scale=0.89
  step  322/445 | (warm-up text) | align=0.0002 | text_tf=4.1267 | latent_scale=0.89
  step  323/445 | (warm-up text) | align=0.0002 | text_tf=4.2653 | latent_scale=0.89
  step  324/445 | (warm-up text) | align=0.0002 | text_tf=4.2723 | latent_scale=0.89
  step  325/445 | (warm-up text) | align=0.0002 | text_tf=4.0187 | latent_scale=0.89
  step  326/445 | (warm-up text) | align=0.0002 | text_tf=4.2052 | latent_scale=0.89
  step  327/445 | (warm-up text) | align=0.0002 | text_tf=3.9392 | latent_scale=0.89
  step  328/445 | (warm-up text) | align=0.0002 | text_tf=4.3854 | latent_scale=0.89
  step  329/445 | (warm-up text) | align=0.0002 | text_tf=3.9756 | latent_scale=0.89
  step  330/445 | (warm-up text) | align=0.0002 | text_tf=4.5300 | latent_scale=0.90
  step  330/445 | grad_norm=0.00 | sec/step~8.72 | keep=0.52 | K=8 | llama(T): tf=7.6027 first=6.8603 kCE=4.3488 KD=0.0000 acc=0.056 state=14.8814 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=6.0041e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0006 rms_cal~0.0106 embed_rms~0.01058]
  step  331/445 | (warm-up text) | align=0.0002 | text_tf=3.9405 | latent_scale=0.90
  step  332/445 | (warm-up text) | align=0.0002 | text_tf=4.5648 | latent_scale=0.90
  step  333/445 | (warm-up text) | align=0.0002 | text_tf=4.3016 | latent_scale=0.90
  step  334/445 | (warm-up text) | align=0.0002 | text_tf=4.0480 | latent_scale=0.90
  step  335/445 | (warm-up text) | align=0.0002 | text_tf=4.4017 | latent_scale=0.90
  step  336/445 | (warm-up text) | align=0.0002 | text_tf=3.9086 | latent_scale=0.90
  step  337/445 | (warm-up text) | align=0.0002 | text_tf=4.0574 | latent_scale=0.90
  step  338/445 | (warm-up text) | align=0.0002 | text_tf=4.0926 | latent_scale=0.90
  step  339/445 | (warm-up text) | align=0.0002 | text_tf=4.1564 | latent_scale=0.90
  step  340/445 | (warm-up text) | align=0.0002 | text_tf=4.7334 | latent_scale=0.90
  step  340/445 | grad_norm=0.00 | sec/step~8.90 | keep=0.52 | K=8 | llama(T): tf=7.4248 first=6.5932 kCE=4.3758 KD=0.0000 acc=0.028 state=14.8091 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=8.8818e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0006 rms_cal~0.0106 embed_rms~0.01058]
  step  341/445 | (warm-up text) | align=0.0002 | text_tf=3.9186 | latent_scale=0.91
  step  342/445 | (warm-up text) | align=0.0002 | text_tf=4.1806 | latent_scale=0.91
  step  343/445 | (warm-up text) | align=0.0002 | text_tf=3.4991 | latent_scale=0.91
  step  344/445 | (warm-up text) | align=0.0002 | text_tf=3.9302 | latent_scale=0.91
  step  345/445 | (warm-up text) | align=0.0002 | text_tf=4.2866 | latent_scale=0.91
  step  346/445 | (warm-up text) | align=0.0002 | text_tf=4.2439 | latent_scale=0.91
  step  347/445 | (warm-up text) | align=0.0002 | text_tf=4.2263 | latent_scale=0.91
  step  348/445 | (warm-up text) | align=0.0002 | text_tf=4.0400 | latent_scale=0.91
  step  349/445 | (warm-up text) | align=0.0002 | text_tf=4.2101 | latent_scale=0.91
  step  350/445 | (warm-up text) | align=0.0002 | text_tf=4.5119 | latent_scale=0.91
  step  350/445 | grad_norm=0.00 | sec/step~9.23 | keep=0.52 | K=8 | llama(T): tf=7.8601 first=6.8857 kCE=4.6879 KD=0.0000 acc=0.056 state=15.3479 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0006 rms_cal~0.0106 embed_rms~0.01058]
  step  351/445 | (warm-up text) | align=0.0002 | text_tf=4.2277 | latent_scale=0.91
  step  352/445 | (warm-up text) | align=0.0002 | text_tf=4.2816 | latent_scale=0.92
  step  353/445 | (warm-up text) | align=0.0002 | text_tf=4.2443 | latent_scale=0.92
  step  354/445 | (warm-up text) | align=0.0002 | text_tf=3.7155 | latent_scale=0.92
  step  355/445 | (warm-up text) | align=0.0002 | text_tf=4.1659 | latent_scale=0.92
  step  356/445 | (warm-up text) | align=0.0002 | text_tf=3.8727 | latent_scale=0.92
  step  357/445 | (warm-up text) | align=0.0002 | text_tf=4.2099 | latent_scale=0.92
  step  358/445 | (warm-up text) | align=0.0002 | text_tf=3.6971 | latent_scale=0.92
  step  359/445 | (warm-up text) | align=0.0002 | text_tf=3.9705 | latent_scale=0.92
  step  360/445 | (warm-up text) | align=0.0002 | text_tf=4.1504 | latent_scale=0.92
  step  360/445 | grad_norm=0.00 | sec/step~8.80 | keep=0.52 | K=8 | llama(T): tf=7.3240 first=6.2590 kCE=4.2572 KD=0.0000 acc=0.083 state=14.4606 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0006 rms_cal~0.0106 embed_rms~0.01058]
  step  361/445 | (warm-up text) | align=0.0002 | text_tf=4.2193 | latent_scale=0.92
  step  362/445 | (warm-up text) | align=0.0002 | text_tf=4.1041 | latent_scale=0.92
  step  363/445 | (warm-up text) | align=0.0002 | text_tf=4.4640 | latent_scale=0.93
  step  364/445 | (warm-up text) | align=0.0002 | text_tf=4.1186 | latent_scale=0.93
  step  365/445 | (warm-up text) | align=0.0002 | text_tf=3.6250 | latent_scale=0.93
  step  366/445 | (warm-up text) | align=0.0002 | text_tf=4.1774 | latent_scale=0.93
  step  367/445 | (warm-up text) | align=0.0002 | text_tf=3.8626 | latent_scale=0.93
  step  368/445 | (warm-up text) | align=0.0002 | text_tf=4.1770 | latent_scale=0.93
  step  369/445 | (warm-up text) | align=0.0002 | text_tf=3.7203 | latent_scale=0.93
  step  370/445 | (warm-up text) | align=0.0002 | text_tf=3.7796 | latent_scale=0.93
  step  370/445 | grad_norm=0.00 | sec/step~8.76 | keep=0.52 | K=8 | llama(T): tf=7.5432 first=7.3299 kCE=5.2462 KD=0.0000 acc=0.028 state=15.0753 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0006 rms_cal~0.0106 embed_rms~0.01058]
  step  371/445 | (warm-up text) | align=0.0002 | text_tf=4.0932 | latent_scale=0.93
  step  372/445 | (warm-up text) | align=0.0002 | text_tf=4.2447 | latent_scale=0.93
  step  373/445 | (warm-up text) | align=0.0002 | text_tf=4.3434 | latent_scale=0.93
  step  374/445 | (warm-up text) | align=0.0002 | text_tf=4.1220 | latent_scale=0.94
  step  375/445 | (warm-up text) | align=0.0002 | text_tf=3.5854 | latent_scale=0.94
  step  376/445 | (warm-up text) | align=0.0002 | text_tf=4.1853 | latent_scale=0.94
  step  377/445 | (warm-up text) | align=0.0002 | text_tf=3.9610 | latent_scale=0.94
  step  378/445 | (warm-up text) | align=0.0002 | text_tf=3.9251 | latent_scale=0.94
  step  379/445 | (warm-up text) | align=0.0002 | text_tf=3.8801 | latent_scale=0.94
  step  380/445 | (warm-up text) | align=0.0002 | text_tf=4.0325 | latent_scale=0.94
  step  380/445 | grad_norm=0.00 | sec/step~9.05 | keep=0.52 | K=8 | llama(T): tf=7.8521 first=7.4187 kCE=4.5373 KD=0.0000 acc=0.083 state=15.9842 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=2.2737e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0006 rms_cal~0.0106 embed_rms~0.01058]
  step  381/445 | (warm-up text) | align=0.0002 | text_tf=3.9754 | latent_scale=0.94
  step  382/445 | (warm-up text) | align=0.0002 | text_tf=3.9628 | latent_scale=0.94
  step  383/445 | (warm-up text) | align=0.0002 | text_tf=3.6879 | latent_scale=0.94
  step  384/445 | (warm-up text) | align=0.0002 | text_tf=4.0436 | latent_scale=0.94
  step  385/445 | (warm-up text) | align=0.0002 | text_tf=4.3391 | latent_scale=0.95
  step  386/445 | (warm-up text) | align=0.0002 | text_tf=4.2313 | latent_scale=0.95
  step  387/445 | (warm-up text) | align=0.0002 | text_tf=3.7007 | latent_scale=0.95
  step  388/445 | (warm-up text) | align=0.0002 | text_tf=4.0980 | latent_scale=0.95
  step  389/445 | (warm-up text) | align=0.0002 | text_tf=3.9368 | latent_scale=0.95
  step  390/445 | (warm-up text) | align=0.0002 | text_tf=3.7488 | latent_scale=0.95
  step  390/445 | grad_norm=0.00 | sec/step~9.26 | keep=0.52 | K=8 | llama(T): tf=7.1159 first=6.6062 kCE=4.4957 KD=0.0000 acc=0.056 state=16.4793 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0006 rms_cal~0.0106 embed_rms~0.01058]
  step  391/445 | (warm-up text) | align=0.0002 | text_tf=3.5020 | latent_scale=0.95
  step  392/445 | (warm-up text) | align=0.0002 | text_tf=4.2690 | latent_scale=0.95
  step  393/445 | (warm-up text) | align=0.0002 | text_tf=4.2993 | latent_scale=0.95
  step  394/445 | (warm-up text) | align=0.0002 | text_tf=3.3742 | latent_scale=0.95
  step  395/445 | (warm-up text) | align=0.0002 | text_tf=3.9306 | latent_scale=0.95
  step  396/445 | (warm-up text) | align=0.0002 | text_tf=3.5383 | latent_scale=0.96
  step  397/445 | (warm-up text) | align=0.0002 | text_tf=4.3916 | latent_scale=0.96
  step  398/445 | (warm-up text) | align=0.0002 | text_tf=4.1755 | latent_scale=0.96
  step  399/445 | (warm-up text) | align=0.0002 | text_tf=4.2947 | latent_scale=0.96
  step  400/445 | (warm-up text) | align=0.0002 | text_tf=3.6967 | latent_scale=0.96
  step  400/445 | grad_norm=0.00 | sec/step~9.19 | keep=0.52 | K=8 | llama(T): tf=7.3794 first=7.0051 kCE=4.7310 KD=0.0000 acc=0.028 state=17.4642 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=2.2737e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0007 rms_cal~0.0106 embed_rms~0.01058]
  step  401/445 | (warm-up text) | align=0.0002 | text_tf=3.8303 | latent_scale=0.96
  step  402/445 | (warm-up text) | align=0.0002 | text_tf=4.0873 | latent_scale=0.96
  step  403/445 | (warm-up text) | align=0.0002 | text_tf=3.6201 | latent_scale=0.96
  step  404/445 | (warm-up text) | align=0.0002 | text_tf=4.0275 | latent_scale=0.96
  step  405/445 | (warm-up text) | align=0.0002 | text_tf=3.7209 | latent_scale=0.96
  step  406/445 | (warm-up text) | align=0.0002 | text_tf=4.7014 | latent_scale=0.96
  step  407/445 | (warm-up text) | align=0.0002 | text_tf=4.5569 | latent_scale=0.96
  step  408/445 | (warm-up text) | align=0.0002 | text_tf=3.4608 | latent_scale=0.97
  step  409/445 | (warm-up text) | align=0.0002 | text_tf=4.3962 | latent_scale=0.97
  step  410/445 | (warm-up text) | align=0.0002 | text_tf=4.2976 | latent_scale=0.97
  step  410/445 | grad_norm=0.00 | sec/step~9.36 | keep=0.52 | K=8 | llama(T): tf=8.0376 first=7.2943 kCE=5.1003 KD=0.0000 acc=0.056 state=17.3918 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=4.2988e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0007 rms_cal~0.0106 embed_rms~0.01058]
  step  411/445 | (warm-up text) | align=0.0002 | text_tf=3.7381 | latent_scale=0.97
  step  412/445 | (warm-up text) | align=0.0002 | text_tf=4.0941 | latent_scale=0.97
  step  413/445 | (warm-up text) | align=0.0002 | text_tf=3.8860 | latent_scale=0.97
  step  414/445 | (warm-up text) | align=0.0002 | text_tf=4.8279 | latent_scale=0.97
  step  415/445 | (warm-up text) | align=0.0002 | text_tf=3.8344 | latent_scale=0.97
  step  416/445 | (warm-up text) | align=0.0002 | text_tf=4.2555 | latent_scale=0.97
  step  417/445 | (warm-up text) | align=0.0002 | text_tf=4.0240 | latent_scale=0.97
  step  418/445 | (warm-up text) | align=0.0002 | text_tf=3.7121 | latent_scale=0.97
  step  419/445 | (warm-up text) | align=0.0002 | text_tf=4.0770 | latent_scale=0.98
  step  420/445 | (warm-up text) | align=0.0002 | text_tf=3.7290 | latent_scale=0.98
  step  420/445 | grad_norm=0.00 | sec/step~9.91 | keep=0.52 | K=8 | llama(T): tf=7.9891 first=7.2095 kCE=4.4642 KD=0.0000 acc=0.028 state=18.4693 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.7408e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0007 rms_cal~0.0106 embed_rms~0.01058]
  step  421/445 | (warm-up text) | align=0.0002 | text_tf=3.5874 | latent_scale=0.98
  step  422/445 | (warm-up text) | align=0.0002 | text_tf=3.5501 | latent_scale=0.98
  step  423/445 | (warm-up text) | align=0.0002 | text_tf=3.7668 | latent_scale=0.98
  step  424/445 | (warm-up text) | align=0.0002 | text_tf=4.4871 | latent_scale=0.98
  step  425/445 | (warm-up text) | align=0.0002 | text_tf=4.0516 | latent_scale=0.98
  step  426/445 | (warm-up text) | align=0.0002 | text_tf=3.8641 | latent_scale=0.98
  step  427/445 | (warm-up text) | align=0.0002 | text_tf=4.4221 | latent_scale=0.98
  step  428/445 | (warm-up text) | align=0.0002 | text_tf=4.0491 | latent_scale=0.98
  step  429/445 | (warm-up text) | align=0.0002 | text_tf=4.1207 | latent_scale=0.98
  step  430/445 | (warm-up text) | align=0.0002 | text_tf=4.2418 | latent_scale=0.99
  step  430/445 | grad_norm=0.00 | sec/step~9.02 | keep=0.52 | K=8 | llama(T): tf=8.7747 first=8.1068 kCE=4.8785 KD=0.0000 acc=0.028 state=18.0131 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=1.7408e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0007 rms_cal~0.0106 embed_rms~0.01058]
  step  431/445 | (warm-up text) | align=0.0002 | text_tf=4.0019 | latent_scale=0.99
  step  432/445 | (warm-up text) | align=0.0002 | text_tf=3.2976 | latent_scale=0.99
  step  433/445 | (warm-up text) | align=0.0002 | text_tf=4.0452 | latent_scale=0.99
  step  434/445 | (warm-up text) | align=0.0002 | text_tf=3.9981 | latent_scale=0.99
  step  435/445 | (warm-up text) | align=0.0002 | text_tf=3.6338 | latent_scale=0.99
  step  436/445 | (warm-up text) | align=0.0002 | text_tf=4.3443 | latent_scale=0.99
  step  437/445 | (warm-up text) | align=0.0002 | text_tf=3.8846 | latent_scale=0.99
  step  438/445 | (warm-up text) | align=0.0002 | text_tf=3.4479 | latent_scale=0.99
  step  439/445 | (warm-up text) | align=0.0002 | text_tf=3.8697 | latent_scale=0.99
  step  440/445 | (warm-up text) | align=0.0002 | text_tf=4.0889 | latent_scale=0.99
  step  440/445 | grad_norm=0.00 | sec/step~8.80 | keep=0.52 | K=8 | llama(T): tf=7.7634 first=7.2015 kCE=4.7398 KD=0.0000 acc=0.083 state=17.4718 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0007 rms_cal~0.0106 embed_rms~0.01058]
  step  441/445 | (warm-up text) | align=0.0002 | text_tf=4.8077 | latent_scale=1.00
  step  442/445 | (warm-up text) | align=0.0002 | text_tf=4.0968 | latent_scale=1.00
  step  443/445 | (warm-up text) | align=0.0002 | text_tf=4.2853 | latent_scale=1.00
  step  444/445 | (warm-up text) | align=0.0002 | text_tf=4.3511 | latent_scale=1.00
  step  445/445 | (warm-up text) | align=0.0002 | text_tf=3.5696 | latent_scale=1.00
  step  445/445 | grad_norm=0.00 | sec/step~5.34 | keep=0.52 | K=8 | llama(T): tf=8.1602 first=6.9250 kCE=5.0088 KD=0.0000 acc=0.000 state=18.3062 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0007 rms_cal~0.0106 embed_rms~0.01058]
[checkpoint] Freed 0.0B before save.
[checkpoint] Saved latest: encoder.pt, state.pt, config.json, adapter_llama.pt, deep_prefix_llama.pt, refiner.pt
[checkpoint] Freed 0.0B after save (non-canonical).
  ✅ Saved (and pruned to) latest at step 890
Epoch 3/10
We detected that you are passing `past_key_values` as a tuple of tuples. This is deprecated and will be removed in v4.47. Please convert your cache or use an appropriate `Cache` class (https://huggingface.co/docs/transformers/kv_cache#legacy-cache-format)
  step  10/445 | grad_norm=97.79 | sec/step~7.46 | keep=0.52 | K=8 | llama(L): tf=8.4045 first=7.2318 kCE=5.3556 KD=11.5595 acc=0.028 state=18.0055 align=0.0000 latA=0.8255 latP=0.4647 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0007 rms_cal~0.0106 embed_rms~0.01058]
[warmup] step=909 mode=text (tail)
  step  20/445 | (tail text) | align=0.0002 | text_tf=3.8949 | latent_scale=1.00
  step  20/445 | grad_norm=144.50 | sec/step~9.31 | keep=0.52 | K=8 | llama(T): tf=8.3816 first=7.2127 kCE=5.2634 KD=0.0000 acc=0.083 state=18.3636 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=6.9633e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0007 rms_cal~0.0106 embed_rms~0.01058]
  step  30/445 | grad_norm=6.87 | sec/step~7.13 | keep=0.52 | K=8 | llama(L): tf=8.1333 first=6.7629 kCE=5.9817 KD=4.5367 acc=0.111 state=17.0536 align=0.0000 latA=0.8103 latP=0.4606 | scale_pen(llama)=9.0949e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0007 rms_cal~0.0106 embed_rms~0.01058]
  step  40/445 | grad_norm=8.08 | sec/step~8.22 | keep=0.52 | K=8 | llama(L): tf=8.5955 first=7.8242 kCE=5.1152 KD=6.7874 acc=0.028 state=19.7072 align=0.0000 latA=0.8437 latP=0.4633 | scale_pen(llama)=9.0949e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0007 rms_cal~0.0106 embed_rms~0.01058]
  step  50/445 | grad_norm=3.02 | sec/step~7.30 | keep=0.52 | K=8 | llama(L): tf=8.6828 first=7.7154 kCE=5.2959 KD=5.6350 acc=0.056 state=18.8222 align=0.0000 latA=0.8464 latP=0.4620 | scale_pen(llama)=9.0949e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0007 rms_cal~0.0106 embed_rms~0.01058]
  step  60/445 | grad_norm=17.48 | sec/step~8.11 | keep=0.52 | K=8 | llama(L): tf=8.5021 first=8.4594 kCE=4.4566 KD=5.8388 acc=0.000 state=19.0099 align=0.0000 latA=0.8659 latP=0.4634 | scale_pen(llama)=6.9633e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0007 rms_cal~0.0106 embed_rms~0.01058]
  step  70/445 | grad_norm=3.67 | sec/step~9.14 | keep=0.52 | K=8 | llama(L): tf=8.4118 first=8.0712 kCE=5.1872 KD=4.2627 acc=0.028 state=20.1730 align=0.0000 latA=0.8782 latP=0.4613 | scale_pen(llama)=6.9633e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0008 rms_cal~0.0106 embed_rms~0.01058]
  step  80/445 | grad_norm=1.88 | sec/step~7.49 | keep=0.52 | K=8 | llama(L): tf=8.1185 first=7.6348 kCE=4.5085 KD=4.9527 acc=0.083 state=18.3564 align=0.0000 latA=0.8577 latP=0.4623 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0008 rms_cal~0.0106 embed_rms~0.01058]
  step  90/445 | grad_norm=2.89 | sec/step~8.29 | keep=0.52 | K=8 | llama(L): tf=8.6788 first=6.8998 kCE=4.6795 KD=4.3786 acc=0.056 state=18.0895 align=0.0000 latA=0.8529 latP=0.4628 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0008 rms_cal~0.0106 embed_rms~0.01058]
  step  100/445 | grad_norm=1.50 | sec/step~7.26 | keep=0.52 | K=8 | llama(L): tf=8.1785 first=7.0066 kCE=4.3754 KD=4.0448 acc=0.028 state=16.2278 align=0.0000 latA=0.8732 latP=0.4607 | scale_pen(llama)=1.2790e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0008 rms_cal~0.0106 embed_rms~0.01058]
  step  101/445 | (tail text) | align=0.0003 | text_tf=4.6462 | latent_scale=1.00
  step  110/445 | grad_norm=0.38 | sec/step~8.76 | keep=0.53 | K=8 | llama(L): tf=7.9737 first=7.7731 kCE=5.0569 KD=5.5373 acc=0.056 state=18.1013 align=0.0000 latA=0.8862 latP=0.4578 | scale_pen(llama)=6.0041e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0008 rms_cal~0.0106 embed_rms~0.01058]
  step  120/445 | grad_norm=2.28 | sec/step~7.10 | keep=0.53 | K=8 | llama(L): tf=8.1613 first=7.0891 kCE=5.1818 KD=3.8067 acc=0.028 state=16.1320 align=0.0000 latA=0.8584 latP=0.4581 | scale_pen(llama)=9.0949e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0008 rms_cal~0.0106 embed_rms~0.01058]
  step  125/445 | (tail text) | align=0.0002 | text_tf=3.1610 | latent_scale=1.00
  step  127/445 | (tail text) | align=0.0003 | text_tf=4.1021 | latent_scale=1.00
  step  130/445 | grad_norm=0.82 | sec/step~6.88 | keep=0.53 | K=8 | llama(L): tf=8.6099 first=7.5842 kCE=4.7017 KD=4.0616 acc=0.056 state=15.6741 align=0.0000 latA=0.8822 latP=0.4571 | scale_pen(llama)=9.0949e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0008 rms_cal~0.0106 embed_rms~0.01058]
  step  140/445 | grad_norm=1.48 | sec/step~7.09 | keep=0.53 | K=8 | llama(L): tf=8.0108 first=6.9862 kCE=4.6968 KD=5.0302 acc=0.000 state=16.1380 align=0.0000 latA=0.8685 latP=0.4519 | scale_pen(llama)=2.2737e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0008 rms_cal~0.0106 embed_rms~0.01058]
  step  150/445 | grad_norm=1.06 | sec/step~7.91 | keep=0.53 | K=8 | llama(L): tf=8.1668 first=6.8496 kCE=4.7173 KD=3.6153 acc=0.139 state=17.8531 align=0.0000 latA=0.8770 latP=0.4491 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0008 rms_cal~0.0106 embed_rms~0.01058]
  step  160/445 | grad_norm=0.45 | sec/step~7.36 | keep=0.53 | K=8 | llama(L): tf=8.2854 first=7.6341 kCE=4.9595 KD=3.5867 acc=0.028 state=17.1860 align=0.0000 latA=0.8932 latP=0.4465 | scale_pen(llama)=2.2737e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0009 rms_cal~0.0106 embed_rms~0.01058]
  step  170/445 | grad_norm=0.23 | sec/step~7.31 | keep=0.53 | K=8 | llama(L): tf=7.9910 first=7.0802 kCE=4.4417 KD=3.4118 acc=0.111 state=16.6146 align=0.0000 latA=0.8624 latP=0.4415 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0009 rms_cal~0.0106 embed_rms~0.01058]
  step  180/445 | grad_norm=1.14 | sec/step~7.23 | keep=0.53 | K=8 | llama(L): tf=8.3260 first=7.1983 kCE=4.3521 KD=3.5792 acc=0.028 state=16.8959 align=0.0000 latA=0.8677 latP=0.4427 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0009 rms_cal~0.0106 embed_rms~0.01058]
  step  190/445 | grad_norm=1.26 | sec/step~7.54 | keep=0.53 | K=8 | llama(L): tf=7.7202 first=7.9968 kCE=4.4637 KD=4.4069 acc=0.000 state=16.4385 align=0.0000 latA=0.8703 latP=0.4378 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0009 rms_cal~0.0106 embed_rms~0.01058]
  step  200/445 | grad_norm=1.09 | sec/step~7.36 | keep=0.53 | K=8 | llama(L): tf=8.0250 first=6.9633 kCE=4.7328 KD=4.3476 acc=0.111 state=16.2269 align=0.0000 latA=0.8663 latP=0.4325 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0009 rms_cal~0.0106 embed_rms~0.01058]
  step  210/445 | grad_norm=0.71 | sec/step~7.00 | keep=0.53 | K=8 | llama(L): tf=8.4974 first=8.1734 kCE=4.9320 KD=4.5075 acc=0.028 state=15.6639 align=0.0000 latA=0.8738 latP=0.4278 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0009 rms_cal~0.0106 embed_rms~0.01058]
  step  220/445 | grad_norm=0.37 | sec/step~7.28 | keep=0.53 | K=8 | llama(L): tf=7.8605 first=7.6771 kCE=4.2615 KD=3.5324 acc=0.000 state=15.6755 align=0.0000 latA=0.8727 latP=0.4223 | scale_pen(llama)=3.5527e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0009 rms_cal~0.0106 embed_rms~0.01058]
  step  230/445 | grad_norm=0.30 | sec/step~7.40 | keep=0.53 | K=8 | llama(L): tf=8.2102 first=7.8463 kCE=4.5698 KD=3.4279 acc=0.028 state=16.6480 align=0.0000 latA=0.8598 latP=0.4171 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0009 rms_cal~0.0106 embed_rms~0.01058]
  step  240/445 | grad_norm=1.29 | sec/step~7.35 | keep=0.53 | K=8 | llama(L): tf=7.9339 first=7.4618 kCE=3.9655 KD=3.3579 acc=0.028 state=16.5542 align=0.0000 latA=0.8702 latP=0.4165 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0009 rms_cal~0.0106 embed_rms~0.01058]
  step  250/445 | grad_norm=1.16 | sec/step~7.19 | keep=0.53 | K=8 | llama(L): tf=8.3161 first=7.5514 kCE=4.7972 KD=3.5960 acc=0.000 state=16.0507 align=0.0000 latA=0.8624 latP=0.4147 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0009 rms_cal~0.0106 embed_rms~0.01058]
  step  260/445 | grad_norm=0.48 | sec/step~7.35 | keep=0.53 | K=8 | llama(L): tf=8.1008 first=7.7174 kCE=4.4822 KD=3.1670 acc=0.000 state=16.0481 align=0.0000 latA=0.8711 latP=0.4069 | scale_pen(llama)=1.2790e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0010 rms_cal~0.0106 embed_rms~0.01058]
  step  270/445 | (tail text) | align=0.0002 | text_tf=4.3800 | latent_scale=1.00
  step  270/445 | grad_norm=0.33 | sec/step~8.97 | keep=0.53 | K=8 | llama(T): tf=8.1864 first=7.6912 kCE=4.3518 KD=0.0000 acc=0.000 state=16.3788 align=0.0002 latA=0.0000 latP=0.0000 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0010 rms_cal~0.0106 embed_rms~0.01058]
  step  280/445 | grad_norm=0.32 | sec/step~7.35 | keep=0.53 | K=8 | llama(L): tf=7.9791 first=7.6405 kCE=4.5159 KD=3.2656 acc=0.083 state=15.0644 align=0.0000 latA=0.8466 latP=0.3937 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0010 rms_cal~0.0106 embed_rms~0.01058]
  step  290/445 | grad_norm=0.21 | sec/step~8.15 | keep=0.54 | K=8 | llama(L): tf=7.6797 first=7.5270 kCE=3.8528 KD=3.8244 acc=0.028 state=17.2637 align=0.0000 latA=0.8424 latP=0.3847 | scale_pen(llama)=1.2790e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0010 rms_cal~0.0106 embed_rms~0.01058]
  step  291/445 | (tail text) | align=0.0002 | text_tf=3.8149 | latent_scale=1.00
  step  298/445 | (tail text) | align=0.0002 | text_tf=4.0847 | latent_scale=1.00
  step  300/445 | grad_norm=1.01 | sec/step~7.82 | keep=0.54 | K=8 | llama(L): tf=7.8652 first=7.4012 kCE=4.2608 KD=5.4943 acc=0.028 state=16.6385 align=0.0000 latA=0.8481 latP=0.3866 | scale_pen(llama)=1.7408e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0010 rms_cal~0.0106 embed_rms~0.01058]
  step  310/445 | grad_norm=0.49 | sec/step~7.15 | keep=0.54 | K=8 | llama(L): tf=7.8366 first=7.8605 kCE=4.4177 KD=3.8922 acc=0.000 state=15.2867 align=0.0000 latA=0.8699 latP=0.3830 | scale_pen(llama)=1.7408e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0010 rms_cal~0.0106 embed_rms~0.01058]
  step  320/445 | grad_norm=0.42 | sec/step~7.19 | keep=0.54 | K=8 | llama(L): tf=8.5204 first=7.4663 kCE=4.8333 KD=4.5974 acc=0.028 state=15.0053 align=0.0000 latA=0.8527 latP=0.3762 | scale_pen(llama)=3.1974e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0010 rms_cal~0.0106 embed_rms~0.01058]
  step  330/445 | grad_norm=0.48 | sec/step~7.67 | keep=0.54 | K=8 | llama(L): tf=8.3228 first=7.6570 kCE=4.6820 KD=5.3493 acc=0.056 state=15.5679 align=0.0000 latA=0.8607 latP=0.3699 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0010 rms_cal~0.0106 embed_rms~0.01058]
  step  340/445 | grad_norm=0.39 | sec/step~6.93 | keep=0.54 | K=8 | llama(L): tf=7.7816 first=7.4250 kCE=4.3458 KD=3.4352 acc=0.000 state=14.2551 align=0.0000 latA=0.8494 latP=0.3625 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0010 rms_cal~0.0106 embed_rms~0.01058]
  step  350/445 | grad_norm=0.13 | sec/step~7.91 | keep=0.54 | K=8 | llama(L): tf=8.0344 first=7.4948 kCE=4.1781 KD=3.3079 acc=0.000 state=15.7554 align=0.0000 latA=0.8335 latP=0.3531 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0010 rms_cal~0.0106 embed_rms~0.01058]
  step  360/445 | grad_norm=0.50 | sec/step~7.15 | keep=0.54 | K=8 | llama(L): tf=7.6197 first=7.1302 kCE=4.6288 KD=3.1931 acc=0.056 state=14.5365 align=0.0000 latA=0.8275 latP=0.3598 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0010 rms_cal~0.0106 embed_rms~0.01058]
  step  369/445 | (tail text) | align=0.0002 | text_tf=5.0004 | latent_scale=1.00
  step  370/445 | grad_norm=0.95 | sec/step~7.21 | keep=0.54 | K=8 | llama(L): tf=7.5488 first=6.9530 kCE=4.1998 KD=3.0103 acc=0.111 state=14.2552 align=0.0000 latA=0.8216 latP=0.3551 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0010 rms_cal~0.0106 embed_rms~0.01058]
  step  380/445 | grad_norm=0.74 | sec/step~7.27 | keep=0.54 | K=8 | llama(L): tf=7.5355 first=7.2016 kCE=4.6801 KD=3.1364 acc=0.194 state=14.5676 align=0.0000 latA=0.8389 latP=0.3471 | scale_pen(llama)=8.8818e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0011 rms_cal~0.0106 embed_rms~0.01058]
  step  390/445 | grad_norm=0.27 | sec/step~7.69 | keep=0.54 | K=8 | llama(L): tf=7.8713 first=7.2361 kCE=4.3686 KD=3.0939 acc=0.111 state=15.4742 align=0.0000 latA=0.8314 latP=0.3442 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0011 rms_cal~0.0106 embed_rms~0.01058]
  step  395/445 | (tail text) | align=0.0002 | text_tf=4.6916 | latent_scale=1.00
  step  400/445 | grad_norm=0.24 | sec/step~7.93 | keep=0.54 | K=8 | llama(L): tf=7.3877 first=7.2062 kCE=4.2827 KD=2.9935 acc=0.083 state=15.5678 align=0.0000 latA=0.8296 latP=0.3380 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0011 rms_cal~0.0106 embed_rms~0.01058]
  step  410/445 | grad_norm=0.22 | sec/step~7.70 | keep=0.54 | K=8 | llama(L): tf=7.5383 first=7.4757 kCE=4.3105 KD=4.7860 acc=0.083 state=14.2551 align=0.0000 latA=0.8332 latP=0.3284 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0011 rms_cal~0.0106 embed_rms~0.01058]
  step  420/445 | grad_norm=0.73 | sec/step~8.46 | keep=0.54 | K=8 | llama(L): tf=8.1782 first=7.3620 kCE=4.7200 KD=3.4462 acc=0.139 state=16.3180 align=0.0000 latA=0.8422 latP=0.3283 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0011 rms_cal~0.0106 embed_rms~0.01058]
  step  428/445 | (tail text) | align=0.0002 | text_tf=4.2101 | latent_scale=1.00
  step  430/445 | grad_norm=0.51 | sec/step~7.32 | keep=0.54 | K=8 | llama(L): tf=8.1724 first=7.5100 kCE=4.1751 KD=3.0636 acc=0.000 state=14.0676 align=0.0000 latA=0.8286 latP=0.3163 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0011 rms_cal~0.0106 embed_rms~0.01058]
  step  440/445 | grad_norm=0.47 | sec/step~7.11 | keep=0.54 | K=8 | llama(L): tf=7.5517 first=7.0189 kCE=5.1185 KD=3.1180 acc=0.056 state=13.9739 align=0.0000 latA=0.8154 latP=0.3396 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0011 rms_cal~0.0106 embed_rms~0.01058]
  step  445/445 | grad_norm=0.15 | sec/step~4.73 | keep=0.54 | K=8 | llama(L): tf=7.8648 first=7.9495 kCE=4.1332 KD=2.8682 acc=0.125 state=11.8173 align=0.0000 latA=0.8470 latP=0.3056 | scale_pen(llama)=1.2790e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0011 rms_cal~0.0106 embed_rms~0.01058]
[checkpoint] Freed 0.0B before save.
[checkpoint] Saved latest: encoder.pt, state.pt, config.json, adapter_llama.pt, deep_prefix_llama.pt, refiner.pt
[checkpoint] Freed 0.0B after save (non-canonical).
  ✅ Saved (and pruned to) latest at step 1335
Epoch 4/10
  step  10/445 | grad_norm=1.09 | sec/step~7.30 | keep=0.55 | K=8 | llama(L): tf=7.5092 first=7.1493 kCE=4.2669 KD=3.0153 acc=0.028 state=14.7553 align=0.0000 latA=0.8107 latP=0.3082 | scale_pen(llama)=1.2790e-13 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0011 rms_cal~0.0106 embed_rms~0.01058]
  step  20/445 | grad_norm=0.53 | sec/step~7.11 | keep=0.55 | K=8 | llama(L): tf=7.7305 first=7.5671 kCE=4.1463 KD=3.8828 acc=0.056 state=12.6612 align=0.0000 latA=0.8419 latP=0.2976 | scale_pen(llama)=8.8818e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0011 rms_cal~0.0106 embed_rms~0.01058]
  step  30/445 | grad_norm=0.30 | sec/step~7.15 | keep=0.55 | K=8 | llama(L): tf=7.3265 first=7.0024 kCE=4.3485 KD=3.0061 acc=0.056 state=13.6926 align=0.0000 latA=0.8288 latP=0.3008 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0011 rms_cal~0.0106 embed_rms~0.01058]
  step  37/445 | (tail text) | align=0.0002 | text_tf=3.7197 | latent_scale=1.00
  step  40/445 | grad_norm=0.32 | sec/step~7.37 | keep=0.55 | K=8 | llama(L): tf=8.0257 first=7.1336 kCE=4.4962 KD=3.8922 acc=0.139 state=14.6305 align=0.0000 latA=0.8305 latP=0.2902 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0011 rms_cal~0.0106 embed_rms~0.01058]
  step  50/445 | grad_norm=0.16 | sec/step~7.41 | keep=0.55 | K=8 | llama(L): tf=8.3664 first=8.0576 kCE=3.9903 KD=3.1935 acc=0.000 state=13.7241 align=0.0000 latA=0.8418 latP=0.2778 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0011 rms_cal~0.0106 embed_rms~0.01058]
  step  60/445 | grad_norm=0.79 | sec/step~7.72 | keep=0.55 | K=8 | llama(L): tf=8.0381 first=7.3233 kCE=4.4019 KD=5.4884 acc=0.028 state=13.6927 align=0.0000 latA=0.8363 latP=0.2844 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0011 rms_cal~0.0106 embed_rms~0.01058]
  step  70/445 | grad_norm=0.48 | sec/step~7.28 | keep=0.55 | K=8 | llama(L): tf=7.5832 first=7.3059 kCE=4.3106 KD=5.0724 acc=0.000 state=13.0363 align=0.0000 latA=0.8209 latP=0.2902 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0011 rms_cal~0.0106 embed_rms~0.01058]
  step  74/445 | (tail text) | align=0.0002 | text_tf=3.7128 | latent_scale=1.00
  step  80/445 | grad_norm=0.36 | sec/step~7.54 | keep=0.55 | K=8 | llama(L): tf=7.6048 first=7.0038 kCE=4.2554 KD=3.3481 acc=0.056 state=13.9739 align=0.0000 latA=0.8135 latP=0.2807 | scale_pen(llama)=3.1974e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0011 rms_cal~0.0106 embed_rms~0.01058]
  step  90/445 | grad_norm=0.52 | sec/step~7.42 | keep=0.55 | K=8 | llama(L): tf=7.6983 first=7.7229 kCE=4.0683 KD=3.4679 acc=0.028 state=12.3800 align=0.0000 latA=0.8323 latP=0.2776 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0011 rms_cal~0.0106 embed_rms~0.01058]
  step  100/445 | grad_norm=0.43 | sec/step~7.85 | keep=0.55 | K=8 | llama(L): tf=7.8308 first=7.1087 kCE=3.6975 KD=4.2428 acc=0.083 state=15.1931 align=0.0000 latA=0.8256 latP=0.2645 | scale_pen(llama)=3.1974e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0012 rms_cal~0.0106 embed_rms~0.01058]
  step  110/445 | grad_norm=0.30 | sec/step~7.45 | keep=0.55 | K=8 | llama(L): tf=7.7140 first=7.5632 kCE=4.0747 KD=3.7492 acc=0.028 state=13.0363 align=0.0000 latA=0.8266 latP=0.2722 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0012 rms_cal~0.0106 embed_rms~0.01058]
  step  120/445 | grad_norm=1.21 | sec/step~7.75 | keep=0.55 | K=8 | llama(L): tf=7.4844 first=6.9148 kCE=4.0288 KD=3.1977 acc=0.056 state=15.2867 align=0.0000 latA=0.8197 latP=0.2683 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0012 rms_cal~0.0106 embed_rms~0.01058]
  step  130/445 | grad_norm=1.27 | sec/step~7.24 | keep=0.55 | K=8 | llama(L): tf=8.2626 first=8.1413 kCE=4.2026 KD=5.0493 acc=0.028 state=13.5053 align=0.0000 latA=0.8390 latP=0.2615 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0012 rms_cal~0.0106 embed_rms~0.01058]
  step  140/445 | grad_norm=0.59 | sec/step~7.35 | keep=0.55 | K=8 | llama(L): tf=8.0929 first=7.7578 kCE=3.6145 KD=3.2014 acc=0.000 state=13.1301 align=0.0000 latA=0.8372 latP=0.2465 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0012 rms_cal~0.0106 embed_rms~0.01058]
  step  150/445 | grad_norm=0.89 | sec/step~6.94 | keep=0.56 | K=8 | llama(L): tf=8.1953 first=6.5944 kCE=3.9773 KD=3.0526 acc=0.111 state=12.0987 align=0.0000 latA=0.8004 latP=0.2470 | scale_pen(llama)=3.5527e-15 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0012 rms_cal~0.0106 embed_rms~0.01058]
  step  154/445 | (tail text) | align=0.0002 | text_tf=3.9742 | latent_scale=1.00
  step  160/445 | grad_norm=0.54 | sec/step~7.58 | keep=0.56 | K=8 | llama(L): tf=8.3175 first=7.7789 kCE=4.2523 KD=3.3937 acc=0.028 state=14.0677 align=0.0000 latA=0.8483 latP=0.2473 | scale_pen(llama)=3.1974e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0012 rms_cal~0.0106 embed_rms~0.01058]
  step  170/445 | grad_norm=0.25 | sec/step~7.96 | keep=0.56 | K=8 | llama(L): tf=7.8115 first=7.3040 kCE=4.1077 KD=3.1222 acc=0.167 state=15.5994 align=0.0000 latA=0.8166 latP=0.2488 | scale_pen(llama)=5.6843e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0012 rms_cal~0.0106 embed_rms~0.01058]
  step  180/445 | grad_norm=0.94 | sec/step~8.23 | keep=0.56 | K=8 | llama(L): tf=7.6960 first=7.7702 kCE=4.0406 KD=3.0175 acc=0.028 state=15.4742 align=0.0000 latA=0.8382 latP=0.2510 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0012 rms_cal~0.0106 embed_rms~0.01058]
  step  190/445 | grad_norm=1.28 | sec/step~8.07 | keep=0.56 | K=8 | llama(L): tf=7.5580 first=7.4526 kCE=4.1094 KD=2.9672 acc=0.028 state=15.9432 align=0.0000 latA=0.8330 latP=0.2483 | scale_pen(llama)=1.4211e-14 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0012 rms_cal~0.0106 embed_rms~0.01058]
  step  193/445 | (tail text) | align=0.0003 | text_tf=3.7897 | latent_scale=1.00
  step  200/445 | grad_norm=1.07 | sec/step~7.37 | keep=0.56 | K=8 | llama(L): tf=7.8151 first=7.1298 kCE=3.8885 KD=3.8954 acc=0.028 state=14.3489 align=0.0000 latA=0.8150 latP=0.2348 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0012 rms_cal~0.0106 embed_rms~0.01058]
  step  210/445 | grad_norm=0.58 | sec/step~7.28 | keep=0.56 | K=8 | llama(L): tf=7.9189 first=7.6357 kCE=4.4230 KD=2.8716 acc=0.028 state=13.6927 align=0.0000 latA=0.8467 latP=0.2492 | scale_pen(llama)=0.0000e+00 | K=8 tau=2.00 | stats=[llama: rms_raw~1.0012 rms_cal~0.0106 embed_rms~0.01058]
[WARN] KD teacher forward failed; retrying per-example: CUDA out of memory. Tried to allocate 14.19 GiB. GPU 0 has a total capacity of 79.19 GiB of which 12.63 GiB is free. Including non-PyTorch memory, this process has 66.54 GiB memory in use. Of the allocated memory 39.33 GiB is allocated by PyTorch, and 26.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/projects/m000066/sujinesh/LatentWire/latentwire/losses.py", line 137, in kd_first_k_prefix_vs_text
    teacher_logits_full = torch.cat(logits_chunks, dim=0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.19 GiB. GPU 0 has a total capacity of 79.19 GiB of which 12.63 GiB is free. Including non-PyTorch memory, this process has 66.54 GiB memory in use. Of the allocated memory 39.33 GiB is allocated by PyTorch, and 26.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/projects/m000066/sujinesh/LatentWire/latentwire/train.py", line 2374, in <module>
    main()
  File "/projects/m000066/sujinesh/LatentWire/latentwire/train.py", line 1646, in main
    loss_kd_raw = kd_first_k_prefix_vs_text(
  File "/projects/m000066/sujinesh/LatentWire/latentwire/losses.py", line 159, in kd_first_k_prefix_vs_text
    teacher_logits_full = torch.cat(logits_chunks, dim=0)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.19 GiB. GPU 0 has a total capacity of 79.19 GiB of which 12.63 GiB is free. Including non-PyTorch memory, this process has 66.54 GiB memory in use. Of the allocated memory 40.12 GiB is allocated by PyTorch, and 25.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
