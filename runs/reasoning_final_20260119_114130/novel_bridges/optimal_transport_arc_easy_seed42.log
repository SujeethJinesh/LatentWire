/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
============================================================
TELEPATHY TRAINING: ARC_EASY
============================================================

Dataset: arc_easy (4 classes)
Random baseline: 25.0%
Source layer: 31
Soft tokens: 8
Steps: 1500
Diversity weight: 0.1
============================================================
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 1765.28it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:14,  4.69s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.39s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.68s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.55s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.13s/it]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2934.45it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:03,  1.88s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:03<00:01,  1.97s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.29s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.20s/it]
2026-01-19 11:44:28,438 - INFO - OptimalTransportBridge: 8 anchors, eps=0.1
Target embedding RMS: 0.0027
Using Optimal Transport Bridge (NOVEL) - epsilon=0.1

Training on 2251 samples
Validation: 2376 samples
Starting training...

ARC_EASY:   0%|                                                            | 0/1500 [00:00<?, ?it/s]ARC_EASY:   0%|                                                            | 0/1500 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1285, in main
    loss, loss_dict = train_step(
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 714, in train_step
    soft_tokens, aux_loss, diversity, z_variance = bridge_module(src_h, src_mask)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 232, in forward
    src_proj = self.src_proj(src_hidden.float())  # [B, S, tgt_dim]
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 must have the same dtype, but got Float and BFloat16

[ERROR] Training interrupted by exception at step 1
[ERROR] RuntimeError: mat1 and mat2 must have the same dtype, but got Float and BFloat16

[EMERGENCY] Checkpoint saved to runs/reasoning_final_20260119_114130/novel_bridges/optimal_transport_arc_easy_seed42/emergency_checkpoint_step0.pt
[EMERGENCY] Error: RuntimeError: mat1 and mat2 must have the same dtype, but got Float and BFloat16
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1530, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 1285, in main
    loss, loss_dict = train_step(
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/train_telepathy.py", line 714, in train_step
    soft_tokens, aux_loss, diversity, z_variance = bridge_module(src_h, src_mask)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/cross_model_experiments.py", line 232, in forward
    src_proj = self.src_proj(src_hidden.float())  # [B, S, tgt_dim]
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 must have the same dtype, but got Float and BFloat16
