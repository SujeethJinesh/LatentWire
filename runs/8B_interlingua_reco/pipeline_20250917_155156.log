
=========================================
Starting pipeline at Wed Sep 17 15:51:56 PDT 2025
=========================================


=========================================
TRAIN + PER-EPOCH EVAL
=========================================


=========================================
EPOCH 1/12
=========================================

/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading dataset subset...
Loading SQuAD subset...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 3488.71it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:05,  1.76s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.23s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.30s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.14it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.06s/it]
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 3433.73it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.37s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:01,  1.00it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.03s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.04it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.01s/it]
Llama hidden size: 4096, Qwen hidden size: 3584
[WARN] t=0 alignment failed: t=0 mismatch: got 12366, expected 60704
[WARN] t=0 alignment failed: t=0 mismatch: got 12095, expected 59604
Initialized adapter colorizers from LM embedding stats.
⚠️  No valid checkpoint found to resume; starting fresh.
Epoch 1/1
[DEBUG] Optimizer state devices (sample):
  
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
  step  10/3129 | grad_norm=173.39 | sec/step~7.20 | keep=1.00 | K=6 | llama: tf=12.9473 first=16.7037 kCE=9.4603 KD=3.7355 man=0.0002 | scale_pen(llama)=0.0000e+00 | qwen: tf=12.5197 first=14.8571 kCE=13.2069 KD=5.4109 man=0.0003 | scale_pen(qwen)=0.0000e+00 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  20/3129 | grad_norm=331.60 | sec/step~7.29 | keep=1.00 | K=6 | llama: tf=12.9831 first=16.2840 kCE=9.4457 KD=4.0380 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=12.3075 first=15.5875 kCE=14.1953 KD=4.4800 man=0.0003 | scale_pen(qwen)=0.0000e+00 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  30/3129 | grad_norm=473.80 | sec/step~6.58 | keep=1.00 | K=6 | llama: tf=11.9536 first=16.0150 kCE=9.8314 KD=4.0146 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=13.0275 first=16.1560 kCE=13.5730 KD=5.5174 man=0.0002 | scale_pen(qwen)=0.0000e+00 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  40/3129 | grad_norm=116.27 | sec/step~7.42 | keep=1.00 | K=6 | llama: tf=12.9712 first=17.8659 kCE=9.7684 KD=3.8694 man=0.0002 | scale_pen(llama)=2.7853e-12 | qwen: tf=12.9577 first=16.5484 kCE=13.7838 KD=4.4620 man=0.0003 | scale_pen(qwen)=5.6843e-14 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  50/3129 | grad_norm=222.14 | sec/step~8.64 | keep=1.00 | K=6 | llama: tf=12.2924 first=16.0590 kCE=9.1397 KD=3.4206 man=0.0002 | scale_pen(llama)=2.7853e-12 | qwen: tf=12.0343 first=13.7026 kCE=13.4306 KD=5.0456 man=0.0003 | scale_pen(qwen)=5.6843e-14 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  60/3129 | grad_norm=341.70 | sec/step~7.09 | keep=1.00 | K=6 | llama: tf=14.1389 first=17.7321 kCE=8.4118 KD=3.5750 man=0.0001 | scale_pen(llama)=2.7853e-12 | qwen: tf=13.1698 first=15.5669 kCE=15.2066 KD=3.5557 man=0.0003 | scale_pen(qwen)=5.6843e-14 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  70/3129 | grad_norm=33.63 | sec/step~7.26 | keep=1.00 | K=6 | llama: tf=12.5810 first=16.0222 kCE=9.2500 KD=3.7601 man=0.0002 | scale_pen(llama)=2.2737e-13 | qwen: tf=13.1560 first=16.0985 kCE=13.8415 KD=4.8137 man=0.0003 | scale_pen(qwen)=2.0464e-12 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  80/3129 | grad_norm=94.14 | sec/step~7.73 | keep=1.00 | K=6 | llama: tf=11.9909 first=13.6403 kCE=8.3303 KD=3.1631 man=0.0001 | scale_pen(llama)=2.2737e-13 | qwen: tf=11.8010 first=12.0921 kCE=13.1315 KD=3.8601 man=0.0003 | scale_pen(qwen)=2.0464e-12 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  90/3129 | grad_norm=150.95 | sec/step~7.98 | keep=1.00 | K=6 | llama: tf=12.9319 first=13.4436 kCE=8.5902 KD=3.5013 man=0.0002 | scale_pen(llama)=2.2737e-13 | qwen: tf=11.3176 first=12.7134 kCE=13.0847 KD=3.8441 man=0.0003 | scale_pen(qwen)=2.0464e-12 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  100/3129 | grad_norm=17.47 | sec/step~8.39 | keep=1.00 | K=6 | llama: tf=13.2342 first=15.9021 kCE=8.6114 KD=3.1230 man=0.0002 | scale_pen(llama)=6.0041e-13 | qwen: tf=12.9935 first=15.2521 kCE=14.5340 KD=3.8640 man=0.0003 | scale_pen(qwen)=1.7195e-12 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  110/3129 | grad_norm=61.28 | sec/step~7.76 | keep=1.00 | K=6 | llama: tf=12.5840 first=15.6745 kCE=8.0790 KD=3.1546 man=0.0002 | scale_pen(llama)=6.0041e-13 | qwen: tf=13.3635 first=14.5834 kCE=14.6027 KD=3.6416 man=0.0003 | scale_pen(qwen)=1.7195e-12 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  120/3129 | grad_norm=107.38 | sec/step~9.56 | keep=1.00 | K=6 | llama: tf=12.5821 first=14.4777 kCE=8.7297 KD=2.9495 man=0.0002 | scale_pen(llama)=6.0041e-13 | qwen: tf=11.8592 first=13.5088 kCE=13.4553 KD=4.4301 man=0.0003 | scale_pen(qwen)=1.7195e-12 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  130/3129 | grad_norm=6.25 | sec/step~6.38 | keep=1.00 | K=6 | llama: tf=13.0827 first=15.4745 kCE=8.6382 KD=4.1304 man=0.0002 | scale_pen(llama)=1.4211e-14 | qwen: tf=11.6104 first=13.8957 kCE=13.7081 KD=4.7318 man=0.0003 | scale_pen(qwen)=1.2790e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  140/3129 | grad_norm=36.43 | sec/step~6.48 | keep=1.00 | K=6 | llama: tf=12.0320 first=15.7635 kCE=8.3000 KD=3.8914 man=0.0002 | scale_pen(llama)=1.4211e-14 | qwen: tf=12.9712 first=14.6317 kCE=14.2546 KD=4.6073 man=0.0003 | scale_pen(qwen)=1.2790e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  150/3129 | grad_norm=66.76 | sec/step~7.71 | keep=1.00 | K=6 | llama: tf=12.2163 first=16.4574 kCE=8.9145 KD=3.4155 man=0.0002 | scale_pen(llama)=1.4211e-14 | qwen: tf=12.1152 first=16.0914 kCE=14.1923 KD=4.1044 man=0.0003 | scale_pen(qwen)=1.2790e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  160/3129 | grad_norm=95.90 | sec/step~8.30 | keep=1.00 | K=6 | llama: tf=11.7124 first=13.3038 kCE=8.6993 KD=3.2053 man=0.0001 | scale_pen(llama)=2.2737e-13 | qwen: tf=10.6694 first=12.1027 kCE=12.4379 KD=5.0865 man=0.0003 | scale_pen(qwen)=4.2988e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  170/3129 | grad_norm=38.57 | sec/step~8.25 | keep=1.00 | K=6 | llama: tf=11.9235 first=15.4214 kCE=7.9130 KD=2.8857 man=0.0002 | scale_pen(llama)=2.2737e-13 | qwen: tf=10.8487 first=15.1272 kCE=13.7776 KD=4.4441 man=0.0003 | scale_pen(qwen)=4.2988e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  180/3129 | grad_norm=72.93 | sec/step~8.08 | keep=1.00 | K=6 | llama: tf=11.8016 first=15.6364 kCE=9.2085 KD=3.5961 man=0.0002 | scale_pen(llama)=2.2737e-13 | qwen: tf=11.4863 first=15.0944 kCE=13.6708 KD=4.5141 man=0.0003 | scale_pen(qwen)=4.2988e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  190/3129 | grad_norm=111.23 | sec/step~8.24 | keep=1.00 | K=6 | llama: tf=11.9192 first=14.6909 kCE=8.2150 KD=3.4365 man=0.0002 | scale_pen(llama)=2.2737e-13 | qwen: tf=10.5238 first=14.3146 kCE=13.1332 KD=4.6650 man=0.0003 | scale_pen(qwen)=4.2988e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  200/3129 | grad_norm=103.90 | sec/step~8.42 | keep=1.00 | K=6 | llama: tf=11.7615 first=14.9012 kCE=8.4604 KD=3.3481 man=0.0002 | scale_pen(llama)=1.2825e-12 | qwen: tf=11.8355 first=14.7165 kCE=13.3120 KD=4.4103 man=0.0003 | scale_pen(qwen)=1.4211e-12 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  210/3129 | grad_norm=202.59 | sec/step~7.19 | keep=1.00 | K=6 | llama: tf=13.5782 first=15.3688 kCE=7.8993 KD=3.3022 man=0.0002 | scale_pen(llama)=1.2825e-12 | qwen: tf=11.0609 first=13.8441 kCE=14.3807 KD=3.8154 man=0.0003 | scale_pen(qwen)=1.4211e-12 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  220/3129 | grad_norm=323.74 | sec/step~6.77 | keep=1.00 | K=6 | llama: tf=12.6484 first=15.1888 kCE=8.3321 KD=3.8774 man=0.0002 | scale_pen(llama)=1.2825e-12 | qwen: tf=12.1079 first=13.6299 kCE=13.7133 KD=4.6045 man=0.0003 | scale_pen(qwen)=1.4211e-12 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  230/3129 | grad_norm=30.36 | sec/step~7.45 | keep=1.00 | K=6 | llama: tf=12.6846 first=15.1702 kCE=8.6511 KD=4.0146 man=0.0002 | scale_pen(llama)=8.1855e-12 | qwen: tf=12.1668 first=14.7368 kCE=13.4014 KD=5.7752 man=0.0003 | scale_pen(qwen)=2.2204e-12 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  240/3129 | grad_norm=89.85 | sec/step~8.92 | keep=1.00 | K=6 | llama: tf=12.6666 first=15.2611 kCE=8.8142 KD=3.1358 man=0.0002 | scale_pen(llama)=8.1855e-12 | qwen: tf=11.5543 first=14.6879 kCE=13.4946 KD=5.0324 man=0.0003 | scale_pen(qwen)=2.2204e-12 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  250/3129 | grad_norm=144.08 | sec/step~7.96 | keep=1.00 | K=6 | llama: tf=12.6556 first=15.0233 kCE=8.3718 KD=3.2351 man=0.0001 | scale_pen(llama)=8.1855e-12 | qwen: tf=12.5980 first=15.3004 kCE=14.4431 KD=4.9010 man=0.0003 | scale_pen(qwen)=2.2204e-12 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  260/3129 | grad_norm=18.23 | sec/step~8.69 | keep=1.00 | K=6 | llama: tf=12.7178 first=13.8631 kCE=7.8387 KD=3.0067 man=0.0002 | scale_pen(llama)=8.5301e-12 | qwen: tf=12.1806 first=13.2533 kCE=14.1368 KD=4.3696 man=0.0003 | scale_pen(qwen)=1.8794e-12 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  270/3129 | grad_norm=62.66 | sec/step~7.85 | keep=1.00 | K=6 | llama: tf=12.5348 first=13.8937 kCE=8.7133 KD=3.4002 man=0.0002 | scale_pen(llama)=8.5301e-12 | qwen: tf=12.4873 first=12.8563 kCE=13.8944 KD=4.3890 man=0.0003 | scale_pen(qwen)=1.8794e-12 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  280/3129 | grad_norm=103.69 | sec/step~8.36 | keep=1.00 | K=6 | llama: tf=11.4280 first=14.9417 kCE=8.7227 KD=3.4089 man=0.0001 | scale_pen(llama)=8.5301e-12 | qwen: tf=10.1375 first=14.0541 kCE=12.8959 KD=4.7179 man=0.0003 | scale_pen(qwen)=1.8794e-12 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  290/3129 | grad_norm=6.01 | sec/step~7.81 | keep=1.00 | K=6 | llama: tf=12.3362 first=14.0748 kCE=7.8437 KD=3.3371 man=0.0002 | scale_pen(llama)=2.4016e-12 | qwen: tf=11.6634 first=13.1347 kCE=14.0482 KD=4.1022 man=0.0003 | scale_pen(qwen)=6.9633e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  300/3129 | grad_norm=34.39 | sec/step~8.21 | keep=1.00 | K=6 | llama: tf=12.0753 first=12.6886 kCE=8.2492 KD=3.0921 man=0.0002 | scale_pen(llama)=2.4016e-12 | qwen: tf=10.5543 first=10.9708 kCE=12.9467 KD=4.4223 man=0.0003 | scale_pen(qwen)=6.9633e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  310/3129 | grad_norm=62.83 | sec/step~8.01 | keep=1.00 | K=6 | llama: tf=12.8993 first=13.9996 kCE=7.7330 KD=3.0168 man=0.0002 | scale_pen(llama)=2.4016e-12 | qwen: tf=11.5855 first=13.2570 kCE=13.7803 KD=3.8350 man=0.0003 | scale_pen(qwen)=6.9633e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  320/3129 | grad_norm=90.16 | sec/step~6.32 | keep=1.00 | K=6 | llama: tf=11.8857 first=14.8257 kCE=8.2619 KD=4.3224 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=13.0510 first=14.8179 kCE=14.0185 KD=4.7494 man=0.0003 | scale_pen(qwen)=3.5527e-15 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  330/3129 | grad_norm=44.90 | sec/step~7.23 | keep=1.00 | K=6 | llama: tf=12.6521 first=14.2334 kCE=8.6553 KD=3.6375 man=0.0002 | scale_pen(llama)=0.0000e+00 | qwen: tf=12.3461 first=13.3649 kCE=14.2018 KD=4.5991 man=0.0003 | scale_pen(qwen)=3.5527e-15 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  340/3129 | grad_norm=87.71 | sec/step~7.39 | keep=1.00 | K=6 | llama: tf=12.2474 first=13.5647 kCE=8.2501 KD=3.5850 man=0.0001 | scale_pen(llama)=0.0000e+00 | qwen: tf=11.4516 first=12.1134 kCE=13.1650 KD=4.3950 man=0.0003 | scale_pen(qwen)=3.5527e-15 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  350/3129 | grad_norm=135.37 | sec/step~7.27 | keep=1.00 | K=6 | llama: tf=11.5102 first=13.3432 kCE=7.8123 KD=3.6562 man=0.0002 | scale_pen(llama)=0.0000e+00 | qwen: tf=11.4040 first=12.1854 kCE=13.2781 KD=4.2902 man=0.0003 | scale_pen(qwen)=3.5527e-15 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  360/3129 | grad_norm=28.64 | sec/step~7.07 | keep=1.00 | K=6 | llama: tf=12.8347 first=13.8542 kCE=7.8886 KD=3.5559 man=0.0002 | scale_pen(llama)=5.1159e-13 | qwen: tf=11.1089 first=12.6878 kCE=13.5178 KD=3.9359 man=0.0003 | scale_pen(qwen)=3.5527e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  370/3129 | grad_norm=63.94 | sec/step~7.22 | keep=1.00 | K=6 | llama: tf=11.9029 first=14.1517 kCE=7.8669 KD=3.3623 man=0.0001 | scale_pen(llama)=5.1159e-13 | qwen: tf=11.5653 first=13.1259 kCE=13.5867 KD=3.8651 man=0.0003 | scale_pen(qwen)=3.5527e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  380/3129 | grad_norm=101.18 | sec/step~8.30 | keep=1.00 | K=6 | llama: tf=11.8780 first=13.7901 kCE=8.0164 KD=3.3072 man=0.0002 | scale_pen(llama)=5.1159e-13 | qwen: tf=11.7203 first=11.9366 kCE=14.0039 KD=4.4014 man=0.0003 | scale_pen(qwen)=3.5527e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  390/3129 | grad_norm=20.04 | sec/step~6.93 | keep=1.00 | K=6 | llama: tf=11.7121 first=14.2581 kCE=8.1937 KD=3.7664 man=0.0002 | scale_pen(llama)=5.6843e-14 | qwen: tf=11.9659 first=13.2855 kCE=13.9869 KD=4.7983 man=0.0003 | scale_pen(qwen)=6.9633e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  400/3129 | grad_norm=48.91 | sec/step~7.79 | keep=1.00 | K=6 | llama: tf=11.9334 first=13.3278 kCE=8.3268 KD=2.9857 man=0.0002 | scale_pen(llama)=5.6843e-14 | qwen: tf=11.8878 first=11.8757 kCE=13.6088 KD=4.1395 man=0.0003 | scale_pen(qwen)=6.9633e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  410/3129 | grad_norm=78.71 | sec/step~8.47 | keep=1.00 | K=6 | llama: tf=13.0665 first=15.0341 kCE=7.5213 KD=2.8515 man=0.0002 | scale_pen(llama)=5.6843e-14 | qwen: tf=12.2339 first=13.9751 kCE=14.3895 KD=4.1983 man=0.0003 | scale_pen(qwen)=6.9633e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  420/3129 | grad_norm=22.23 | sec/step~7.93 | keep=1.00 | K=6 | llama: tf=11.6499 first=12.8205 kCE=9.0659 KD=3.2388 man=0.0002 | scale_pen(llama)=2.8777e-13 | qwen: tf=11.7879 first=11.6599 kCE=13.3771 KD=4.1850 man=0.0003 | scale_pen(qwen)=5.1159e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  430/3129 | grad_norm=81.48 | sec/step~8.07 | keep=1.00 | K=6 | llama: tf=11.6416 first=12.1929 kCE=7.5744 KD=3.1043 man=0.0002 | scale_pen(llama)=2.8777e-13 | qwen: tf=10.2649 first=10.4047 kCE=13.3158 KD=4.1887 man=0.0003 | scale_pen(qwen)=5.1159e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  440/3129 | grad_norm=133.47 | sec/step~8.01 | keep=1.00 | K=6 | llama: tf=11.5218 first=13.5542 kCE=8.0506 KD=3.2554 man=0.0002 | scale_pen(llama)=2.8777e-13 | qwen: tf=11.9137 first=12.3941 kCE=13.3353 KD=4.8137 man=0.0003 | scale_pen(qwen)=5.1159e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  450/3129 | grad_norm=9.13 | sec/step~7.77 | keep=1.00 | K=6 | llama: tf=11.2772 first=12.8872 kCE=8.2236 KD=3.1200 man=0.0001 | scale_pen(llama)=1.2790e-13 | qwen: tf=11.4731 first=11.4895 kCE=13.5092 KD=4.0414 man=0.0003 | scale_pen(qwen)=2.2737e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  460/3129 | grad_norm=66.65 | sec/step~8.04 | keep=1.00 | K=6 | llama: tf=11.2112 first=13.6105 kCE=7.7482 KD=3.3445 man=0.0002 | scale_pen(llama)=1.2790e-13 | qwen: tf=12.0632 first=12.7277 kCE=14.3504 KD=4.1587 man=0.0003 | scale_pen(qwen)=2.2737e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  470/3129 | grad_norm=120.70 | sec/step~6.92 | keep=1.00 | K=6 | llama: tf=11.4727 first=14.2132 kCE=8.2358 KD=3.6709 man=0.0002 | scale_pen(llama)=1.2790e-13 | qwen: tf=11.1669 first=13.0466 kCE=13.2278 KD=4.6811 man=0.0003 | scale_pen(qwen)=2.2737e-13 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  480/3129 | grad_norm=180.14 | sec/step~7.52 | keep=1.00 | K=6 | llama: tf=11.8871 first=13.1851 kCE=8.9129 KD=3.4838 man=0.0002 | scale_pen(llama)=3.5527e-13 | qwen: tf=11.2530 first=11.4456 kCE=13.0699 KD=4.6398 man=0.0003 | scale_pen(qwen)=1.4211e-14 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  490/3129 | grad_norm=30.46 | sec/step~7.87 | keep=1.00 | K=6 | llama: tf=12.2419 first=13.1099 kCE=8.3605 KD=3.3342 man=0.0002 | scale_pen(llama)=3.5527e-13 | qwen: tf=12.5456 first=11.8424 kCE=14.3642 KD=4.1360 man=0.0003 | scale_pen(qwen)=1.4211e-14 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  500/3129 | grad_norm=62.50 | sec/step~8.38 | keep=1.00 | K=6 | llama: tf=11.1455 first=12.6223 kCE=7.8238 KD=2.8599 man=0.0002 | scale_pen(llama)=3.5527e-13 | qwen: tf=11.2736 first=11.2335 kCE=13.9931 KD=3.9803 man=0.0003 | scale_pen(qwen)=1.4211e-14 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
  step  510/3129 | grad_norm=94.12 | sec/step~7.22 | keep=1.00 | K=6 | llama: tf=11.2323 first=13.1461 kCE=7.9993 KD=3.8329 man=0.0001 | scale_pen(llama)=3.5527e-13 | qwen: tf=11.6582 first=11.2732 kCE=14.2116 KD=4.9355 man=0.0003 | scale_pen(qwen)=1.4211e-14 | K=6 tau=1.25 | stats=[llama: rms_raw~0.0106 rms_cal~0.0106 embed_rms~0.01058; qwen: rms_raw~0.0137 rms_cal~0.0136 embed_rms~0.01364]
