/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Device: cuda:1
GPU: NVIDIA H100 80GB HBM3

======================================================================
MEMORY BENCHMARK
======================================================================

--- Direct Mistral Inference ---
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2367.43it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:04<00:08,  4.31s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:08<00:04,  4.09s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.85s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.94s/it]
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
  Peak memory: 0 MB

--- LoRA Training (rank=8) ---
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2994.51it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.86s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.90s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.76s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.80s/it]
  Peak memory: 0 MB, Trainable: 3,407,872

--- Bridge Training (8 tokens) ---
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2877.25it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:12,  4.10s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.03s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.96s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  2.79s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.25s/it]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 3386.14it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.86s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:07<00:03,  3.90s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.74s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.79s/it]
Traceback (most recent call last):
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_benchmarks.py", line 658, in <module>
    main()
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_benchmarks.py", line 630, in main
    results = run_memory_benchmark(args, device)
  File "/scratch/m000066/sujinesh/LatentWire/telepathy/run_benchmarks.py", line 477, in run_memory_benchmark
    outputs = mistral(inputs_embeds=latents, labels=inputs.input_ids)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py", line 1095, in forward
    loss = loss_fct(shift_logits, shift_labels)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py", line 1293, in forward
    return F.cross_entropy(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/functional.py", line 3479, in cross_entropy
    return torch._C._nn.cross_entropy_loss(
ValueError: Expected input batch_size (7) to match target batch_size (1).
