{
  "samples": 16,
  "max_new_tokens": 12,
  "latent_len": 16,
  "device": "cuda",
  "dtype": "torch.bfloat16",
  "avg_prompt_tokens": {
    "llama": 290.75,
    "qwen": 278.5625
  },
  "compression": {
    "llama": 18.171875,
    "qwen": 17.41015625
  },
  "payload_bytes": 16384,
  "wire": {
    "text_bytes_onecopy": {
      "llama_avg": 1476,
      "qwen_avg": 1323,
      "max_avg": 1476
    },
    "text_bytes_twocopies": {
      "sum_avg": 2799
    },
    "latent_bytes": {
      "fp32": 16384,
      "fp16": 8192
    },
    "wire_compression": {
      "vs_onecopy_fp16": 0.18017578125,
      "vs_onecopy_fp32": 0.090087890625
    }
  },
  "text": {
    "llama": {
      "em": 0.5625,
      "f1": 0.7356004901960784,
      "nll_token": 11.496574388513089
    },
    "qwen": {
      "em": 0.625,
      "f1": 0.761904761904762,
      "nll_token": 25.969573822021484
    },
    "wall_clock_sec": 1.9655177593231201
  },
  "latent": {
    "llama": {
      "em": 0.0,
      "f1": 0.0,
      "nll_token": 9.892033641621218
    },
    "qwen": {
      "em": 0.0,
      "f1": 0.0,
      "nll_token": 7.144904417991638
    },
    "wall_clock_sec": 0.9810159206390381
  },
  "token_budget": {
    "mode": "content_only",
    "k": 16,
    "llama": {
      "em": 0.0,
      "f1": 0.0
    },
    "qwen": {
      "em": 0.0,
      "f1": 0.03125
    },
    "wall_clock_sec": 1.0568146705627441
  },
  "joint": {
    "em": 0.0,
    "f1": 0.0,
    "agreement": 0.0,
    "oracle": {
      "em": null,
      "f1": null
    }
  },
  "debug": {
    "llama": {
      "adapter_scale": 1.0251884460449219,
      "Z_std": 0.9986426830291748,
      "Z_mean_norm": 15.978144645690918,
      "prefix_std": 0.010567772202193737,
      "prefix_mean_norm": 0.6734179258346558,
      "embed_rms": 0.010565795935690403,
      "encoder_text_mode": "standard",
      "calibration_mode": "embed_rms",
      "append_bos_after_prefix": "auto",
      "latent_anchor_mode": "text",
      "latent_anchor_text": "<|start_header_id|>assistant<|end_header_id|>",
      "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct"
    },
    "qwen": {
      "adapter_scale": 1.0042412281036377,
      "Z_std": 0.9986426830291748,
      "Z_mean_norm": 15.978144645690918,
      "prefix_std": 0.01364673301577568,
      "prefix_mean_norm": 0.8157193064689636,
      "embed_rms": 0.013642282225191593,
      "encoder_text_mode": "standard",
      "calibration_mode": "embed_rms",
      "append_bos_after_prefix": "auto",
      "latent_anchor_mode": "text",
      "latent_anchor_text": "<|start_header_id|>assistant<|end_header_id|>",
      "model_id": "Qwen/Qwen2.5-7B-Instruct"
    },
    "latent_anchor_mode": "auto",
    "latent_anchor_text": "<|start_header_id|>assistant<|end_header_id|>",
    "prefix_gain": 1.0,
    "calibration_mode": "embed_rms",
    "append_bos_after_prefix": "auto",
    "decode": {
      "min_new_tokens": 2,
      "eos_ban_steps": 6,
      "first_token_top_p": 1.0,
      "first_token_temperature": 0.0
    }
  },
  "oracle": {
    "em": 0.0,
    "f1": 0.0
  },
  "dataset": "squad"
}