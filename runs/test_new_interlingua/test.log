/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
================================================================================
TESTING: Anchor-Guided Cross-Model Interlingua Architecture
================================================================================

Device: cuda

[1/7] Loading frozen models...
  - SentenceTransformer...
  - Llama-3.1-8B...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 3910.77it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.29s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.16s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.24it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.06it/s]
  - Qwen2.5-7B...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2144.05it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:20,  6.81s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:14<00:14,  7.13s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:21<00:07,  7.19s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:27<00:00,  6.83s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:27<00:00,  6.93s/it]
  ✓ All models loaded

[2/7] Instantiating new architecture components...
  ✓ AlignmentTransformer: 14,642,688 params
  ✓ InterlinguaAdapter (Llama): 10,563,585 params
  ✓ InterlinguaAdapter (Qwen): 10,299,905 params
  Total trainable: 35,506,178 params (35.5M)

[3/7] Loading test data (SQuAD, n=1000)...
  ✓ Loaded 1000 examples
  Example: Context: Tesla was the fourth of five children. He had an older brother named Dane and three sisters...

[4/7] Testing forward pass (single example)...
Traceback (most recent call last):
  File "/projects/m000066/sujinesh/LatentWire/scripts/test_new_interlingua.py", line 793, in <module>
    test_architecture(args)
  File "/projects/m000066/sujinesh/LatentWire/scripts/test_new_interlingua.py", line 472, in test_architecture
    z_llama = alignment_tf(
  File "/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/projects/m000066/sujinesh/LatentWire/scripts/test_new_interlingua.py", line 120, in forward
    x = self.proj_llama(token_embeds)  # [B, T, d_inter]
  File "/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/projects/m000066/sujinesh/LatentWire/.venv/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 117, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 must have the same dtype, but got BFloat16 and Float
