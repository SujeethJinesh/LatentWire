{
  "samples": 200,
  "max_new_tokens": 12,
  "latent_len": 16,
  "device": "cuda",
  "dtype": "torch.bfloat16",
  "avg_prompt_tokens": {
    "llama": 245.065,
    "qwen": 231.69
  },
  "compression": {
    "llama": 15.3165625,
    "qwen": 14.480625
  },
  "payload_bytes": 16384,
  "wire": {
    "text_bytes_onecopy": {
      "llama_avg": 1259,
      "qwen_avg": 1107,
      "max_avg": 1259
    },
    "text_bytes_twocopies": {
      "sum_avg": 2366
    },
    "latent_bytes": {
      "fp32": 16384,
      "fp16": 8192
    },
    "wire_compression": {
      "vs_onecopy_fp16": 0.1536865234375,
      "vs_onecopy_fp32": 0.07684326171875
    }
  },
  "text": {
    "wall_clock_sec": 17.180128574371338,
    "llama": {
      "em": 0.58,
      "f1": 0.7994106570072514,
      "nll_token": 12.72173482274305
    },
    "qwen": {
      "em": 0.68,
      "f1": 0.8528460272957177,
      "nll_token": 25.81069942126198
    }
  },
  "latent": {
    "wall_clock_sec": 14.611945152282715,
    "llama": {
      "em": 0.0,
      "f1": 0.024258449883449888,
      "nll_token": 8.76029359510426
    },
    "qwen": {
      "em": 0.0,
      "f1": 0.02424750086514793,
      "nll_token": 8.422177261461027
    }
  },
  "token_budget": {
    "mode": "content_only",
    "k": 16,
    "llama": {
      "em": 0.0,
      "f1": 0.038205738705738714
    },
    "wall_clock_sec": 12.735944032669067,
    "qwen": {
      "em": 0.01,
      "f1": 0.04269888444888446
    }
  },
  "joint": {
    "em": 0.0,
    "f1": 0.027446613027495383,
    "agreement": 0.0,
    "oracle": {
      "em": null,
      "f1": null
    }
  },
  "debug": {
    "llama": {
      "adapter_scale": 1.04381263256073,
      "Z_std": 1.0006574392318726,
      "Z_mean_norm": 16.01050567626953,
      "prefix_std": 0.010572738945484161,
      "prefix_mean_norm": 0.6752429008483887,
      "embed_rms": 0.010578219778835773,
      "encoder_text_mode": "raw",
      "calibration_mode": "embed_rms",
      "append_bos_after_prefix": "auto",
      "latent_anchor_mode": "text",
      "latent_anchor_text": "Answer: ",
      "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct"
    },
    "qwen": {
      "adapter_scale": 1.0086380243301392,
      "Z_std": 1.0008751153945923,
      "Z_mean_norm": 16.013988494873047,
      "prefix_std": 0.013631599955260754,
      "prefix_mean_norm": 0.8152983784675598,
      "embed_rms": 0.013649147935211658,
      "encoder_text_mode": "qwen_chat",
      "calibration_mode": "embed_rms",
      "append_bos_after_prefix": "auto",
      "latent_anchor_mode": "text",
      "latent_anchor_text": "Answer: ",
      "model_id": "Qwen/Qwen2.5-7B-Instruct"
    },
    "latent_anchor_mode": "text",
    "latent_anchor_text": "Answer: ",
    "prefix_gain": 1.0,
    "calibration_mode": "embed_rms",
    "append_bos_after_prefix": "auto",
    "decode": {
      "min_new_tokens": 3,
      "eos_ban_steps": 6,
      "first_token_top_p": 1.0,
      "first_token_temperature": 0.0
    }
  },
  "oracle": {
    "em": 0.0,
    "f1": 0.035559745809745816
  },
  "dataset": "squad"
}