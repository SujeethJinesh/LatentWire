W1130 15:32:49.652000 732633 torch/distributed/run.py:793] 
W1130 15:32:49.652000 732633 torch/distributed/run.py:793] *****************************************
W1130 15:32:49.652000 732633 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1130 15:32:49.652000 732633 torch/distributed/run.py:793] *****************************************
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[W1130 15:33:00.441898318 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W1130 15:33:00.447347928 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W1130 15:33:00.453847857 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W1130 15:33:00.507774202 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
======================================================================
Phase 12: Diffusion Bridge with Rectified Flow
======================================================================
Optimizations enabled:
  - Cosine LR Scheduler (warmup=500)
  - EMA (decay=0.999)
  - Gradient Clipping (max_norm=1.0)

Flow Loss will NOT drop to zero - this is normal.
Look for stable loss around 0.3-1.0 (not spikes/NaN).
======================================================================
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 3404.47it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 1821.83it/s]
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 3416.25it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 5129.08it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:13,  4.36s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:13,  4.38s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:13,  4.55s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.32s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.41s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.41s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.31s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:09<00:09,  4.70s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:13<00:04,  4.54s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:13<00:04,  4.39s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:13<00:04,  4.63s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:14<00:04,  4.97s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  3.18s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:14<00:00,  3.63s/it]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 3762.83it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.42s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.81s/it]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.45s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.86s/it]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 4435.29it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 4076.10it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:16<00:00,  3.57s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:16<00:00,  4.08s/it]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 6703.74it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:05<00:11,  5.66s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:05<00:10,  5.31s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:04<00:09,  4.69s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:05<00:10,  5.16s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:10<00:04,  4.99s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:09<00:04,  4.85s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:09<00:04,  4.56s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:09<00:04,  4.74s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:12<00:00,  4.15s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:12<00:00,  4.28s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [00:13<00:00,  4.24s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:13<00:00,  4.42s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [00:13<00:00,  4.44s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:13<00:00,  4.35s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:13<00:00,  4.66s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [00:13<00:00,  4.53s/it]
[LatentBridgeV12] DiT Diffusion Bridge initialized
  - num_latents: 128
  - depth: 6
  - heads: 8
  - src_dim: 4096 -> tgt_dim: 4096
[LatentBridgeV12] DiT Diffusion Bridge initialized[LatentBridgeV12] DiT Diffusion Bridge initialized
  - num_latents: 128
  - depth: 6
  - heads: 8
  - src_dim: 4096 -> tgt_dim: 4096

  - num_latents: 128
  - depth: 6
  - heads: 8
  - src_dim: 4096 -> tgt_dim: 4096
W1130 15:34:34.955000 732633 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 732645 closing signal SIGTERM
W1130 15:34:34.956000 732633 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 732646 closing signal SIGTERM
W1130 15:34:34.957000 732633 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 732647 closing signal SIGTERM
E1130 15:34:37.185000 732633 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: -9) local_rank: 0 (pid: 732643) of binary: /marlowe/apps/Mambaforge/24.3.0-0/bin/python
Traceback (most recent call last):
  File "/users/sujinesh/.local/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
telepathy/train_telepathy_v12.py FAILED
-------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-11-30_15:34:34
  host      : n19.cm.cluster
  rank      : 0 (local_rank: 0)
  exitcode  : -9 (pid: 732643)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 732643
=======================================================
