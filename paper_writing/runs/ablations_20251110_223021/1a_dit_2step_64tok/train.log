W1110 22:30:23.314000 228589 torch/distributed/run.py:793] 
W1110 22:30:23.314000 228589 torch/distributed/run.py:793] *****************************************
W1110 22:30:23.314000 228589 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1110 22:30:23.314000 228589 torch/distributed/run.py:793] *****************************************
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
====================================================================================================================================================================================
EARLY CUDA DIAGNOSTICS (before DDP setup)
============================================================
torch.cuda.is_available() check...

EARLY CUDA DIAGNOSTICS (before DDP setup)
============================================================
torch.cuda.is_available() check...

EARLY CUDA DIAGNOSTICS (before DDP setup)
============================================================
torch.cuda.is_available() check...
============================================================
EARLY CUDA DIAGNOSTICS (before DDP setup)
============================================================
torch.cuda.is_available() check...
