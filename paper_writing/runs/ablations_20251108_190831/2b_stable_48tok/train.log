W1108 22:38:12.965000 2905279 torch/distributed/run.py:793] 
W1108 22:38:12.965000 2905279 torch/distributed/run.py:793] *****************************************
W1108 22:38:12.965000 2905279 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1108 22:38:12.965000 2905279 torch/distributed/run.py:793] *****************************************
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
==== Config ====
source_model: mistralai/Mistral-7B-Instruct-v0.3
target_model: meta-llama/Meta-Llama-3.1-8B-Instruct
translator_type: bottleneck_gated
bottleneck_dim: 1024
soft_tokens: 48
depth: 6
heads: 16
lr: 0.0001
weight_decay: 0.01
train_steps: 3000
warmup_steps: 750
per_device_batch: 10
eval_every: 250
eval_samples: 500
max_new_tokens: 256
seed: 1234
bf16: True
save_path: paper_writing/runs/ablations_20251108_190831/2b_stable_48tok/checkpoint.pt
show_eval_samples: 1
early_stop_patience: 5
dataset: gsm8k
info_nce_weight: 0.05
Loading source model/tokenizer...
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 40.74it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.59it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 7281.78it/s]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 1658.92it/s]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 5150.60it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.80it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  2.04it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  2.01it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  2.05it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.89it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.82it/s]
Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  2.02it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.97it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  2.03it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.16it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.08it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.11it/s]
Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.15it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.12it/s]
Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.06it/s]
Loading target model/tokenizer...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 1942.03it/s]
Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 338.37it/s]
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 8355.19it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 8976.57it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  2.22it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  2.19it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  2.41it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  1.83it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.17it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.16it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.11it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.87it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  2.01it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  1.99it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  2.20it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  2.01it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.30it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.25it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.08it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.08it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.08it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.08it/s]

Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.17it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.07it/s]
Source hidden dim: 4096 | Target hidden dim: 4096
Target embedding RMS: 0.0105
Translator parameters: 142.8M
Loading GSM8K...
Optimizer groups: 50 decay, 87 no_decay, 6 gates (LR ×3)
Step 20/3000 | Loss (avg over last 20): 9.6684
Step 40/3000 | Loss (avg over last 20): 9.7857
Step 60/3000 | Loss (avg over last 20): 9.3676
Step 80/3000 | Loss (avg over last 20): 8.7218
Step 100/3000 | Loss (avg over last 20): 8.2552
Step 120/3000 | Loss (avg over last 20): 7.6971
Step 140/3000 | Loss (avg over last 20): 7.3679
Step 160/3000 | Loss (avg over last 20): 7.0801
Step 180/3000 | Loss (avg over last 20): 6.5887
Step 200/3000 | Loss (avg over last 20): 6.7171
Step 220/3000 | Loss (avg over last 20): 6.1383
Step 240/3000 | Loss (avg over last 20): 6.3448
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(

============================================================
SAMPLE OUTPUTS (first 3 examples):
============================================================

--- Example 1 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and...
Gold answer: 18
Target-alone: 210.0.0
Bridged: [invalid]
Bridged generation start:  =...

--- Example 2 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolt...
Gold answer: 3
Target-alone: 3
Bridged: [invalid]
Bridged generation start: =9 =6
=5-7=8<<5>>9=7 5 5>>4=9 6 =8=9>>5 3 =5-9=4>>5<<9 =7 6<<8 =5
=6-9 =4<<6 7 =9 5-5=10...

--- Example 3 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
Josh decides to try flipping a house.  He buys a house for $80,000 and then puts ...
Gold answer: 70000
Target-alone: 97500
Bridged: [invalid]
Bridged generation start: 	50=3=50 is=50 and=50'50=52=50.
50=51=50="50=2=50=$50=10=50='50=1=50?50==50 was=50^50=20=51 =50 = 50. 50+51= ...
============================================================

[Eval] Step 250 | Target-alone acc: 0.296 | Bridged acc: 0.010
[Early Stop] New best bridged acc: 0.010, resetting patience
Step 260/3000 | Loss (avg over last 20): 5.9657
Step 280/3000 | Loss (avg over last 20): 5.9543
Step 300/3000 | Loss (avg over last 20): 5.9843
Step 320/3000 | Loss (avg over last 20): 5.6776
Step 340/3000 | Loss (avg over last 20): 5.7001
Step 360/3000 | Loss (avg over last 20): 5.4987
Step 380/3000 | Loss (avg over last 20): 5.4388
Step 400/3000 | Loss (avg over last 20): 5.6096
Step 420/3000 | Loss (avg over last 20): 5.3337
Step 440/3000 | Loss (avg over last 20): 5.2236
Step 460/3000 | Loss (avg over last 20): 5.2837
Step 480/3000 | Loss (avg over last 20): 5.2126
Step 500/3000 | Loss (avg over last 20): 5.2547

============================================================
SAMPLE OUTPUTS (first 3 examples):
============================================================

--- Example 1 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and...
Gold answer: 18
Target-alone: 210.0.0
Bridged: [invalid]

--- Example 2 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolt...
Gold answer: 3
Target-alone: 3
Bridged: [invalid]
Bridged generation start: 1>>3=>>4>>12>>3>>4+>>2-1>>=1>>+1>>>>14>>3+11>>5>>1>1>><<141>>7>>1*1>>8>>13>>>>24>>42>>>>4<<...

--- Example 3 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
Josh decides to try flipping a house.  He buys a house for $80,000 and then puts ...
Gold answer: 70000
Target-alone: 97500
Bridged: [invalid]
Bridged generation start: 120=300120=200120000150120=180120=160120000800120=400120=220120=150120000200120=,000120120100120010012060012012060000012010000012060010012010060012006001201000120120800120120001206006001206000120100100000600000600100=600100000000600600=600600000100000100600=800120000400120120200120120/12012030012060...
============================================================

[Eval] Step 500 | Target-alone acc: 0.296 | Bridged acc: 0.000
[Early Stop] No improvement, patience: 1/5
Step 520/3000 | Loss (avg over last 20): 5.2456
Step 540/3000 | Loss (avg over last 20): 5.1072
Step 560/3000 | Loss (avg over last 20): 5.1413
Step 580/3000 | Loss (avg over last 20): 5.0697
Step 600/3000 | Loss (avg over last 20): 5.0789
Step 620/3000 | Loss (avg over last 20): 5.1288
Step 640/3000 | Loss (avg over last 20): 5.0405
Step 660/3000 | Loss (avg over last 20): 5.1441
Step 680/3000 | Loss (avg over last 20): 5.2757
Step 700/3000 | Loss (avg over last 20): 4.9973
Step 720/3000 | Loss (avg over last 20): 5.0398
Step 740/3000 | Loss (avg over last 20): 4.9060
