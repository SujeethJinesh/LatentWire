W1108 19:08:33.091000 2607507 torch/distributed/run.py:793] 
W1108 19:08:33.091000 2607507 torch/distributed/run.py:793] *****************************************
W1108 19:08:33.091000 2607507 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1108 19:08:33.091000 2607507 torch/distributed/run.py:793] *****************************************
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
==== Config ====
source_model: mistralai/Mistral-7B-Instruct-v0.3
target_model: meta-llama/Meta-Llama-3.1-8B-Instruct
translator_type: bottleneck_gated
bottleneck_dim: 1024
soft_tokens: 64
depth: 8
heads: 16
lr: 0.0001
weight_decay: 0.01
train_steps: 3000
warmup_steps: 750
per_device_batch: 10
eval_every: 250
eval_samples: 500
max_new_tokens: 256
seed: 1234
bf16: True
save_path: paper_writing/runs/ablations_20251108_190831/1a_stable_64tok/checkpoint.pt
show_eval_samples: 1
early_stop_patience: 5
dataset: gsm8k
info_nce_weight: 0.05
Loading source model/tokenizer...
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 1124.48it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  2.35it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  2.79it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  3.21it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.98it/s]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2644.58it/s]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 5304.77it/s]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 4705.65it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  2.20it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  2.11it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  2.50it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  2.52it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  2.42it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  2.67it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.64it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.53it/s]
Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.62it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.52it/s]
Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.79it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.74it/s]
Loading target model/tokenizer...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 1265.73it/s]
Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 264.39it/s]
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 667.19it/s]
Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 404.12it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  2.37it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  2.32it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  1.87it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  1.93it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.22it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.04it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.88it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.83it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  2.09it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  2.10it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  1.89it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  1.86it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.16it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.17it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.19it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.15it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.17it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.15it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.03it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.05it/s]
Source hidden dim: 4096 | Target hidden dim: 4096
Target embedding RMS: 0.0105
Translator parameters: 189.0M
Loading GSM8K...
Optimizer groups: 66 decay, 115 no_decay, 8 gates (LR ×3)
Step 20/3000 | Loss (avg over last 20): 10.0748
Step 40/3000 | Loss (avg over last 20): 9.4257
Step 60/3000 | Loss (avg over last 20): 9.0834
Step 80/3000 | Loss (avg over last 20): 8.1065
Step 100/3000 | Loss (avg over last 20): 7.6316
Step 120/3000 | Loss (avg over last 20): 7.2969
Step 140/3000 | Loss (avg over last 20): 7.0307
Step 160/3000 | Loss (avg over last 20): 7.0810
Step 180/3000 | Loss (avg over last 20): 6.2433
Step 200/3000 | Loss (avg over last 20): 5.8922
Step 220/3000 | Loss (avg over last 20): 5.6573
Step 240/3000 | Loss (avg over last 20): 5.5637
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(

============================================================
SAMPLE OUTPUTS (first 3 examples):
============================================================

--- Example 1 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and...
Gold answer: 18
Target-alone: 210.0.0
Bridged: [invalid]

--- Example 2 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolt...
Gold answer: 3
Target-alone: 3
Bridged: [invalid]
Bridged generation start:    -  11   >   there   a   are   d   c   that   we   The   b   million   dozen  90  300  160  600  230  32   inside  201  550  9  60  250  290...

--- Example 3 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
Josh decides to try flipping a house.  He buys a house for $80,000 and then puts ...
Gold answer: 70000
Target-alone: 97500
Bridged: [invalid]
Bridged generation start: dozen   inside  160  25  12  550  250  32   hours  230  290  640...
============================================================

[Eval] Step 250 | Target-alone acc: 0.296 | Bridged acc: 0.016
[Early Stop] New best bridged acc: 0.016, resetting patience
Step 260/3000 | Loss (avg over last 20): 5.4654
Step 280/3000 | Loss (avg over last 20): 5.4314
Step 300/3000 | Loss (avg over last 20): 5.4734
Step 320/3000 | Loss (avg over last 20): 5.2548
Step 340/3000 | Loss (avg over last 20): 5.2767
Step 360/3000 | Loss (avg over last 20): 5.3786
Step 380/3000 | Loss (avg over last 20): 5.3076
Step 400/3000 | Loss (avg over last 20): 5.4141
Step 420/3000 | Loss (avg over last 20): 5.3217
Step 440/3000 | Loss (avg over last 20): 5.3032
Step 460/3000 | Loss (avg over last 20): 5.3200
Step 480/3000 | Loss (avg over last 20): 5.3278
Step 500/3000 | Loss (avg over last 20): 5.3164

============================================================
SAMPLE OUTPUTS (first 3 examples):
============================================================

--- Example 1 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and...
Gold answer: 18
Target-alone: 210.0.0
Bridged: [invalid]

--- Example 2 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolt...
Gold answer: 3
Target-alone: 3
Bridged: [invalid]
Bridged generation start: 22122:22:
22142218222222922##22<<225622 he225022 *223222A22 a2236228022>22 x2
+...

--- Example 3 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
Josh decides to try flipping a house.  He buys a house for $80,000 and then puts ...
Gold answer: 70000
Target-alone: 97500
Bridged: [invalid]
Bridged generation start: 
=+
=,
= he
0>>
0-0
2=
20
...
============================================================

[Eval] Step 500 | Target-alone acc: 0.296 | Bridged acc: 0.012
[Early Stop] No improvement, patience: 1/5
Step 520/3000 | Loss (avg over last 20): 5.3980
Step 540/3000 | Loss (avg over last 20): 5.1774
Step 560/3000 | Loss (avg over last 20): 5.2024
Step 580/3000 | Loss (avg over last 20): 5.1962
Step 600/3000 | Loss (avg over last 20): 5.1398
Step 620/3000 | Loss (avg over last 20): 5.1923
Step 640/3000 | Loss (avg over last 20): 5.1748
Step 660/3000 | Loss (avg over last 20): 5.0986
Step 680/3000 | Loss (avg over last 20): 5.2971
Step 700/3000 | Loss (avg over last 20): 5.1141
Step 720/3000 | Loss (avg over last 20): 5.1721
Step 740/3000 | Loss (avg over last 20): 5.0472

============================================================
SAMPLE OUTPUTS (first 3 examples):
============================================================

--- Example 1 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and...
Gold answer: 18
Target-alone: 210.0.0
Bridged: [invalid]
Bridged generation start: $ 5 $ 20 $ 3 $ 1 $=2 $=6 $=>> $= << $=, $=5 $=
 $<<= $...

--- Example 2 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolt...
Gold answer: 3
Target-alone: 3
Bridged: [invalid]
Bridged generation start: 
>>

0

<<

8

7

 >>

####

1

:

/

20

3

16

4

24

40

12
=6
 6= 5
 <<2
 <<6
 <<...

--- Example 3 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
Josh decides to try flipping a house.  He buys a house for $80,000 and then puts ...
Gold answer: 70000
Target-alone: 97500
Bridged: [invalid]
Bridged generation start: ##00
 $00
20
0050
001000000000=0000 $0000$0000*00005000000+000000000000000000000...
============================================================

[Eval] Step 750 | Target-alone acc: 0.296 | Bridged acc: 0.012
[Early Stop] No improvement, patience: 2/5
Step 760/3000 | Loss (avg over last 20): 7.9586
Step 780/3000 | Loss (avg over last 20): 7.5078
Step 800/3000 | Loss (avg over last 20): 6.4001
Step 820/3000 | Loss (avg over last 20): 6.0580
Step 840/3000 | Loss (avg over last 20): 5.9720
Step 860/3000 | Loss (avg over last 20): 6.0623
Step 880/3000 | Loss (avg over last 20): 5.8612
Step 900/3000 | Loss (avg over last 20): 5.6898
Step 920/3000 | Loss (avg over last 20): 6.0439
Step 940/3000 | Loss (avg over last 20): 5.8370
Step 960/3000 | Loss (avg over last 20): 5.8667
Step 980/3000 | Loss (avg over last 20): 5.7064
Step 1000/3000 | Loss (avg over last 20): 5.5657

============================================================
SAMPLE OUTPUTS (first 3 examples):
============================================================

--- Example 1 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and...
Gold answer: 18
Target-alone: 210.0.0
Bridged: [invalid]

--- Example 2 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolt...
Gold answer: 3
Target-alone: 3
Bridged: [invalid]
Bridged generation start:   water   *= 6= 4=  = the  the the2=2= the=2 the= 3=22==2/2=6 =4=26=2 ==2*=2 of=2+=2.
=24== the222 the 622/=21=2...

--- Example 3 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
Josh decides to try flipping a house.  He buys a house for $80,000 and then puts ...
Gold answer: 70000
Target-alone: 97500
Bridged: [invalid]
Bridged generation start: 0000000=000==000
0000
00
0000=0000,0000 0000/0000 $0000150000000 of0000001000000.
0000003000000####000000300000000250000000800000000400000000 total00000025500000040000008000000600000060000000'0000001000000015000000=$0000002400000001500000*00000,00000 00000/00000600000060000000 $00000...
============================================================

[Eval] Step 1000 | Target-alone acc: 0.296 | Bridged acc: 0.008
[Early Stop] No improvement, patience: 3/5
Step 1020/3000 | Loss (avg over last 20): 5.7582
Step 1040/3000 | Loss (avg over last 20): 5.6518
Step 1060/3000 | Loss (avg over last 20): 5.6924
Step 1080/3000 | Loss (avg over last 20): 5.7049
Step 1100/3000 | Loss (avg over last 20): 5.5014
Step 1120/3000 | Loss (avg over last 20): 5.5554
Step 1140/3000 | Loss (avg over last 20): 5.6182
Step 1160/3000 | Loss (avg over last 20): 5.5609
Step 1180/3000 | Loss (avg over last 20): 5.4275
Step 1200/3000 | Loss (avg over last 20): 5.6216
Step 1220/3000 | Loss (avg over last 20): 5.4601
Step 1240/3000 | Loss (avg over last 20): 5.7131

============================================================
SAMPLE OUTPUTS (first 3 examples):
============================================================

--- Example 1 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and...
Gold answer: 18
Target-alone: 210.0.0
Bridged: [invalid]

--- Example 2 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolt...
Gold answer: 3
Target-alone: 3
Bridged: [invalid]
Bridged generation start: e= the>>= the/=.
 the=.
/=
 the=
/=2 the=2*= the2= the*=22=2.
= the5==15==10==####==24==20==7==0==9==16==50==40==5=2 of=2,=  of= the<<=2<<= the...

--- Example 3 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
Josh decides to try flipping a house.  He buys a house for $80,000 and then puts ...
Gold answer: 70000
Target-alone: 97500
Bridged: [invalid]
Bridged generation start: 00000=00000000==000=120000012000001200
0=0=

=
==
00
120000= 0000 000
120
000120=000120

12000==000120000
 000= $000
00000
 $0000 $000=00000000000=/000
/0000/000=10000001500000,000
150000=1500000 0000000000 $
00000
000 1200120
01200000012000...
============================================================

[Eval] Step 1250 | Target-alone acc: 0.296 | Bridged acc: 0.012
[Early Stop] No improvement, patience: 4/5
Step 1260/3000 | Loss (avg over last 20): 5.4380
Step 1280/3000 | Loss (avg over last 20): 5.3646
Step 1300/3000 | Loss (avg over last 20): 5.6321
Step 1320/3000 | Loss (avg over last 20): 5.3339
Step 1340/3000 | Loss (avg over last 20): 5.4212
Step 1360/3000 | Loss (avg over last 20): 5.4174
Step 1380/3000 | Loss (avg over last 20): 5.3984
Step 1400/3000 | Loss (avg over last 20): 5.3205
Step 1420/3000 | Loss (avg over last 20): 5.4091
Step 1440/3000 | Loss (avg over last 20): 5.5574
Step 1460/3000 | Loss (avg over last 20): 5.4215
Step 1480/3000 | Loss (avg over last 20): 5.4242
Step 1500/3000 | Loss (avg over last 20): 5.3383

============================================================
SAMPLE OUTPUTS (first 3 examples):
============================================================

--- Example 1 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and...
Gold answer: 18
Target-alone: 210.0.0
Bridged: [invalid]

--- Example 2 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolt...
Gold answer: 3
Target-alone: 3
Bridged: [invalid]
Bridged generation start:  that// =/=.
/=*/2.
/2*/
=/
2/

/
 /
 the2/<<=/<<2/>>=/>>2/*=/*2/0=/02/ the2=2==2
=22= =2 ==...

--- Example 3 ---
Question: You are a helpful math tutor. Solve the problem step by step, then end your final line with '#### <number>'.

Problem:
Josh decides to try flipping a house.  He buys a house for $80,000 and then puts ...
Gold answer: 70000
Target-alone: 97500
Bridged: [invalid]
Bridged generation start: 00001200
 total
00 
00/
0.
0
60000060000
60000060000 

600
00 $0
12000120000120
00500 $00012000050006000
,00
12000
2400...
============================================================

[Eval] Step 1500 | Target-alone acc: 0.296 | Bridged acc: 0.012
[Early Stop] No improvement, patience: 5/5
[Early Stop] Stopping early at step 1500. Best bridged acc: 0.016
Saved BEST translator (acc=0.016) to paper_writing/runs/ablations_20251108_190831/1a_stable_64tok/checkpoint.pt
[rank1]:[E1108 20:22:25.656980378 ProcessGroupNCCL.cpp:616] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=23993, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600045 milliseconds before timing out.
[rank3]:[E1108 20:22:25.657328821 ProcessGroupNCCL.cpp:616] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=23993, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600038 milliseconds before timing out.
[rank2]:[E1108 20:22:25.657591117 ProcessGroupNCCL.cpp:616] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=23993, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600022 milliseconds before timing out.
[rank2]:[E1108 20:22:25.660409718 ProcessGroupNCCL.cpp:1785] [PG ID 0 PG GUID 0(default_pg) Rank 2] Exception (either an error or timeout) detected by watchdog at work: 23993, last enqueued NCCL work: 23993, last completed NCCL work: 23992.
[rank3]:[E1108 20:22:25.664036633 ProcessGroupNCCL.cpp:1785] [PG ID 0 PG GUID 0(default_pg) Rank 3] Exception (either an error or timeout) detected by watchdog at work: 23993, last enqueued NCCL work: 23993, last completed NCCL work: 23992.
[rank1]:[E1108 20:22:25.668096502 ProcessGroupNCCL.cpp:1785] [PG ID 0 PG GUID 0(default_pg) Rank 1] Exception (either an error or timeout) detected by watchdog at work: 23993, last enqueued NCCL work: 23993, last completed NCCL work: 23992.
[rank2]:[E1108 20:22:26.381076365 ProcessGroupNCCL.cpp:1834] [PG ID 0 PG GUID 0(default_pg) Rank 2] Timeout at NCCL work: 23993, last enqueued NCCL work: 23993, last completed NCCL work: 23992.
[rank2]:[E1108 20:22:26.381145369 ProcessGroupNCCL.cpp:630] [Rank 2] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank2]:[E1108 20:22:26.381166682 ProcessGroupNCCL.cpp:636] [Rank 2] To avoid data inconsistency, we are taking the entire process down.
[rank2]:[E1108 20:22:26.382170476 ProcessGroupNCCL.cpp:1595] [PG ID 0 PG GUID 0(default_pg) Rank 2] Process group watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=23993, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600022 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x1555542b9446 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x155509bcfa92 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x155509bd6ed3 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x155509bd893d in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x1555547445c0 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x94ac3 (0x15555526fac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126850 (0x155555301850 in /lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[E1108 20:22:26.382221873 ProcessGroupNCCL.cpp:1834] [PG ID 0 PG GUID 0(default_pg) Rank 1] Timeout at NCCL work: 23993, last enqueued NCCL work: 23993, last completed NCCL work: 23992.
[rank1]:[E1108 20:22:26.382231532 ProcessGroupNCCL.cpp:630] [Rank 1] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank1]:[E1108 20:22:26.382249039 ProcessGroupNCCL.cpp:636] [Rank 1] To avoid data inconsistency, we are taking the entire process down.
[rank1]:[E1108 20:22:26.383211224 ProcessGroupNCCL.cpp:1595] [PG ID 0 PG GUID 0(default_pg) Rank 1] Process group watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=23993, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600045 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x1555542b9446 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x155509bcfa92 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x155509bd6ed3 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x155509bd893d in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x1555547445c0 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x94ac3 (0x15555526fac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126850 (0x155555301850 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
[rank3]:[E1108 20:22:26.384249845 ProcessGroupNCCL.cpp:1834] [PG ID 0 PG GUID 0(default_pg) Rank 3] Timeout at NCCL work: 23993, last enqueued NCCL work: 23993, last completed NCCL work: 23992.
[rank3]:[E1108 20:22:26.384259883 ProcessGroupNCCL.cpp:630] [Rank 3] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank3]:[E1108 20:22:26.384277994 ProcessGroupNCCL.cpp:636] [Rank 3] To avoid data inconsistency, we are taking the entire process down.
[rank3]:[E1108 20:22:26.385265498 ProcessGroupNCCL.cpp:1595] [PG ID 0 PG GUID 0(default_pg) Rank 3] Process group watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=23993, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600038 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x1555542b9446 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x155509bcfa92 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x155509bd6ed3 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x155509bd893d in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x1555547445c0 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x94ac3 (0x15555526fac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126850 (0x155555301850 in /lib/x86_64-linux-gnu/libc.so.6)

  what():  [PG ID 0 PG GUID 0(default_pg) Rank 2] Process group watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=23993, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600022 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x1555542b9446 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x155509bcfa92 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x155509bd6ed3 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x155509bd893d in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x1555547445c0 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x94ac3 (0x15555526fac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126850 (0x155555301850 in /lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1601 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x1555542b9446 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe7eb1b (0x15550984db1b in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x1555547445c0 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x94ac3 (0x15555526fac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #4: <unknown function> + 0x126850 (0x155555301850 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG ID 0 PG GUID 0(default_pg) Rank 1] Process group watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=23993, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600045 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x1555542b9446 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x155509bcfa92 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x155509bd6ed3 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x155509bd893d in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x1555547445c0 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x94ac3 (0x15555526fac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126850 (0x155555301850 in /lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1601 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x1555542b9446 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe7eb1b (0x15550984db1b in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x1555547445c0 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x94ac3 (0x15555526fac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #4: <unknown function> + 0x126850 (0x155555301850 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG ID 0 PG GUID 0(default_pg) Rank 3] Process group watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=23993, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600038 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x1555542b9446 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x155509bcfa92 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x155509bd6ed3 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x155509bd893d in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x145c0 (0x1555547445c0 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch.so)
frame #5: <unknown function> + 0x94ac3 (0x15555526fac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126850 (0x155555301850 in /lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1601 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x1555542b9446 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe7eb1b (0x15550984db1b in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x1555547445c0 in /users/sujinesh/.local/lib/python3.10/site-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x94ac3 (0x15555526fac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #4: <unknown function> + 0x126850 (0x155555301850 in /lib/x86_64-linux-gnu/libc.so.6)

W1108 20:22:27.673000 2607507 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2607511 closing signal SIGTERM
E1108 20:22:28.481000 2607507 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: -6) local_rank: 1 (pid: 2607512) of binary: /marlowe/apps/Mambaforge/24.3.0-0/bin/python
Traceback (most recent call last):
  File "/users/sujinesh/.local/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
========================================================
paper_writing/cross_attention.py FAILED
--------------------------------------------------------
Failures:
[1]:
  time      : 2025-11-08_20:22:27
  host      : n22.cm.cluster
  rank      : 2 (local_rank: 2)
  exitcode  : -6 (pid: 2607513)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 2607513
[2]:
  time      : 2025-11-08_20:22:27
  host      : n22.cm.cluster
  rank      : 3 (local_rank: 3)
  exitcode  : -6 (pid: 2607514)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 2607514
--------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-11-08_20:22:27
  host      : n22.cm.cluster
  rank      : 1 (local_rank: 1)
  exitcode  : -6 (pid: 2607512)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 2607512
========================================================
