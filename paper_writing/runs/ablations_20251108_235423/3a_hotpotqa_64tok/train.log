W1109 04:57:42.427000 3463066 torch/distributed/run.py:793] 
W1109 04:57:42.427000 3463066 torch/distributed/run.py:793] *****************************************
W1109 04:57:42.427000 3463066 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1109 04:57:42.427000 3463066 torch/distributed/run.py:793] *****************************************
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
==== Config ====
source_model: mistralai/Mistral-7B-Instruct-v0.3
target_model: meta-llama/Meta-Llama-3.1-8B-Instruct
bottleneck_dim: 1024
soft_tokens: 64
depth: 8
heads: 16
lr: 0.0001
weight_decay: 0.01
train_steps: 3000
warmup_steps: 750
per_device_batch: 10
eval_every: 250
eval_samples: 500
max_new_tokens: 256
seed: 1234
bf16: True
save_path: paper_writing/runs/ablations_20251108_235423/3a_hotpotqa_64tok/checkpoint.pt
show_eval_samples: 1
early_stop_patience: 5
dataset: hotpotqa
info_nce_weight: 0.05
eval_batch_size: 125
no_compile: False
Loading source model/tokenizer...
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 2914.06it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 1588.75it/s]
Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  2.73it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 3492.34it/s]
Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  3.30it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 808.00it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  3.39it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  3.30it/s]
Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  2.10it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  2.16it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  2.34it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  2.59it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  2.40it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.79it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.67it/s]
Loading checkpoint shards:  67%|██████▋   | 2/3 [00:00<00:00,  2.52it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.47it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.40it/s]
Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.74it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.60it/s]
Loading target model/tokenizer...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 3947.58it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 9603.44it/s]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  7.96it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 3325.51it/s]
Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 564.68it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  3.92it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  2.47it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  1.96it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  3.39it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  1.92it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.01it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.13it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.35it/s]
Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.83it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.84it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  2.20it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  1.99it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  1.97it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.35it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.27it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.24it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.11it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.20it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.09it/s]
Compiling target model with torch.compile for faster inference...
Source hidden dim: 4096 | Target hidden dim: 4096
Target embedding RMS (median): 0.0107
Translator parameters: 189.0M
Loading HOTPOTQA...
Generating train split:   0%|          | 0/90447 [00:00<?, ? examples/s]Generating train split:   3%|▎         | 3000/90447 [00:00<00:05, 15594.47 examples/s]Generating train split:   6%|▌         | 5000/90447 [00:00<00:12, 7048.48 examples/s] Generating train split:   7%|▋         | 6000/90447 [00:00<00:12, 6654.04 examples/s]Generating train split:   8%|▊         | 7000/90447 [00:01<00:13, 6128.60 examples/s]Generating train split:   9%|▉         | 8000/90447 [00:01<00:13, 5919.58 examples/s]Generating train split:  10%|▉         | 9000/90447 [00:01<00:13, 5819.97 examples/s]Generating train split:  11%|█         | 10000/90447 [00:01<00:14, 5672.96 examples/s]Generating train split:  12%|█▏        | 11000/90447 [00:01<00:14, 5544.26 examples/s]Generating train split:  13%|█▎        | 12000/90447 [00:01<00:14, 5572.16 examples/s]Generating train split:  14%|█▍        | 13000/90447 [00:02<00:20, 3715.64 examples/s]Generating train split:  15%|█▌        | 14000/90447 [00:02<00:19, 3914.80 examples/s]Generating train split:  17%|█▋        | 15000/90447 [00:02<00:17, 4217.45 examples/s]Generating train split:  18%|█▊        | 16000/90447 [00:02<00:15, 4906.62 examples/s]Generating train split:  22%|██▏       | 20000/90447 [00:03<00:06, 10797.21 examples/s]Generating train split:  25%|██▌       | 23000/90447 [00:03<00:04, 14432.12 examples/s]Generating train split:  28%|██▊       | 25000/90447 [00:03<00:06, 10825.23 examples/s]Generating train split:  30%|██▉       | 27000/90447 [00:03<00:05, 10903.01 examples/s]Generating train split:  32%|███▏      | 29000/90447 [00:03<00:06, 9940.04 examples/s] Generating train split:  34%|███▍      | 31000/90447 [00:04<00:06, 9716.36 examples/s]Generating train split:  36%|███▋      | 33000/90447 [00:04<00:05, 11370.98 examples/s]Generating train split:  39%|███▊      | 35000/90447 [00:04<00:05, 9418.57 examples/s] Generating train split:  41%|████      | 37000/90447 [00:04<00:07, 7151.37 examples/s]Generating train split:  42%|████▏     | 38000/90447 [00:05<00:07, 7351.42 examples/s]Generating train split:  44%|████▍     | 40000/90447 [00:05<00:05, 9092.79 examples/s]Generating train split:  46%|████▋     | 42000/90447 [00:05<00:04, 10165.33 examples/s]Generating train split:  50%|████▉     | 45000/90447 [00:05<00:03, 13670.57 examples/s]Generating train split:  54%|█████▍    | 49224/90447 [00:05<00:02, 15855.72 examples/s]Generating train split:  57%|█████▋    | 51224/90447 [00:05<00:02, 14104.38 examples/s]Generating train split:  59%|█████▉    | 53224/90447 [00:05<00:02, 14494.61 examples/s]Generating train split:  61%|██████    | 55224/90447 [00:06<00:02, 14432.57 examples/s]Generating train split:  64%|██████▍   | 58224/90447 [00:06<00:02, 15190.94 examples/s]Generating train split:  67%|██████▋   | 60224/90447 [00:06<00:02, 13095.62 examples/s]Generating train split:  69%|██████▉   | 62224/90447 [00:06<00:02, 11769.94 examples/s]Generating train split:  71%|███████   | 64224/90447 [00:06<00:02, 11474.51 examples/s]Generating train split:  73%|███████▎  | 66224/90447 [00:07<00:02, 10780.82 examples/s]Generating train split:  77%|███████▋  | 69224/90447 [00:07<00:02, 10353.53 examples/s]Generating train split:  79%|███████▊  | 71224/90447 [00:07<00:01, 10265.14 examples/s]Generating train split:  82%|████████▏ | 74224/90447 [00:07<00:01, 11113.55 examples/s]Generating train split:  86%|████████▋ | 78224/90447 [00:08<00:00, 14170.69 examples/s]Generating train split:  90%|████████▉ | 81224/90447 [00:08<00:00, 15420.26 examples/s]Generating train split:  92%|█████████▏| 83224/90447 [00:08<00:00, 10714.46 examples/s]Generating train split:  96%|█████████▋| 87224/90447 [00:08<00:00, 12952.02 examples/s]Generating train split:  99%|█████████▊| 89224/90447 [00:08<00:00, 13851.62 examples/s]Generating train split: 100%|██████████| 90447/90447 [00:09<00:00, 10045.96 examples/s]
Generating validation split:   0%|          | 0/7405 [00:00<?, ? examples/s]Generating validation split:  81%|████████  | 6000/7405 [00:00<00:00, 54006.46 examples/s]Generating validation split: 100%|██████████| 7405/7405 [00:00<00:00, 47081.22 examples/s]
Optimizer groups: 66 decay, 99 no_decay, 16 gates (LR ×3)

============================================================
INITIAL EVALUATION (Step 0 - Before Training)
============================================================
[Distributed Eval] Sharding 500 samples across 4 ranks:
  Rank 0: samples 0 to 125 (125 samples)
  Rank 1: samples 125 to 250 (125 samples)
  Rank 2: samples 250 to 375 (125 samples)
  Rank 3: samples 375 to 500 (125 samples)
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(

============================================================
SAMPLE OUTPUTS (first 3 examples):
============================================================

--- Example 1 ---
Question: ...
Gold answer: [invalid]
Target-alone: 0
Bridged: [invalid]
Bridged generation start: 2

## Step 1
The number of successful completion.

This is a good idea to use the number of unsuccessful completion. The number of successive steps in the process. The answer to this question. The result to this step. The results to this problem. The outcome to this solution. The output to this resu...

--- Example 2 ---
Question: ...
Gold answer: [invalid]
Target-alone: 1.
Bridged: [invalid]
Bridged generation start: 2

## Step 1
The number of successful completion.

This is a good idea to use the number of unsuccessful completion. The number of successive steps in the process. The answer to this question. The result to this step. The results to this problem. The outcome to this solution. The output to this resu...

--- Example 3 ---
Question: ...
Gold answer: [invalid]
Target-alone: 3.5.7.9
Bridged: [invalid]
Bridged generation start: 2

## Step 1
The number of successful completion.

This is a good idea to use the number of unsuccessful completion. The number of successive steps in the process. The answer to this question. The result to this step. The results to this problem. The outcome to this solution. The output to this resu...
============================================================

[Eval] Step 0 | Target-alone acc: 0.296 | Bridged acc: 1.000
============================================================


============================================================
LABEL ALIGNMENT DIAGNOSTIC (Step 0)
============================================================
  Input embeddings shape: torch.Size([10, 71, 4096])
  Labels shape: torch.Size([10, 71])
  Attention mask shape: torch.Size([10, 71])
  Soft token count (K): 64
  Total tokens: 710
  Supervised tokens: 43
  Masked tokens: 667
  Sample 0 first 10 labels: [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100]
  Sample 0 last 10 labels: [-100, -100, -100, -100, -100, -100, -100, 128000, 26287, 12126]
  All soft token labels == -100? True
  Supervised tokens per sample: [3, 2, 6, 4, 5, 7, 5, 6, 3, 2]
============================================================

/users/sujinesh/.local/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:167: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:167: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:167: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:167: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
Step 20/3000 | Loss (avg over last 20): 9.1942
Step 40/3000 | Loss (avg over last 20): 8.3703
Step 60/3000 | Loss (avg over last 20): 7.4461
Step 80/3000 | Loss (avg over last 20): 5.5321
Step 100/3000 | Loss (avg over last 20): 4.3159
Step 120/3000 | Loss (avg over last 20): 4.1785
Step 140/3000 | Loss (avg over last 20): 4.0108
Step 160/3000 | Loss (avg over last 20): 3.8677
Step 180/3000 | Loss (avg over last 20): 4.0138
Step 200/3000 | Loss (avg over last 20): 3.9613
Step 220/3000 | Loss (avg over last 20): 3.7874
Step 240/3000 | Loss (avg over last 20): 3.6978
[Distributed Eval] Sharding 500 samples across 4 ranks:
  Rank 0: samples 0 to 125 (125 samples)
  Rank 1: samples 125 to 250 (125 samples)
  Rank 2: samples 250 to 375 (125 samples)
  Rank 3: samples 375 to 500 (125 samples)
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(

============================================================
SAMPLE OUTPUTS (first 3 examples):
============================================================

--- Example 1 ---
Question: ...
Gold answer: [invalid]
Target-alone: 0
Bridged: [invalid]
Bridged generation start:  |  |
| --- | --- | ---
|  |  | |

|  |
--- | --- |
|  |

| --- |
|
| 1.  | 
| 2.  |
|
--- | 3.  |

= 4.  = 5.  =
| 6.  |= 7.  =

| 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35. 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49. 50...

--- Example 2 ---
Question: ...
Gold answer: [invalid]
Target-alone: 1.
Bridged: [invalid]
Bridged generation start:  |  |
| --- | --- | ---
|  |  | |

|  |
--- | --- |
|  |

| --- |
|
| 1.  | 
| 2.  |
|
--- | 3.  |

= 4.  = 5.  =
| 6.  |= 7.  =

| 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35. 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49. 50...

--- Example 3 ---
Question: ...
Gold answer: [invalid]
Target-alone: 3.5.7.9
Bridged: [invalid]
Bridged generation start:  |  |
| --- | --- | ---
|  |  | |

|  |
--- | --- |
|  |

| --- |
|
| 1.  | 
| 2.  |
|
--- | 3.  |

= 4.  = 5.  =
| 6.  |= 7.  =

| 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35. 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49. 50...
============================================================

[Eval] Step 250 | Target-alone acc: 0.296 | Bridged acc: 1.000
[Early Stop] New best bridged acc: 1.000, resetting patience
Step 260/3000 | Loss (avg over last 20): 3.7510
Step 280/3000 | Loss (avg over last 20): 3.4081
Step 300/3000 | Loss (avg over last 20): 3.5394
Step 320/3000 | Loss (avg over last 20): 3.3886
Step 340/3000 | Loss (avg over last 20): 3.3431
Step 360/3000 | Loss (avg over last 20): 3.5348
Step 380/3000 | Loss (avg over last 20): 3.4673
Step 400/3000 | Loss (avg over last 20): 3.4146
Step 420/3000 | Loss (avg over last 20): 3.5262
Step 440/3000 | Loss (avg over last 20): 3.4946
Step 460/3000 | Loss (avg over last 20): 3.4180
Step 480/3000 | Loss (avg over last 20): 3.4779
Step 500/3000 | Loss (avg over last 20): 3.3651
[Distributed Eval] Sharding 500 samples across 4 ranks:
  Rank 0: samples 0 to 125 (125 samples)
  Rank 1: samples 125 to 250 (125 samples)
  Rank 2: samples 250 to 375 (125 samples)
  Rank 3: samples 375 to 500 (125 samples)
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(

============================================================
SAMPLE OUTPUTS (first 3 examples):
============================================================

--- Example 1 ---
Question: ...
Gold answer: [invalid]
Target-alone: 0
Bridged: [invalid]
Bridged generation start: 2013, 2014, 2020 |

## Early life and education

Born in New York City, New York, to a family of Puerto Rican descent, Rodriguez was raised in the Bronx. He attended the High School of Art and Design in Manhattan.

Rodriguez graduated from the University of Miami with a degree in music theory and co...

--- Example 2 ---
Question: ...
Gold answer: [invalid]
Target-alone: 1.
Bridged: [invalid]
Bridged generation start: 2004 | 2005 | 2010 | 2022 |

|  |
| Studio album by The Black Keys |
| Released | April 1, 2008 (2008-04-01) |
| Recorded | 1999–2007 |
| Genre | 
* Blues rock
* garage rock
*
* Hard rock

 |
| Length | 39:47 |
| Label | Fat Possum |
| Producer | The Black Crowes' Rich Robinson and Dan Auerbach |
| ...

--- Example 3 ---
Question: ...
Gold answer: [invalid]
Target-alone: 3.5.7.9
Bridged: [invalid]
Bridged generation start: 2007, the album was re-released in a special edition with bonus tracks and a DVD featuring live performances. The album has been certified platinum by the RIAA.

## Track listing

1. "The Day That Never Comes"
2. "Cyanide"
3. "My Apocalypse"
4. "That Was Just Destroyer"
5. "Welcome Home (Sanitarium)...
============================================================

[Eval] Step 500 | Target-alone acc: 0.296 | Bridged acc: 1.000
[Early Stop] No improvement, patience: 1/5
Step 520/3000 | Loss (avg over last 20): 3.3195
Step 540/3000 | Loss (avg over last 20): 3.3249
Step 560/3000 | Loss (avg over last 20): 3.4400
Step 580/3000 | Loss (avg over last 20): 3.3918
Step 600/3000 | Loss (avg over last 20): 3.2186
Step 620/3000 | Loss (avg over last 20): 3.3680
Step 640/3000 | Loss (avg over last 20): 3.0880
Step 660/3000 | Loss (avg over last 20): 3.1993
Step 680/3000 | Loss (avg over last 20): 3.3800
Step 700/3000 | Loss (avg over last 20): 3.2313
Step 720/3000 | Loss (avg over last 20): 3.2568
Step 740/3000 | Loss (avg over last 20): 3.2814
[Distributed Eval] Sharding 500 samples across 4 ranks:
  Rank 0: samples 0 to 125 (125 samples)
  Rank 1: samples 125 to 250 (125 samples)
  Rank 2: samples 250 to 375 (125 samples)
  Rank 3: samples 375 to 500 (125 samples)
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(

============================================================
SAMPLE OUTPUTS (first 3 examples):
============================================================

--- Example 1 ---
Question: ...
Gold answer: [invalid]
Target-alone: 0
Bridged: [invalid]
Bridged generation start: 1.	Introduction
The purpose of this report is to provide an overview of the current state of the global economy, with a focus on the impact of the COVID-19 pandemic and the subsequent economic recovery.
2.	The Global Economy in 2020
In 2021, the global GDP was estimated to be around $88 trillion, wh...

--- Example 2 ---
Question: ...
Gold answer: [invalid]
Target-alone: 1.
Bridged: [invalid]
Bridged generation start: 1000 4th Avenue, Seattle, Washington, United States   98104   47.6061° N, 122.3321° W   1916    1927    1933    1962    1979    1988    1995    2007    The Seattle Times   2011    2020   2021   1,000,000+   English   Daily newspaper   The Seattle Post-Intelligencer   The Stranger   Seattle Weekly   ...

--- Example 3 ---
Question: ...
Gold answer: [invalid]
Target-alone: 3.5.7.9
Bridged: [invalid]
Bridged generation start: 1000 Ways to Die is an American documentary television series that aired on Spike TV from 2008 to 2012. The show was created by Ryan Dunn and Michael Cargnello, and it features re-enactments of people dying in unusual or humorous ways. The series premiered on June 3, 2009, and ran for four seasons u...
============================================================

[Eval] Step 750 | Target-alone acc: 0.296 | Bridged acc: 1.000
[Early Stop] No improvement, patience: 2/5
Step 760/3000 | Loss (avg over last 20): 5.3845
Step 780/3000 | Loss (avg over last 20): 6.5677
Step 800/3000 | Loss (avg over last 20): 5.1640
Step 820/3000 | Loss (avg over last 20): 4.5640
Step 840/3000 | Loss (avg over last 20): 4.8960
