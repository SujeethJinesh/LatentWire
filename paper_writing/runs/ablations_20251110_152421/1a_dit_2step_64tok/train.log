W1110 15:24:24.930000 3736210 torch/distributed/run.py:793] 
W1110 15:24:24.930000 3736210 torch/distributed/run.py:793] *****************************************
W1110 15:24:24.930000 3736210 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1110 15:24:24.930000 3736210 torch/distributed/run.py:793] *****************************************
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[W1110 15:24:38.865206431 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W1110 15:24:38.865941964 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W1110 15:24:38.867652008 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W1110 15:24:38.878640663 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
Reproducibility enabled: base_seed=1234, effective_seed=1234
==== Config ====
source_model: mistralai/Mistral-7B-Instruct-v0.3
target_model: meta-llama/Meta-Llama-3.1-8B-Instruct
bottleneck_dim: 1024
soft_tokens: 64
depth: 2
heads: 8
lr: 0.0001
weight_decay: 0.01
train_steps: 1000
warmup_steps: 750
per_device_batch: 10
eval_every: 250
eval_samples: 200
max_new_tokens: 100
seed: 1234
bf16: True
save_path: paper_writing/runs/ablations_20251110_152421/1a_dit_2step_64tok/checkpoint.pt
show_eval_samples: 1
early_stop_patience: 2
dataset: gsm8k
info_nce_weight: 0.05
eval_batch_size: 50
no_compile: True
bridge: dit
dit_dim: 512
dit_depth: 6
dit_heads: 8
dit_steps_train: 2
dit_steps_eval: 4
dit_dropout: 0.1
dit_cfg: 0.0
dit_drop_cond: 0.1
dit_cfg_dropout: None
dit_pool: mean
dit_cond_dim: 512
dit_loss_weight: 0.1
dit_loss_warmup: 0
dit_teacher: answer

==== Reproducibility Settings ====
Base seed: 1234
Effective seed (with rank offset): 1234
CUDA deterministic: True
CUDA benchmark: False
Deterministic algorithms: True
CUBLAS workspace: :16:8
World size: 4 (each rank samples different data)
Loading source model/tokenizer...
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 1875.25it/s]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 7177.93it/s]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 7410.43it/s]
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 3/3 [00:00<00:00, 4858.27it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:42, 21.49s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:43, 21.63s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.61s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:43, 21.65s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:42<00:21, 21.06s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:41<00:20, 20.79s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:41<00:20, 20.86s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:41<00:20, 20.84s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.57s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.98s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.82s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.32s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.58s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 20.00s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.59s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.00s/it]
Loading target model/tokenizer...
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 2142.14it/s]
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 5880.55it/s]
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 9441.31it/s]
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 1068.88it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:04, 21.39s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:04, 21.53s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:04, 21.50s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:04, 21.49s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:41<00:40, 20.34s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:41<00:40, 20.48s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:41<00:41, 20.51s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:41<00:40, 20.49s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:00<00:20, 20.04s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:00<00:20, 20.05s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:00<00:20, 20.11s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:00<00:20, 20.14s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:06<00:00, 14.24s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:06<00:00, 14.25s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:06<00:00, 14.24s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:06<00:00, 16.53s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:06<00:00, 16.53s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:06<00:00, 14.23s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:06<00:00, 16.55s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:06<00:00, 16.54s/it]
torch.compile() disabled via --no_compile flag (prevents CUDA Graph OOM)
Source hidden dim: 4096 | Target hidden dim: 4096
Target embedding RMS (median): 0.0107
NOTE: RMS scale matching is applied during batch collation (before concat)
Bridge: dit (DiTBridgeTranslator)
  Using DiTBridge: dim=512, depth=6, heads=8, steps(train/eval)=2/4, cfg=0.0, pool=mean, cond_dim=512
Translator parameters: 44.1M
Loading GSM8K...
Data sampler initialized with seed 1234 (base=1234, rank=0)
Optimizer groups: 37 decay, 36 no_decay, 0 gates (LR ×3)

============================================================
INITIAL EVALUATION (Step 0 - Before Training)
============================================================
[Distributed Eval] Sharding 200 samples across 4 ranks:
  Rank 0: samples 0 to 50 (50 samples)
  Rank 1: samples 50 to 100 (50 samples)
  Rank 2: samples 100 to 150 (50 samples)
  Rank 3: samples 150 to 200 (50 samples)
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/users/sujinesh/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(

============================================================
SAMPLE OUTPUTS (first 3 examples):
============================================================

--- Example 1 ---
Question: ...
Gold answer: 18
Target-alone: 12
Bridged: [invalid]
Bridged generation start: _REFUSE) to the rescue.\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\...

--- Example 2 ---
Question: ...
Gold answer: 3
Target-alone: 12
Bridged: [invalid]
Bridged generation start: _REFUSE

## Step 1: Identify the main topic of the text
The main topic of the text is the comparison between the two types of texts: a formal text and an informal text.

## Step 2: Identify the key features of the formal text
The key features of the formal text are:
- It is written in a professional...

--- Example 3 ---
Question: ...
Gold answer: 70000
Target-alone: 12
Bridged: [invalid]
Bridged generation start: _REF_1_._|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|_|...
============================================================

[Eval] Step 0 | Target-alone acc: 0.010 | Bridged acc: 0.000
============================================================


============================================================
LABEL ALIGNMENT DIAGNOSTIC (Step 0)
============================================================
  Input embeddings shape: torch.Size([10, 277, 4096])
  Labels shape: torch.Size([10, 277])
  Attention mask shape: torch.Size([10, 277])
  Soft token count (K): 64
  Total tokens: 2770
  Supervised tokens: 1035
  Masked tokens: 1735
  Sample 0 first 10 labels: [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100]
  Sample 0 last 10 labels: [717, 2511, 717, 2033, 12556, 3153, 627, 827, 220, 717]
  All soft token labels == -100? True
  Supervised tokens per sample: [87, 133, 62, 125, 96, 55, 143, 213, 51, 70]
============================================================

/users/sujinesh/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: Memory Efficient attention defaults to a non-deterministic algorithm. To explicitly enable determinism call torch.use_deterministic_algorithms(True, warn_only=False). (Triggered internally at ../aten/src/ATen/native/transformers/cuda/attention_backward.cu:655.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/users/sujinesh/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: Flash Attention defaults to a non-deterministic algorithm. To explicitly enable determinism call torch.use_deterministic_algorithms(True, warn_only=False). (Triggered internally at ../aten/src/ATen/native/transformers/cuda/attention_backward.cu:102.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/users/sujinesh/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: Memory Efficient attention defaults to a non-deterministic algorithm. To explicitly enable determinism call torch.use_deterministic_algorithms(True, warn_only=False). (Triggered internally at ../aten/src/ATen/native/transformers/cuda/attention_backward.cu:655.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/users/sujinesh/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: Flash Attention defaults to a non-deterministic algorithm. To explicitly enable determinism call torch.use_deterministic_algorithms(True, warn_only=False). (Triggered internally at ../aten/src/ATen/native/transformers/cuda/attention_backward.cu:102.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/users/sujinesh/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: Memory Efficient attention defaults to a non-deterministic algorithm. To explicitly enable determinism call torch.use_deterministic_algorithms(True, warn_only=False). (Triggered internally at ../aten/src/ATen/native/transformers/cuda/attention_backward.cu:655.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/users/sujinesh/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: Flash Attention defaults to a non-deterministic algorithm. To explicitly enable determinism call torch.use_deterministic_algorithms(True, warn_only=False). (Triggered internally at ../aten/src/ATen/native/transformers/cuda/attention_backward.cu:102.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/users/sujinesh/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: Memory Efficient attention defaults to a non-deterministic algorithm. To explicitly enable determinism call torch.use_deterministic_algorithms(True, warn_only=False). (Triggered internally at ../aten/src/ATen/native/transformers/cuda/attention_backward.cu:655.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/users/sujinesh/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: Flash Attention defaults to a non-deterministic algorithm. To explicitly enable determinism call torch.use_deterministic_algorithms(True, warn_only=False). (Triggered internally at ../aten/src/ATen/native/transformers/cuda/attention_backward.cu:102.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank3]: Traceback (most recent call last):
[rank3]:   File "/projects/m000066/sujinesh/LatentWire/paper_writing/cross_attention.py", line 1659, in <module>
[rank3]:     main()
[rank3]:   File "/projects/m000066/sujinesh/LatentWire/paper_writing/cross_attention.py", line 1446, in main
[rank3]:     data = build_batch_inputs(samples, src_model, src_tok, tgt_model, tgt_tok,
[rank3]:   File "/projects/m000066/sujinesh/LatentWire/paper_writing/cross_attention.py", line 854, in build_batch_inputs
[rank3]:     soft_tokens = translator(src_h, src_mask, teacher_soft_tokens=teacher_soft)
[rank3]:   File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1639, in forward
[rank3]:     inputs, kwargs = self._pre_forward(*inputs, **kwargs)
[rank3]:   File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1528, in _pre_forward
[rank3]:     if torch.is_grad_enabled() and self.reducer._rebuild_buckets():
[rank3]: RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not used in producing loss. You can enable unused parameter detection by passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`, and by 
[rank3]: making sure all `forward` function outputs participate in calculating loss. 
[rank3]: If you already have done the above, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable).
[rank3]: Parameter indices which did not receive grad for rank 3: 0
[rank3]:  In addition, you can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print out information about which particular parameters did not receive gradient on this rank as part of this error
[rank0]: Traceback (most recent call last):
[rank0]:   File "/projects/m000066/sujinesh/LatentWire/paper_writing/cross_attention.py", line 1659, in <module>
[rank0]:     main()
[rank0]:   File "/projects/m000066/sujinesh/LatentWire/paper_writing/cross_attention.py", line 1446, in main
[rank0]:     data = build_batch_inputs(samples, src_model, src_tok, tgt_model, tgt_tok,
[rank0]:   File "/projects/m000066/sujinesh/LatentWire/paper_writing/cross_attention.py", line 854, in build_batch_inputs
[rank0]:     soft_tokens = translator(src_h, src_mask, teacher_soft_tokens=teacher_soft)
[rank0]:   File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1639, in forward
[rank0]:     inputs, kwargs = self._pre_forward(*inputs, **kwargs)
[rank0]:   File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1528, in _pre_forward
[rank0]:     if torch.is_grad_enabled() and self.reducer._rebuild_buckets():
[rank0]: RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not used in producing loss. You can enable unused parameter detection by passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`, and by 
[rank0]: making sure all `forward` function outputs participate in calculating loss. 
[rank0]: If you already have done the above, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable).
[rank0]: Parameter indices which did not receive grad for rank 0: 0
[rank0]:  In addition, you can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print out information about which particular parameters did not receive gradient on this rank as part of this error
[rank2]: Traceback (most recent call last):
[rank2]:   File "/projects/m000066/sujinesh/LatentWire/paper_writing/cross_attention.py", line 1659, in <module>
[rank2]:     main()
[rank2]:   File "/projects/m000066/sujinesh/LatentWire/paper_writing/cross_attention.py", line 1446, in main
[rank2]:     data = build_batch_inputs(samples, src_model, src_tok, tgt_model, tgt_tok,
[rank2]:   File "/projects/m000066/sujinesh/LatentWire/paper_writing/cross_attention.py", line 854, in build_batch_inputs
[rank2]:     soft_tokens = translator(src_h, src_mask, teacher_soft_tokens=teacher_soft)
[rank2]:   File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1639, in forward
[rank2]:     inputs, kwargs = self._pre_forward(*inputs, **kwargs)
[rank2]:   File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1528, in _pre_forward
[rank2]:     if torch.is_grad_enabled() and self.reducer._rebuild_buckets():
[rank2]: RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not used in producing loss. You can enable unused parameter detection by passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`, and by 
[rank2]: making sure all `forward` function outputs participate in calculating loss. 
[rank2]: If you already have done the above, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable).
[rank2]: Parameter indices which did not receive grad for rank 2: 0
[rank2]:  In addition, you can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print out information about which particular parameters did not receive gradient on this rank as part of this error
[rank1]: Traceback (most recent call last):
[rank1]:   File "/projects/m000066/sujinesh/LatentWire/paper_writing/cross_attention.py", line 1659, in <module>
[rank1]:     main()
[rank1]:   File "/projects/m000066/sujinesh/LatentWire/paper_writing/cross_attention.py", line 1446, in main
[rank1]:     data = build_batch_inputs(samples, src_model, src_tok, tgt_model, tgt_tok,
[rank1]:   File "/projects/m000066/sujinesh/LatentWire/paper_writing/cross_attention.py", line 854, in build_batch_inputs
[rank1]:     soft_tokens = translator(src_h, src_mask, teacher_soft_tokens=teacher_soft)
[rank1]:   File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1639, in forward
[rank1]:     inputs, kwargs = self._pre_forward(*inputs, **kwargs)
[rank1]:   File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1528, in _pre_forward
[rank1]:     if torch.is_grad_enabled() and self.reducer._rebuild_buckets():
[rank1]: RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not used in producing loss. You can enable unused parameter detection by passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`, and by 
[rank1]: making sure all `forward` function outputs participate in calculating loss. 
[rank1]: If you already have done the above, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable).
[rank1]: Parameter indices which did not receive grad for rank 1: 0
[rank1]:  In addition, you can set the environment variable TORCH_DISTRIBUTED_DEBUG to either INFO or DETAIL to print out information about which particular parameters did not receive gradient on this rank as part of this error
[rank0]:[W1110 15:29:05.709556214 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
W1110 15:29:08.775000 3736210 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3736250 closing signal SIGTERM
W1110 15:29:08.776000 3736210 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3736251 closing signal SIGTERM
W1110 15:29:08.776000 3736210 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3736252 closing signal SIGTERM
E1110 15:29:10.271000 3736210 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 3 (pid: 3736253) of binary: /marlowe/apps/Mambaforge/24.3.0-0/bin/python
Traceback (most recent call last):
  File "/users/sujinesh/.local/bin/torchrun", line 7, in <module>
    sys.exit(main())
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/users/sujinesh/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
paper_writing/cross_attention.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-11-10_15:29:08
  host      : n05.cm.cluster
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 3736253)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
